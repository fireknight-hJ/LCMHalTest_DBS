Z_UTIL_X2_1814Z_UTIL_X2_1813Z_UTIL_X2_1812Z_UTIL_X2_1811Z_UTIL_X2_1810Z_UTIL_X2_1809Z_UTIL_X2_1808Z_UTIL_X2_1807Z_UTIL_X2_1806Z_UTIL_X2_1805Z_UTIL_X2_1804Z_UTIL_X2_1803Z_UTIL_X2_1802Z_UTIL_X2_1801Z_UTIL_X2_1800Z_UTIL_X2_1799Z_UTIL_X2_1798Z_UTIL_X2_1797Z_UTIL_X2_1796Z_UTIL_X2_1795Z_UTIL_X2_1794Z_UTIL_X2_1793Z_UTIL_X2_1792Z_UTIL_X2_1791Z_UTIL_X2_1790Z_UTIL_X2_1789Z_UTIL_X2_1788Z_UTIL_X2_1787Z_UTIL_X2_1786Z_UTIL_X2_1785Z_UTIL_X2_1784Z_UTIL_X2_1783Z_UTIL_X2_1782Z_UTIL_X2_1781Z_UTIL_X2_1780Z_UTIL_X2_1779Z_UTIL_X2_1778Z_UTIL_X2_1777Z_UTIL_X2_1776Z_UTIL_X2_1775Z_UTIL_X2_1774Z_UTIL_X2_1773Z_UTIL_X2_1772Z_UTIL_X2_1771Z_UTIL_X2_1770Z_UTIL_X2_1769Z_UTIL_X2_1768Z_UTIL_X2_1767Z_UTIL_X2_1766Z_UTIL_X2_1765Z_UTIL_X2_1764Z_UTIL_X2_1763Z_UTIL_X2_1762Z_UTIL_X2_1761Z_UTIL_X2_1760Z_UTIL_X2_1759Z_UTIL_X2_1758Z_UTIL_X2_1757Z_UTIL_X2_1756Z_UTIL_X2_1755Z_UTIL_X2_1754Z_UTIL_X2_1753Z_UTIL_X2_1752Z_UTIL_X2_1751Z_UTIL_X2_1750Z_UTIL_X2_1749Z_UTIL_X2_1748Z_UTIL_X2_1747Z_UTIL_X2_1746Z_UTIL_X2_1745Z_UTIL_X2_1744Z_UTIL_X2_1743Z_UTIL_X2_1742Z_UTIL_X2_1741Z_UTIL_X2_1740Z_UTIL_X2_1739Z_UTIL_X2_1738Z_UTIL_X2_1737Z_UTIL_X2_1736Z_UTIL_X2_1735Z_UTIL_X2_1734Z_UTIL_X2_1733Z_UTIL_X2_1732Z_UTIL_X2_1731Z_UTIL_X2_1730Z_UTIL_X2_1729Z_UTIL_X2_1728Z_UTIL_X2_1727Z_UTIL_X2_1726Z_UTIL_X2_1725Z_UTIL_X2_1724Z_UTIL_X2_1723Z_UTIL_X2_1722Z_UTIL_X2_1721Z_UTIL_X2_1720Z_UTIL_X2_1719Z_UTIL_X2_1718Z_UTIL_X2_1717Z_UTIL_X2_1716Z_UTIL_X2_1715Z_UTIL_X2_1714Z_UTIL_X2_1713Z_UTIL_X2_1712Z_UTIL_X2_1711Z_UTIL_X2_1710Z_UTIL_X2_1709Z_UTIL_X2_1708Z_UTIL_X2_1707Z_UTIL_X2_1706Z_UTIL_X2_1705Z_UTIL_X2_1704Z_UTIL_X2_1703Z_UTIL_X2_1702Z_UTIL_X2_1701Z_UTIL_X2_1700Z_UTIL_X2_1699Z_UTIL_X2_1698Z_UTIL_X2_1697Z_UTIL_X2_1696Z_UTIL_X2_1695Z_UTIL_X2_1694Z_UTIL_X2_1693Z_UTIL_X2_1692Z_UTIL_X2_1691Z_UTIL_X2_1690Z_UTIL_X2_1689Z_UTIL_X2_1688Z_UTIL_X2_1687Z_UTIL_X2_1686Z_UTIL_X2_1685Z_UTIL_X2_1684Z_UTIL_X2_1683Z_UTIL_X2_1682Z_UTIL_X2_1681Z_UTIL_X2_1680Z_UTIL_X2_1679Z_UTIL_X2_1678Z_UTIL_X2_1677Z_UTIL_X2_1676Z_UTIL_X2_1675Z_UTIL_X2_1674Z_UTIL_X2_1673Z_UTIL_X2_1672Z_UTIL_X2_1671Z_UTIL_X2_1670Z_UTIL_X2_1669Z_UTIL_X2_1668Z_UTIL_X2_1667Z_UTIL_X2_1666Z_UTIL_X2_1665Z_UTIL_X2_1664Z_UTIL_X2_1663Z_UTIL_X2_1662Z_UTIL_X2_1661Z_UTIL_X2_1660Z_UTIL_X2_1659Z_UTIL_X2_1658Z_UTIL_X2_1657Z_UTIL_X2_1656Z_UTIL_X2_1655Z_UTIL_X2_1654Z_UTIL_X2_1653Z_UTIL_X2_1652Z_UTIL_X2_1651Z_UTIL_X2_1650Z_UTIL_X2_1649Z_UTIL_X2_1648Z_UTIL_X2_1647Z_UTIL_X2_1646Z_UTIL_X2_1645Z_UTIL_X2_1644Z_UTIL_X2_1643Z_UTIL_X2_1642Z_UTIL_X2_1641Z_UTIL_X2_1640Z_UTIL_X2_1639Z_UTIL_X2_1638Z_UTIL_X2_1637Z_UTIL_X2_1636Z_UTIL_X2_1635Z_UTIL_X2_1634Z_UTIL_X2_1633Z_UTIL_X2_1632Z_UTIL_X2_1631Z_UTIL_X2_1630Z_UTIL_X2_1629Z_UTIL_X2_1628Z_UTIL_X2_1627Z_UTIL_X2_1626Z_UTIL_X2_1625Z_UTIL_X2_1624Z_UTIL_X2_1623Z_UTIL_X2_1622Z_UTIL_X2_1621Z_UTIL_X2_1620Z_UTIL_X2_1619Z_UTIL_X2_1618Z_UTIL_X2_1617Z_UTIL_X2_1616Z_UTIL_X2_1615Z_UTIL_X2_1614Z_UTIL_X2_1613Z_UTIL_X2_1612Z_UTIL_X2_1611Z_UTIL_X2_1610Z_UTIL_X2_1609Z_UTIL_X2_1608Z_UTIL_X2_1607Z_UTIL_X2_1606Z_UTIL_X2_1605Z_UTIL_X2_1604Z_UTIL_X2_1603Z_UTIL_X2_1602Z_UTIL_X2_1601Z_UTIL_X2_1600Z_UTIL_X2_1599Z_UTIL_X2_1598Z_UTIL_X2_1597Z_UTIL_X2_1596Z_UTIL_X2_1595Z_UTIL_X2_1594Z_UTIL_X2_1593Z_UTIL_X2_1592Z_UTIL_X2_1591Z_UTIL_X2_1590Z_UTIL_X2_1589Z_UTIL_X2_1588Z_UTIL_X2_1587Z_UTIL_X2_1586Z_UTIL_X2_1585Z_UTIL_X2_1584Z_UTIL_X2_1583Z_UTIL_X2_1582Z_UTIL_X2_1581Z_UTIL_X2_1580Z_UTIL_X2_1579Z_UTIL_X2_1578Z_UTIL_X2_1577Z_UTIL_X2_1576Z_UTIL_X2_1575Z_UTIL_X2_1574Z_UTIL_X2_1573Z_UTIL_X2_1572Z_UTIL_X2_1571Z_UTIL_X2_1570Z_UTIL_X2_1569Z_UTIL_X2_1568Z_UTIL_X2_1567Z_UTIL_X2_1566Z_UTIL_X2_1565Z_UTIL_X2_1564Z_UTIL_X2_1563Z_UTIL_X2_1562Z_UTIL_X2_1561Z_UTIL_X2_1560Z_UTIL_X2_1559Z_UTIL_X2_1558Z_UTIL_X2_1557Z_UTIL_X2_1556Z_UTIL_X2_1555Z_UTIL_X2_1554Z_UTIL_X2_1553Z_UTIL_X2_1552Z_UTIL_X2_1551Z_UTIL_X2_1550Z_UTIL_X2_1549Z_UTIL_X2_1548Z_UTIL_X2_1547Z_UTIL_X2_1546Z_UTIL_X2_1545Z_UTIL_X2_1544Z_UTIL_X2_1543Z_UTIL_X2_1542Z_UTIL_X2_1541Z_UTIL_X2_1540Z_UTIL_X2_1539Z_UTIL_X2_1538Z_UTIL_X2_1537Z_UTIL_X2_1536Z_UTIL_X2_1535Z_UTIL_X2_1534Z_UTIL_X2_1533Z_UTIL_X2_1532Z_UTIL_X2_1531Z_UTIL_X2_1530Z_UTIL_X2_1529Z_UTIL_X2_1528Z_UTIL_X2_1527Z_UTIL_X2_1526Z_UTIL_X2_1525Z_UTIL_X2_1524Z_UTIL_X2_1523Z_UTIL_X2_1522Z_UTIL_X2_1521Z_UTIL_X2_1520Z_UTIL_X2_1519Z_UTIL_X2_1518Z_UTIL_X2_1517Z_UTIL_X2_1516Z_UTIL_X2_1515Z_UTIL_X2_1514Z_UTIL_X2_1513Z_UTIL_X2_1512Z_UTIL_X2_1511Z_UTIL_X2_1510Z_UTIL_X2_1509Z_UTIL_X2_1508Z_UTIL_X2_1507Z_UTIL_X2_1506Z_UTIL_X2_1505Z_UTIL_X2_1504Z_UTIL_X2_1503Z_UTIL_X2_1502Z_UTIL_X2_1501Z_UTIL_X2_1500Z_UTIL_X2_1499Z_UTIL_X2_1498Z_UTIL_X2_1497Z_UTIL_X2_1496Z_UTIL_X2_1495Z_UTIL_X2_1494Z_UTIL_X2_1493Z_UTIL_X2_1492Z_UTIL_X2_1491Z_UTIL_X2_1490Z_UTIL_X2_1489Z_UTIL_X2_1488Z_UTIL_X2_1487Z_UTIL_X2_1486Z_UTIL_X2_1485Z_UTIL_X2_1484Z_UTIL_X2_1483Z_UTIL_X2_1482Z_UTIL_X2_1481Z_UTIL_X2_1480Z_UTIL_X2_1479Z_UTIL_X2_1478Z_UTIL_X2_1477Z_UTIL_X2_1476Z_UTIL_X2_1475Z_UTIL_X2_1474Z_UTIL_X2_1473Z_UTIL_X2_1472Z_UTIL_X2_1471Z_UTIL_X2_1470Z_UTIL_X2_1469Z_UTIL_X2_1468Z_UTIL_X2_1467Z_UTIL_X2_1466Z_UTIL_X2_1465Z_UTIL_X2_1464Z_UTIL_X2_1463Z_UTIL_X2_1462Z_UTIL_X2_1461Z_UTIL_X2_1460Z_UTIL_X2_1459Z_UTIL_X2_1458Z_UTIL_X2_1457Z_UTIL_X2_1456Z_UTIL_X2_1455Z_UTIL_X2_1454Z_UTIL_X2_1453Z_UTIL_X2_1452Z_UTIL_X2_1451Z_UTIL_X2_1450Z_UTIL_X2_1449Z_UTIL_X2_1448Z_UTIL_X2_1447Z_UTIL_X2_1446Z_UTIL_X2_1445Z_UTIL_X2_1444Z_UTIL_X2_1443Z_UTIL_X2_1442Z_UTIL_X2_1441Z_UTIL_X2_1440Z_UTIL_X2_1439Z_UTIL_X2_1438Z_UTIL_X2_1437Z_UTIL_X2_1436Z_UTIL_X2_1435Z_UTIL_X2_1434Z_UTIL_X2_1433Z_UTIL_X2_1432Z_UTIL_X2_1431Z_UTIL_X2_1430Z_UTIL_X2_1429Z_UTIL_X2_1428Z_UTIL_X2_1427Z_UTIL_X2_1426Z_UTIL_X2_1425Z_UTIL_X2_1424Z_UTIL_X2_1423Z_UTIL_X2_1422Z_UTIL_X2_1421Z_UTIL_X2_1420Z_UTIL_X2_1419Z_UTIL_X2_1418Z_UTIL_X2_1417Z_UTIL_X2_1416Z_UTIL_X2_1415Z_UTIL_X2_1414Z_UTIL_X2_1413Z_UTIL_X2_1412Z_UTIL_X2_1411Z_UTIL_X2_1410Z_UTIL_X2_1409Z_UTIL_X2_1408Z_UTIL_X2_1407Z_UTIL_X2_1406Z_UTIL_X2_1405Z_UTIL_X2_1404Z_UTIL_X2_1403Z_UTIL_X2_1402Z_UTIL_X2_1401Z_UTIL_X2_1400Z_UTIL_X2_1399Z_UTIL_X2_1398Z_UTIL_X2_1397Z_UTIL_X2_1396Z_UTIL_X2_1395Z_UTIL_X2_1394Z_UTIL_X2_1393Z_UTIL_X2_1392Z_UTIL_X2_1391Z_UTIL_X2_1390Z_UTIL_X2_1389Z_UTIL_X2_1388Z_UTIL_X2_1387Z_UTIL_X2_1386Z_UTIL_X2_1385Z_UTIL_X2_1384Z_UTIL_X2_1383Z_UTIL_X2_1382Z_UTIL_X2_1381Z_UTIL_X2_1380Z_UTIL_X2_1379Z_UTIL_X2_1378Z_UTIL_X2_1377Z_UTIL_X2_1376Z_UTIL_X2_1375Z_UTIL_X2_1374Z_UTIL_X2_1373Z_UTIL_X2_1372Z_UTIL_X2_1371Z_UTIL_X2_1370Z_UTIL_X2_1369Z_UTIL_X2_1368Z_UTIL_X2_1367Z_UTIL_X2_1366Z_UTIL_X2_1365Z_UTIL_X2_1364Z_UTIL_X2_1363Z_UTIL_X2_1362Z_UTIL_X2_1361Z_UTIL_X2_1360Z_UTIL_X2_1359Z_UTIL_X2_1358Z_UTIL_X2_1357Z_UTIL_X2_1356Z_UTIL_X2_1355Z_UTIL_X2_1354Z_UTIL_X2_1353Z_UTIL_X2_1352Z_UTIL_X2_1351Z_UTIL_X2_1350Z_UTIL_X2_1349Z_UTIL_X2_1348Z_UTIL_X2_1347Z_UTIL_X2_1346Z_UTIL_X2_1345Z_UTIL_X2_1344Z_UTIL_X2_1343Z_UTIL_X2_1342Z_UTIL_X2_1341Z_UTIL_X2_1340Z_UTIL_X2_1339Z_UTIL_X2_1338Z_UTIL_X2_1337Z_UTIL_X2_1336Z_UTIL_X2_1335Z_UTIL_X2_1334Z_UTIL_X2_1333Z_UTIL_X2_1332Z_UTIL_X2_1331Z_UTIL_X2_1330Z_UTIL_X2_1329Z_UTIL_X2_1328Z_UTIL_X2_1327Z_UTIL_X2_1326Z_UTIL_X2_1325Z_UTIL_X2_1324Z_UTIL_X2_1323Z_UTIL_X2_1322Z_UTIL_X2_1321Z_UTIL_X2_1320Z_UTIL_X2_1319Z_UTIL_X2_1318Z_UTIL_X2_1317Z_UTIL_X2_1316Z_UTIL_X2_1315Z_UTIL_X2_1314Z_UTIL_X2_1313Z_UTIL_X2_1312Z_UTIL_X2_1311Z_UTIL_X2_1310Z_UTIL_X2_1309Z_UTIL_X2_1308Z_UTIL_X2_1307Z_UTIL_X2_1306Z_UTIL_X2_1305Z_UTIL_X2_1304Z_UTIL_X2_1303Z_UTIL_X2_1302Z_UTIL_X2_1301Z_UTIL_X2_1300Z_UTIL_X2_1299Z_UTIL_X2_1298Z_UTIL_X2_1297Z_UTIL_X2_1296Z_UTIL_X2_1295Z_UTIL_X2_1294Z_UTIL_X2_1293Z_UTIL_X2_1292Z_UTIL_X2_1291Z_UTIL_X2_1290Z_UTIL_X2_1289Z_UTIL_X2_1288Z_UTIL_X2_1287Z_UTIL_X2_1286Z_UTIL_X2_1285Z_UTIL_X2_1284Z_UTIL_X2_1283Z_UTIL_X2_1282Z_UTIL_X2_1281Z_UTIL_X2_1280Z_UTIL_X2_1279Z_UTIL_X2_1278Z_UTIL_X2_1277Z_UTIL_X2_1276Z_UTIL_X2_1275Z_UTIL_X2_1274Z_UTIL_X2_1273Z_UTIL_X2_1272Z_UTIL_X2_1271Z_UTIL_X2_1270Z_UTIL_X2_1269Z_UTIL_X2_1268Z_UTIL_X2_1267Z_UTIL_X2_1266Z_UTIL_X2_1265Z_UTIL_X2_1264Z_UTIL_X2_1263Z_UTIL_X2_1262Z_UTIL_X2_1261Z_UTIL_X2_1260Z_UTIL_X2_1259Z_UTIL_X2_1258Z_UTIL_X2_1257Z_UTIL_X2_1256Z_UTIL_X2_1255Z_UTIL_X2_1254Z_UTIL_X2_1253Z_UTIL_X2_1252Z_UTIL_X2_1251Z_UTIL_X2_1250Z_UTIL_X2_1249Z_UTIL_X2_1248Z_UTIL_X2_1247Z_UTIL_X2_1246Z_UTIL_X2_1245Z_UTIL_X2_1244Z_UTIL_X2_1243Z_UTIL_X2_1242Z_UTIL_X2_1241Z_UTIL_X2_1240Z_UTIL_X2_1239Z_UTIL_X2_1238Z_UTIL_X2_1237Z_UTIL_X2_1236Z_UTIL_X2_1235Z_UTIL_X2_1234Z_UTIL_X2_1233Z_UTIL_X2_1232Z_UTIL_X2_1231Z_UTIL_X2_1230Z_UTIL_X2_1229Z_UTIL_X2_1228Z_UTIL_X2_1227Z_UTIL_X2_1226Z_UTIL_X2_1225Z_UTIL_X2_1224Z_UTIL_X2_1223Z_UTIL_X2_1222Z_UTIL_X2_1221Z_UTIL_X2_1220Z_UTIL_X2_1219Z_UTIL_X2_1218Z_UTIL_X2_1217Z_UTIL_X2_1216Z_UTIL_X2_1215Z_UTIL_X2_1214Z_UTIL_X2_1213Z_UTIL_X2_1212Z_UTIL_X2_1211Z_UTIL_X2_1210Z_UTIL_X2_1209Z_UTIL_X2_1208Z_UTIL_X2_1207Z_UTIL_X2_1206Z_UTIL_X2_1205Z_UTIL_X2_1204Z_UTIL_X2_1203Z_UTIL_X2_1202Z_UTIL_X2_1201Z_UTIL_X2_1200Z_UTIL_X2_1199Z_UTIL_X2_1198Z_UTIL_X2_1197Z_UTIL_X2_1196Z_UTIL_X2_1195Z_UTIL_X2_1194Z_UTIL_X2_1193Z_UTIL_X2_1192Z_UTIL_X2_1191Z_UTIL_X2_1190Z_UTIL_X2_1189Z_UTIL_X2_1188Z_UTIL_X2_1187Z_UTIL_X2_1186Z_UTIL_X2_1185Z_UTIL_X2_1184Z_UTIL_X2_1183Z_UTIL_X2_1182Z_UTIL_X2_1181Z_UTIL_X2_1180Z_UTIL_X2_1179Z_UTIL_X2_1178Z_UTIL_X2_1177Z_UTIL_X2_1176Z_UTIL_X2_1175Z_UTIL_X2_1174Z_UTIL_X2_1173Z_UTIL_X2_1172Z_UTIL_X2_1171Z_UTIL_X2_1170Z_UTIL_X2_1169Z_UTIL_X2_1168Z_UTIL_X2_1167Z_UTIL_X2_1166Z_UTIL_X2_1165Z_UTIL_X2_1164Z_UTIL_X2_1163Z_UTIL_X2_1162Z_UTIL_X2_1161Z_UTIL_X2_1160Z_UTIL_X2_1159Z_UTIL_X2_1158Z_UTIL_X2_1157Z_UTIL_X2_1156Z_UTIL_X2_1155Z_UTIL_X2_1154Z_UTIL_X2_1153Z_UTIL_X2_1152Z_UTIL_X2_1151Z_UTIL_X2_1150Z_UTIL_X2_1149Z_UTIL_X2_1148Z_UTIL_X2_1147Z_UTIL_X2_1146Z_UTIL_X2_1145Z_UTIL_X2_1144Z_UTIL_X2_1143Z_UTIL_X2_1142Z_UTIL_X2_1141Z_UTIL_X2_1140Z_UTIL_X2_1139Z_UTIL_X2_1138Z_UTIL_X2_1137Z_UTIL_X2_1136Z_UTIL_X2_1135Z_UTIL_X2_1134Z_UTIL_X2_1133Z_UTIL_X2_1132Z_UTIL_X2_1131Z_UTIL_X2_1130Z_UTIL_X2_1129Z_UTIL_X2_1128Z_UTIL_X2_1127Z_UTIL_X2_1126Z_UTIL_X2_1125Z_UTIL_X2_1124Z_UTIL_X2_1123Z_UTIL_X2_1122Z_UTIL_X2_1121Z_UTIL_X2_1120Z_UTIL_X2_1119Z_UTIL_X2_1118Z_UTIL_X2_1117Z_UTIL_X2_1116Z_UTIL_X2_1115Z_UTIL_X2_1114Z_UTIL_X2_1113Z_UTIL_X2_1112Z_UTIL_X2_1111Z_UTIL_X2_1110Z_UTIL_X2_1109Z_UTIL_X2_1108Z_UTIL_X2_1107Z_UTIL_X2_1106Z_UTIL_X2_1105Z_UTIL_X2_1104Z_UTIL_X2_1103Z_UTIL_X2_1102Z_UTIL_X2_1101Z_UTIL_X2_1100Z_UTIL_X2_1099Z_UTIL_X2_1098Z_UTIL_X2_1097Z_UTIL_X2_1096Z_UTIL_X2_1095Z_UTIL_X2_1094Z_UTIL_X2_1093Z_UTIL_X2_1092Z_UTIL_X2_1091Z_UTIL_X2_1090Z_UTIL_X2_1089Z_UTIL_X2_1088Z_UTIL_X2_1087Z_UTIL_X2_1086Z_UTIL_X2_1085Z_UTIL_X2_1084Z_UTIL_X2_1083Z_UTIL_X2_1082Z_UTIL_X2_1081Z_UTIL_X2_1080Z_UTIL_X2_1079Z_UTIL_X2_1078Z_UTIL_X2_1077Z_UTIL_X2_1076Z_UTIL_X2_1075Z_UTIL_X2_1074Z_UTIL_X2_1073Z_UTIL_X2_1072Z_UTIL_X2_1071Z_UTIL_X2_1070Z_UTIL_X2_1069Z_UTIL_X2_1068Z_UTIL_X2_1067Z_UTIL_X2_1066Z_UTIL_X2_1065Z_UTIL_X2_1064Z_UTIL_X2_1063Z_UTIL_X2_1062Z_UTIL_X2_1061Z_UTIL_X2_1060Z_UTIL_X2_1059Z_UTIL_X2_1058Z_UTIL_X2_1057Z_UTIL_X2_1056Z_UTIL_X2_1055Z_UTIL_X2_1054Z_UTIL_X2_1053Z_UTIL_X2_1052Z_UTIL_X2_1051Z_UTIL_X2_1050Z_UTIL_X2_1049Z_UTIL_X2_1048Z_UTIL_X2_1047Z_UTIL_X2_1046Z_UTIL_X2_1045Z_UTIL_X2_1044Z_UTIL_X2_1043Z_UTIL_X2_1042Z_UTIL_X2_1041Z_UTIL_X2_1040Z_UTIL_X2_1039Z_UTIL_X2_1038Z_UTIL_X2_1037Z_UTIL_X2_1036Z_UTIL_X2_1035Z_UTIL_X2_1034Z_UTIL_X2_1033Z_UTIL_X2_1032Z_UTIL_X2_1031Z_UTIL_X2_1030Z_UTIL_X2_1029Z_UTIL_X2_1028Z_UTIL_X2_1027Z_UTIL_X2_1026Z_UTIL_X2_1025Z_UTIL_X2_1024Z_UTIL_X2_1023Z_UTIL_X2_1022Z_UTIL_X2_1021Z_UTIL_X2_1020Z_UTIL_X2_1019Z_UTIL_X2_1018Z_UTIL_X2_1017Z_UTIL_X2_1016Z_UTIL_X2_1015Z_UTIL_X2_1014Z_UTIL_X2_1013Z_UTIL_X2_1012Z_UTIL_X2_1011Z_UTIL_X2_1010Z_UTIL_X2_1009Z_UTIL_X2_1008Z_UTIL_X2_1007Z_UTIL_X2_1006Z_UTIL_X2_1005Z_UTIL_X2_1004Z_UTIL_X2_1003Z_UTIL_X2_1002Z_UTIL_X2_1001Z_UTIL_X2_1000Z_UTIL_X2_999Z_UTIL_X2_998Z_UTIL_X2_997Z_UTIL_X2_996Z_UTIL_X2_995Z_UTIL_X2_994Z_UTIL_X2_993Z_UTIL_X2_992Z_UTIL_X2_991Z_UTIL_X2_990Z_UTIL_X2_989Z_UTIL_X2_988Z_UTIL_X2_987Z_UTIL_X2_986Z_UTIL_X2_985Z_UTIL_X2_984Z_UTIL_X2_983Z_UTIL_X2_982Z_UTIL_X2_981Z_UTIL_X2_980Z_UTIL_X2_979Z_UTIL_X2_978Z_UTIL_X2_977Z_UTIL_X2_976Z_UTIL_X2_975Z_UTIL_X2_974Z_UTIL_X2_973Z_UTIL_X2_972Z_UTIL_X2_971Z_UTIL_X2_970Z_UTIL_X2_969Z_UTIL_X2_968Z_UTIL_X2_967Z_UTIL_X2_966Z_UTIL_X2_965Z_UTIL_X2_964Z_UTIL_X2_963Z_UTIL_X2_962Z_UTIL_X2_961Z_UTIL_X2_960Z_UTIL_X2_959Z_UTIL_X2_958Z_UTIL_X2_957Z_UTIL_X2_956Z_UTIL_X2_955Z_UTIL_X2_954Z_UTIL_X2_953Z_UTIL_X2_952Z_UTIL_X2_951Z_UTIL_X2_950Z_UTIL_X2_949Z_UTIL_X2_948Z_UTIL_X2_947Z_UTIL_X2_946Z_UTIL_X2_945Z_UTIL_X2_944Z_UTIL_X2_943Z_UTIL_X2_942Z_UTIL_X2_941Z_UTIL_X2_940Z_UTIL_X2_939Z_UTIL_X2_938Z_UTIL_X2_937Z_UTIL_X2_936Z_UTIL_X2_935Z_UTIL_X2_934Z_UTIL_X2_933Z_UTIL_X2_932Z_UTIL_X2_931Z_UTIL_X2_930Z_UTIL_X2_929Z_UTIL_X2_928Z_UTIL_X2_927Z_UTIL_X2_926Z_UTIL_X2_925Z_UTIL_X2_924Z_UTIL_X2_923Z_UTIL_X2_922Z_UTIL_X2_921Z_UTIL_X2_920Z_UTIL_X2_919Z_UTIL_X2_918Z_UTIL_X2_917Z_UTIL_X2_916Z_UTIL_X2_915Z_UTIL_X2_914Z_UTIL_X2_913Z_UTIL_X2_912Z_UTIL_X2_911Z_UTIL_X2_910Z_UTIL_X2_909Z_UTIL_X2_908Z_UTIL_X2_907Z_UTIL_X2_906Z_UTIL_X2_905Z_UTIL_X2_904Z_UTIL_X2_903Z_UTIL_X2_902Z_UTIL_X2_901Z_UTIL_X2_900Z_UTIL_X2_899Z_UTIL_X2_898Z_UTIL_X2_897Z_UTIL_X2_896Z_UTIL_X2_895Z_UTIL_X2_894Z_UTIL_X2_893Z_UTIL_X2_892Z_UTIL_X2_891Z_UTIL_X2_890Z_UTIL_X2_889Z_UTIL_X2_888Z_UTIL_X2_887Z_UTIL_X2_886Z_UTIL_X2_885Z_UTIL_X2_884Z_UTIL_X2_883Z_UTIL_X2_882Z_UTIL_X2_881Z_UTIL_X2_880Z_UTIL_X2_879Z_UTIL_X2_878Z_UTIL_X2_877Z_UTIL_X2_876Z_UTIL_X2_875Z_UTIL_X2_874Z_UTIL_X2_873Z_UTIL_X2_872Z_UTIL_X2_871Z_UTIL_X2_870Z_UTIL_X2_869Z_UTIL_X2_868Z_UTIL_X2_867Z_UTIL_X2_866Z_UTIL_X2_865Z_UTIL_X2_864Z_UTIL_X2_863Z_UTIL_X2_862Z_UTIL_X2_861Z_UTIL_X2_860Z_UTIL_X2_859Z_UTIL_X2_858Z_UTIL_X2_857Z_UTIL_X2_856Z_UTIL_X2_855Z_UTIL_X2_854Z_UTIL_X2_853Z_UTIL_X2_852Z_UTIL_X2_851Z_UTIL_X2_850Z_UTIL_X2_849Z_UTIL_X2_848Z_UTIL_X2_847Z_UTIL_X2_846Z_UTIL_X2_845Z_UTIL_X2_844Z_UTIL_X2_843Z_UTIL_X2_842Z_UTIL_X2_841Z_UTIL_X2_840Z_UTIL_X2_839Z_UTIL_X2_838Z_UTIL_X2_837Z_UTIL_X2_836Z_UTIL_X2_835Z_UTIL_X2_834Z_UTIL_X2_833Z_UTIL_X2_832Z_UTIL_X2_831Z_UTIL_X2_830Z_UTIL_X2_829Z_UTIL_X2_828Z_UTIL_X2_827Z_UTIL_X2_826Z_UTIL_X2_825Z_UTIL_X2_824Z_UTIL_X2_823Z_UTIL_X2_822Z_UTIL_X2_821Z_UTIL_X2_820Z_UTIL_X2_819Z_UTIL_X2_818Z_UTIL_X2_817Z_UTIL_X2_816Z_UTIL_X2_815Z_UTIL_X2_814Z_UTIL_X2_813Z_UTIL_X2_812Z_UTIL_X2_811Z_UTIL_X2_810Z_UTIL_X2_809Z_UTIL_X2_808Z_UTIL_X2_807Z_UTIL_X2_806Z_UTIL_X2_805Z_UTIL_X2_804Z_UTIL_X2_803Z_UTIL_X2_802Z_UTIL_X2_801Z_UTIL_X2_800Z_UTIL_X2_799Z_UTIL_X2_798Z_UTIL_X2_797Z_UTIL_X2_796Z_UTIL_X2_795Z_UTIL_X2_794Z_UTIL_X2_793Z_UTIL_X2_792Z_UTIL_X2_791Z_UTIL_X2_790Z_UTIL_X2_789Z_UTIL_X2_788Z_UTIL_X2_787Z_UTIL_X2_786Z_UTIL_X2_785Z_UTIL_X2_784Z_UTIL_X2_783Z_UTIL_X2_782Z_UTIL_X2_781Z_UTIL_X2_780Z_UTIL_X2_779Z_UTIL_X2_778Z_UTIL_X2_777Z_UTIL_X2_776Z_UTIL_X2_775Z_UTIL_X2_774Z_UTIL_X2_773Z_UTIL_X2_772Z_UTIL_X2_771Z_UTIL_X2_770Z_UTIL_X2_769Z_UTIL_X2_768Z_UTIL_X2_767Z_UTIL_X2_766Z_UTIL_X2_765Z_UTIL_X2_764Z_UTIL_X2_763Z_UTIL_X2_762Z_UTIL_X2_761Z_UTIL_X2_760Z_UTIL_X2_759Z_UTIL_X2_758Z_UTIL_X2_757Z_UTIL_X2_756Z_UTIL_X2_755Z_UTIL_X2_754Z_UTIL_X2_753Z_UTIL_X2_752Z_UTIL_X2_751Z_UTIL_X2_750Z_UTIL_X2_749Z_UTIL_X2_748Z_UTIL_X2_747Z_UTIL_X2_746Z_UTIL_X2_745Z_UTIL_X2_744Z_UTIL_X2_743Z_UTIL_X2_742Z_UTIL_X2_741Z_UTIL_X2_740Z_UTIL_X2_739Z_UTIL_X2_738Z_UTIL_X2_737Z_UTIL_X2_736Z_UTIL_X2_735Z_UTIL_X2_734Z_UTIL_X2_733Z_UTIL_X2_732Z_UTIL_X2_731Z_UTIL_X2_730Z_UTIL_X2_729Z_UTIL_X2_728Z_UTIL_X2_727Z_UTIL_X2_726Z_UTIL_X2_725Z_UTIL_X2_724Z_UTIL_X2_723Z_UTIL_X2_722Z_UTIL_X2_721Z_UTIL_X2_720Z_UTIL_X2_719Z_UTIL_X2_718Z_UTIL_X2_717Z_UTIL_X2_716Z_UTIL_X2_715Z_UTIL_X2_714Z_UTIL_X2_713Z_UTIL_X2_712Z_UTIL_X2_711Z_UTIL_X2_710Z_UTIL_X2_709Z_UTIL_X2_708Z_UTIL_X2_707Z_UTIL_X2_706Z_UTIL_X2_705Z_UTIL_X2_704Z_UTIL_X2_703Z_UTIL_X2_702Z_UTIL_X2_701Z_UTIL_X2_700Z_UTIL_X2_699Z_UTIL_X2_698Z_UTIL_X2_697Z_UTIL_X2_696Z_UTIL_X2_695Z_UTIL_X2_694Z_UTIL_X2_693Z_UTIL_X2_692Z_UTIL_X2_691Z_UTIL_X2_690Z_UTIL_X2_689Z_UTIL_X2_688Z_UTIL_X2_687Z_UTIL_X2_686Z_UTIL_X2_685Z_UTIL_X2_684Z_UTIL_X2_683Z_UTIL_X2_682Z_UTIL_X2_681Z_UTIL_X2_680Z_UTIL_X2_679Z_UTIL_X2_678Z_UTIL_X2_677Z_UTIL_X2_676Z_UTIL_X2_675Z_UTIL_X2_674Z_UTIL_X2_673Z_UTIL_X2_672Z_UTIL_X2_671Z_UTIL_X2_670Z_UTIL_X2_669Z_UTIL_X2_668Z_UTIL_X2_667Z_UTIL_X2_666Z_UTIL_X2_665Z_UTIL_X2_664Z_UTIL_X2_663Z_UTIL_X2_662Z_UTIL_X2_661Z_UTIL_X2_660Z_UTIL_X2_659Z_UTIL_X2_658Z_UTIL_X2_657Z_UTIL_X2_656Z_UTIL_X2_655Z_UTIL_X2_654Z_UTIL_X2_653Z_UTIL_X2_652Z_UTIL_X2_651Z_UTIL_X2_650Z_UTIL_X2_649Z_UTIL_X2_648Z_UTIL_X2_647Z_UTIL_X2_646Z_UTIL_X2_645Z_UTIL_X2_644Z_UTIL_X2_643Z_UTIL_X2_642Z_UTIL_X2_641Z_UTIL_X2_640Z_UTIL_X2_639Z_UTIL_X2_638Z_UTIL_X2_637Z_UTIL_X2_636Z_UTIL_X2_635Z_UTIL_X2_634Z_UTIL_X2_633Z_UTIL_X2_632Z_UTIL_X2_631Z_UTIL_X2_630Z_UTIL_X2_629Z_UTIL_X2_628Z_UTIL_X2_627Z_UTIL_X2_626Z_UTIL_X2_625Z_UTIL_X2_624Z_UTIL_X2_623Z_UTIL_X2_622Z_UTIL_X2_621Z_UTIL_X2_620Z_UTIL_X2_619Z_UTIL_X2_618Z_UTIL_X2_617Z_UTIL_X2_616Z_UTIL_X2_615Z_UTIL_X2_614Z_UTIL_X2_613Z_UTIL_X2_612Z_UTIL_X2_611Z_UTIL_X2_610Z_UTIL_X2_609Z_UTIL_X2_608Z_UTIL_X2_607Z_UTIL_X2_606Z_UTIL_X2_605Z_UTIL_X2_604Z_UTIL_X2_603Z_UTIL_X2_602Z_UTIL_X2_601Z_UTIL_X2_600Z_UTIL_X2_599Z_UTIL_X2_598Z_UTIL_X2_597Z_UTIL_X2_596Z_UTIL_X2_595Z_UTIL_X2_594Z_UTIL_X2_593Z_UTIL_X2_592Z_UTIL_X2_591Z_UTIL_X2_590Z_UTIL_X2_589Z_UTIL_X2_588Z_UTIL_X2_587Z_UTIL_X2_586Z_UTIL_X2_585Z_UTIL_X2_584Z_UTIL_X2_583Z_UTIL_X2_582Z_UTIL_X2_581Z_UTIL_X2_580Z_UTIL_X2_579Z_UTIL_X2_578Z_UTIL_X2_577Z_UTIL_X2_576Z_UTIL_X2_575Z_UTIL_X2_574Z_UTIL_X2_573Z_UTIL_X2_572Z_UTIL_X2_571Z_UTIL_X2_570Z_UTIL_X2_569Z_UTIL_X2_568Z_UTIL_X2_567Z_UTIL_X2_566Z_UTIL_X2_565Z_UTIL_X2_564Z_UTIL_X2_563Z_UTIL_X2_562Z_UTIL_X2_561Z_UTIL_X2_560Z_UTIL_X2_559Z_UTIL_X2_558Z_UTIL_X2_557Z_UTIL_X2_556Z_UTIL_X2_555Z_UTIL_X2_554Z_UTIL_X2_553Z_UTIL_X2_552Z_UTIL_X2_551Z_UTIL_X2_550Z_UTIL_X2_549Z_UTIL_X2_548Z_UTIL_X2_547Z_UTIL_X2_546Z_UTIL_X2_545Z_UTIL_X2_544Z_UTIL_X2_543Z_UTIL_X2_542Z_UTIL_X2_541Z_UTIL_X2_540Z_UTIL_X2_539Z_UTIL_X2_538Z_UTIL_X2_537Z_UTIL_X2_536Z_UTIL_X2_535Z_UTIL_X2_534Z_UTIL_X2_533Z_UTIL_X2_532Z_UTIL_X2_531Z_UTIL_X2_530Z_UTIL_X2_529Z_UTIL_X2_528Z_UTIL_X2_527Z_UTIL_X2_526Z_UTIL_X2_525Z_UTIL_X2_524Z_UTIL_X2_523Z_UTIL_X2_522Z_UTIL_X2_521Z_UTIL_X2_520Z_UTIL_X2_519Z_UTIL_X2_518Z_UTIL_X2_517Z_UTIL_X2_516Z_UTIL_X2_515Z_UTIL_X2_514Z_UTIL_X2_513Z_UTIL_X2_512Z_UTIL_X2_511Z_UTIL_X2_510Z_UTIL_X2_509Z_UTIL_X2_508Z_UTIL_X2_507Z_UTIL_X2_506Z_UTIL_X2_505Z_UTIL_X2_504Z_UTIL_X2_503Z_UTIL_X2_502Z_UTIL_X2_501Z_UTIL_X2_500Z_UTIL_X2_499Z_UTIL_X2_498Z_UTIL_X2_497Z_UTIL_X2_496Z_UTIL_X2_495Z_UTIL_X2_494Z_UTIL_X2_493Z_UTIL_X2_492Z_UTIL_X2_491Z_UTIL_X2_490Z_UTIL_X2_489Z_UTIL_X2_488Z_UTIL_X2_487Z_UTIL_X2_486Z_UTIL_X2_485Z_UTIL_X2_484Z_UTIL_X2_483Z_UTIL_X2_482Z_UTIL_X2_481Z_UTIL_X2_480Z_UTIL_X2_479Z_UTIL_X2_478Z_UTIL_X2_477Z_UTIL_X2_476Z_UTIL_X2_475Z_UTIL_X2_474Z_UTIL_X2_473Z_UTIL_X2_472Z_UTIL_X2_471Z_UTIL_X2_470Z_UTIL_X2_469Z_UTIL_X2_468Z_UTIL_X2_467Z_UTIL_X2_466Z_UTIL_X2_465Z_UTIL_X2_464Z_UTIL_X2_463Z_UTIL_X2_462Z_UTIL_X2_461Z_UTIL_X2_460Z_UTIL_X2_459Z_UTIL_X2_458Z_UTIL_X2_457Z_UTIL_X2_456Z_UTIL_X2_455Z_UTIL_X2_454Z_UTIL_X2_453Z_UTIL_X2_452Z_UTIL_X2_451Z_UTIL_X2_450Z_UTIL_X2_449Z_UTIL_X2_448Z_UTIL_X2_447Z_UTIL_X2_446Z_UTIL_X2_445Z_UTIL_X2_444Z_UTIL_X2_443Z_UTIL_X2_442Z_UTIL_X2_441Z_UTIL_X2_440Z_UTIL_X2_439Z_UTIL_X2_438Z_UTIL_X2_437Z_UTIL_X2_436Z_UTIL_X2_435Z_UTIL_X2_434Z_UTIL_X2_433Z_UTIL_X2_432Z_UTIL_X2_431Z_UTIL_X2_430Z_UTIL_X2_429Z_UTIL_X2_428Z_UTIL_X2_427Z_UTIL_X2_426Z_UTIL_X2_425Z_UTIL_X2_424Z_UTIL_X2_423Z_UTIL_X2_422Z_UTIL_X2_421Z_UTIL_X2_420Z_UTIL_X2_419Z_UTIL_X2_418Z_UTIL_X2_417Z_UTIL_X2_416Z_UTIL_X2_415Z_UTIL_X2_414Z_UTIL_X2_413Z_UTIL_X2_412Z_UTIL_X2_411Z_UTIL_X2_410Z_UTIL_X2_409Z_UTIL_X2_408Z_UTIL_X2_407Z_UTIL_X2_406Z_UTIL_X2_405Z_UTIL_X2_404Z_UTIL_X2_403Z_UTIL_X2_402Z_UTIL_X2_401Z_UTIL_X2_400Z_UTIL_X2_399Z_UTIL_X2_398Z_UTIL_X2_397Z_UTIL_X2_396Z_UTIL_X2_395Z_UTIL_X2_394Z_UTIL_X2_393Z_UTIL_X2_392Z_UTIL_X2_391Z_UTIL_X2_390Z_UTIL_X2_389Z_UTIL_X2_388Z_UTIL_X2_387Z_UTIL_X2_386Z_UTIL_X2_385Z_UTIL_X2_384Z_UTIL_X2_383Z_UTIL_X2_382Z_UTIL_X2_381Z_UTIL_X2_380Z_UTIL_X2_379Z_UTIL_X2_378Z_UTIL_X2_377Z_UTIL_X2_376Z_UTIL_X2_375Z_UTIL_X2_374Z_UTIL_X2_373Z_UTIL_X2_372Z_UTIL_X2_371Z_UTIL_X2_370Z_UTIL_X2_369Z_UTIL_X2_368Z_UTIL_X2_367Z_UTIL_X2_366Z_UTIL_X2_365Z_UTIL_X2_364Z_UTIL_X2_363Z_UTIL_X2_362Z_UTIL_X2_361Z_UTIL_X2_360Z_UTIL_X2_359Z_UTIL_X2_358Z_UTIL_X2_357Z_UTIL_X2_356Z_UTIL_X2_355Z_UTIL_X2_354Z_UTIL_X2_353Z_UTIL_X2_352Z_UTIL_X2_351Z_UTIL_X2_350Z_UTIL_X2_349Z_UTIL_X2_348Z_UTIL_X2_347Z_UTIL_X2_346Z_UTIL_X2_345Z_UTIL_X2_344Z_UTIL_X2_343Z_UTIL_X2_342Z_UTIL_X2_341Z_UTIL_X2_340Z_UTIL_X2_339Z_UTIL_X2_338Z_UTIL_X2_337Z_UTIL_X2_336Z_UTIL_X2_335Z_UTIL_X2_334Z_UTIL_X2_333Z_UTIL_X2_332Z_UTIL_X2_331Z_UTIL_X2_330Z_UTIL_X2_329Z_UTIL_X2_328Z_UTIL_X2_327Z_UTIL_X2_326Z_UTIL_X2_325Z_UTIL_X2_324Z_UTIL_X2_323Z_UTIL_X2_322Z_UTIL_X2_321Z_UTIL_X2_320Z_UTIL_X2_319Z_UTIL_X2_318Z_UTIL_X2_317Z_UTIL_X2_316Z_UTIL_X2_315Z_UTIL_X2_314Z_UTIL_X2_313Z_UTIL_X2_312Z_UTIL_X2_311Z_UTIL_X2_310Z_UTIL_X2_309Z_UTIL_X2_308Z_UTIL_X2_307Z_UTIL_X2_306Z_UTIL_X2_305Z_UTIL_X2_304Z_UTIL_X2_303Z_UTIL_X2_302Z_UTIL_X2_301Z_UTIL_X2_300Z_UTIL_X2_299Z_UTIL_X2_298Z_UTIL_X2_297Z_UTIL_X2_296Z_UTIL_X2_295Z_UTIL_X2_294Z_UTIL_X2_293Z_UTIL_X2_292Z_UTIL_X2_291Z_UTIL_X2_290Z_UTIL_X2_289Z_UTIL_X2_288Z_UTIL_X2_287Z_UTIL_X2_286Z_UTIL_X2_285Z_UTIL_X2_284Z_UTIL_X2_283Z_UTIL_X2_282Z_UTIL_X2_281Z_UTIL_X2_280Z_UTIL_X2_279Z_UTIL_X2_278Z_UTIL_X2_277Z_UTIL_X2_276Z_UTIL_X2_275Z_UTIL_X2_274Z_UTIL_X2_273Z_UTIL_X2_272Z_UTIL_X2_271Z_UTIL_X2_270Z_UTIL_X2_269Z_UTIL_X2_268Z_UTIL_X2_267Z_UTIL_X2_266Z_UTIL_X2_265Z_UTIL_X2_264Z_UTIL_X2_263Z_UTIL_X2_262Z_UTIL_X2_261Z_UTIL_X2_260Z_UTIL_X2_259Z_UTIL_X2_258Z_UTIL_X2_257Z_UTIL_X2_256Z_UTIL_X2_255Z_UTIL_X2_254Z_UTIL_X2_253Z_UTIL_X2_252Z_UTIL_X2_251Z_UTIL_X2_250Z_UTIL_X2_249Z_UTIL_X2_248Z_UTIL_X2_247Z_UTIL_X2_246Z_UTIL_X2_245Z_UTIL_X2_244Z_UTIL_X2_243Z_UTIL_X2_242Z_UTIL_X2_241Z_UTIL_X2_240Z_UTIL_X2_239Z_UTIL_X2_238Z_UTIL_X2_237Z_UTIL_X2_236Z_UTIL_X2_235Z_UTIL_X2_234Z_UTIL_X2_233Z_UTIL_X2_232Z_UTIL_X2_231Z_UTIL_X2_230Z_UTIL_X2_229Z_UTIL_X2_228Z_UTIL_X2_227Z_UTIL_X2_226Z_UTIL_X2_225Z_UTIL_X2_224Z_UTIL_X2_223Z_UTIL_X2_222Z_UTIL_X2_221Z_UTIL_X2_220Z_UTIL_X2_219Z_UTIL_X2_218Z_UTIL_X2_217Z_UTIL_X2_216Z_UTIL_X2_215Z_UTIL_X2_214Z_UTIL_X2_213Z_UTIL_X2_212Z_UTIL_X2_211Z_UTIL_X2_210Z_UTIL_X2_209Z_UTIL_X2_208Z_UTIL_X2_207Z_UTIL_X2_206Z_UTIL_X2_205Z_UTIL_X2_204Z_UTIL_X2_203Z_UTIL_X2_202Z_UTIL_X2_201Z_UTIL_X2_200Z_UTIL_X2_199Z_UTIL_X2_198Z_UTIL_X2_197Z_UTIL_X2_196Z_UTIL_X2_195Z_UTIL_X2_194Z_UTIL_X2_193Z_UTIL_X2_192Z_UTIL_X2_191Z_UTIL_X2_190Z_UTIL_X2_189Z_UTIL_X2_188Z_UTIL_X2_187Z_UTIL_X2_186Z_UTIL_X2_185Z_UTIL_X2_184Z_UTIL_X2_183Z_UTIL_X2_182Z_UTIL_X2_181Z_UTIL_X2_180Z_UTIL_X2_179Z_UTIL_X2_178Z_UTIL_X2_177Z_UTIL_X2_176Z_UTIL_X2_175Z_UTIL_X2_174Z_UTIL_X2_173Z_UTIL_X2_172Z_UTIL_X2_171Z_UTIL_X2_170Z_UTIL_X2_169Z_UTIL_X2_168Z_UTIL_X2_167Z_UTIL_X2_166Z_UTIL_X2_165Z_UTIL_X2_164Z_UTIL_X2_163Z_UTIL_X2_162Z_UTIL_X2_161Z_UTIL_X2_160Z_UTIL_X2_159Z_UTIL_X2_158Z_UTIL_X2_157Z_UTIL_X2_156Z_UTIL_X2_155Z_UTIL_X2_154Z_UTIL_X2_153Z_UTIL_X2_152Z_UTIL_X2_151Z_UTIL_X2_150Z_UTIL_X2_149Z_UTIL_X2_148Z_UTIL_X2_147Z_UTIL_X2_146Z_UTIL_X2_145Z_UTIL_X2_144Z_UTIL_X2_143Z_UTIL_X2_142Z_UTIL_X2_141Z_UTIL_X2_140Z_UTIL_X2_139Z_UTIL_X2_138Z_UTIL_X2_137Z_UTIL_X2_136Z_UTIL_X2_135Z_UTIL_X2_134Z_UTIL_X2_133Z_UTIL_X2_132Z_UTIL_X2_131Z_UTIL_X2_130Z_UTIL_X2_129Z_UTIL_X2_128Z_UTIL_X2_127Z_UTIL_X2_126Z_UTIL_X2_125Z_UTIL_X2_124Z_UTIL_X2_123Z_UTIL_X2_122Z_UTIL_X2_121Z_UTIL_X2_120Z_UTIL_X2_119Z_UTIL_X2_118Z_UTIL_X2_117Z_UTIL_X2_116Z_UTIL_X2_115Z_UTIL_X2_114Z_UTIL_X2_113Z_UTIL_X2_112Z_UTIL_X2_111Z_UTIL_X2_110Z_UTIL_X2_109Z_UTIL_X2_108Z_UTIL_X2_107Z_UTIL_X2_106Z_UTIL_X2_105Z_UTIL_X2_104Z_UTIL_X2_103Z_UTIL_X2_102Z_UTIL_X2_101Z_UTIL_X2_100Z_UTIL_X2_99Z_UTIL_X2_98Z_UTIL_X2_97Z_UTIL_X2_96Z_UTIL_X2_95Z_UTIL_X2_94Z_UTIL_X2_93Z_UTIL_X2_92Z_UTIL_X2_91Z_UTIL_X2_90Z_UTIL_X2_89Z_UTIL_X2_88Z_UTIL_X2_87Z_UTIL_X2_86Z_UTIL_X2_85Z_UTIL_X2_84Z_UTIL_X2_83Z_UTIL_X2_82Z_UTIL_X2_81Z_UTIL_X2_80Z_UTIL_X2_79Z_UTIL_X2_78Z_UTIL_X2_77Z_UTIL_X2_76Z_UTIL_X2_75Z_UTIL_X2_74Z_UTIL_X2_73Z_UTIL_X2_72Z_UTIL_X2_71Z_UTIL_X2_70Z_UTIL_X2_69Z_UTIL_X2_68Z_UTIL_X2_67Z_UTIL_X2_66Z_UTIL_X2_65Z_UTIL_X2_64Z_UTIL_X2_63Z_UTIL_X2_62Z_UTIL_X2_61Z_UTIL_X2_60Z_UTIL_X2_59Z_UTIL_X2_58Z_UTIL_X2_57Z_UTIL_X2_56Z_UTIL_X2_55Z_UTIL_X2_54Z_UTIL_X2_53Z_UTIL_X2_52Z_UTIL_X2_51Z_UTIL_X2_50Z_UTIL_X2_49Z_UTIL_X2_48Z_UTIL_X2_47Z_UTIL_X2_46Z_UTIL_X2_45Z_UTIL_X2_44Z_UTIL_X2_43Z_UTIL_X2_42Z_UTIL_X2_41Z_UTIL_X2_40Z_UTIL_X2_39Z_UTIL_X2_38Z_UTIL_X2_37Z_UTIL_X2_36Z_UTIL_X2_35Z_UTIL_X2_34Z_UTIL_X2_33Z_UTIL_X2_32Z_UTIL_X2_31Z_UTIL_X2_30Z_UTIL_X2_29Z_UTIL_X2_28Z_UTIL_X2_27Z_UTIL_X2_26Z_UTIL_X2_25Z_UTIL_X2_24Z_UTIL_X2_23Z_UTIL_X2_22Z_UTIL_X2_21Z_UTIL_X2_20Z_UTIL_X2_19Z_UTIL_X2_18Z_UTIL_X2_17Z_UTIL_X2_16Z_UTIL_X2_15Z_UTIL_X2_14Z_UTIL_X2_13Z_UTIL_X2_12Z_UTIL_X2_11Z_UTIL_X2_10Z_UTIL_X2_9Z_UTIL_X2_8Z_UTIL_X2_7Z_UTIL_X2_6Z_UTIL_X2_5Z_UTIL_X2_4Z_UTIL_X2_3Z_UTIL_X2_2Z_UTIL_X2_1Z_UTIL_X2_0ZEPHYR_INCLUDE_SYS_UTIL_INTERNAL_UTIL_X2_H_/* ZEPHYR_INCLUDE_SYS_UTIL_INTERNAL_UTIL_X2_H_ */"util_internal_util_x2.h""util_internal_util_dec.h""util_internal_util_inc.h""util_internal_is_eq.h""util_loops.h"Z_SPARSE_LIST_EVEN_NUMBERS0, EMPTY, 2, EMPTY, 4, EMPTY, 6, EMPTY, 8, EMPTY, 10, EMPTY, 12, EMPTY, 14, EMPTY, 16, EMPTY, 18, EMPTY, 20, EMPTY, 22, EMPTY, 24, EMPTY, 26, EMPTY, 28, EMPTY, 30, EMPTY, 32, EMPTY, 34, EMPTY, 36, EMPTY, 38, EMPTY, 40, EMPTY, 42, EMPTY, 44, EMPTY, 46, EMPTY, 48, EMPTY, 50, EMPTY, 52, EMPTY, 54, EMPTY, 56, EMPTY, 58, EMPTY, 60, EMPTY, 62, EMPTYZ_SPARSE_LIST_ODD_NUMBERSEMPTY, 1, EMPTY, 3, EMPTY, 5, EMPTY, 7, EMPTY, 9, EMPTY, 11, EMPTY, 13, EMPTY, 15, EMPTY, 17, EMPTY, 19, EMPTY, 21, EMPTY, 23, EMPTY, 25, EMPTY, 27, EMPTY, 29, EMPTY, 31, EMPTY, 33, EMPTY, 35, EMPTY, 37, EMPTY, 39, EMPTY, 41, EMPTY, 43, EMPTY, 45, EMPTY, 47, EMPTY, 49, EMPTY, 51, EMPTY, 53, EMPTY, 55, EMPTY, 57, EMPTY, 59, EMPTY, 61, EMPTY, 63MACRO_MC_15(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_14(m, __VA_ARGS__,))MACRO_MC_14(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_13(m, __VA_ARGS__,))MACRO_MC_13(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_12(m, __VA_ARGS__,))MACRO_MC_12(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_11(m, __VA_ARGS__,))MACRO_MC_11(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_10(m, __VA_ARGS__,))MACRO_MC_10(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_9(m, __VA_ARGS__,))MACRO_MC_9(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_8(m, __VA_ARGS__,))MACRO_MC_8(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_7(m, __VA_ARGS__,))MACRO_MC_7(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_6(m, __VA_ARGS__,))MACRO_MC_6(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_5(m, __VA_ARGS__,))MACRO_MC_5(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_4(m, __VA_ARGS__,))MACRO_MC_4(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_3(m, __VA_ARGS__,))MACRO_MC_3(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_2(m, __VA_ARGS__,))MACRO_MC_2(m,a,__VA_ARGS__...)UTIL_CAT(m(a), MACRO_MC_1(m, __VA_ARGS__,))MACRO_MC_1(m,a,__VA_ARGS__...)m(a)MACRO_MC_0(__VA_ARGS__...)MACRO_MAP_CAT_N_(N,__VA_ARGS__...)UTIL_CAT(MACRO_MC_, N)(__VA_ARGS__,)MACRO_MAP_CAT_(__VA_ARGS__...)MACRO_MAP_CAT_N(NUM_VA_ARGS_LESS_1(__VA_ARGS__), __VA_ARGS__)NUM_VA_ARGS_LESS_1_IMPL(_ignored,_0,_1,_2,_3,_4,_5,_6,_7,_8,_9,_10,_11,_12,_13,_14,_15,_16,_17,_18,_19,_20,_21,_22,_23,_24,_25,_26,_27,_28,_29,_30,_31,_32,_33,_34,_35,_36,_37,_38,_39,_40,_41,_42,_43,_44,_45,_46,_47,_48,_49,_50,_51,_52,_53,_54,_55,_56,_57,_58,_59,_60,_61,_62,N,__VA_ARGS__...)UTIL_REPEAT(__VA_ARGS__...)UTIL_LISTIFY(__VA_ARGS__)UTIL_EXPAND(__VA_ARGS__...)UTIL_EVAL(__VA_ARGS__...)UTIL_BOOL(x)UTIL_COMPL(UTIL_NOT(x))UTIL_COMPL_1UTIL_COMPL_0UTIL_COMPL(b)UTIL_PRIMITIVE_CAT(UTIL_COMPL_, b)UTIL_NOT_0UTIL_NOT(x)UTIL_CHECK(UTIL_PRIMITIVE_CAT(UTIL_NOT_, x))UTIL_CHECK(__VA_ARGS__...)UTIL_CHECK_N(__VA_ARGS__, 0,)UTIL_CHECK_N(x,n,__VA_ARGS__...)nUTIL_PRIMITIVE_CAT(a,__VA_ARGS__...)a ## __VA_ARGS__UTIL_CAT(a,__VA_ARGS__...)UTIL_PRIMITIVE_CAT(a, __VA_ARGS__)Z_LIST_NO_EMPTIES(e)COND_CODE_1(IS_EMPTY(e), (), (Z_LIST_ADD_ELEM(e)))Z_LIST_DROP_FIRST(__VA_ARGS__...)GET_ARGS_LESS_N(1, __VA_ARGS__)Z_LIST_ADD_ELEM(e)EMPTY, eZ_IS_EMPTY_CASE_0001Z_IS_EMPTY__(_0,_1,_2,_3)Z_HAS_COMMA(Z_CAT5(Z_IS_EMPTY_CASE_, _0, _1, _2, _3))Z_CAT5(_0,_1,_2,_3,_4)_0 ## _1 ## _2 ## _3 ## _4Z_CAT4(_0,_1,_2,_3)_0 ## _1 ## _2 ## _3Z_IS_EMPTY_(__VA_ARGS__...)Z_IS_EMPTY__( Z_HAS_COMMA(__VA_ARGS__), Z_HAS_COMMA(Z_TRIGGER_PARENTHESIS_ __VA_ARGS__), Z_HAS_COMMA(__VA_ARGS__ ( )), Z_HAS_COMMA(Z_TRIGGER_PARENTHESIS_ __VA_ARGS__ ( )))Z_TRIGGER_PARENTHESIS_(__VA_ARGS__...)Z_HAS_COMMA(__VA_ARGS__...)NUM_VA_ARGS_LESS_1_IMPL(__VA_ARGS__, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)__DEBRACKET(__VA_ARGS__...)__GET_ARG2_DEBRACKET(ignore_this,val,__VA_ARGS__...)__DEBRACKET val__COND_CODE(one_or_two_args,_if_code,_else_code)__GET_ARG2_DEBRACKET(one_or_two_args _if_code, _else_code)Z_COND_CODE_0(_flag,_if_0_code,_else_code)__COND_CODE(_ZZZZ ## _flag, _if_0_code, _else_code)Z_COND_CODE_1(_flag,_if_1_code,_else_code)__COND_CODE(_XXXX ## _flag, _if_1_code, _else_code)Z_IS_EQ(_0,_1)Z_HAS_COMMA(Z_CAT4(Z_IS_, _0, _EQ_, _1)())Z_IS_ENABLED3(ignore_this,val,__VA_ARGS__...)valZ_IS_ENABLED2(one_or_two_args)Z_IS_ENABLED3(one_or_two_args 1, 0)Z_IS_ENABLED1(config_macro)Z_IS_ENABLED2(_XXXX ## config_macro)/* Used by UTIL_X2 *//* Used by UTIL_DEC *//* Used by UTIL_INC *//*
 * Generic sparse list of even numbers (check the implementation of
 * GPIO_DT_RESERVED_RANGES_NGPIOS as a usage example)
 *//*
 * Generic sparse list of odd numbers (check the implementation of
 * GPIO_DT_RESERVED_RANGES_NGPIOS as a usage example)
 *//* Used by Z_IS_EQ *//* To make sure it works also for 2 arguments in total *//* Used by MACRO_MAP_CAT *//* Implementation details for NUM_VA_ARGS_LESS_1 *//* Adding ',' after each element would add empty element at the end of
 * list, which is hard to remove, so instead precede each element with ',',
 * this way first element is empty, and this one is easy to drop.
 *//* Used by LIST_DROP_EMPTY() *//*empty*//* reference: https://gustedt.wordpress.com/2010/06/08/detect-empty-macro-arguments/ *//* Used by IS_EMPTY() *//* Used to remove brackets from around a single argument. *//* Gets second argument and removes brackets around that argument. It
 * is expected that the parameter is provided in brackets/parentheses.
 *//* Used internally by COND_CODE_1 and COND_CODE_0. *//* Implementation of IS_EQ(). Returns 1 if _0 and _1 are the same integer from
 * 0 to 4095, 0 otherwise.
 *//* And our second argument is thus now cooked to be 1 in the case
 * where the value is defined to 1, and 0 if not:
 *//* Then we append an extra argument to fool the gcc preprocessor into
 * accepting it as a varargs macro.
 *                         arg1   arg2  arg3
 *   ENABLED:   Z_IS_ENABLED3(_YYYY,    1,    0)
 *   DISABLED   Z_IS_ENABLED3(_XXXX 1,  0)
 *//* Here's the core trick, we map "_XXXX1" to "_YYYY," (i.e. a string
 * with a trailing comma), so it has the effect of making this a
 * two-argument tuple to the preprocessor only in the case where the
 * value is defined to "1"
 *   ENABLED:    _YYYY,    <--- note comma!
 *   DISABLED:   _XXXX
 *//* This is called from IS_ENABLED(), and sticks on a "_XXXX" prefix,
 * it will now be "_XXXX1" if config_macro is "1", or just "_XXXX" if it's
 * undefined.
 *   ENABLED:   Z_IS_ENABLED2(_XXXX1)
 *   DISABLED   Z_IS_ENABLED2(_XXXX)
 *//* IS_ENABLED() helpers *//**
 * @file
 * @brief Misc utilities
 *
 * Repetitive or obscure helper macros needed by sys/util.h.
 *//*
 * Copyright (c) 2011-2014, Wind River Systems, Inc.
 * Copyright (c) 2020, Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/sys/util_internal.h>MACRO_MAP_CAT_N(N,__VA_ARGS__...)MACRO_MAP_CAT_N_(N, __VA_ARGS__)MACRO_MAP_CAT(__VA_ARGS__...)MACRO_MAP_CAT_(__VA_ARGS__)NUM_VA_ARGS_LESS_1(__VA_ARGS__...)NUM_VA_ARGS_LESS_1_IMPL(__VA_ARGS__, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, ~)REVERSE_ARGS(__VA_ARGS__...)Z_FOR_EACH_ENGINE(Z_FOR_EACH_EXEC, (,), Z_BYPASS, _, __VA_ARGS__)FOR_EACH_IDX_FIXED_ARG(F,sep,fixed_arg,__VA_ARGS__...)Z_FOR_EACH_IDX_FIXED_ARG(F, sep, fixed_arg, REVERSE_ARGS(__VA_ARGS__))FOR_EACH_FIXED_ARG(F,sep,fixed_arg,__VA_ARGS__...)Z_FOR_EACH_FIXED_ARG(F, sep, fixed_arg, REVERSE_ARGS(__VA_ARGS__))FOR_EACH_IDX(F,sep,__VA_ARGS__...)Z_FOR_EACH_IDX(F, sep, REVERSE_ARGS(__VA_ARGS__))FOR_EACH_NONEMPTY_TERM(F,term,__VA_ARGS__...)COND_CODE_0( NUM_VA_ARGS_LESS_1(LIST_DROP_EMPTY(__VA_ARGS__, _)), (), ( FOR_EACH(F, term, LIST_DROP_EMPTY(__VA_ARGS__)) __DEBRACKET term ))FOR_EACH(F,sep,__VA_ARGS__...)Z_FOR_EACH(F, sep, REVERSE_ARGS(__VA_ARGS__))LISTIFY(LEN,F,sep,__VA_ARGS__...)UTIL_CAT(Z_UTIL_LISTIFY_, LEN)(F, sep, __VA_ARGS__)UTIL_X2(y)UTIL_PRIMITIVE_CAT(Z_UTIL_X2_, y)UTIL_DEC(x)UTIL_PRIMITIVE_CAT(Z_UTIL_DEC_, x)UTIL_INC(x)UTIL_PRIMITIVE_CAT(Z_UTIL_INC_, x)UTIL_AND(a,b)COND_CODE_1(UTIL_BOOL(a), (b), (0))UTIL_OR(a,b)COND_CODE_1(UTIL_BOOL(a), (a), (b))GET_ARGS_LESS_N(N,__VA_ARGS__...)Z_GET_ARGS_LESS_ ## N(__VA_ARGS__)GET_ARG_N(N,__VA_ARGS__...)Z_GET_ARG_ ## N(__VA_ARGS__)IDENTITY(V)VEMPTYLIST_DROP_EMPTY(__VA_ARGS__...)Z_LIST_DROP_FIRST(FOR_EACH(Z_LIST_NO_EMPTIES, (), __VA_ARGS__))IS_EQ(a,b)Z_IS_EQ(a, b)IS_EMPTY(__VA_ARGS__...)Z_IS_EMPTY_(__VA_ARGS__)IF_ENABLED(_flag,_code)COND_CODE_1(_flag, _code, ())COND_CODE_0(_flag,_if_0_code,_else_code)Z_COND_CODE_0(_flag, _if_0_code, _else_code)COND_CODE_1(_flag,_if_1_code,_else_code)Z_COND_CODE_1(_flag, _if_1_code, _else_code)IS_ENABLED(config_macro)IS_BIT_MASK(m)IS_SHIFTED_BIT_MASK(m, 0)IS_SHIFTED_BIT_MASK(m,s)(!(((m) >> (s)) & (((m) >> (s)) + 1U)))IS_POWER_OF_TWO(x)(((x) != 0U) && (((x) & ((x) - 1U)) == 0U))BIT64_MASK(n)(BIT64(n) - 1ULL)BIT_MASK(n)(BIT(n) - 1UL)WRITE_BIT(var,bit,set)((var) = (set) ? ((var) | BIT(bit)) : ((var) & ~BIT(bit)))BIT64(_n)(1ULL << (_n))BIT(n)(1UL << (n))ZEPHYR_INCLUDE_SYS_UTIL_MACROS_H_BIT/* ZEPHYR_INCLUDE_SYS_UTIL_MACROS_H_ *//**
 * @brief Mapping macro that pastes a fixed number of results together
 *
 * Similar to @ref MACRO_MAP_CAT(), but expects a fixed number of
 * arguments. If more arguments are given than are expected, the rest
 * are ignored.
 *
 * @param N   Number of arguments to map
 * @param ... Macro to expand on each argument, followed by its
 *            arguments. (The macro should take exactly one argument.)
 * @return The results of expanding the macro on each argument, all pasted
 *         together
 *//**
 * @brief Mapping macro that pastes results together
 *
 * This is similar to FOR_EACH() in that it invokes a macro repeatedly
 * on each element of `__VA_ARGS__`. However, unlike FOR_EACH(),
 * MACRO_MAP_CAT() pastes the results together into a single token.
 *
 * For example, with this macro FOO:
 *
 *     #define FOO(x) item_##x##_
 *
 * <tt>MACRO_MAP_CAT(FOO, a, b, c),</tt> expands to the token:
 *
 *     item_a_item_b_item_c_
 *
 * @param ... Macro to expand on each argument, followed by its
 *            arguments. (The macro should take exactly one argument.)
 * @return The results of expanding the macro on each argument, all pasted
 *         together
 *//**
 * @brief Number of arguments in the variable arguments list minus one.
 *
 * @param ... List of arguments
 * @return  Number of variadic arguments in the argument list, minus one
 *//** @brief Reverse arguments order.
 *
 * @param ... Variable argument list.
 *//**
 * @brief Calls macro @p F for each variable argument with an index and fixed
 *        argument
 *
 * This is like the combination of FOR_EACH_IDX() with FOR_EACH_FIXED_ARG().
 *
 * Example:
 *
 *     #define F(idx, x, fixed_arg) int fixed_arg##idx = x
 *     FOR_EACH_IDX_FIXED_ARG(F, (;), a, 4, 5, 6);
 *
 * This expands to:
 *
 *     int a0 = 4;
 *     int a1 = 5;
 *     int a2 = 6;
 *
 * @param F Macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            This is required to enable providing a comma as separator.
 * @param fixed_arg Fixed argument passed to @p F as the third macro parameter.
 * @param ... Variable list of arguments. The macro @p F is invoked as
 *            <tt>F(index, element, fixed_arg)</tt> for each element in
 *            the list.
 *//**
 * @brief Call macro @p F on each provided argument, with an additional fixed
 *	  argument as a parameter.
 *
 * This is like FOR_EACH(), except @p F should be a macro which takes two
 * arguments: <tt>F(variable_arg, fixed_arg)</tt>.
 *
 * Example:
 *
 *     static void func(int val, void *dev);
 *     FOR_EACH_FIXED_ARG(func, (;), dev, 4, 5, 6);
 *
 * This expands to:
 *
 *     func(4, dev);
 *     func(5, dev);
 *     func(6, dev);
 *
 * @param F Macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param fixed_arg Fixed argument passed to @p F as the second macro parameter.
 * @param ... Variable argument list. The macro @p F is invoked as
 *            <tt>F(element, fixed_arg)</tt> for each element in the list.
 *//**
 * @brief Call macro @p F on each provided argument, with the argument's index
 *        as an additional parameter.
 *
 * This is like FOR_EACH(), except @p F should be a macro which takes two
 * arguments: <tt>F(index, variable_arg)</tt>.
 *
 * Example:
 *
 *     #define F(idx, x) int a##idx = x
 *     FOR_EACH_IDX(F, (;), 4, 5, 6);
 *
 * This expands to:
 *
 *     int a0 = 4;
 *     int a1 = 5;
 *     int a2 = 6;
 *
 * @param F Macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... Variable argument list. The macro @p F is invoked as
 *            <tt>F(index, element)</tt> for each element in the list.
 *//* plus a final terminator *//* FOR_EACH() on nonempty elements, *//* otherwise, expand to: *//* if so, expand to nothing *//* are there zero non-empty arguments ? *//**
 * @brief Like FOR_EACH(), but with a terminator instead of a separator,
 *        and drops empty elements from the argument list
 *
 * The @p sep argument to <tt>FOR_EACH(F, (sep), a, b)</tt> is a
 * separator which is placed between calls to @p F, like this:
 *
 *     FOR_EACH(F, (sep), a, b) // F(a) sep F(b)
 *                              //               ^^^ no sep here!
 *
 * By contrast, the @p term argument to <tt>FOR_EACH_NONEMPTY_TERM(F, (term),
 * a, b)</tt> is added after each time @p F appears in the expansion:
 *
 *     FOR_EACH_NONEMPTY_TERM(F, (term), a, b) // F(a) term F(b) term
 *                                             //                ^^^^
 *
 * Further, any empty elements are dropped:
 *
 *     FOR_EACH_NONEMPTY_TERM(F, (term), a, EMPTY, b) // F(a) term F(b) term
 *
 * This is more convenient in some cases, because FOR_EACH_NONEMPTY_TERM()
 * expands to nothing when given an empty argument list, and it's
 * often cumbersome to write a macro @p F that does the right thing
 * even when given an empty argument.
 *
 * One example is when `__VA_ARGS__` may or may not be empty,
 * and the results are embedded in a larger initializer:
 *
 *     #define SQUARE(x) ((x)*(x))
 *
 *     int my_array[] = {
 *             FOR_EACH_NONEMPTY_TERM(SQUARE, (,), FOO(...))
 *             FOR_EACH_NONEMPTY_TERM(SQUARE, (,), BAR(...))
 *             FOR_EACH_NONEMPTY_TERM(SQUARE, (,), BAZ(...))
 *     };
 *
 * This is more convenient than:
 *
 * 1. figuring out whether the @p FOO, @p BAR, and @p BAZ expansions
 *    are empty and adding a comma manually (or not) between FOR_EACH()
 *    calls
 * 2. rewriting SQUARE so it reacts appropriately when "x" is empty
 *    (which would be necessary if e.g. @p FOO expands to nothing)
 *
 * @param F Macro to invoke on each nonempty element of the variable
 *          arguments
 * @param term Terminator (e.g. comma or semicolon) placed after each
 *             invocation of F. Must be in parentheses; this is required
 *             to enable providing a comma as separator.
 * @param ... Variable argument list. The macro @p F is invoked as
 *            <tt>F(element)</tt> for each nonempty element in the list.
 *//**
 * @brief Call a macro @p F on each provided argument with a given
 *        separator between each call.
 *
 * Example:
 *
 *     #define F(x) int a##x
 *     FOR_EACH(F, (;), 4, 5, 6);
 *
 * This expands to:
 *
 *     int a4;
 *     int a5;
 *     int a6;
 *
 * @param F Macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... Variable argument list. The macro @p F is invoked as
 *            <tt>F(element)</tt> for each element in the list.
 *//**
 * @brief Generates a sequence of code with configurable separator.
 *
 * Example:
 *
 *     #define FOO(i, _) MY_PWM ## i
 *     { LISTIFY(PWM_COUNT, FOO, (,)) }
 *
 * The above two lines expand to:
 *
 *    { MY_PWM0 , MY_PWM1 }
 *
 * @param LEN The length of the sequence. Must be an integer literal less
 *            than 4095.
 * @param F A macro function that accepts at least two arguments:
 *          <tt>F(i, ...)</tt>. @p F is called repeatedly in the expansion.
 *          Its first argument @p i is the index in the sequence, and
 *          the variable list of arguments passed to LISTIFY are passed
 *          through to @p F.
 *
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *
 * @note Calling LISTIFY with undefined arguments has undefined
 * behavior.
 *//**
 * @brief UTIL_X2(y) for an integer literal y from 0 to 4095 expands to an
 * integer literal whose value is 2y.
 *//**
 * @brief UTIL_DEC(x) for an integer literal x from 0 to 4095 expands to an
 * integer literal whose value is x-1.
 *
 * @see UTIL_INC(x)
 *//**
 * @brief UTIL_INC(x) for an integer literal x from 0 to 4095 expands to an
 * integer literal whose value is x+1.
 *
 * @see UTIL_DEC(x)
 *//**
 * @brief Like <tt>a && b</tt>, but does evaluation and
 * short-circuiting at C preprocessor time.
 *
 * This is not the same as the binary @p &&, however; in particular,
 * @p a should expand to an integer literal 0 or 1. However, @p b
 * can be any value.
 *
 * This can be useful when @p b is an expression that would cause a
 * build error when @p a is 0.
 *//**
 * @brief Like <tt>a || b</tt>, but does evaluation and
 * short-circuiting at C preprocessor time.
 *
 * This is not the same as the binary @p || operator; in particular,
 * @p a should expand to an integer literal 0 or 1. However, @p b
 * can be any value.
 *
 * This can be useful when @p b is an expression that would cause a
 * build error when @p a is 1.
 *//**
 * @brief Strips n first arguments from the argument list.
 *
 * @param N Number of arguments to discard.
 * @param ... Variable list of arguments.
 *
 * @return argument list without N first arguments.
 *//**
 * @brief Get nth argument from argument list.
 *
 * @param N Argument index to fetch. Counter from 1.
 * @param ... Variable list of arguments from which one argument is returned.
 *
 * @return Nth argument.
 *//**
 * @brief Macro that expands to its argument
 *
 * This is useful in macros like @c FOR_EACH() when there is no
 * transformation required on the list elements.
 *
 * @param V any value
 *//**
 * @brief Macro with an empty expansion
 *
 * This trivial definition is provided for readability when a macro
 * should expand to an empty result, which e.g. is sometimes needed to
 * silence checkpatch.
 *
 * Example:
 *
 *	#define LIST_ITEM(n) , item##n
 *
 * The above would cause checkpatch to complain, but:
 *
 *	#define LIST_ITEM(n) EMPTY, item##n
 *
 * would not.
 *//**
 * @brief Remove empty arguments from list.
 *
 * During macro expansion, `__VA_ARGS__` and other preprocessor
 * generated lists may contain empty elements, e.g.:
 *
 *	#define LIST ,a,b,,d,
 *
 * Using EMPTY to show each empty element, LIST contains:
 *
 *      EMPTY, a, b, EMPTY, d
 *
 * When processing such lists, e.g. using FOR_EACH(), all empty elements
 * will be processed, and may require filtering out.
 * To make that process easier, it is enough to invoke LIST_DROP_EMPTY
 * which will remove all empty elements.
 *
 * Example:
 *
 *	LIST_DROP_EMPTY(LIST)
 *
 * expands to:
 *
 *	a, b, d
 *
 * @param ... list to be processed
 *//**
 * @brief Like <tt>a == b</tt>, but does evaluation and
 * short-circuiting at C preprocessor time.
 *
 * This however only works for integer literal from 0 to 4095.
 *
 *//**
 * @brief Check if a macro has a replacement expression
 *
 * If @p a is a macro defined to a nonempty value, this will return
 * true, otherwise it will return false. It only works with defined
 * macros, so an additional @p \#ifdef test may be needed in some cases.
 *
 * This macro may be used with COND_CODE_1() and COND_CODE_0() while
 * processing `__VA_ARGS__` to avoid processing empty arguments.
 *
 * Example:
 *
 *	#define EMPTY
 *	#define NON_EMPTY	1
 *	#undef  UNDEFINED
 *	IS_EMPTY(EMPTY)
 *	IS_EMPTY(NON_EMPTY)
 *	IS_EMPTY(UNDEFINED)
 *	#if defined(EMPTY) && IS_EMPTY(EMPTY) == true
 *	some_conditional_code
 *	#endif
 *
 * In above examples, the invocations of IS_EMPTY(...) return @p true,
 * @p false, and @p true; @p some_conditional_code is included.
 *
 * @param ... macro to check for emptiness (may be `__VA_ARGS__`)
 *//**
 * @brief Insert code if @p _flag is defined and equals 1.
 *
 * Like COND_CODE_1(), this expands to @p _code if @p _flag is defined to 1;
 * it expands to nothing otherwise.
 *
 * Example:
 *
 *     IF_ENABLED(CONFIG_FLAG, (uint32_t foo;))
 *
 * If @p CONFIG_FLAG is defined to 1, this expands to:
 *
 *     uint32_t foo;
 *
 * and to nothing otherwise.
 *
 * It can be considered as a more compact alternative to:
 *
 *     #if defined(CONFIG_FLAG) && (CONFIG_FLAG == 1)
 *     uint32_t foo;
 *     #endif
 *
 * @param _flag evaluated flag
 * @param _code result if @p _flag expands to 1; must be in parentheses
 *//**
 * @brief Like COND_CODE_1() except tests if @p _flag is 0.
 *
 * This is like COND_CODE_1(), except that it tests whether @p _flag
 * expands to the integer literal 0. It expands to @p _if_0_code if
 * so, and @p _else_code otherwise; both of these must be enclosed in
 * parentheses.
 *
 * @param _flag evaluated flag
 * @param _if_0_code result if @p _flag expands to 0; must be in parentheses
 * @param _else_code result otherwise; must be in parentheses
 * @see COND_CODE_1()
 *//**
 * @brief Insert code depending on whether @p _flag expands to 1 or not.
 *
 * This relies on similar tricks as IS_ENABLED(), but as the result of
 * @p _flag expansion, results in either @p _if_1_code or @p
 * _else_code is expanded.
 *
 * To prevent the preprocessor from treating commas as argument
 * separators, the @p _if_1_code and @p _else_code expressions must be
 * inside brackets/parentheses: <tt>()</tt>. These are stripped away
 * during macro expansion.
 *
 * Example:
 *
 *     COND_CODE_1(CONFIG_FLAG, (uint32_t x;), (there_is_no_flag();))
 *
 * If @p CONFIG_FLAG is defined to 1, this expands to:
 *
 *     uint32_t x;
 *
 * It expands to <tt>there_is_no_flag();</tt> otherwise.
 *
 * This could be used as an alternative to:
 *
 *     #if defined(CONFIG_FLAG) && (CONFIG_FLAG == 1)
 *     #define MAYBE_DECLARE(x) uint32_t x
 *     #else
 *     #define MAYBE_DECLARE(x) there_is_no_flag()
 *     #endif
 *
 *     MAYBE_DECLARE(x);
 *
 * However, the advantage of COND_CODE_1() is that code is resolved in
 * place where it is used, while the @p \#if method defines @p
 * MAYBE_DECLARE on two lines and requires it to be invoked again on a
 * separate line. This makes COND_CODE_1() more concise and also
 * sometimes more useful when used within another macro's expansion.
 *
 * @note @p _flag can be the result of preprocessor expansion, e.g.
 *	 an expression involving <tt>NUM_VA_ARGS_LESS_1(...)</tt>.
 *	 However, @p _if_1_code is only expanded if @p _flag expands
 *	 to the integer literal 1. Integer expressions that evaluate
 *	 to 1, e.g. after doing some arithmetic, will not work.
 *
 * @param _flag evaluated flag
 * @param _if_1_code result if @p _flag expands to 1; must be in parentheses
 * @param _else_code result otherwise; must be in parentheses
 *//* INTERNAL: the first pass above is just to expand any existing
 * macros, we need the macro value to be e.g. a literal "1" at
 * expansion time in the next macro, not "(1)", etc... Standard
 * recursive expansion does not work.
 *//**
 * @brief Check for macro definition in compiler-visible expressions
 *
 * This trick was pioneered in Linux as the config_enabled() macro. It
 * has the effect of taking a macro value that may be defined to "1"
 * or may not be defined at all and turning it into a literal
 * expression that can be handled by the C compiler instead of just
 * the preprocessor. It is often used with a @p CONFIG_FOO macro which
 * may be defined to 1 via Kconfig, or left undefined.
 *
 * That is, it works similarly to <tt>\#if defined(CONFIG_FOO)</tt>
 * except that its expansion is a C expression. Thus, much <tt>\#ifdef</tt>
 * usage can be replaced with equivalents like:
 *
 *     if (IS_ENABLED(CONFIG_FOO)) {
 *             do_something_with_foo
 *     }
 *
 * This is cleaner since the compiler can generate errors and warnings
 * for @p do_something_with_foo even when @p CONFIG_FOO is undefined.
 *
 * Note: Use of IS_ENABLED in a <tt>\#if</tt> statement is discouraged
 *       as it doesn't provide any benefit vs plain <tt>\#if defined()</tt>
 *
 * @param config_macro Macro to check
 * @return 1 if @p config_macro is defined to 1, 0 otherwise (including
 *         if @p config_macro is not defined)
 *//**
 * @brief Check if bits are set continuously from the LSB.
 *
 * @param m Check whether the bits are set continuously from LSB.
 *//**
 * @brief Check if bits are set continuously from the specified bit
 *
 * The macro is not dependent on the bit-width.
 *
 * @param m Check whether the bits are set continuously or not.
 * @param s Specify the lowest bit for that is continuously set bits.
 *//** @brief Check if a @p x is a power of two *//**
 * @brief 64-bit bit mask with bits 0 through <tt>n-1</tt> (inclusive) set,
 * or 0 if @p n is 0.
 *//**
 * @brief Bit mask with bits 0 through <tt>n-1</tt> (inclusive) set,
 * or 0 if @p n is 0.
 *//**
 * @brief Set or clear a bit depending on a boolean value
 *
 * The argument @p var is a variable whose value is written to as a
 * side effect.
 *
 * @param var Variable to be altered
 * @param bit Bit number
 * @param set if 0, clears @p bit in @p var; any other value sets @p bit
 *//** @brief 64-bit unsigned integer with bit position @p _n set. *//**
 * @brief Unsigned integer with bit position @p n set (signed in
 * assembly language).
 *//*
 * Most of the eldritch implementation details for all the macrobatics
 * below (APIs like IS_ENABLED(), COND_CODE_1(), etc.) are hidden away
 * in this file.
 *//**
 * @addtogroup sys-util
 * @{
 *//**
 * @file
 * @brief Macro utilities
 *
 * Macro utilities are the public interface for C/C++ code and device tree
 * related implementation.  In general, C/C++ will include <sys/util.h>
 * instead this file directly.  For device tree implementation, this file
 * should be include instead <sys/util_internal.h>
 *//*
 * Copyright (c) 2011-2014, Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */atomic_nandatomic_t *long *__atomic_fetch_nand_4volatile voidvolatile void *atomic_and__atomic_fetch_and_4atomic_xor__atomic_fetch_xor_4atomic_or__atomic_fetch_or_4atomic_ptr_clearatomic_ptr_t *atomic_clearatomic_ptr_set__atomic_exchange_4atomic_setatomic_ptr_getconst atomic_ptr_tconst atomic_ptr_t *__atomic_load_4const volatile voidconst volatile void *atomic_getconst atomic_tconst atomic_t *atomic_decatomic_incatomic_sub__atomic_fetch_sub_4atomic_add__atomic_fetch_add_4atomic_ptr_cas__atomic_compare_exchange_4atomic_ptr_val_t *atomic_casatomic_val_t *ZEPHYR_INCLUDE_SYS_ATOMIC_BUILTIN_H___ATOMIC_SEQ_CST/* ZEPHYR_INCLUDE_SYS_ATOMIC_BUILTIN_H_ *//**
 *
 * @brief Atomic bitwise NAND.
 *
 * This routine atomically sets @a target to the bitwise NAND of @a target
 * and @a value. (This operation is equivalent to target = ~(target & value).)
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to NAND.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic bitwise AND.
 *
 * This routine atomically sets @a target to the bitwise AND of @a target
 * and @a value.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to AND.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic bitwise exclusive OR (XOR).
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * This routine atomically sets @a target to the bitwise exclusive OR (XOR) of
 * @a target and @a value.
 *
 * @param target Address of atomic variable.
 * @param value Value to XOR
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic bitwise inclusive OR.
 *
 * This routine atomically sets @a target to the bitwise inclusive OR of
 * @a target and @a value.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to OR.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic clear of a pointer value
 *
 * This routine atomically sets @a target to zero and returns its previous
 * value. (Hence, it is equivalent to atomic_set(target, 0).)
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic clear.
 *
 * This routine atomically sets @a target to zero and returns its previous
 * value. (Hence, it is equivalent to atomic_set(target, 0).)
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic get-and-set for pointer values
 *
 * This routine atomically sets @a target to @a value and returns
 * the previous value of @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to write to @a target.
 *
 * @return Previous value of @a target.
 *//* This builtin, as described by Intel, is not a traditional
	 * test-and-set operation, but rather an atomic exchange operation. It
	 * writes value into *ptr, and returns the previous contents of *ptr.
	 *//**
 *
 * @brief Atomic get-and-set.
 *
 * This routine atomically sets @a target to @a value and returns
 * the previous value of @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to write to @a target.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic get a pointer value
 *
 * This routine performs an atomic read on @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of pointer variable.
 *
 * @return Value of @a target.
 *//**
 *
 * @brief Atomic get.
 *
 * This routine performs an atomic read on @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 *
 * @return Value of @a target.
 *//**
 *
 * @brief Atomic decrement.
 *
 * This routine performs an atomic decrement by 1 on @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic increment.
 *
 * This routine performs an atomic increment by 1 on @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic subtraction.
 *
 * This routine performs an atomic subtraction on @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to subtract.
 *
 * @return Previous value of @a target.
 *//**
 *
 * @brief Atomic addition.
 *
 * This routine performs an atomic addition on @a target.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param value Value to add.
 *
 * @return Previous value of @a target.
 *//**
 * @brief Atomic compare-and-set with pointer values
 *
 * This routine performs an atomic compare-and-set on @a target. If the current
 * value of @a target equals @a old_value, @a target is set to @a new_value.
 * If the current value of @a target does not equal @a old_value, @a target
 * is left unchanged.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param old_value Original value to compare against.
 * @param new_value New value to store.
 * @return true if @a new_value is written, false otherwise.
 *//**
 * @brief Atomic compare-and-set.
 *
 * This routine performs an atomic compare-and-set on @a target. If the current
 * value of @a target equals @a old_value, @a target is set to @a new_value.
 * If the current value of @a target does not equal @a old_value, @a target
 * is left unchanged.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable.
 * @param old_value Original value to compare against.
 * @param new_value New value to store.
 * @return true if @a new_value is written, false otherwise.
 *//**
 * @addtogroup atomic_apis Atomic Services APIs
 * @ingroup kernel_apis
 * @{
 *//* Included from <atomic.h> *//*
 * Copyright (c) 1997-2015, Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* atomic operations */targetvalueold_valuenew_value<zephyr/sys/atomic_builtin.h><zephyr/sys/util_macro.h>atomic_set_bit_tobit(unsigned long)(bit) & (ATOMIC_BITS - 1U)(unsigned long)(bit) & ((sizeof(atomic_val_t) * 8) - 1U)maskatomic_set_bitatomic_clear_bitatomic_test_and_set_bitoldatomic_test_and_clear_bitatomic_test_bitATOMIC_BITS(ATOMIC_BITS - 1)atomic_ptr_val_tatomic_ptr_tatomic_val_tatomic_tATOMIC_DEFINE(name,num_bits)atomic_t name[ATOMIC_BITMAP_SIZE(num_bits)]ATOMIC_BITMAP_SIZE(num_bits)(1 + ((num_bits) - 1) / ATOMIC_BITS)ATOMIC_ELEM(addr,bit)((addr) + ((bit) / ATOMIC_BITS))ATOMIC_MASK(bit)BIT((unsigned long)(bit) & (ATOMIC_BITS - 1U))(sizeof(atomic_val_t) * 8)ATOMIC_PTR_INIT(p)(p)ATOMIC_INIT(i)(i)ZEPHYR_INCLUDE_SYS_ATOMIC_H_defined(CONFIG_ATOMIC_OPERATIONS_C)defined(CONFIG_ATOMIC_OPERATIONS_ARCH)/**
 * @brief Atomically set a bit to a given value.
 *
 * Atomically set bit number @a bit of @a target to value @a val.
 * The target may be a single atomic variable or an array of them.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable or array.
 * @param bit Bit number (starting from 0).
 * @param val true for 1, false for 0.
 *//**
 * @brief Atomically set a bit.
 *
 * Atomically set bit number @a bit of @a target.
 * The target may be a single atomic variable or an array of them.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable or array.
 * @param bit Bit number (starting from 0).
 *//**
 * @brief Atomically clear a bit.
 *
 * Atomically clear bit number @a bit of @a target.
 * The target may be a single atomic variable or an array of them.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable or array.
 * @param bit Bit number (starting from 0).
 *//**
 * @brief Atomically set a bit.
 *
 * Atomically set bit number @a bit of @a target and return its old value.
 * The target may be a single atomic variable or an array of them.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable or array.
 * @param bit Bit number (starting from 0).
 *
 * @return true if the bit was already set, false if it wasn't.
 *//**
 * @brief Atomically test and clear a bit.
 *
 * Atomically clear bit number @a bit of @a target and return its old value.
 * The target may be a single atomic variable or an array of them.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable or array.
 * @param bit Bit number (starting from 0).
 *
 * @return false if the bit was already cleared, true if it wasn't.
 *//**
 * @brief Atomically test a bit.
 *
 * This routine tests whether bit number @a bit of @a target is set or not.
 * The target may be a single atomic variable or an array of them.
 *
 * @note As for all atomic APIs, includes a
 * full/sequentially-consistent memory barrier (where applicable).
 *
 * @param target Address of atomic variable or array.
 * @param bit Bit number (starting from 0).
 *
 * @return true if the bit was set, false if it wasn't.
 *//**
 * @brief Define an array of atomic variables.
 *
 * This macro defines an array of atomic variables containing at least
 * @a num_bits bits.
 *
 * @note
 * If used from file scope, the bits of the array are initialized to zero;
 * if used from within a function, the bits are left uninitialized.
 *
 * @cond INTERNAL_HIDDEN
 * @note
 * This macro should be replicated in the PREDEFINED field of the documentation
 * Doxyfile.
 * @endcond
 *
 * @param name Name of array of atomic variables.
 * @param num_bits Number of bits needed.
 *//**
 * @brief This macro computes the number of atomic variables necessary to
 * represent a bitmap with @a num_bits.
 *
 * @param num_bits Number of bits.
 *//**
 * @brief Initialize an atomic pointer variable.
 *
 * This macro can be used to initialize an atomic pointer variable. For
 * example,
 * @code atomic_ptr_t my_ptr = ATOMIC_PTR_INIT(&data); @endcode
 *
 * @param p Pointer value to assign to atomic pointer variable.
 *//**
 * @brief Initialize an atomic variable.
 *
 * This macro can be used to initialize an atomic variable. For example,
 * @code atomic_t my_var = ATOMIC_INIT(75); @endcode
 *
 * @param i Value to assign to atomic variable.
 *//**
 * @defgroup atomic_apis Atomic Services APIs
 * @ingroup kernel_apis
 * @{
 *//* Portable higher-level utilities: *//* Default.  See this file for the Doxygen reference: *//* CONFIG_XTENSA *//* Other arch specific implementation *//* Not all Xtensa toolchains support GCC-style atomic intrinsics *//* Some architectures need their own implementation *//* Generic-but-slow implementation based on kernel locking and syscalls *//* Low-level primitives come in several styles: *//*
 * Copyright (c) 1997-2015, Wind River Systems, Inc.
 * Copyright (c) 2021 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */assert_print__ASSERT_POST_ACTION(){ }__ASSERT_NO_MSG(test)__ASSERT_EVAL(expr1,expr2,test,fmt,__VA_ARGS__...)expr1__ASSERT(test,fmt,__VA_ARGS__...)__ASSERT_LOC(test)__ASSERT_PRINT("ASSERTION FAIL [%s] @ %s:%d\n", Z_STRINGIFY(test), __FILE__, __LINE__)__ASSERT_MSG_INFO(fmt,__VA_ARGS__...)__ASSERT_PRINT("\t" fmt "\n", ## __VA_ARGS__)__ASSERT_PRINT(fmt,__VA_ARGS__...)assert_print(fmt, ## __VA_ARGS__)ZEPHYR_INCLUDE_SYS___ASSERT_H_CONFIG_ASSERT__ASSERT_ONCONFIG_FORCE_NO_ASSERTdefined(CONFIG_ASSERT_VERBOSE)CONFIG_ASSERT_NO_MSG_INFO!defined(CONFIG_ASSERT_NO_COND_INFO) && !defined(CONFIG_ASSERT_NO_FILE_INFO)defined(CONFIG_ASSERT_NO_COND_INFO) && !defined(CONFIG_ASSERT_NO_FILE_INFO)!defined(CONFIG_ASSERT_NO_COND_INFO) && defined(CONFIG_ASSERT_NO_FILE_INFO)defined(CONFIG_ASSERT_NO_COND_INFO) && defined(CONFIG_ASSERT_NO_FILE_INFO)(__ASSERT_ON < 0) || (__ASSERT_ON > 2)CONFIG_ASSERT_NO_FILE_INFOCONFIG_ASSERT_TEST(__ASSERT_ON == 1)/* ZEPHYR_INCLUDE_SYS___ASSERT_H_ *//*
 * When the assert test mode is enabled, the default kernel fatal error handler
 * and the custom assert hook function may return in order to allow the test to
 * proceed.
 *//* CONFIG_ASSERT_NO_FILE_INFO *//* CONFIG_ASSERT_NO_MSG_INFO *//* CONFIG_ASSERT_VERBOSE *//* Wrapper around printk to avoid including printk.h in assert.h *//*
 * Copyright (c) 2011-2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */formatprintffmtZEPHYR_INCLUDE_SYS_UTIL_H_!(defined(__CHAR_BIT__) && defined(__SIZEOF_LONG__) && defined(__SIZEOF_LONG_LONG__))MAXMINCLAMP/* ZEPHYR_INCLUDE_SYS_UTIL_H_ *//**
 * @brief Wait for an expression to return true with a timeout
 *
 * Spin on an expression with a timeout and optional delay between iterations
 *
 * Commonly needed when waiting on hardware to complete an asynchronous
 * request to read/write/initialize/reset, but useful for any expression.
 *
 * @param expr Truth expression upon which to poll, e.g.: XYZREG & XYZREG_EN
 * @param timeout Timeout to wait for in microseconds, e.g.: 1000 (1ms)
 * @param delay_stmt Delay statement to perform each poll iteration
 *                   e.g.: NULL, k_yield(), k_msleep(1) or k_busy_wait(1)
 *
 * @retval expr As a boolean return, if false then it has timed out.
 *//**
 * @brief For the POSIX architecture add a minimal delay in a busy wait loop.
 * For other architectures this is a no-op.
 *
 * In the POSIX ARCH, code takes zero simulated time to execute,
 * so busy wait loops become infinite loops, unless we
 * force the loop to take a bit of time.
 * Include this macro in all busy wait/spin loops
 * so they will also work when building for the POSIX architecture.
 *
 * @param t Time in microseconds we will busy wait
 *//** @brief Number of Hz in @p x MHz *//** @brief Number of Hz in @p x kHz *//** @brief Number of bytes in @p x gibibytes *//** @brief Number of bytes in @p x mebibytes *//* This is used in linker scripts so need to avoid type casting there *//** @brief Number of bytes in @p x kibibytes *//* This file must be included at the end of the !_ASMLANGUAGE guard.
 * It depends on macros defined in this file above which cannot be forward declared.
 *//**
 * @brief Determine if a buffer exceeds highest address
 *
 * This macro determines if a buffer identified by a starting address @a addr
 * and length @a buflen spans a region of memory that goes beond the highest
 * possible address (thereby resulting in a pointer overflow).
 *
 * @param addr Buffer starting address
 * @param buflen Length of the buffer
 *
 * @return true if pointer overflow detected, false otherwise
 *//**
 * @brief Compute next highest power of two
 *
 * Equivalent to 2^ceil(log2(x))
 *
 * @note This macro expands its argument multiple times (to permit use
 *       in constant expressions), which must not have side effects.
 *
 * @param x An unsigned integral value
 *
 * @return 2^ceil(log2(x)) or 0 if 2^ceil(log2(x)) would saturate 64-bits
 *//**
 * @brief Compute ceil(log2(x))
 *
 * @note This macro expands its argument multiple times (to permit use
 *       in constant expressions), which must not have side effects.
 *
 * @param x An unsigned integral value
 *
 * @return ceil(log2(x)) when 1 <= x <= max(type(x)), 0 when x < 1
 *//**
 * @brief Compute log2(x)
 *
 * @note This macro expands its argument multiple times (to permit use
 *       in constant expressions), which must not have side effects.
 *
 * @param x An unsigned integral value to compute logarithm of (positive only)
 *
 * @return log2(x) when 1 <= x <= max(x), -1 when x < 1
 *//**
 * @brief Copies a UTF-8 encoded string from @p src to @p dst
 *
 * The resulting @p dst will always be NULL terminated if @p n is larger than 0,
 * and the @p dst string will always be properly UTF-8 truncated.
 *
 * @param dst The destination of the UTF-8 string.
 * @param src The source string
 * @param n   The size of the @p dst buffer. Maximum number of characters copied
 *            is @p n - 1. If 0 nothing will be done, and the @p dst will not be
 *            NULL terminated.
 *
 * @return Pointer to the @p dst
 *//**
 * @brief Properly truncate a NULL-terminated UTF-8 string
 *
 * Take a NULL-terminated UTF-8 string and ensure that if the string has been
 * truncated (by setting the NULL terminator) earlier by other means, that
 * the string ends with a properly formatted UTF-8 character (1-4 bytes).
 *
 * @htmlonly
 * Example:
 *      char test_str[] = "";
 *      char trunc_utf8[8];
 *
 *      printf("Original : %s\n", test_str); // 
 *      strncpy(trunc_utf8, test_str, sizeof(trunc_utf8));
 *      trunc_utf8[sizeof(trunc_utf8) - 1] = '\0';
 *      printf("Bad      : %s\n", trunc_utf8); // 
 *      utf8_trunc(trunc_utf8);
 *      printf("Truncated: %s\n", trunc_utf8); // 
 * @endhtmlonly
 *
 * @param utf8_str NULL-terminated string
 *
 * @return Pointer to the @p utf8_str
 *//**
 * @brief      Convert a uint8_t into a decimal string representation.
 *
 * Convert a uint8_t value into its ASCII decimal string representation.
 * The string is terminated if there is enough space in buf.
 *
 * @param buf     Address of where to store the string representation.
 * @param buflen  Size of the storage area for string representation.
 * @param value   The value to convert to decimal string
 *
 * @return     The length of the converted string (excluding terminator if
 *             any), or 0 if an error occurred.
 *//**
 * @brief Convert a binary value to binary coded decimal (BCD 8421).
 *
 * @param bin Binary value to convert.
 *
 * @return BCD 8421 representation of input value.
 *//**
 * @brief Convert a binary coded decimal (BCD 8421) value to binary.
 *
 * @param bcd BCD 8421 value to convert.
 *
 * @return Binary representation of input value.
 *//**
 * @brief      Convert a hexadecimal string into a binary array.
 *
 * @param hex     The hexadecimal string to convert
 * @param hexlen  The length of the hexadecimal string to convert.
 * @param buf     Address of where to store the binary data
 * @param buflen  Size of the storage area for binary data
 *
 * @return     The length of the binary array, or 0 if an error occurred.
 *//**
 * @brief      Convert a binary array into string representation.
 *
 * @param buf     The binary array to convert
 * @param buflen  The length of the binary array to convert
 * @param hex     Address of where to store the string representation.
 * @param hexlen  Size of the storage area for string representation.
 *
 * @return     The length of the converted string, or 0 if an error occurred.
 *//**
 * @brief      Convert a single hexadecimal nibble into a character.
 *
 * @param c     The number to convert
 * @param x     The address of storage for the converted character.
 *
 *  @return Zero on success or (negative) error code otherwise.
 *//**
 * @brief      Convert a single character into a hexadecimal nibble.
 *
 * @param c     The character to convert
 * @param x     The address of storage for the converted number.
 *
 *  @return Zero on success or (negative) error code otherwise.
 *//**
 * @brief byte by byte swap.
 *
 * Swap @a size bytes between memory regions @a a and @a b. This is
 * guaranteed to be done byte by byte.
 *
 * @param a Pointer to the the first memory region.
 * @param b Pointer to the the second memory region.
 * @param size The number of bytes to swap.
 *//**
 * @brief byte by byte memcpy.
 *
 * Copy `size` bytes of `src` into `dest`. This is guaranteed to be done byte by byte.
 *
 * @param dst Pointer to the destination memory.
 * @param src Pointer to the source of the data.
 * @param size The number of bytes to copy.
 *//* shift value and fill opened bit positions with sign bit *//* make all bits of sign_ext be the same as the value's sign bit *//* extract sign bit *//**
 * @brief Arithmetic shift right
 * @param value value to shift
 * @param shift number of bits to shift
 * @return @p value shifted right by @p shift; opened bit positions are
 *         filled with the sign bit
 *//**
 * @brief Is @p x a power of two?
 * @param x value to check
 * @return true if @p x is a power of two, false otherwise
 *//**
 * @brief Checks if a value is within range.
 *
 * @note @p val is evaluated twice.
 *
 * @param val Value to be checked.
 * @param min Lower bound (inclusive).
 * @param max Upper bound (inclusive).
 *
 * @retval true If value is within range
 * @retval false If the value is not within range
 *//**
 * @brief Clamp a value to a given range.
 *
 * @note Arguments are evaluated multiple times. Use Z_CLAMP for a GCC-only,
 * single evaluation version.
 *
 * @param val Value to be clamped.
 * @param low Lowest allowed value (inclusive).
 * @param high Highest allowed value (inclusive).
 *
 * @returns Clamped value.
 *//**
 * @brief Obtain the minimum of two values.
 *
 * @note Arguments are evaluated twice. Use Z_MIN for a GCC-only, single
 * evaluation version
 *
 * @param a First value.
 * @param b Second value.
 *
 * @returns Minimum value of @p a and @p b.
 *//**
 * @brief Obtain the maximum of two values.
 *
 * @note Arguments are evaluated twice. Use Z_MAX for a GCC-only, single
 * evaluation version
 *
 * @param a First value.
 * @param b Second value.
 *
 * @returns Maximum value of @p a and @p b.
 *//**
 * @brief Ceiling function applied to @p numerator / @p divider as a fraction.
 * @deprecated Use DIV_ROUND_UP() instead.
 *//**
 * @brief Divide and round to the nearest integer.
 *
 * Example:
 * @code{.c}
 * DIV_ROUND_CLOSEST(5, 2); // 3
 * DIV_ROUND_CLOSEST(5, -2); // -3
 * DIV_ROUND_CLOSEST(5, 3); // 2
 * @endcode
 *
 * @param n Numerator.
 * @param d Denominator.
 *
 * @return The result of @p n / @p d, rounded to the nearest integer.
 *//**
 * @brief Divide and round up.
 *
 * Example:
 * @code{.c}
 * DIV_ROUND_UP(1, 2); // 1
 * DIV_ROUND_UP(3, 2); // 2
 * @endcode
 *
 * @param n Numerator.
 * @param d Denominator.
 *
 * @return The result of @p n / @p d, rounded up.
 *//** @brief Value of @p x rounded down to the previous word boundary. *//** @brief Value of @p x rounded up to the next word boundary. *//**
 * @brief Value of @p x rounded down to the previous multiple of @p align.
 *//**
 * @brief Value of @p x rounded up to the next multiple of @p align.
 *//**
 * @brief Get a pointer to a structure containing the element
 *
 * Example:
 *
 *	struct foo {
 *		int bar;
 *	};
 *
 *	struct foo my_foo;
 *	int *ptr = &my_foo.bar;
 *
 *	struct foo *container = CONTAINER_OF(ptr, struct foo, bar);
 *
 * Above, @p container points at @p my_foo.
 *
 * @param ptr pointer to a structure element
 * @param type name of the type that @p ptr is an element of
 * @param field the name of the field within the struct @p ptr points to
 * @return a pointer to the structure that contains @p ptr
 *//**
 * @brief Validate CONTAINER_OF parameters, only applies to C mode.
 *//**
 * @brief Validate if two entities have a compatible type
 *
 * @param a the first entity to be compared
 * @param b the second entity to be compared
 * @return 1 if the two elements are compatible, 0 if they are not
 *//**
 * @brief Array-index of @p ptr within @p array, rounded down
 *
 * This macro behaves much like @ref ARRAY_INDEX with the notable
 * difference that it accepts any @p ptr in the range of @p array rather than
 * exclusively a @p ptr aligned to an array-element boundary of @p array.
 *
 * With `CONFIG_ASSERT=y`, this macro will trigger a runtime assertion
 * when @p ptr does not fall into the range of @p array.
 *
 * In C, passing a pointer as @p array causes a compile error.
 *
 * @param array the array in question
 * @param ptr pointer to an element of @p array
 *
 * @return the array index of @p ptr within @p array, on success
 *//**
 * @brief Check if a pointer @p ptr lies within @p array.
 *
 * In C but not C++, this causes a compile error if @p array is not an array
 * (e.g. if @p ptr and @p array are mixed up).
 *
 * @param array an array
 * @param ptr a pointer
 * @return 1 if @p ptr is part of @p array, 0 otherwise
 *//**
 * @brief Index of @p ptr within @p array
 *
 * With `CONFIG_ASSERT=y`, this macro will trigger a runtime assertion
 * when @p ptr does not fall into the range of @p array or when @p ptr
 * is not aligned to an array-element boundary of @p array.
 *
 * In C, passing a pointer as @p array causes a compile error.
 *
 * @param array the array in question
 * @param ptr pointer to an element of @p array
 *
 * @return the array index of @p ptr within @p array, on success
 *//**
 * @brief Whether @p ptr is an element of @p array
 *
 * This macro can be seen as a slightly stricter version of @ref PART_OF_ARRAY
 * in that it also ensures that @p ptr is aligned to an array-element boundary
 * of @p array.
 *
 * In C, passing a pointer as @p array causes a compile error.
 *
 * @param array the array in question
 * @param ptr the pointer to check
 *
 * @return 1 if @p ptr is part of @p array, 0 otherwise
 *//**
 * @brief Number of elements in the given @p array
 *
 * In C++, due to language limitations, this will accept as @p array
 * any type that implements <tt>operator[]</tt>. The results may not be
 * particularly meaningful in this case.
 *
 * In C, passing a pointer as @p array causes a compile error.
 *//**
 * @brief Zero if @p array has an array type, a compile error otherwise
 *
 * This macro is available only from C, not C++.
 *//* The built-in function used below for type checking in C is not
 * supported by GNU C++.
 *//** @brief 0 if @p cond is true-ish; causes a compile error otherwise. *//**
 * @brief Prepare a bitfield element using @p value with @p mask representing
 *	  its field position and width. The result should be combined
 *	  with other fields using a logical OR.
 *//**
 * @brief Extract a bitfield element from @p value corresponding to
 *	  the field mask @p mask.
 *//** @brief Extract the Least Significant Bit from @p value. *//**
 * @brief Create a contiguous 64-bit bitmask starting at bit position @p l
 *        and ending at position @p h.
 *//**
 * @brief Create a contiguous bitmask starting at bit position @p l
 *        and ending at position @p h.
 *//** Number of bits in a long long int. *//** Number of bits in a long int. *//** @brief Cast @p x, a signed integer, to a <tt>void*</tt>. *//** @brief Cast @p x, a pointer, to a signed integer. *//** @brief Cast @p x, an unsigned integer, to a <tt>void*</tt>. *//** @brief Cast @p x, a pointer, to an unsigned integer. *//**
 * @defgroup sys-util Utility Functions
 * @ingroup utilities
 * @{
 *//** @brief Number of bits that make up a type *//* needs to be outside _ASMLANGUAGE so 'true' and 'false' can turn
 * into '1' and '0' for asm or linker scripts
 *//**
 * @file
 * @brief Misc utilities
 *
 * Misc utilities usable by the kernel and application code.
 */sys_port_trace_syscall_exit(id,name,__VA_ARGS__...)sys_port_trace_syscall_enter(id,name,__VA_ARGS__...)ZEPHYR_INCLUDE_TRACING_SYSCALL_H_defined CONFIG_SEGGER_SYSTEMVIEWdefined CONFIG_TRACING_TEST/* ZEPHYR_INCLUDE_TRACING_SYSCALL_H_ *//* end of subsys_tracing_syscall_apis *//**
 * @brief Trace syscall exit
 * @param id Syscall ID (as defined in the generated syscall_list.h)
 * @param name Syscall name as a token (ex: k_thread_create)
 * @param ... Other parameters passed to the syscall, if the syscall has a
 *            return, the return value is the last parameter in the list
 *//**
 * @brief Trace syscall entry
 * @param id Syscall ID (as defined in the generated syscall_list.h)
 * @param name Syscall name as a token (ex: k_thread_create)
 * @param ... Other parameters passed to the syscall
 *//**
 * @brief Syscall Tracing APIs
 * @defgroup subsys_tracing_apis_syscall Syscall Tracing APIs
 * @ingroup subsys_tracing_apis
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/tracingva_list__gnuc_va_list__va_list___VA_LIST_T_H_VA_LIST_DEFINED_VA_LIST_VA_LIST___va_copy(d,s)__builtin_va_copy(d,s)va_copy(d,s)va_arg(v,l)__builtin_va_arg(v,l)va_end(v)__builtin_va_end(v)va_start(v,l)__builtin_va_start(v,l)__GNUC_VA_LIST__need___va_list_ANSI_STDARG_H__STDARG_H!defined(__STRICT_ANSI__) || __STDC_VERSION__ + 0 >= 199900L \_BSD_VA_LISTdefined(__svr4__) || (defined(_SCO_DS) && !defined(__VA_LIST))__i860___SCO_DS!defined (_VA_LIST_) || defined (__BSD_NET2__) || defined (____386BSD____) || defined (__bsdi__) || defined (__sequent__) || defined (__FreeBSD__) || defined(WINNT)!(defined (__BSD_NET2__) || defined (____386BSD____) || defined (__bsdi__) || defined (__sequent__) || defined (__FreeBSD__))/* not _STDARG_H *//* not _ANSI_STDARG_H_ *//* _STDARG_H *//* not __svr4__ *//* not _VA_LIST_, except on certain systems *//* not _VA_LIST_DEFINED *//* not _VA_LIST *//* not _VA_LIST_T_H *//* not __va_list__ *//* The macro __va_list__ is used by BeOS.  *//* The macro _VA_LIST_T_H is used in the Bull dpx2  *//* The macro _VA_LIST is used in SCO Unix 3.2.  *//* The macro _VA_LIST_DEFINED is used in Windows NT 3.5  *//* The macro _VA_LIST_ is the same thing used by this file in Ultrix.
   But on BSD NET2 we must not test or define or undef it.
   (Note that the comments in NET 2's ansi.h
   are incorrect for _VA_LIST_--see stdio.h!)  *//* not __svr4__ || _SCO_DS *//* _VA_LIST_ *//* __i860__ *//* SVR4.2 uses _VA_LIST for an internal alias for va_list,
   so we must avoid testing it and setting it here.
   SVR4 uses _VA_LIST as a flag in stdarg.h, but we should
   have no conflict with that.  *//* We deliberately do not define va_list when called from
   stdio.h, because ANSI C says that stdio.h is not supposed to define
   va_list.  stdio.h needs to have access to that data type, 
   but must not use that name.  It should use the name __gnuc_va_list,
   which is safe because it is reserved for the implementation.  *//* Define va_list, if desired, from __gnuc_va_list. *//* Define the standard macros for the user,
   if this invocation was from the user program.  *//* Define __gnuc_va_list.  *//* not __need___va_list *//*
 * ISO C Standard:  7.15  Variable arguments  <stdarg.h>
 */<stdarg.h>K_SYSCALL_Z_ZSOCK_GETADDRINFO_INTERNALK_SYSCALL_Z_ERRNOK_SYSCALL_ZSOCK_SOCKETPAIRK_SYSCALL_ZSOCK_SOCKETK_SYSCALL_ZSOCK_SHUTDOWNK_SYSCALL_ZSOCK_SETSOCKOPTK_SYSCALL_ZSOCK_SENDTOK_SYSCALL_ZSOCK_SENDMSGK_SYSCALL_ZSOCK_SELECTK_SYSCALL_ZSOCK_RECVFROMK_SYSCALL_ZSOCK_POLLK_SYSCALL_ZSOCK_LISTENK_SYSCALL_ZSOCK_IOCTLK_SYSCALL_ZSOCK_INET_PTONK_SYSCALL_ZSOCK_GET_CONTEXT_OBJECTK_SYSCALL_ZSOCK_GETSOCKOPTK_SYSCALL_ZSOCK_GETSOCKNAMEK_SYSCALL_ZSOCK_GETPEERNAMEK_SYSCALL_ZSOCK_GETHOSTNAMEK_SYSCALL_ZSOCK_FCNTLK_SYSCALL_ZSOCK_CONNECTK_SYSCALL_ZSOCK_CLOSEK_SYSCALL_ZSOCK_BINDK_SYSCALL_ZSOCK_ACCEPTK_SYSCALL_WDT_SETUPK_SYSCALL_WDT_FEEDK_SYSCALL_WDT_DISABLEK_SYSCALL_W1_WRITE_BYTEK_SYSCALL_W1_WRITE_BLOCKK_SYSCALL_W1_WRITE_BITK_SYSCALL_W1_SEARCH_BUSK_SYSCALL_W1_RESET_BUSK_SYSCALL_W1_READ_BYTEK_SYSCALL_W1_READ_BLOCKK_SYSCALL_W1_READ_BITK_SYSCALL_W1_GET_SLAVE_COUNTK_SYSCALL_W1_CONFIGUREK_SYSCALL_W1_CHANGE_BUS_LOCKK_SYSCALL_USER_FAULTK_SYSCALL_UPDATEHUB_UPDATEK_SYSCALL_UPDATEHUB_REBOOTK_SYSCALL_UPDATEHUB_PROBEK_SYSCALL_UPDATEHUB_CONFIRMK_SYSCALL_UPDATEHUB_AUTOHANDLERK_SYSCALL_UART_MUX_FINDK_SYSCALL_TGPIO_PORT_GET_TIMEK_SYSCALL_TGPIO_PORT_GET_CYCLES_PER_SECONDK_SYSCALL_TGPIO_PIN_READ_TS_ECK_SYSCALL_TGPIO_PIN_PERIODIC_OUTPUTK_SYSCALL_TGPIO_PIN_DISABLEK_SYSCALL_TGPIO_PIN_CONFIG_EXT_TIMESTAMPK_SYSCALL_SYS_CACHE_DATA_INVD_RANGEK_SYSCALL_SYS_CACHE_DATA_FLUSH_RANGEK_SYSCALL_SYS_CACHE_DATA_FLUSH_AND_INVD_RANGEK_SYSCALL_SYSCON_WRITE_REGK_SYSCALL_SYSCON_READ_REGK_SYSCALL_SYSCON_GET_SIZEK_SYSCALL_SYSCON_GET_BASEK_SYSCALL_SPI_TRANSCEIVEK_SYSCALL_SPI_RELEASEK_SYSCALL_SMBUS_WORD_DATA_WRITEK_SYSCALL_SMBUS_WORD_DATA_READK_SYSCALL_SMBUS_SMBALERT_SET_CBK_SYSCALL_SMBUS_SMBALERT_REMOVE_CBK_SYSCALL_SMBUS_QUICKK_SYSCALL_SMBUS_PCALLK_SYSCALL_SMBUS_HOST_NOTIFY_SET_CBK_SYSCALL_SMBUS_HOST_NOTIFY_REMOVE_CBK_SYSCALL_SMBUS_GET_CONFIGK_SYSCALL_SMBUS_CONFIGUREK_SYSCALL_SMBUS_BYTE_WRITEK_SYSCALL_SMBUS_BYTE_READK_SYSCALL_SMBUS_BYTE_DATA_WRITEK_SYSCALL_SMBUS_BYTE_DATA_READK_SYSCALL_SMBUS_BLOCK_WRITEK_SYSCALL_SMBUS_BLOCK_READK_SYSCALL_SMBUS_BLOCK_PCALLK_SYSCALL_SIP_SVC_PLAT_UPDATE_TRANS_IDK_SYSCALL_SIP_SVC_PLAT_GET_TRANS_IDXK_SYSCALL_SIP_SVC_PLAT_GET_ERROR_CODEK_SYSCALL_SIP_SVC_PLAT_FUNC_ID_VALIDK_SYSCALL_SIP_SVC_PLAT_FREE_ASYNC_MEMORYK_SYSCALL_SIP_SVC_PLAT_FORMAT_TRANS_IDK_SYSCALL_SIP_SVC_PLAT_ASYNC_RES_RESK_SYSCALL_SIP_SVC_PLAT_ASYNC_RES_REQK_SYSCALL_SIP_SUPERVISORY_CALLK_SYSCALL_SENSOR_SAMPLE_FETCH_CHANK_SYSCALL_SENSOR_SAMPLE_FETCHK_SYSCALL_SENSOR_RECONFIGURE_READ_IODEVK_SYSCALL_SENSOR_GET_DECODERK_SYSCALL_SENSOR_CHANNEL_GETK_SYSCALL_SENSOR_ATTR_SETK_SYSCALL_SENSOR_ATTR_GETK_SYSCALL_SDHC_SET_IOK_SYSCALL_SDHC_REQUESTK_SYSCALL_SDHC_HW_RESETK_SYSCALL_SDHC_GET_HOST_PROPSK_SYSCALL_SDHC_EXECUTE_TUNINGK_SYSCALL_SDHC_ENABLE_INTERRUPTK_SYSCALL_SDHC_DISABLE_INTERRUPTK_SYSCALL_SDHC_CARD_PRESENTK_SYSCALL_SDHC_CARD_BUSYK_SYSCALL_RTIO_SUBMITK_SYSCALL_RTIO_SQE_COPY_IN_GET_HANDLESK_SYSCALL_RTIO_SQE_CANCELK_SYSCALL_RTIO_RELEASE_BUFFERK_SYSCALL_RTIO_CQE_GET_MEMPOOL_BUFFERK_SYSCALL_RTIO_CQE_COPY_OUTK_SYSCALL_RTC_UPDATE_SET_CALLBACKK_SYSCALL_RTC_SET_TIMEK_SYSCALL_RTC_SET_CALIBRATIONK_SYSCALL_RTC_GET_TIMEK_SYSCALL_RTC_GET_CALIBRATIONK_SYSCALL_RTC_ALARM_SET_TIMEK_SYSCALL_RTC_ALARM_SET_CALLBACKK_SYSCALL_RTC_ALARM_IS_PENDINGK_SYSCALL_RTC_ALARM_GET_TIMEK_SYSCALL_RTC_ALARM_GET_SUPPORTED_FIELDSK_SYSCALL_RETAINED_MEM_WRITEK_SYSCALL_RETAINED_MEM_SIZEK_SYSCALL_RETAINED_MEM_READK_SYSCALL_RETAINED_MEM_CLEARK_SYSCALL_RESET_STATUSK_SYSCALL_RESET_LINE_TOGGLEK_SYSCALL_RESET_LINE_DEASSERTK_SYSCALL_RESET_LINE_ASSERTK_SYSCALL_PWM_SET_CYCLESK_SYSCALL_PWM_GET_CYCLES_PER_SECK_SYSCALL_PWM_ENABLE_CAPTUREK_SYSCALL_PWM_DISABLE_CAPTUREK_SYSCALL_PWM_CAPTURE_CYCLESK_SYSCALL_PTP_CLOCK_GETK_SYSCALL_PS2_WRITEK_SYSCALL_PS2_READK_SYSCALL_PS2_ENABLE_CALLBACKK_SYSCALL_PS2_DISABLE_CALLBACKK_SYSCALL_PS2_CONFIGK_SYSCALL_PHY_WRITEK_SYSCALL_PHY_READK_SYSCALL_PHY_LINK_CALLBACK_SETK_SYSCALL_PHY_GET_LINK_STATEK_SYSCALL_PHY_CONFIGURE_LINKK_SYSCALL_PECI_TRANSFERK_SYSCALL_PECI_ENABLEK_SYSCALL_PECI_DISABLEK_SYSCALL_PECI_CONFIGK_SYSCALL_NRF_QSPI_NOR_XIP_ENABLEK_SYSCALL_NET_IF_IPV6_ADDR_RM_BY_INDEXK_SYSCALL_NET_IF_IPV6_ADDR_LOOKUP_BY_INDEXK_SYSCALL_NET_IF_IPV6_ADDR_ADD_BY_INDEXK_SYSCALL_NET_IF_IPV4_SET_NETMASK_BY_INDEXK_SYSCALL_NET_IF_IPV4_SET_GW_BY_INDEXK_SYSCALL_NET_IF_IPV4_ADDR_RM_BY_INDEXK_SYSCALL_NET_IF_IPV4_ADDR_LOOKUP_BY_INDEXK_SYSCALL_NET_IF_IPV4_ADDR_ADD_BY_INDEXK_SYSCALL_NET_IF_GET_BY_INDEXK_SYSCALL_NET_ETH_GET_PTP_CLOCK_BY_INDEXK_SYSCALL_NET_ADDR_PTONK_SYSCALL_NET_ADDR_NTOPK_SYSCALL_MDIO_WRITE_C45K_SYSCALL_MDIO_WRITEK_SYSCALL_MDIO_READ_C45K_SYSCALL_MDIO_READK_SYSCALL_MDIO_BUS_ENABLEK_SYSCALL_MDIO_BUS_DISABLEK_SYSCALL_MBOX_SET_ENABLEDK_SYSCALL_MBOX_SENDK_SYSCALL_MBOX_MTU_GETK_SYSCALL_MBOX_MAX_CHANNELS_GETK_SYSCALL_MAXIM_DS3231_REQ_SYNCPOINTK_SYSCALL_MAXIM_DS3231_GET_SYNCPOINTK_SYSCALL_LED_WRITE_CHANNELSK_SYSCALL_LED_SET_COLORK_SYSCALL_LED_SET_CHANNELK_SYSCALL_LED_SET_BRIGHTNESSK_SYSCALL_LED_ONK_SYSCALL_LED_OFFK_SYSCALL_LED_GET_INFOK_SYSCALL_LED_BLINKK_SYSCALL_KSCAN_ENABLE_CALLBACKK_SYSCALL_KSCAN_DISABLE_CALLBACKK_SYSCALL_KSCAN_CONFIGK_SYSCALL_IVSHMEM_SET_STATEK_SYSCALL_IVSHMEM_REGISTER_HANDLERK_SYSCALL_IVSHMEM_INT_PEERK_SYSCALL_IVSHMEM_GET_VECTORSK_SYSCALL_IVSHMEM_GET_STATEK_SYSCALL_IVSHMEM_GET_RW_MEM_SECTIONK_SYSCALL_IVSHMEM_GET_PROTOCOLK_SYSCALL_IVSHMEM_GET_OUTPUT_MEM_SECTIONK_SYSCALL_IVSHMEM_GET_MEMK_SYSCALL_IVSHMEM_GET_MAX_PEERSK_SYSCALL_IVSHMEM_GET_IDK_SYSCALL_IVSHMEM_ENABLE_INTERRUPTSK_SYSCALL_IPM_SET_ENABLEDK_SYSCALL_IPM_SENDK_SYSCALL_IPM_MAX_ID_VAL_GETK_SYSCALL_IPM_MAX_DATA_SIZE_GETK_SYSCALL_IPM_COMPLETEK_SYSCALL_I3C_TRANSFERK_SYSCALL_I3C_DO_CCCK_SYSCALL_I2S_TRIGGERK_SYSCALL_I2S_CONFIGUREK_SYSCALL_I2S_BUF_WRITEK_SYSCALL_I2S_BUF_READK_SYSCALL_I2C_TRANSFERK_SYSCALL_I2C_TARGET_DRIVER_UNREGISTERK_SYSCALL_I2C_TARGET_DRIVER_REGISTERK_SYSCALL_I2C_RECOVER_BUSK_SYSCALL_I2C_GET_CONFIGK_SYSCALL_I2C_CONFIGUREK_SYSCALL_HWSPINLOCK_UNLOCKK_SYSCALL_HWSPINLOCK_TRYLOCKK_SYSCALL_HWSPINLOCK_LOCKK_SYSCALL_HWSPINLOCK_GET_MAX_IDK_SYSCALL_HWINFO_GET_SUPPORTED_RESET_CAUSEK_SYSCALL_HWINFO_GET_RESET_CAUSEK_SYSCALL_HWINFO_GET_DEVICE_IDK_SYSCALL_HWINFO_CLEAR_RESET_CAUSEK_SYSCALL_GPIO_PORT_TOGGLE_BITSK_SYSCALL_GPIO_PORT_SET_MASKED_RAWK_SYSCALL_GPIO_PORT_SET_BITS_RAWK_SYSCALL_GPIO_PORT_GET_RAWK_SYSCALL_GPIO_PORT_GET_DIRECTIONK_SYSCALL_GPIO_PORT_CLEAR_BITS_RAWK_SYSCALL_GPIO_PIN_INTERRUPT_CONFIGUREK_SYSCALL_GPIO_PIN_GET_CONFIGK_SYSCALL_GPIO_PIN_CONFIGUREK_SYSCALL_GPIO_GET_PENDING_INTK_SYSCALL_GNSS_SET_PERIODIC_CONFIGK_SYSCALL_GNSS_SET_NAVIGATION_MODEK_SYSCALL_GNSS_SET_FIX_RATEK_SYSCALL_GNSS_SET_ENABLED_SYSTEMSK_SYSCALL_GNSS_GET_SUPPORTED_SYSTEMSK_SYSCALL_GNSS_GET_PERIODIC_CONFIGK_SYSCALL_GNSS_GET_NAVIGATION_MODEK_SYSCALL_GNSS_GET_FIX_RATEK_SYSCALL_GNSS_GET_ENABLED_SYSTEMSK_SYSCALL_FUEL_GAUGE_SET_PROPSK_SYSCALL_FUEL_GAUGE_SET_PROPK_SYSCALL_FUEL_GAUGE_GET_PROPSK_SYSCALL_FUEL_GAUGE_GET_PROPK_SYSCALL_FUEL_GAUGE_GET_BUFFER_PROPK_SYSCALL_FUEL_GAUGE_BATTERY_CUTOFFK_SYSCALL_FLASH_WRITEK_SYSCALL_FLASH_SIMULATOR_GET_MEMORYK_SYSCALL_FLASH_SFDP_READK_SYSCALL_FLASH_READ_JEDEC_IDK_SYSCALL_FLASH_READK_SYSCALL_FLASH_GET_WRITE_BLOCK_SIZEK_SYSCALL_FLASH_GET_PARAMETERSK_SYSCALL_FLASH_GET_PAGE_INFO_BY_OFFSK_SYSCALL_FLASH_GET_PAGE_INFO_BY_IDXK_SYSCALL_FLASH_GET_PAGE_COUNTK_SYSCALL_FLASH_EX_OPK_SYSCALL_FLASH_ERASEK_SYSCALL_ESPI_WRITE_REQUESTK_SYSCALL_ESPI_WRITE_LPC_REQUESTK_SYSCALL_ESPI_WRITE_FLASHK_SYSCALL_ESPI_SEND_VWIREK_SYSCALL_ESPI_SEND_OOBK_SYSCALL_ESPI_SAF_SET_PROTECTION_REGIONSK_SYSCALL_ESPI_SAF_GET_CHANNEL_STATUSK_SYSCALL_ESPI_SAF_FLASH_WRITEK_SYSCALL_ESPI_SAF_FLASH_READK_SYSCALL_ESPI_SAF_FLASH_ERASEK_SYSCALL_ESPI_SAF_CONFIGK_SYSCALL_ESPI_SAF_ACTIVATEK_SYSCALL_ESPI_RECEIVE_VWIREK_SYSCALL_ESPI_RECEIVE_OOBK_SYSCALL_ESPI_READ_REQUESTK_SYSCALL_ESPI_READ_LPC_REQUESTK_SYSCALL_ESPI_READ_FLASHK_SYSCALL_ESPI_GET_CHANNEL_STATUSK_SYSCALL_ESPI_FLASH_ERASEK_SYSCALL_ESPI_CONFIGK_SYSCALL_ENTROPY_GET_ENTROPYK_SYSCALL_EMUL_FUEL_GAUGE_SET_BATTERY_CHARGINGK_SYSCALL_EMUL_FUEL_GAUGE_IS_BATTERY_CUTOFFK_SYSCALL_EEPROM_WRITEK_SYSCALL_EEPROM_READK_SYSCALL_EEPROM_GET_SIZEK_SYSCALL_DMA_SUSPENDK_SYSCALL_DMA_STOPK_SYSCALL_DMA_STARTK_SYSCALL_DMA_RESUMEK_SYSCALL_DMA_REQUEST_CHANNELK_SYSCALL_DMA_RELEASE_CHANNELK_SYSCALL_DMA_CHAN_FILTERK_SYSCALL_DAC_WRITE_VALUEK_SYSCALL_DAC_CHANNEL_SETUPK_SYSCALL_COUNTER_US_TO_TICKSK_SYSCALL_COUNTER_TICKS_TO_USK_SYSCALL_COUNTER_STOPK_SYSCALL_COUNTER_STARTK_SYSCALL_COUNTER_SET_TOP_VALUEK_SYSCALL_COUNTER_SET_GUARD_PERIODK_SYSCALL_COUNTER_SET_CHANNEL_ALARMK_SYSCALL_COUNTER_IS_COUNTING_UPK_SYSCALL_COUNTER_GET_VALUE_64K_SYSCALL_COUNTER_GET_VALUEK_SYSCALL_COUNTER_GET_TOP_VALUEK_SYSCALL_COUNTER_GET_PENDING_INTK_SYSCALL_COUNTER_GET_NUM_OF_CHANNELSK_SYSCALL_COUNTER_GET_MAX_TOP_VALUEK_SYSCALL_COUNTER_GET_GUARD_PERIODK_SYSCALL_COUNTER_GET_FREQUENCYK_SYSCALL_COUNTER_CANCEL_CHANNEL_ALARMK_SYSCALL_CHARGER_SET_PROPK_SYSCALL_CHARGER_GET_PROPK_SYSCALL_CAN_STOPK_SYSCALL_CAN_STATS_GET_STUFF_ERRORSK_SYSCALL_CAN_STATS_GET_RX_OVERRUNSK_SYSCALL_CAN_STATS_GET_FORM_ERRORSK_SYSCALL_CAN_STATS_GET_CRC_ERRORSK_SYSCALL_CAN_STATS_GET_BIT_ERRORSK_SYSCALL_CAN_STATS_GET_BIT1_ERRORSK_SYSCALL_CAN_STATS_GET_BIT0_ERRORSK_SYSCALL_CAN_STATS_GET_ACK_ERRORSK_SYSCALL_CAN_STARTK_SYSCALL_CAN_SET_TIMING_DATAK_SYSCALL_CAN_SET_TIMINGK_SYSCALL_CAN_SET_MODEK_SYSCALL_CAN_SET_BITRATE_DATAK_SYSCALL_CAN_SET_BITRATEK_SYSCALL_CAN_SENDK_SYSCALL_CAN_REMOVE_RX_FILTERK_SYSCALL_CAN_RECOVERK_SYSCALL_CAN_GET_TIMING_MINK_SYSCALL_CAN_GET_TIMING_MAXK_SYSCALL_CAN_GET_TIMING_DATA_MINK_SYSCALL_CAN_GET_TIMING_DATA_MAXK_SYSCALL_CAN_GET_STATEK_SYSCALL_CAN_GET_MAX_FILTERSK_SYSCALL_CAN_GET_MAX_BITRATEK_SYSCALL_CAN_GET_CORE_CLOCKK_SYSCALL_CAN_GET_CAPABILITIESK_SYSCALL_CAN_CALC_TIMING_DATAK_SYSCALL_CAN_CALC_TIMINGK_SYSCALL_CAN_ADD_RX_FILTER_MSGQK_SYSCALL_BC12_SET_ROLEK_SYSCALL_BC12_SET_RESULT_CBK_SYSCALL_BBRAM_WRITEK_SYSCALL_BBRAM_READK_SYSCALL_BBRAM_GET_SIZEK_SYSCALL_BBRAM_CHECK_STANDBY_POWERK_SYSCALL_BBRAM_CHECK_POWERK_SYSCALL_BBRAM_CHECK_INVALIDK_SYSCALL_AUXDISPLAY_WRITEK_SYSCALL_AUXDISPLAY_POSITION_BLINKING_SET_ENABLEDK_SYSCALL_AUXDISPLAY_IS_BUSYK_SYSCALL_AUXDISPLAY_DISPLAY_POSITION_SETK_SYSCALL_AUXDISPLAY_DISPLAY_POSITION_GETK_SYSCALL_AUXDISPLAY_DISPLAY_ONK_SYSCALL_AUXDISPLAY_DISPLAY_OFFK_SYSCALL_AUXDISPLAY_CUSTOM_COMMANDK_SYSCALL_AUXDISPLAY_CUSTOM_CHARACTER_SETK_SYSCALL_AUXDISPLAY_CURSOR_SHIFT_SETK_SYSCALL_AUXDISPLAY_CURSOR_SET_ENABLEDK_SYSCALL_AUXDISPLAY_CURSOR_POSITION_SETK_SYSCALL_AUXDISPLAY_CURSOR_POSITION_GETK_SYSCALL_AUXDISPLAY_CLEARK_SYSCALL_AUXDISPLAY_CAPABILITIES_GETK_SYSCALL_AUXDISPLAY_BRIGHTNESS_SETK_SYSCALL_AUXDISPLAY_BRIGHTNESS_GETK_SYSCALL_AUXDISPLAY_BACKLIGHT_SETK_SYSCALL_AUXDISPLAY_BACKLIGHT_GETK_SYSCALL_ATOMIC_XORK_SYSCALL_ATOMIC_SUBK_SYSCALL_ATOMIC_SETK_SYSCALL_ATOMIC_PTR_SETK_SYSCALL_ATOMIC_PTR_CASK_SYSCALL_ATOMIC_ORK_SYSCALL_ATOMIC_NANDK_SYSCALL_ATOMIC_CASK_SYSCALL_ATOMIC_ANDK_SYSCALL_ATOMIC_ADDK_SYSCALL_ADC_READ_ASYNCK_SYSCALL_ADC_READK_SYSCALL_ADC_CHANNEL_SETUPK_SYSCALL_LIMITK_SYSCALL_BADK_SYSCALL_Z_SYS_MUTEX_KERNEL_UNLOCKK_SYSCALL_Z_SYS_MUTEX_KERNEL_LOCKK_SYSCALL_Z_LOG_MSG_STATIC_CREATEK_SYSCALL_Z_LOG_MSG_SIMPLE_CREATE_2K_SYSCALL_Z_LOG_MSG_SIMPLE_CREATE_1K_SYSCALL_Z_LOG_MSG_SIMPLE_CREATE_0K_SYSCALL_Z_LOG_MSG_RUNTIME_VCREATEK_SYSCALL_ZEPHYR_WRITE_STDOUTK_SYSCALL_ZEPHYR_READ_STDINK_SYSCALL_ZEPHYR_FWRITEK_SYSCALL_ZEPHYR_FPUTCK_SYSCALL_UART_TX_U16K_SYSCALL_UART_TX_ABORTK_SYSCALL_UART_TXK_SYSCALL_UART_RX_ENABLE_U16K_SYSCALL_UART_RX_ENABLEK_SYSCALL_UART_RX_DISABLEK_SYSCALL_UART_POLL_OUT_U16K_SYSCALL_UART_POLL_OUTK_SYSCALL_UART_POLL_IN_U16K_SYSCALL_UART_POLL_INK_SYSCALL_UART_LINE_CTRL_SETK_SYSCALL_UART_LINE_CTRL_GETK_SYSCALL_UART_IRQ_UPDATEK_SYSCALL_UART_IRQ_TX_ENABLEK_SYSCALL_UART_IRQ_TX_DISABLEK_SYSCALL_UART_IRQ_RX_ENABLEK_SYSCALL_UART_IRQ_RX_DISABLEK_SYSCALL_UART_IRQ_IS_PENDINGK_SYSCALL_UART_IRQ_ERR_ENABLEK_SYSCALL_UART_IRQ_ERR_DISABLEK_SYSCALL_UART_ERR_CHECKK_SYSCALL_UART_DRV_CMDK_SYSCALL_UART_CONFIG_GETK_SYSCALL_UART_CONFIGUREK_SYSCALL_SYS_RAND_GETK_SYSCALL_SYS_RAND32_GETK_SYSCALL_SYS_CSRAND_GETK_SYSCALL_SYS_CLOCK_HW_CYCLES_PER_SEC_RUNTIME_GETK_SYSCALL_LOG_PROCESSK_SYSCALL_LOG_PANICK_SYSCALL_LOG_FILTER_SETK_SYSCALL_LOG_BUFFERED_CNTK_SYSCALL_K_YIELDK_SYSCALL_K_WAKEUPK_SYSCALL_K_USLEEPK_SYSCALL_K_UPTIME_TICKSK_SYSCALL_K_TIMER_USER_DATA_SETK_SYSCALL_K_TIMER_USER_DATA_GETK_SYSCALL_K_TIMER_STOPK_SYSCALL_K_TIMER_STATUS_SYNCK_SYSCALL_K_TIMER_STATUS_GETK_SYSCALL_K_TIMER_STARTK_SYSCALL_K_TIMER_REMAINING_TICKSK_SYSCALL_K_TIMER_EXPIRES_TICKSK_SYSCALL_K_THREAD_TIMEOUT_REMAINING_TICKSK_SYSCALL_K_THREAD_TIMEOUT_EXPIRES_TICKSK_SYSCALL_K_THREAD_SUSPENDK_SYSCALL_K_THREAD_STARTK_SYSCALL_K_THREAD_STACK_SPACE_GETK_SYSCALL_K_THREAD_STACK_FREEK_SYSCALL_K_THREAD_STACK_ALLOCK_SYSCALL_K_THREAD_RESUMEK_SYSCALL_K_THREAD_PRIORITY_SETK_SYSCALL_K_THREAD_PRIORITY_GETK_SYSCALL_K_THREAD_NAME_SETK_SYSCALL_K_THREAD_NAME_COPYK_SYSCALL_K_THREAD_JOINK_SYSCALL_K_THREAD_DEADLINE_SETK_SYSCALL_K_THREAD_CUSTOM_DATA_SETK_SYSCALL_K_THREAD_CUSTOM_DATA_GETK_SYSCALL_K_THREAD_CREATEK_SYSCALL_K_THREAD_ABORTK_SYSCALL_K_STR_OUTK_SYSCALL_K_STACK_PUSHK_SYSCALL_K_STACK_POPK_SYSCALL_K_STACK_ALLOC_INITK_SYSCALL_K_SLEEPK_SYSCALL_K_SEM_TAKEK_SYSCALL_K_SEM_RESETK_SYSCALL_K_SEM_INITK_SYSCALL_K_SEM_GIVEK_SYSCALL_K_SEM_COUNT_GETK_SYSCALL_K_SCHED_CURRENT_THREAD_QUERYK_SYSCALL_K_QUEUE_PEEK_TAILK_SYSCALL_K_QUEUE_PEEK_HEADK_SYSCALL_K_QUEUE_IS_EMPTYK_SYSCALL_K_QUEUE_INITK_SYSCALL_K_QUEUE_GETK_SYSCALL_K_QUEUE_CANCEL_WAITK_SYSCALL_K_QUEUE_ALLOC_PREPENDK_SYSCALL_K_QUEUE_ALLOC_APPENDK_SYSCALL_K_POLL_SIGNAL_RESETK_SYSCALL_K_POLL_SIGNAL_RAISEK_SYSCALL_K_POLL_SIGNAL_INITK_SYSCALL_K_POLL_SIGNAL_CHECKK_SYSCALL_K_POLLK_SYSCALL_K_PIPE_WRITE_AVAILK_SYSCALL_K_PIPE_READ_AVAILK_SYSCALL_K_PIPE_PUTK_SYSCALL_K_PIPE_GETK_SYSCALL_K_PIPE_FLUSHK_SYSCALL_K_PIPE_BUFFER_FLUSHK_SYSCALL_K_PIPE_ALLOC_INITK_SYSCALL_K_OBJECT_RELEASEK_SYSCALL_K_OBJECT_ALLOC_SIZEK_SYSCALL_K_OBJECT_ALLOCK_SYSCALL_K_OBJECT_ACCESS_GRANTK_SYSCALL_K_MUTEX_UNLOCKK_SYSCALL_K_MUTEX_LOCKK_SYSCALL_K_MUTEX_INITK_SYSCALL_K_MSGQ_PUTK_SYSCALL_K_MSGQ_PURGEK_SYSCALL_K_MSGQ_PEEK_ATK_SYSCALL_K_MSGQ_PEEKK_SYSCALL_K_MSGQ_NUM_USED_GETK_SYSCALL_K_MSGQ_NUM_FREE_GETK_SYSCALL_K_MSGQ_GET_ATTRSK_SYSCALL_K_MSGQ_GETK_SYSCALL_K_MSGQ_ALLOC_INITK_SYSCALL_K_MEM_PAGING_THREAD_STATS_GETK_SYSCALL_K_MEM_PAGING_STATS_GETK_SYSCALL_K_MEM_PAGING_HISTOGRAM_EVICTION_GETK_SYSCALL_K_MEM_PAGING_HISTOGRAM_BACKING_STORE_PAGE_OUT_GETK_SYSCALL_K_MEM_PAGING_HISTOGRAM_BACKING_STORE_PAGE_IN_GETK_SYSCALL_K_IS_PREEMPT_THREADK_SYSCALL_K_FUTEX_WAKEK_SYSCALL_K_FUTEX_WAITK_SYSCALL_K_FLOAT_ENABLEK_SYSCALL_K_FLOAT_DISABLEK_SYSCALL_K_EVENT_WAIT_ALLK_SYSCALL_K_EVENT_WAITK_SYSCALL_K_EVENT_SET_MASKEDK_SYSCALL_K_EVENT_SETK_SYSCALL_K_EVENT_POSTK_SYSCALL_K_EVENT_INITK_SYSCALL_K_EVENT_CLEARK_SYSCALL_K_CONDVAR_WAITK_SYSCALL_K_CONDVAR_SIGNALK_SYSCALL_K_CONDVAR_INITK_SYSCALL_K_CONDVAR_BROADCASTK_SYSCALL_K_BUSY_WAITK_SYSCALL_DEVICE_IS_READYK_SYSCALL_DEVICE_GET_BINDINGK_SYSCALL_CLOCK_GETTIMEZEPHYR_SYSCALL_LIST_H/* ZEPHYR_SYSCALL_LIST_H *//* Following syscalls are not used in image *//* auto-generated by gen_syscalls.py, don't edit */USER_DATA_SEG0x330x2bZEPHYR_INCLUDE_ARCH_X86_IA32_SYSCALL_H_/* ZEPHYR_INCLUDE_ARCH_X86_IA32_SYSCALL_H_ *//* On x86, read the CS register (which cannot be manually set) *//* Syscall invocation macros. x86-specific machine constraints used to ensure
 * args land in the proper registers, see implementation of
 * z_x86_syscall_entry_stub in userspace.S
 *//* at dpl=3 *//**
 * @file
 * @brief x86 (IA32) specific syscall header
 *
 * This header contains the x86 specific syscall interface.  It is
 * included by the syscall interface architecture-abstraction header
 * (include/arch/syscall.h)
 *//*
 * Copyright (c) 2018 Linaro Limited.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/arch/x86/ia32<zephyr/arch/x86/ia32/syscall.h>ZEPHYR_INCLUDE_ARCH_SYSCALL_H_defined(CONFIG_X86_64)defined(CONFIG_RISCV)/* ZEPHYR_INCLUDE_ARCH_SYSCALL_H_ *//*
 * Copyright (c) 1997-2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* syscall.h - automatically selects the correct syscall.h file to include */<syscall_list.h>k_is_user_contextz_syscall_trap_k_syscall_handler_tZEPHYR_INCLUDE_SYSCALL_H_defined(__ZEPHYR_SUPERVISOR__)defined(__ZEPHYR_USER__)/**
 * Indicate whether the CPU is currently in user mode
 *
 * @return true if the CPU is currently running with user permissions
 *//* True if a syscall function must trap to the kernel, usually a
 * compile-time decision.
 *//**
 * @typedef _k_syscall_handler_t
 * @brief System call handler function type
 *
 * These are kernel-side skeleton functions for system calls. They are
 * necessary to sanitize the arguments passed into the system call:
 *
 * - Any kernel object or device pointers are validated with _SYSCALL_IS_OBJ()
 * - Any memory buffers passed in are checked to ensure that the calling thread
 *   actually has access to them
 * - Many kernel calls do no sanity checking of parameters other than
 *   assertions. The handler must check all of these conditions using
 *   _SYSCALL_ASSERT()
 * - If the system call has more than 6 arguments, then arg6 will be a pointer
 *   to some struct containing arguments 6+. The struct itself needs to be
 *   validated like any other buffer passed in from userspace, and its members
 *   individually validated (if necessary) and then passed to the real
 *   implementation like normal arguments
 *
 * Even if the system call implementation has no return value, these always
 * return something, even 0, to prevent register leakage to userspace.
 *
 * Once everything has been validated, the real implementation will be executed.
 *
 * @param arg1 system call argument 1
 * @param arg2 system call argument 2
 * @param arg3 system call argument 3
 * @param arg4 system call argument 4
 * @param arg5 system call argument 5
 * @param arg6 system call argument 6
 * @param ssf System call stack frame pointer. Used to generate kernel oops
 *            via _arch_syscall_oops_at(). Contents are arch-specific.
 * @return system call return value, or 0 if the system call implementation
 *         return void
 *
 *//*
 * System Call Declaration macros
 *
 * These macros are used in public header files to declare system calls.
 * They generate inline functions which have different implementations
 * depending on the current compilation context:
 *
 * - Kernel-only code, or CONFIG_USERSPACE disabled, these inlines will
 *   directly call the implementation
 * - User-only code, these inlines will marshal parameters and elevate
 *   privileges
 * - Mixed or indeterminate code, these inlines will do a runtime check
 *   to determine what course of action is needed.
 *
 * All system calls require a verifier function and an implementation
 * function.  These must follow a naming convention. For a system call
 * named k_foo():
 *
 * - The handler function will be named z_vrfy_k_foo(). Handler
 *   functions have the same type signature as the wrapped call,
 *   verify arguments passed up from userspace, and call the
 *   implementation function. See documentation for that typedef for
 *   more information.  - The implementation function will be named
 *   z_impl_k_foo(). This is the actual implementation of the system
 *   call.
 *//*
 * Copyright (c) 2017, Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/syscall.h><zephyr/tracing/tracing_syscall.h>sys_clock_hw_cycles_per_sec_runtime_getZ_INCLUDE_SYSCALLS_TIME_UNITS_Hdefined(CONFIG_TRACING_SYSCALL)DISABLE_SYSCALL_TRACINGz_impl_sys_clock_hw_cycles_per_sec_runtime_get/* include guard *//home/haojie/zephyrproject/zephyr/build/zephyr/include/generated/syscalls<syscalls/time_units.h>z_clock_hw_cycles_per_secTIME_CONSTEXPRk_ticks_to_cyc_ceil64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_cyc, Z_CCYC, true, false)k_ticks_to_cyc_ceil32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_cyc, Z_CCYC, true, false)k_ticks_to_cyc_near64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_cyc, Z_CCYC, false, true)k_ticks_to_cyc_near32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_cyc, Z_CCYC, false, true)k_ticks_to_cyc_floor64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_cyc, Z_CCYC, false, false)k_ticks_to_cyc_floor32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_cyc, Z_CCYC, false, false)k_ticks_to_ns_ceil64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_ns, true, true, false)k_ticks_to_ns_ceil32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_ns, true, true, false)k_ticks_to_ns_near64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_ns, true, false, true)k_ticks_to_ns_near32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_ns, true, false, true)k_ticks_to_ns_floor64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_ns, true, false, false)k_ticks_to_ns_floor32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_ns, true, false, false)k_ticks_to_us_ceil64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_us, true, true, false)k_ticks_to_us_ceil32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_us, true, true, false)k_ticks_to_us_near64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_us, true, false, true)k_ticks_to_us_near32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_us, true, false, true)k_ticks_to_us_floor64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_us, true, false, false)k_ticks_to_us_floor32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_us, true, false, false)k_ticks_to_ms_ceil64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_ms, true, true, false)k_ticks_to_ms_ceil32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_ms, true, true, false)k_ticks_to_ms_near64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_ms, true, false, true)k_ticks_to_ms_near32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_ms, true, false, true)k_ticks_to_ms_floor64(t)z_tmcvt_64(t, Z_HZ_ticks, Z_HZ_ms, true, false, false)k_ticks_to_ms_floor32(t)z_tmcvt_32(t, Z_HZ_ticks, Z_HZ_ms, true, false, false)k_cyc_to_ticks_ceil64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ticks, Z_CCYC, true, false)k_cyc_to_ticks_ceil32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ticks, Z_CCYC, true, false)k_cyc_to_ticks_near64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ticks, Z_CCYC, false, true)k_cyc_to_ticks_near32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ticks, Z_CCYC, false, true)k_cyc_to_ticks_floor64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ticks, Z_CCYC, false, false)k_cyc_to_ticks_floor32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ticks, Z_CCYC, false, false)k_cyc_to_ns_ceil64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ns, Z_CCYC, true, false)k_cyc_to_ns_ceil32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ns, Z_CCYC, true, false)k_cyc_to_ns_near64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ns, Z_CCYC, false, true)k_cyc_to_ns_near32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ns, Z_CCYC, false, true)k_cyc_to_ns_floor64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ns, Z_CCYC, false, false)k_cyc_to_ns_floor32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ns, Z_CCYC, false, false)k_cyc_to_us_ceil64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_us, Z_CCYC, true, false)k_cyc_to_us_ceil32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_us, Z_CCYC, true, false)k_cyc_to_us_near64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_us, Z_CCYC, false, true)k_cyc_to_us_near32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_us, Z_CCYC, false, true)k_cyc_to_us_floor64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_us, Z_CCYC, false, false)k_cyc_to_us_floor32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_us, Z_CCYC, false, false)k_cyc_to_ms_ceil64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ms, Z_CCYC, true, false)k_cyc_to_ms_ceil32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ms, Z_CCYC, true, false)k_cyc_to_ms_near64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ms, Z_CCYC, false, true)k_cyc_to_ms_near32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ms, Z_CCYC, false, true)k_cyc_to_ms_floor64(t)z_tmcvt_64(t, Z_HZ_cyc, Z_HZ_ms, Z_CCYC, false, false)k_cyc_to_ms_floor32(t)z_tmcvt_32(t, Z_HZ_cyc, Z_HZ_ms, Z_CCYC, false, false)k_ns_to_ticks_ceil64(t)z_tmcvt_64(t, Z_HZ_ns, Z_HZ_ticks, true, true, false)k_ns_to_ticks_ceil32(t)z_tmcvt_32(t, Z_HZ_ns, Z_HZ_ticks, true, true, false)k_ns_to_ticks_near64(t)z_tmcvt_64(t, Z_HZ_ns, Z_HZ_ticks, true, false, true)k_ns_to_ticks_near32(t)z_tmcvt_32(t, Z_HZ_ns, Z_HZ_ticks, true, false, true)k_ns_to_ticks_floor64(t)z_tmcvt_64(t, Z_HZ_ns, Z_HZ_ticks, true, false, false)k_ns_to_ticks_floor32(t)z_tmcvt_32(t, Z_HZ_ns, Z_HZ_ticks, true, false, false)k_ns_to_cyc_ceil64(t)z_tmcvt_64(t, Z_HZ_ns, Z_HZ_cyc, Z_CCYC, true, false)k_ns_to_cyc_ceil32(t)z_tmcvt_32(t, Z_HZ_ns, Z_HZ_cyc, Z_CCYC, true, false)k_ns_to_cyc_near64(t)z_tmcvt_64(t, Z_HZ_ns, Z_HZ_cyc, Z_CCYC, false, true)k_ns_to_cyc_near32(t)z_tmcvt_32(t, Z_HZ_ns, Z_HZ_cyc, Z_CCYC, false, true)k_ns_to_cyc_floor64(t)z_tmcvt_64(t, Z_HZ_ns, Z_HZ_cyc, Z_CCYC, false, false)k_ns_to_cyc_floor32(t)z_tmcvt_32(t, Z_HZ_ns, Z_HZ_cyc, Z_CCYC, false, false)k_us_to_ticks_ceil64(t)z_tmcvt_64(t, Z_HZ_us, Z_HZ_ticks, true, true, false)k_us_to_ticks_ceil32(t)z_tmcvt_32(t, Z_HZ_us, Z_HZ_ticks, true, true, false)k_us_to_ticks_near64(t)z_tmcvt_64(t, Z_HZ_us, Z_HZ_ticks, true, false, true)k_us_to_ticks_near32(t)z_tmcvt_32(t, Z_HZ_us, Z_HZ_ticks, true, false, true)k_us_to_ticks_floor64(t)z_tmcvt_64(t, Z_HZ_us, Z_HZ_ticks, true, false, false)k_us_to_ticks_floor32(t)z_tmcvt_32(t, Z_HZ_us, Z_HZ_ticks, true, false, false)k_us_to_cyc_ceil64(t)z_tmcvt_64(t, Z_HZ_us, Z_HZ_cyc, Z_CCYC, true, false)k_us_to_cyc_ceil32(t)z_tmcvt_32(t, Z_HZ_us, Z_HZ_cyc, Z_CCYC, true, false)k_us_to_cyc_near64(t)z_tmcvt_64(t, Z_HZ_us, Z_HZ_cyc, Z_CCYC, false, true)k_us_to_cyc_near32(t)z_tmcvt_32(t, Z_HZ_us, Z_HZ_cyc, Z_CCYC, false, true)k_us_to_cyc_floor64(t)z_tmcvt_64(t, Z_HZ_us, Z_HZ_cyc, Z_CCYC, false, false)k_us_to_cyc_floor32(t)z_tmcvt_32(t, Z_HZ_us, Z_HZ_cyc, Z_CCYC, false, false)k_ms_to_ticks_ceil64(t)z_tmcvt_64(t, Z_HZ_ms, Z_HZ_ticks, true, true, false)k_ms_to_ticks_ceil32(t)z_tmcvt_32(t, Z_HZ_ms, Z_HZ_ticks, true, true, false)k_ms_to_ticks_near64(t)z_tmcvt_64(t, Z_HZ_ms, Z_HZ_ticks, true, false, true)k_ms_to_ticks_near32(t)z_tmcvt_32(t, Z_HZ_ms, Z_HZ_ticks, true, false, true)k_ms_to_ticks_floor64(t)z_tmcvt_64(t, Z_HZ_ms, Z_HZ_ticks, true, false, false)k_ms_to_ticks_floor32(t)z_tmcvt_32(t, Z_HZ_ms, Z_HZ_ticks, true, false, false)k_ms_to_cyc_ceil64(t)z_tmcvt_64(t, Z_HZ_ms, Z_HZ_cyc, Z_CCYC, true, false)k_ms_to_cyc_ceil32(t)z_tmcvt_32(t, Z_HZ_ms, Z_HZ_cyc, Z_CCYC, true, false)k_ms_to_cyc_near64(t)z_tmcvt_64(t, Z_HZ_ms, Z_HZ_cyc, Z_CCYC, false, true)k_ms_to_cyc_near32(t)z_tmcvt_32(t, Z_HZ_ms, Z_HZ_cyc, Z_CCYC, false, true)k_ms_to_cyc_floor64(t)z_tmcvt_64(t, Z_HZ_ms, Z_HZ_cyc, Z_CCYC, false, false)k_ms_to_cyc_floor32(t)z_tmcvt_32(t, Z_HZ_ms, Z_HZ_cyc, Z_CCYC, false, false)Z_CCYC(!IS_ENABLED(CONFIG_TIMER_READS_ITS_FREQUENCY_AT_RUNTIME))Z_HZ_ticksZ_HZ_cycsys_clock_hw_cycles_per_sec()Z_HZ_ns1000000000Z_HZ_us1000000Z_HZ_msz_tmcvt(__t,__from_hz,__to_hz,__const_hz,__result32,__round_up,__round_off)((__result32) ? z_tmcvt_32(__t, __from_hz, __to_hz, __const_hz, __round_up, __round_off) : z_tmcvt_64(__t, __from_hz, __to_hz, __const_hz, __round_up, __round_off))z_tmcvt_64(__t,__from_hz,__to_hz,__const_hz,__round_up,__round_off)((__const_hz) ? ( z_tmcvt_is_identity(__from_hz, __to_hz) ? (uint64_t) (__t) : z_tmcvt_is_int_div(__from_hz, __to_hz) ? z_tmcvt_int_div_64(__t, __from_hz, __to_hz, __round_up, __round_off) : z_tmcvt_is_int_mul(__from_hz, __to_hz) ? z_tmcvt_int_mul_64(__t, __from_hz, __to_hz) : z_tmcvt_gen_64(__t, __from_hz, __to_hz, __round_up, __round_off) ) : z_tmcvt_gen_64_slow(__t, __from_hz, __to_hz, __round_up, __round_off) )z_tmcvt_32(__t,__from_hz,__to_hz,__const_hz,__round_up,__round_off)((__const_hz) ? ( z_tmcvt_is_identity(__from_hz, __to_hz) ? (uint32_t) (__t) : z_tmcvt_is_int_div(__from_hz, __to_hz) ? z_tmcvt_int_div_32(__t, __from_hz, __to_hz, __round_up, __round_off) : z_tmcvt_is_int_mul(__from_hz, __to_hz) ? z_tmcvt_int_mul_32(__t, __from_hz, __to_hz) : z_tmcvt_gen_32(__t, __from_hz, __to_hz, __round_up, __round_off) ) : z_tmcvt_gen_32(__t, __from_hz, __to_hz, __round_up, __round_off) )z_tmcvt_gen_64(__t,__from_hz,__to_hz,__round_up,__round_off)(z_tmcvt_use_fast_algo(__from_hz, __to_hz) ? z_tmcvt_gen_64_fast(__t, __from_hz, __to_hz, __round_up, __round_off) : z_tmcvt_gen_64_slow(__t, __from_hz, __to_hz, __round_up, __round_off))z_tmcvt_gen_64_slow(__t,__from_hz,__to_hz,__round_up,__round_off)(((uint64_t) (__t) / (__from_hz))*(__to_hz) + (((uint64_t) (__t) % (__from_hz))*(__to_hz) + z_tmcvt_off_gen(__from_hz, __to_hz, __round_up, __round_off)) / (__from_hz))z_tmcvt_gen_64_fast(__t,__from_hz,__to_hz,__round_up,__round_off)(((uint64_t) (__t)*(__to_hz) + z_tmcvt_off_gen(__from_hz, __to_hz, __round_up, __round_off)) / (__from_hz))z_tmcvt_int_mul_64(__t,__from_hz,__to_hz)(uint64_t) (__t)*((__to_hz) / (__from_hz))z_tmcvt_int_div_64(__t,__from_hz,__to_hz,__round_up,__round_off)(((uint64_t) (__t) + z_tmcvt_off_div(__from_hz, __to_hz, __round_up, __round_off)) / z_tmcvt_divisor(__from_hz, __to_hz))z_tmcvt_gen_32(__t,__from_hz,__to_hz,__round_up,__round_off)((uint32_t) (((uint64_t) (__t)*(__to_hz) + z_tmcvt_off_gen(__from_hz, __to_hz, __round_up, __round_off)) / (__from_hz)))z_tmcvt_int_mul_32(__t,__from_hz,__to_hz)(uint32_t) (__t)*((__to_hz) / (__from_hz))z_tmcvt_int_div_32(__t,__from_hz,__to_hz,__round_up,__round_off)((uint64_t) (__t) <= 0xffffffffU - z_tmcvt_off_div(__from_hz, __to_hz, __round_up, __round_off) ? ((uint32_t)((__t) + z_tmcvt_off_div(__from_hz, __to_hz, __round_up, __round_off)) / z_tmcvt_divisor(__from_hz, __to_hz)) : (uint32_t) (((uint64_t) (__t) + z_tmcvt_off_div(__from_hz, __to_hz, __round_up, __round_off)) / z_tmcvt_divisor(__from_hz, __to_hz)) )z_tmcvt_off_gen(__from_hz,__to_hz,__round_up,__round_off)((__round_off) ? (__from_hz) / 2 : (__round_up) ? (__from_hz) - 1 : 0)z_tmcvt_divisor(a,b)((a) / (b))z_tmcvt_off_div(__from_hz,__to_hz,__round_up,__round_off)((__round_off) ? ((__from_hz) / (__to_hz)) / 2 : (__round_up) ? ((__from_hz) / (__to_hz)) - 1 : 0)z_tmcvt_is_int_div(__from_hz,__to_hz)((__from_hz) > (__to_hz) && (__from_hz) % (__to_hz) == 0U)z_tmcvt_is_int_mul(__from_hz,__to_hz)((__to_hz) > (__from_hz) && (__to_hz) % (__from_hz) == 0U)z_tmcvt_is_identity(__from_hz,__to_hz)((__to_hz) == (__from_hz))z_tmcvt_use_fast_algo(from_hz,to_hz)((DIV_ROUND_UP(CONFIG_SYS_CLOCK_MAX_TIMEOUT_DAYS * 24ULL * 3600ULL * from_hz, UINT32_MAX) * to_hz) <= UINT32_MAX)sys_clock_hw_cycles_per_sec_runtime_get()SYS_TIMEOUT_MS(ms)Z_TIMEOUT_TICKS((ms) == SYS_FOREVER_MS ? K_TICKS_FOREVER : Z_TIMEOUT_MS_TICKS(ms))SYS_FOREVER_US(-1)SYS_FOREVER_MSZEPHYR_INCLUDE_TIME_UNITS_H_defined(CONFIG_TIMER_READS_ITS_FREQUENCY_AT_RUNTIME)defined(__cplusplus) && __cplusplus >= 201402L/* ZEPHYR_INCLUDE_TIME_UNITS_H_ *//* Generated.  Do not edit.  See above. *//** @brief Convert ticks to hardware cycles. 64 bits. Rounds up.
 *
 * Converts time values in ticks to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert ticks to hardware cycles. 32 bits. Rounds up.
 *
 * Converts time values in ticks to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert ticks to hardware cycles. 64 bits. Round nearest.
 *
 * Converts time values in ticks to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert ticks to hardware cycles. 32 bits. Round nearest.
 *
 * Converts time values in ticks to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert ticks to hardware cycles. 64 bits. Truncates.
 *
 * Converts time values in ticks to hardware cycles.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert ticks to hardware cycles. 32 bits. Truncates.
 *
 * Converts time values in ticks to hardware cycles.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert ticks to nanoseconds. 64 bits. Rounds up.
 *
 * Converts time values in ticks to nanoseconds.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in nanoseconds. uint64_t
 *//** @brief Convert ticks to nanoseconds. 32 bits. Rounds up.
 *
 * Converts time values in ticks to nanoseconds.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in nanoseconds. uint32_t
 *//** @brief Convert ticks to nanoseconds. 64 bits. Round nearest.
 *
 * Converts time values in ticks to nanoseconds.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in nanoseconds. uint64_t
 *//** @brief Convert ticks to nanoseconds. 32 bits. Round nearest.
 *
 * Converts time values in ticks to nanoseconds.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in nanoseconds. uint32_t
 *//** @brief Convert ticks to nanoseconds. 64 bits. Truncates.
 *
 * Converts time values in ticks to nanoseconds.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in nanoseconds. uint64_t
 *//** @brief Convert ticks to nanoseconds. 32 bits. Truncates.
 *
 * Converts time values in ticks to nanoseconds.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in nanoseconds. uint32_t
 *//** @brief Convert ticks to microseconds. 64 bits. Rounds up.
 *
 * Converts time values in ticks to microseconds.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in microseconds. uint64_t
 *//** @brief Convert ticks to microseconds. 32 bits. Rounds up.
 *
 * Converts time values in ticks to microseconds.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in microseconds. uint32_t
 *//** @brief Convert ticks to microseconds. 64 bits. Round nearest.
 *
 * Converts time values in ticks to microseconds.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in microseconds. uint64_t
 *//** @brief Convert ticks to microseconds. 32 bits. Round nearest.
 *
 * Converts time values in ticks to microseconds.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in microseconds. uint32_t
 *//** @brief Convert ticks to microseconds. 64 bits. Truncates.
 *
 * Converts time values in ticks to microseconds.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in microseconds. uint64_t
 *//** @brief Convert ticks to microseconds. 32 bits. Truncates.
 *
 * Converts time values in ticks to microseconds.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in microseconds. uint32_t
 *//** @brief Convert ticks to milliseconds. 64 bits. Rounds up.
 *
 * Converts time values in ticks to milliseconds.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in milliseconds. uint64_t
 *//** @brief Convert ticks to milliseconds. 32 bits. Rounds up.
 *
 * Converts time values in ticks to milliseconds.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in milliseconds. uint32_t
 *//** @brief Convert ticks to milliseconds. 64 bits. Round nearest.
 *
 * Converts time values in ticks to milliseconds.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in milliseconds. uint64_t
 *//** @brief Convert ticks to milliseconds. 32 bits. Round nearest.
 *
 * Converts time values in ticks to milliseconds.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in milliseconds. uint32_t
 *//** @brief Convert ticks to milliseconds. 64 bits. Truncates.
 *
 * Converts time values in ticks to milliseconds.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in milliseconds. uint64_t
 *//** @brief Convert ticks to milliseconds. 32 bits. Truncates.
 *
 * Converts time values in ticks to milliseconds.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in ticks. uint64_t
 *
 * @return The converted time value in milliseconds. uint32_t
 *//** @brief Convert hardware cycles to ticks. 64 bits. Rounds up.
 *
 * Converts time values in hardware cycles to ticks.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert hardware cycles to ticks. 32 bits. Rounds up.
 *
 * Converts time values in hardware cycles to ticks.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert hardware cycles to ticks. 64 bits. Round nearest.
 *
 * Converts time values in hardware cycles to ticks.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert hardware cycles to ticks. 32 bits. Round nearest.
 *
 * Converts time values in hardware cycles to ticks.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert hardware cycles to ticks. 64 bits. Truncates.
 *
 * Converts time values in hardware cycles to ticks.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert hardware cycles to ticks. 32 bits. Truncates.
 *
 * Converts time values in hardware cycles to ticks.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert hardware cycles to nanoseconds. 64 bits. Rounds up.
 *
 * Converts time values in hardware cycles to nanoseconds.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in nanoseconds. uint64_t
 *//** @brief Convert hardware cycles to nanoseconds. 32 bits. Rounds up.
 *
 * Converts time values in hardware cycles to nanoseconds.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in nanoseconds. uint32_t
 *//** @brief Convert hardware cycles to nanoseconds. 64 bits. Round nearest.
 *
 * Converts time values in hardware cycles to nanoseconds.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in nanoseconds. uint64_t
 *//** @brief Convert hardware cycles to nanoseconds. 32 bits. Round nearest.
 *
 * Converts time values in hardware cycles to nanoseconds.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in nanoseconds. uint32_t
 *//** @brief Convert hardware cycles to nanoseconds. 64 bits. Truncates.
 *
 * Converts time values in hardware cycles to nanoseconds.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in nanoseconds. uint64_t
 *//** @brief Convert hardware cycles to nanoseconds. 32 bits. Truncates.
 *
 * Converts time values in hardware cycles to nanoseconds.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in nanoseconds. uint32_t
 *//** @brief Convert hardware cycles to microseconds. 64 bits. Rounds up.
 *
 * Converts time values in hardware cycles to microseconds.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in microseconds. uint64_t
 *//** @brief Convert hardware cycles to microseconds. 32 bits. Rounds up.
 *
 * Converts time values in hardware cycles to microseconds.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in microseconds. uint32_t
 *//** @brief Convert hardware cycles to microseconds. 64 bits. Round nearest.
 *
 * Converts time values in hardware cycles to microseconds.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in microseconds. uint64_t
 *//** @brief Convert hardware cycles to microseconds. 32 bits. Round nearest.
 *
 * Converts time values in hardware cycles to microseconds.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in microseconds. uint32_t
 *//** @brief Convert hardware cycles to microseconds. 64 bits. Truncates.
 *
 * Converts time values in hardware cycles to microseconds.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in microseconds. uint64_t
 *//** @brief Convert hardware cycles to microseconds. 32 bits. Truncates.
 *
 * Converts time values in hardware cycles to microseconds.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in microseconds. uint32_t
 *//** @brief Convert hardware cycles to milliseconds. 64 bits. Rounds up.
 *
 * Converts time values in hardware cycles to milliseconds.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in milliseconds. uint64_t
 *//** @brief Convert hardware cycles to milliseconds. 32 bits. Rounds up.
 *
 * Converts time values in hardware cycles to milliseconds.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in milliseconds. uint32_t
 *//** @brief Convert hardware cycles to milliseconds. 64 bits. Round nearest.
 *
 * Converts time values in hardware cycles to milliseconds.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in milliseconds. uint64_t
 *//** @brief Convert hardware cycles to milliseconds. 32 bits. Round nearest.
 *
 * Converts time values in hardware cycles to milliseconds.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in milliseconds. uint32_t
 *//** @brief Convert hardware cycles to milliseconds. 64 bits. Truncates.
 *
 * Converts time values in hardware cycles to milliseconds.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in milliseconds. uint64_t
 *//** @brief Convert hardware cycles to milliseconds. 32 bits. Truncates.
 *
 * Converts time values in hardware cycles to milliseconds.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in hardware cycles. uint64_t
 *
 * @return The converted time value in milliseconds. uint32_t
 *//** @brief Convert nanoseconds to ticks. 64 bits. Rounds up.
 *
 * Converts time values in nanoseconds to ticks.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert nanoseconds to ticks. 32 bits. Rounds up.
 *
 * Converts time values in nanoseconds to ticks.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert nanoseconds to ticks. 64 bits. Round nearest.
 *
 * Converts time values in nanoseconds to ticks.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert nanoseconds to ticks. 32 bits. Round nearest.
 *
 * Converts time values in nanoseconds to ticks.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert nanoseconds to ticks. 64 bits. Truncates.
 *
 * Converts time values in nanoseconds to ticks.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert nanoseconds to ticks. 32 bits. Truncates.
 *
 * Converts time values in nanoseconds to ticks.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert nanoseconds to hardware cycles. 64 bits. Rounds up.
 *
 * Converts time values in nanoseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert nanoseconds to hardware cycles. 32 bits. Rounds up.
 *
 * Converts time values in nanoseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert nanoseconds to hardware cycles. 64 bits. Round nearest.
 *
 * Converts time values in nanoseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert nanoseconds to hardware cycles. 32 bits. Round nearest.
 *
 * Converts time values in nanoseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert nanoseconds to hardware cycles. 64 bits. Truncates.
 *
 * Converts time values in nanoseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert nanoseconds to hardware cycles. 32 bits. Truncates.
 *
 * Converts time values in nanoseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in nanoseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert microseconds to ticks. 64 bits. Rounds up.
 *
 * Converts time values in microseconds to ticks.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert microseconds to ticks. 32 bits. Rounds up.
 *
 * Converts time values in microseconds to ticks.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert microseconds to ticks. 64 bits. Round nearest.
 *
 * Converts time values in microseconds to ticks.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert microseconds to ticks. 32 bits. Round nearest.
 *
 * Converts time values in microseconds to ticks.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert microseconds to ticks. 64 bits. Truncates.
 *
 * Converts time values in microseconds to ticks.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert microseconds to ticks. 32 bits. Truncates.
 *
 * Converts time values in microseconds to ticks.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert microseconds to hardware cycles. 64 bits. Rounds up.
 *
 * Converts time values in microseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert microseconds to hardware cycles. 32 bits. Rounds up.
 *
 * Converts time values in microseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert microseconds to hardware cycles. 64 bits. Round nearest.
 *
 * Converts time values in microseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert microseconds to hardware cycles. 32 bits. Round nearest.
 *
 * Converts time values in microseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert microseconds to hardware cycles. 64 bits. Truncates.
 *
 * Converts time values in microseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert microseconds to hardware cycles. 32 bits. Truncates.
 *
 * Converts time values in microseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in microseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert milliseconds to ticks. 64 bits. Rounds up.
 *
 * Converts time values in milliseconds to ticks.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert milliseconds to ticks. 32 bits. Rounds up.
 *
 * Converts time values in milliseconds to ticks.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert milliseconds to ticks. 64 bits. Round nearest.
 *
 * Converts time values in milliseconds to ticks.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert milliseconds to ticks. 32 bits. Round nearest.
 *
 * Converts time values in milliseconds to ticks.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert milliseconds to ticks. 64 bits. Truncates.
 *
 * Converts time values in milliseconds to ticks.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in ticks. uint64_t
 *//** @brief Convert milliseconds to ticks. 32 bits. Truncates.
 *
 * Converts time values in milliseconds to ticks.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in ticks. uint32_t
 *//** @brief Convert milliseconds to hardware cycles. 64 bits. Rounds up.
 *
 * Converts time values in milliseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert milliseconds to hardware cycles. 32 bits. Rounds up.
 *
 * Converts time values in milliseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds up to the next highest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert milliseconds to hardware cycles. 64 bits. Round nearest.
 *
 * Converts time values in milliseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert milliseconds to hardware cycles. 32 bits. Round nearest.
 *
 * Converts time values in milliseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Rounds to the nearest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//** @brief Convert milliseconds to hardware cycles. 64 bits. Truncates.
 *
 * Converts time values in milliseconds to hardware cycles.
 * Computes result in 64 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint64_t
 *//** @brief Convert milliseconds to hardware cycles. 32 bits. Truncates.
 *
 * Converts time values in milliseconds to hardware cycles.
 * Computes result in 32 bit precision.
 * Truncates to the next lowest output unit.
 *
 * @param t Source time in milliseconds. uint64_t
 *
 * @return The converted time value in hardware cycles. uint32_t
 *//* Some more concise declarations to simplify the generator script and
 * save bytes below
 *//* The following code is programmatically generated using this perl
 * code, which enumerates all possible combinations of units, rounding
 * modes and precision.  Do not edit directly.
 *
 * Note that nano/microsecond conversions are only defined with 64 bit
 * precision.  These units conversions were not available in 32 bit
 * variants historically, and doing 32 bit math with units that small
 * has precision traps that we probably don't want to support in an
 * official API.
 *
 * #!/usr/bin/perl -w
 * use strict;
 *
 * my %human = ("ms" => "milliseconds",
 *              "us" => "microseconds",
 *              "ns" => "nanoseconds",
 *              "cyc" => "hardware cycles",
 *              "ticks" => "ticks");
 * my %human_round = ("ceil" => "Rounds up",
 *		   "near" => "Round nearest",
 *		   "floor" => "Truncates");
 *
 * sub big { return $_[0] eq "us" || $_[0] eq "ns"; }
 * sub prefix { return $_[0] eq "ms" || $_[0] eq "us" || $_[0] eq "ns"; }
 *
 * for my $from_unit ("ms", "us", "ns", "cyc", "ticks") {
 *     for my $to_unit ("ms", "us", "ns", "cyc", "ticks") {
 *         next if $from_unit eq $to_unit;
 *         next if prefix($from_unit) && prefix($to_unit);
 *         for my $round ("floor", "near", "ceil") {
 *             for(my $big=0; $big <= 1; $big++) {
 *                 my $sz = $big ? 64 : 32;
 *                 my $sym = "k_${from_unit}_to_${to_unit}_$round$sz";
 *                 my $type = "uint${sz}_t";
 *                 my $const_hz = ($from_unit eq "cyc" || $to_unit eq "cyc")
 *                     ? "Z_CCYC" : "true";
 *                 my $ret32 = $big ? "64" : "32";
 *                 my $rup = $round eq "ceil" ? "true" : "false";
 *                 my $roff = $round eq "near" ? "true" : "false";
 *
 *                 my $hfrom = $human{$from_unit};
 *                 my $hto = $human{$to_unit};
 *		my $hround = $human_round{$round};
 *                 print "/", "** \@brief Convert $hfrom to $hto. $ret32 bits. $hround.\n";
 *                 print " *\n";
 *                 print " * Converts time values in $hfrom to $hto.\n";
 *                 print " * Computes result in $sz bit precision.\n";
 *                 if ($round eq "ceil") {
 *                     print " * Rounds up to the next highest output unit.\n";
 *                 } elsif ($round eq "near") {
 *                     print " * Rounds to the nearest output unit.\n";
 *                 } else {
 *                     print " * Truncates to the next lowest output unit.\n";
 *                 }
 *                 print " *\n";
 *		print " * \@param t Source time in $hfrom. uint64_t\n";
 *		print " *\n";
 *                 print " * \@return The converted time value in $hto. $type\n";
 *                 print " *", "/\n";
 *
 *                 print "/", "* Generated.  Do not edit.  See above. *", "/\n";
 *                 print "#define $sym(t) \\\n";
 *                 print "\tz_tmcvt_$ret32(t, Z_HZ_$from_unit, Z_HZ_$to_unit,";
 *                 print " $const_hz, $rup, $roff)\n";
 *                 print "\n\n";
 *             }
 *         }
 *     }
 * }
 *//* Convert, generating a 64-bit result *//* Convert, generating a 32-bit result *//* General 64-bit conversion. Uses one of the two above macros *//* Slow 64-bit conversion. This avoids overflowing the multiply *//* Fast 64-bit conversion. This relies on the multiply not overflowing *//* Integer multiplcation 64-bit conversion *//* Integer division 64-bit conversion *//* General 32-bit conversion *//* Integer multiplication 32-bit conversion *//* Integer division 32-bit conversion *//*
 * Compute the offset needed to round the result correctly when
 * the conversion requires a full mul/div
 *//* Clang emits a divide-by-zero warning even though the int_div macro
 * results are only used when the divisor will not be zero. Work
 * around this by substituting 1 to make the compiler happy.
 *//*
 * Compute the offset needed to round the result correctly when
 * the conversion requires a simple integer division
 *//* true if the conversion requires a simple integer division *//* true if the conversion requires a simple integer multiply *//* true if the conversion is the identity *//* Time converter generator gadget.  Selects from one of three
 * conversion algorithms: ones that take advantage when the
 * frequencies are an integer ratio (in either direction), or a full
 * precision conversion.  Clever use of extra arguments causes all the
 * selection logic to be optimized out, and the generated code even
 * reduces to 32 bit only if a ratio conversion is available and the
 * result is 32 bits.
 *
 * This isn't intended to be used directly, instead being wrapped
 * appropriately in a user-facing API.  The boolean arguments are:
 *
 *    const_hz  - The hz arguments are known to be compile-time
 *                constants (because otherwise the modulus test would
 *                have to be done at runtime)
 *    result32  - The result will be truncated to 32 bits on use
 *    round_up  - Return the ceiling of the resulting fraction
 *    round_off - Return the nearest value to the resulting fraction
 *                (pass both round_up/off as false to get "round_down")
 *
 * All of this must be implemented as expressions so that, when constant,
 * the results may be used to initialize global variables.
 *//** @internal
 * Macro determines if fast conversion algorithm can be used. It checks if
 * maximum timeout represented in source frequency domain and multiplied by
 * target frequency fits in 64 bits.
 *
 * @param from_hz Source frequency.
 * @param to_hz Target frequency.
 *
 * @retval true Use faster algorithm.
 * @retval false Use algorithm preventing overflow of intermediate value.
 *//**
 * @brief Get the system timer frequency.
 * @return system timer frequency in Hz
 *//* CONFIG_TIMER_READS_ITS_FREQUENCY_AT_RUNTIME *//* Exhaustively enumerated, highly optimized time unit conversion API *//** @brief System-wide macro to convert milliseconds to kernel timeouts
 *//** @brief System-wide macro to denote "forever" in microseconds
 *
 * See @ref SYS_FOREVER_MS.
 *//** @brief System-wide macro to denote "forever" in milliseconds
 *
 *  Usage of this macro is limited to APIs that want to expose a timeout value
 *  that can optionally be unlimited, or "forever".
 *  This macro can not be fed into kernel functions or macros directly. Use
 *  @ref SYS_TIMEOUT_MS instead.
 *//**
 * @file
 * @defgroup timeutil_unit_apis Time Units Helpers
 * @ingroup timeutil_apis
 *
 * @brief Various helper APIs for converting between time units.
 * @{
 */<zephyr/sys/time_units.h>utf8_lcpyutf8_truncu8_to_decbin2bcdbcd2bin0x0Fhex2binbin2hexconst uint8_tconst uint8_t *hex2charchar2hexbyteswptaabbbytecpyvolatile uint8_tvolatile uint8_t *const volatile uint8_tconst volatile uint8_t *arithmetic_shift_rightsign_extis_power_of_twoWAIT_FOR(expr,timeout,delay_stmt)({ uint32_t _wf_cycle_count = k_us_to_cyc_ceil32(timeout); uint32_t _wf_start = k_cycle_get_32(); while (!(expr) && (_wf_cycle_count > (k_cycle_get_32() - _wf_start))) { delay_stmt; Z_SPIN_DELAY(10); } (expr); })Z_SPIN_DELAY(t)MHZ(x)(KHZ(x) * 1000)KHZ(x)((x) * 1000)GB(x)(MB(x) << 10)MB(x)(KB(x) << 10)KB(x)(((size_t)x) << 10)Z_DETECT_POINTER_OVERFLOW(addr,buflen)(((buflen) != 0) && ((UINTPTR_MAX - (uintptr_t)(addr)) <= ((uintptr_t)((buflen) - 1))))NHPOT(x)((x) < 1 ? 1 : ((x) > (1ULL<<63) ? 0 : 1ULL << LOG2CEIL(x)))LOG2CEIL(x)((x) < 1 ? 0 : __z_log2((x)-1) + 1)LOG2(x)((x) < 1 ? -1 : __z_log2(x))__z_log2(x)(sizeof(__typeof__(x)) > 4 ? __z_log2q(x) : __z_log2d(x))__z_log2q(x)(64 - __builtin_clzll(x) - 1)__z_log2d(x)(32 - __builtin_clz(x) - 1)IN_RANGE(val,min,max)((val) >= (min) && (val) <= (max))CLAMP(val,low,high)(((val) <= (low)) ? (low) : MIN(val, high))MIN(a,b)(((a) < (b)) ? (a) : (b))MAX(a,b)(((a) > (b)) ? (a) : (b))ceiling_fraction(numerator,divider)__DEPRECATED_MACRO DIV_ROUND_UP(numerator, divider)DIV_ROUND_CLOSEST(n,d)((((n) < 0) ^ ((d) < 0)) ? ((n) - ((d) / 2)) / (d) : ((n) + ((d) / 2)) / (d))DIV_ROUND_UP(n,d)(((n) + (d) - 1) / (d))WB_DN(x)ROUND_DOWN(x, sizeof(void *))WB_UP(x)ROUND_UP(x, sizeof(void *))ROUND_DOWN(x,align)(((unsigned long)(x) / (unsigned long)(align)) * (unsigned long)(align))ROUND_UP(x,align)((((unsigned long)(x) + ((unsigned long)(align) - 1)) / (unsigned long)(align)) * (unsigned long)(align))CONTAINER_OF(ptr,type,field)({ CONTAINER_OF_VALIDATE(ptr, type, field) ((type *)(((char *)(ptr)) - offsetof(type, field))); })CONTAINER_OF_VALIDATE(ptr,type,field)BUILD_ASSERT(SAME_TYPE(*(ptr), ((type *)0)->field) || SAME_TYPE(*(ptr), void), "pointer type mismatch in CONTAINER_OF");SAME_TYPE(a,b)__builtin_types_compatible_p(__typeof__(a), __typeof__(b))ARRAY_INDEX_FLOOR(array,ptr)({ __ASSERT_NO_MSG(PART_OF_ARRAY(array, ptr)); (POINTER_TO_UINT(ptr) - POINTER_TO_UINT(array)) / sizeof((array)[0]); })PART_OF_ARRAY(array,ptr)((ptr) && POINTER_TO_UINT(array) <= POINTER_TO_UINT(ptr) && POINTER_TO_UINT(ptr) < POINTER_TO_UINT(&(array)[ARRAY_SIZE(array)]))ARRAY_INDEX(array,ptr)({ __ASSERT_NO_MSG(IS_ARRAY_ELEMENT(array, ptr)); (__typeof__((array)[0]) *)(ptr) - (array); })IS_ARRAY_ELEMENT(array,ptr)((ptr) && POINTER_TO_UINT(array) <= POINTER_TO_UINT(ptr) && POINTER_TO_UINT(ptr) < POINTER_TO_UINT(&(array)[ARRAY_SIZE(array)]) && (POINTER_TO_UINT(ptr) - POINTER_TO_UINT(array)) % sizeof((array)[0]) == 0)ARRAY_SIZE(array)((size_t) (IS_ARRAY(array) + (sizeof(array) / sizeof((array)[0]))))IS_ARRAY(array)ZERO_OR_COMPILE_ERROR( !__builtin_types_compatible_p(__typeof__(array), __typeof__(&(array)[0])))ZERO_OR_COMPILE_ERROR(cond)((int) sizeof(char[1 - 2 * !(cond)]) - 1)FIELD_PREP(mask,value)(((value) * LSB_GET(mask)) & (mask))FIELD_GET(mask,value)(((value) & (mask)) / LSB_GET(mask))LSB_GET(value)((value) & -(value))GENMASK64(h,l)(((~0ULL) - (1ULL << (l)) + 1) & (~0ULL >> (BITS_PER_LONG_LONG - 1 - (h))))GENMASK(h,l)(((~0UL) - (1UL << (l)) + 1) & (~0UL >> (BITS_PER_LONG - 1 - (h))))BITS_PER_LONG_LONG(__CHAR_BIT__ * __SIZEOF_LONG_LONG__)BITS_PER_LONG(__CHAR_BIT__ * __SIZEOF_LONG__)INT_TO_POINTER(x)((void *) (intptr_t) (x))POINTER_TO_INT(x)((intptr_t) (x))UINT_TO_POINTER(x)((void *) (uintptr_t) (x))POINTER_TO_UINT(x)((uintptr_t) (x))NUM_BITS(t)(sizeof(t) * 8)__SIZEOF_LONG_LONG__binbcddstsrcshiftutf8_strbufbuflenhexhexlensys_dlist_lensys_dlist_t *lenlistsys_dlist_getsys_dlist_removesys_dnode_t *constprevnextsys_dlist_insert_atpossys_dlist_insertsys_dlist_prependheadsys_dlist_appendtailsys_dlist_peek_tailsys_dlist_peek_prevsys_dlist_peek_prev_no_checksys_dlist_peek_nextsys_dlist_peek_next_no_checksys_dlist_peek_head_not_emptysys_dlist_peek_headsys_dlist_has_multiple_nodessys_dlist_is_emptysys_dlist_is_tailsys_dlist_is_headsys_dnode_is_linkedsys_dnode_initsys_dlist_initsys_dnode_tsys_dlist_t_dnodeSYS_DLIST_STATIC_INIT(ptr_to_list){ {(ptr_to_list)}, {(ptr_to_list)} }SYS_DLIST_FOR_EACH_CONTAINER_SAFE(__dl,__cn,__cns,__n)for (__cn = SYS_DLIST_PEEK_HEAD_CONTAINER(__dl, __cn, __n), __cns = SYS_DLIST_PEEK_NEXT_CONTAINER(__dl, __cn, __n); __cn != NULL; __cn = __cns, __cns = SYS_DLIST_PEEK_NEXT_CONTAINER(__dl, __cn, __n))SYS_DLIST_FOR_EACH_CONTAINER(__dl,__cn,__n)for (__cn = SYS_DLIST_PEEK_HEAD_CONTAINER(__dl, __cn, __n); __cn != NULL; __cn = SYS_DLIST_PEEK_NEXT_CONTAINER(__dl, __cn, __n))SYS_DLIST_PEEK_NEXT_CONTAINER(__dl,__cn,__n)((__cn != NULL) ? SYS_DLIST_CONTAINER(sys_dlist_peek_next(__dl, &(__cn->__n)), __cn, __n) : NULL)SYS_DLIST_PEEK_HEAD_CONTAINER(__dl,__cn,__n)SYS_DLIST_CONTAINER(sys_dlist_peek_head(__dl), __cn, __n)SYS_DLIST_CONTAINER(__dn,__cn,__n)((__dn != NULL) ? CONTAINER_OF(__dn, __typeof__(*__cn), __n) : NULL)SYS_DLIST_FOR_EACH_NODE_SAFE(__dl,__dn,__dns)for (__dn = sys_dlist_peek_head(__dl), __dns = sys_dlist_peek_next(__dl, __dn); __dn != NULL; __dn = __dns, __dns = sys_dlist_peek_next(__dl, __dn))SYS_DLIST_ITERATE_FROM_NODE(__dl,__dn)for (__dn = __dn ? sys_dlist_peek_next_no_check(__dl, __dn) : sys_dlist_peek_head(__dl); __dn != NULL; __dn = sys_dlist_peek_next(__dl, __dn))SYS_DLIST_FOR_EACH_NODE(__dl,__dn)for (__dn = sys_dlist_peek_head(__dl); __dn != NULL; __dn = sys_dlist_peek_next(__dl, __dn))ZEPHYR_INCLUDE_SYS_DLIST_H_/* ZEPHYR_INCLUDE_SYS_DLIST_H_ *//**
 * @brief Compute the size of the given list in O(n) time
 *
 * @param list A pointer on the list
 *
 * @return an integer equal to the size of the list, or 0 if empty
 *//**
 * @brief get the first node in a list
 *
 * This and other sys_dlist_*() functions are not thread safe.
 *
 * @param list the doubly-linked list to operate on
 *
 * @return the first node in the list, NULL if list is empty
 *//**
 * @brief remove a specific node from a list
 *
 * The list is implicit from the node. The node must be part of a list.
 * This and other sys_dlist_*() functions are not thread safe.
 *
 * @param node the node to remove
 *//**
 * @brief insert node at position
 *
 * Insert a node in a location depending on a external condition. The cond()
 * function checks if the node is to be inserted _before_ the current node
 * against which it is checked.
 * This and other sys_dlist_*() functions are not thread safe.
 *
 * @param list the doubly-linked list to operate on
 * @param node the element to insert
 * @param cond a function that determines if the current node is the correct
 *             insert point
 * @param data parameter to cond()
 *//**
 * @brief Insert a node into a list
 *
 * Insert a node before a specified node in a dlist.
 *
 * @param successor the position before which "node" will be inserted
 * @param node the element to insert
 *//**
 * @brief add node to head of list
 *
 * This and other sys_dlist_*() functions are not thread safe.
 *
 * @param list the doubly-linked list to operate on
 * @param node the element to append
 *//**
 * @brief add node to tail of list
 *
 * This and other sys_dlist_*() functions are not thread safe.
 *
 * @param list the doubly-linked list to operate on
 * @param node the element to append
 *//**
 * @brief get a reference to the tail item in the list
 *
 * @param list the doubly-linked list to operate on
 *
 * @return a pointer to the tail element, NULL if list is empty
 *//**
 * @brief get a reference to the previous item in the list
 *
 * @param list the doubly-linked list to operate on
 * @param node the node from which to get the previous element in the list
 *
 * @return a pointer to the previous element from a node, NULL if node is the
 * 	   tail or NULL (when node comes from reading the head of an empty
 * 	   list).
 *//**
 * @brief get a reference to the previous item in the list, node is not NULL
 *
 * Faster than sys_dlist_peek_prev() if node is known not to be NULL.
 *
 * @param list the doubly-linked list to operate on
 * @param node the node from which to get the previous element in the list
 *
 * @return a pointer to the previous element from a node, NULL if node is the
 *	   tail
 *//**
 * @brief get a reference to the next item in the list
 *
 * @param list the doubly-linked list to operate on
 * @param node the node from which to get the next element in the list
 *
 * @return a pointer to the next element from a node, NULL if node is the tail
 * or NULL (when node comes from reading the head of an empty list).
 *//**
 * @brief get a reference to the next item in the list, node is not NULL
 *
 * Faster than sys_dlist_peek_next() if node is known not to be NULL.
 *
 * @param list the doubly-linked list to operate on
 * @param node the node from which to get the next element in the list
 *
 * @return a pointer to the next element from a node, NULL if node is the tail
 *//**
 * @brief get a reference to the head item in the list
 *
 * The list must be known to be non-empty.
 *
 * @param list the doubly-linked list to operate on
 *
 * @return a pointer to the head element
 *//**
 * @brief get a reference to the head item in the list
 *
 * @param list the doubly-linked list to operate on
 *
 * @return a pointer to the head element, NULL if list is empty
 *//**
 * @brief check if more than one node present
 *
 * This and other sys_dlist_*() functions are not thread safe.
 *
 * @param list the doubly-linked list to operate on
 *
 * @return true if multiple nodes, false otherwise
 *//**
 * @brief check if the list is empty
 *
 * @param list the doubly-linked list to operate on
 *
 * @return true if empty, false otherwise
 *//**
 * @brief check if a node is the list's tail
 *
 * @param list the doubly-linked list to operate on
 * @param node the node to check
 *
 * @return true if node is the tail, false otherwise
 *//**
 * @brief check if a node is the list's head
 *
 * @param list the doubly-linked list to operate on
 * @param node the node to check
 *
 * @return true if node is the head, false otherwise
 *//**
 * @brief check if a node is a member of any list
 *
 * @param node the node
 *
 * @return true if node is linked into a list, false if it is not
 *//**
 * @brief initialize node to its state when not in a list
 *
 * @param node the node
 *//**
 * @brief Static initializer for a doubly-linked list
 *//**
 * @brief initialize list to its empty state
 *
 * @param list the doubly-linked list
 *//**
 * @brief Provide the primitive to safely iterate on a list under a container
 * Note: __cn can be detached, it will not break the loop.
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_DLIST_FOR_EACH_CONTAINER_SAFE(l, c, cn, n) {
 *         <user code>
 *     }
 *
 * @param __dl A pointer on a sys_dlist_t to iterate on
 * @param __cn A pointer to peek each entry of the list
 * @param __cns A pointer for the loop to run safely
 * @param __n The field name of sys_dnode_t within the container struct
 *//**
 * @brief Provide the primitive to iterate on a list under a container
 * Note: the loop is unsafe and thus __cn should not be detached
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_DLIST_FOR_EACH_CONTAINER(l, c, n) {
 *         <user code>
 *     }
 *
 * @param __dl A pointer on a sys_dlist_t to iterate on
 * @param __cn A pointer to peek each entry of the list
 * @param __n The field name of sys_dnode_t within the container struct
 *//**
 * @brief Provide the primitive to peek the next container
 *
 * @param __dl A pointer on a sys_dlist_t to peek
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_dnode_t within the container struct
 *//**
 * @brief Provide the primitive to peek container of the list head
 *
 * @param __dl A pointer on a sys_dlist_t to peek
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_dnode_t within the container struct
 *//**
 * @brief Provide the primitive to resolve the container of a list node
 * Note: it is safe to use with NULL pointer nodes
 *
 * @param __dn A pointer on a sys_dnode_t to get its container
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_dnode_t within the container struct
 *//**
 * @brief Provide the primitive to safely iterate on a list
 * Note: __dn can be removed, it will not break the loop.
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_DLIST_FOR_EACH_NODE_SAFE(l, n, s) {
 *         <user code>
 *     }
 *
 * This and other SYS_DLIST_*() macros are not thread safe.
 *
 * @param __dl A pointer on a sys_dlist_t to iterate on
 * @param __dn A sys_dnode_t pointer to peek each node of the list
 * @param __dns A sys_dnode_t pointer for the loop to run safely
 *//**
 * @brief Provide the primitive to iterate on a list, from a node in the list
 * Note: the loop is unsafe and thus __dn should not be removed
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_DLIST_ITERATE_FROM_NODE(l, n) {
 *         <user code>
 *     }
 *
 * Like SYS_DLIST_FOR_EACH_NODE(), but __dn already contains a node in the list
 * where to start searching for the next entry from. If NULL, it starts from
 * the head.
 *
 * This and other SYS_DLIST_*() macros are not thread safe.
 *
 * @param __dl A pointer on a sys_dlist_t to iterate on
 * @param __dn A sys_dnode_t pointer to peek each node of the list;
 *             it contains the starting node, or NULL to start from the head
 *//**
 * @brief Provide the primitive to iterate on a list
 * Note: the loop is unsafe and thus __dn should not be removed
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_DLIST_FOR_EACH_NODE(l, n) {
 *         <user code>
 *     }
 *
 * This and other SYS_DLIST_*() macros are not thread safe.
 *
 * @param __dl A pointer on a sys_dlist_t to iterate on
 * @param __dn A sys_dnode_t pointer to peek each node of the list
 *//**
 * @brief Doubly-linked list node structure.
 *//**
 * @brief Doubly-linked list structure.
 *//* ptr to previous node (sys_dnode_t) *//* ptr to tail of list (sys_dlist_t) *//* ptr to next node    (sys_dnode_t) *//* ptr to head of list (sys_dlist_t) *//**
 * @file
 * @defgroup doubly-linked-list_apis Doubly-linked list
 * @ingroup datastructure_apis
 *
 * @brief Doubly-linked list implementation
 *
 * Doubly-linked list implementation using inline macros/functions.
 * This API is not thread safe, and thus if a list is used across threads,
 * calls to functions must be protected with synchronization primitives.
 *
 * The lists are expected to be initialized such that both the head and tail
 * pointers point to the list itself.  Initializing the lists in such a fashion
 * simplifies the adding and removing of nodes to/from the list.
 *
 * @{
 *//*
 * Copyright (c) 2013-2015 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */condsuccessorrbnode *z_rb_foreach_nextrbtree *_rb_foreach *rb_walkrb_containsrb_get_maxrb_get_minrb_removerb_insertz_rb_get_minmaxz_rb_walkz_rb_is_blackz_rb_child_rb_foreachrb_visit_trbtreerb_lessthan_trbnodetopis_leftrbnode **max_depthlessthan_fnrootrbnode *[2]childrenRB_FOR_EACH_CONTAINER(tree,node,field)for (struct _rb_foreach __f = _RB_FOREACH_INIT(tree, node); ({struct rbnode *n = z_rb_foreach_next(tree, &__f); node = n ? CONTAINER_OF(n, __typeof__(*(node)), field) : NULL; }) != NULL; )RB_FOR_EACH(tree,node)for (struct _rb_foreach __f = _RB_FOREACH_INIT(tree, node); (node = z_rb_foreach_next(tree, &__f)); )_RB_FOREACH_INIT(tree,node){ .stack = (struct rbnode **) alloca((tree)->max_depth * sizeof(struct rbnode *)), .is_left = (uint8_t *)alloca((tree)->max_depth * sizeof(uint8_t)), .top = -1 }Z_MAX_RBTREE_DEPTH(2 * (Z_PBITS(int *) - Z_TBITS(int *) - 1) + 1)Z_PBITS(t)(8 * sizeof(t))Z_TBITS(t)((sizeof(t)) < 8 ? 2 : 3)alloca__builtin_allocaZEPHYR_INCLUDE_SYS_RB_H_CONFIG_MISRA_SANE/* ZEPHYR_INCLUDE_SYS_RB_H_ *//**
 * @brief Loop over rbtree with implicit container field logic
 *
 * As for RB_FOR_EACH(), but "node" can have an arbitrary type
 * containing a struct rbnode.
 *
 * @param tree A pointer to a struct rbtree to walk
 * @param node The symbol name of a local iterator
 * @param field The field name of a struct rbnode inside node
 *//**
 * @brief Walk a tree in-order without recursing
 *
 * While @ref rb_walk() is very simple, recursing on the C stack can
 * be clumsy for some purposes and on some architectures wastes
 * significant memory in stack frames.  This macro implements a
 * non-recursive "foreach" loop that can iterate directly on the tree,
 * at a moderate cost in code size.
 *
 * Note that the resulting loop is not safe against modifications to
 * the tree.  Changes to the tree structure during the loop will
 * produce incorrect results, as nodes may be skipped or duplicated.
 * Unlike linked lists, no _SAFE variant exists.
 *
 * Note also that the macro expands its arguments multiple times, so
 * they should not be expressions with side effects.
 *
 * @param tree A pointer to a struct rbtree to walk
 * @param node The symbol name of a local struct rbnode* variable to
 *             use as the iterator
 *//**
 * @brief Walk/enumerate a rbtree
 *
 * Very simple recursive enumeration.  Low code size, but requiring a
 * separate function can be clumsy for the user and there is no way to
 * break out of the loop early.  See RB_FOR_EACH for an iterative
 * implementation.
 *//**
 * @brief Returns true if the given node is part of the tree
 *
 * Note that this does not internally dereference the node pointer
 * (though the tree's lessthan callback might!), it just tests it for
 * equality with items in the tree.  So it's feasible to use this to
 * implement a "set" construct by simply testing the pointer value
 * itself.
 *//**
 * @brief Returns the highest-sorted member of the tree
 *//**
 * @brief Returns the lowest-sorted member of the tree
 *//**
 * @brief Remove node from tree
 *//**
 * @brief Insert node into tree
 *//**
 * @brief Prototype for node visitor callback.
 * @param node Node being visited
 * @param cookie User-specified data
 *//** @endcond *//** @cond INTERNAL_HIDDEN *//** Comparison function for nodes in the tree *//** Root node of the tree *//**
 * @brief Balanced red/black tree structure
 *//**
 * @typedef rb_lessthan_t
 * @brief Red/black tree comparison predicate
 *
 * Compares the two nodes and returns true if node A is strictly less
 * than B according to the tree's sorting criteria, false otherwise.
 *
 * Note that during insert, the new node being inserted will always be
 * "A", where "B" is the existing node within the tree against which
 * it is being compared.  This trait can be used (with care!) to
 * implement "most/least recently added" semantics between nodes which
 * would otherwise compare as equal.
 *//* Theoretical maximum depth of tree based on pointer size. If memory
 * is filled with 2-pointer nodes, and the tree can be twice as a
 * packed binary tree, plus root...  Works out to 59 entries for 32
 * bit pointers and 121 at 64 bits.
 *//**
 * @brief Balanced red/black tree node structure
 *//* Our SDK/toolchains integration seems to be inconsistent about
 * whether they expose alloca.h or not.  On gcc it's a moot point as
 * it's always builtin.
 *//**
 * @file
 * @defgroup rbtree_apis Balanced Red/Black Tree
 * @ingroup datastructure_apis
 *
 * @brief Balanced Red/Black Tree implementation
 *
 * This implements an intrusive balanced tree that guarantees
 * O(log2(N)) runtime for all operations and amortized O(1) behavior
 * for creation and destruction of whole trees. The algorithms and
 * naming are conventional per existing academic and didactic
 * implementations, c.f.:
 *
 * https://en.wikipedia.org/wiki/Red%E2%80%93black_tree
 *
 * The implementation is size-optimized to prioritize runtime memory
 * usage. The data structure is intrusive, which is to say the @ref
 * rbnode handle is intended to be placed in a separate struct, in the
 * same way as with other such structures (e.g. Zephyr's @ref
 * doubly-linked-list_apis), and requires no data pointer to be stored
 * in the node. The color bit is unioned with a pointer (fairly common
 * for such libraries). Most notably, there is no "parent" pointer
 * stored in the node, the upper structure of the tree being generated
 * dynamically via a stack as the tree is recursed. So the overall
 * memory overhead of a node is just two pointers, identical with a
 * doubly-linked list.
 *
 * @{
 */treevisit_fncookiefside<zephyr/sys/rb.h><zephyr/sys/dlist.h>z_priq_mq_best_priq_mq *z_priq_rb_best_priq_rb *z_priq_rb_removez_priq_rb_addz_priq_dumb_removez_priq_dumb_best_priq_mq_priq_rbbitmasksys_dlist_t[32]_dnode[32]queuesnext_order_keyZEPHYR_INCLUDE_SCHED_PRIQ_H_/* ZEPHYR_INCLUDE_SCHED_PRIQ_H_ *//* bit 1<<i set if queues[i] is non-empty *//* Traditional/textbook "multi-queue" structure.  Separate lists for a
 * small number (max 32 here) of fixed priorities.  This corresponds
 * to the original Zephyr scheduler.  RAM requirements are
 * comparatively high, but performance is very fast.  Won't work with
 * features like deadline scheduling which need large priority spaces
 * to represent their requirements.
 *//* Two abstractions are defined here for "thread priority queues".
 *
 * One is a "dumb" list implementation appropriate for systems with
 * small numbers of threads and sensitive to code size.  It is stored
 * in sorted order, taking an O(N) cost every time a thread is added
 * to the list.  This corresponds to the way the original _wait_q_t
 * abstraction worked and is very fast as long as the number of
 * threads is small.
 *
 * The other is a balanced tree "fast" implementation with rather
 * larger code size (due to the data structure itself, the code here
 * is just stubs) and higher constant-factor performance overhead, but
 * much better O(logN) scaling in the presence of large number of
 * threads.
 *
 * Each can be used for either the wait_q or system ready queue,
 * configurable at build time.
 *//home/haojie/zephyrproject/zephyr/include/zephyr/kernel/internal/home/haojie/zephyrproject/zephyr/include/zephyr/kernelpqZ_GENLIST_LEN(__lname,__nname)static inline size_t sys_ ## __lname ## _len(sys_ ## __lname ## _t * list) { size_t len = 0; static sys_ ## __nname ## _t * node; Z_GENLIST_FOR_EACH_NODE(__lname, list, node) { len++; } return len; }Z_GENLIST_FIND_AND_REMOVE(__lname,__nname)static inline bool sys_ ## __lname ## _find_and_remove(sys_ ## __lname ## _t *list, sys_ ## __nname ## _t *node) { sys_ ## __nname ## _t *prev = NULL; sys_ ## __nname ## _t *test; Z_GENLIST_FOR_EACH_NODE(__lname, list, test) { if (test == node) { sys_ ## __lname ## _remove(list, prev, node); return true; } prev = test; } return false; }Z_GENLIST_REMOVE(__lname,__nname)static inline void sys_ ## __lname ## _remove(sys_ ## __lname ## _t *list, sys_ ## __nname ## _t *prev_node, sys_ ## __nname ## _t *node) { if (prev_node == NULL) { z_ ## __lname ## _head_set(list, z_ ## __nname ## _next_peek(node)); if (sys_ ## __lname ## _peek_tail(list) == node) { z_ ## __lname ## _tail_set(list, sys_ ## __lname ## _peek_head(list)); } } else { z_ ## __nname ## _next_set(prev_node, z_ ## __nname ## _next_peek(node)); if (sys_ ## __lname ## _peek_tail(list) == node) { z_ ## __lname ## _tail_set(list, prev_node); } } z_ ## __nname ## _next_set(node, NULL); }Z_GENLIST_GET(__lname,__nname)static inline sys_ ## __nname ## _t * sys_ ## __lname ## _get(sys_ ## __lname ## _t *list) { return sys_ ## __lname ## _is_empty(list) ? NULL : sys_ ## __lname ## _get_not_empty(list); }Z_GENLIST_GET_NOT_EMPTY(__lname,__nname)static inline sys_ ## __nname ## _t * sys_ ## __lname ## _get_not_empty(sys_ ## __lname ## _t *list) { sys_ ## __nname ## _t *node = sys_ ## __lname ## _peek_head(list); z_ ## __lname ## _head_set(list, z_ ## __nname ## _next_peek(node)); if (sys_ ## __lname ## _peek_tail(list) == node) { z_ ## __lname ## _tail_set(list, sys_ ## __lname ## _peek_head(list)); } return node; }Z_GENLIST_INSERT(__lname,__nname)static inline void sys_ ## __lname ## _insert(sys_ ## __lname ## _t *list, sys_ ## __nname ## _t *prev, sys_ ## __nname ## _t *node) { if (prev == NULL) { sys_ ## __lname ## _prepend(list, node); } else if (z_ ## __nname ## _next_peek(prev) == NULL) { sys_ ## __lname ## _append(list, node); } else { z_ ## __nname ## _next_set(node, z_ ## __nname ## _next_peek(prev)); z_ ## __nname ## _next_set(prev, node); } }Z_GENLIST_MERGE_LIST(__lname,__nname)static inline void sys_ ## __lname ## _merge_ ## __lname ( sys_ ## __lname ## _t *list, sys_ ## __lname ## _t *list_to_append) { sys_ ## __nname ## _t *head, *tail; head = sys_ ## __lname ## _peek_head(list_to_append); tail = sys_ ## __lname ## _peek_tail(list_to_append); sys_ ## __lname ## _append_list(list, head, tail); sys_ ## __lname ## _init(list_to_append); }Z_GENLIST_APPEND_LIST(__lname,__nname)static inline void sys_ ## __lname ## _append_list(sys_ ## __lname ## _t *list, void *head, void *tail) { if (head != NULL && tail != NULL) { if (sys_ ## __lname ## _peek_tail(list) == NULL) { z_ ## __lname ## _head_set(list, (sys_ ## __nname ## _t *)head); } else { z_ ## __nname ## _next_set( sys_ ## __lname ## _peek_tail(list), (sys_ ## __nname ## _t *)head); } z_ ## __lname ## _tail_set(list, (sys_ ## __nname ## _t *)tail); } }Z_GENLIST_APPEND(__lname,__nname)static inline void sys_ ## __lname ## _append(sys_ ## __lname ## _t *list, sys_ ## __nname ## _t *node) { z_ ## __nname ## _next_set(node, NULL); if (sys_ ## __lname ## _peek_tail(list) == NULL) { z_ ## __lname ## _tail_set(list, node); z_ ## __lname ## _head_set(list, node); } else { z_ ## __nname ## _next_set( sys_ ## __lname ## _peek_tail(list), node); z_ ## __lname ## _tail_set(list, node); } }Z_GENLIST_PREPEND(__lname,__nname)static inline void sys_ ## __lname ## _prepend(sys_ ## __lname ## _t *list, sys_ ## __nname ## _t *node) { z_ ## __nname ## _next_set(node, sys_ ## __lname ## _peek_head(list)); z_ ## __lname ## _head_set(list, node); if (sys_ ## __lname ## _peek_tail(list) == NULL) { z_ ## __lname ## _tail_set(list, sys_ ## __lname ## _peek_head(list)); } }Z_GENLIST_PEEK_NEXT(__lname,__nname)static inline sys_ ## __nname ## _t * sys_ ## __lname ## _peek_next(sys_ ## __nname ## _t *node) { return node != NULL ? sys_ ## __lname ## _peek_next_no_check(node) : NULL; }Z_GENLIST_PEEK_NEXT_NO_CHECK(__lname,__nname)static inline sys_ ## __nname ## _t * sys_ ## __lname ## _peek_next_no_check(sys_ ## __nname ## _t *node) { return z_ ## __nname ## _next_peek(node); }Z_GENLIST_IS_EMPTY(__lname)static inline bool sys_ ## __lname ## _is_empty(sys_ ## __lname ## _t *list) { return (sys_ ## __lname ## _peek_head(list) == NULL); }Z_GENLIST_FOR_EACH_CONTAINER_SAFE(__lname,__l,__cn,__cns,__n)for (__cn = Z_GENLIST_PEEK_HEAD_CONTAINER(__lname, __l, __cn, __n), __cns = Z_GENLIST_PEEK_NEXT_CONTAINER(__lname, __cn, __n); __cn != NULL; __cn = __cns, __cns = Z_GENLIST_PEEK_NEXT_CONTAINER(__lname, __cn, __n))Z_GENLIST_FOR_EACH_CONTAINER(__lname,__l,__cn,__n)for (__cn = Z_GENLIST_PEEK_HEAD_CONTAINER(__lname, __l, __cn, __n); __cn != NULL; __cn = Z_GENLIST_PEEK_NEXT_CONTAINER(__lname, __cn, __n))Z_GENLIST_PEEK_NEXT_CONTAINER(__lname,__cn,__n)((__cn) ? Z_GENLIST_CONTAINER( sys_ ## __lname ## _peek_next(&((__cn)->__n)), __cn, __n) : NULL)Z_GENLIST_PEEK_TAIL_CONTAINER(__lname,__l,__cn,__n)Z_GENLIST_CONTAINER(sys_ ## __lname ## _peek_tail(__l), __cn, __n)Z_GENLIST_PEEK_HEAD_CONTAINER(__lname,__l,__cn,__n)Z_GENLIST_CONTAINER(sys_ ## __lname ## _peek_head(__l), __cn, __n)Z_GENLIST_CONTAINER(__ln,__cn,__n)((__ln) ? CONTAINER_OF((__ln), __typeof__(*(__cn)), __n) : NULL)Z_GENLIST_FOR_EACH_NODE_SAFE(__lname,__l,__sn,__sns)for (__sn = sys_ ## __lname ## _peek_head(__l), __sns = sys_ ## __lname ## _peek_next(__sn); __sn != NULL ; __sn = __sns, __sns = sys_ ## __lname ## _peek_next(__sn))Z_GENLIST_ITERATE_FROM_NODE(__lname,__l,__sn)for (__sn = __sn ? sys_ ## __lname ## _peek_next_no_check(__sn) : sys_ ## __lname ## _peek_head(__l); __sn != NULL; __sn = sys_ ## __lname ## _peek_next(__sn))Z_GENLIST_FOR_EACH_NODE(__lname,__l,__sn)for (__sn = sys_ ## __lname ## _peek_head(__l); __sn != NULL; __sn = sys_ ## __lname ## _peek_next(__sn))ZEPHYR_INCLUDE_SYS_LIST_GEN_H_/* ZEPHYR_INCLUDE_SYS_LIST_GEN_H_ *//* Was node the tail? *//* Was node also the tail? *//*
 * Copyright (c) 2016 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */"list_gen.h"sys_slist_find_and_removesys_slist_t *_slist *sys_snode_t *_snode *slistsnodetestsys_slist_lensys_slist_removesys_slist_getsys_slist_get_not_emptysys_slist_insertsys_slist_merge_slistsys_slist_append_listsys_slist_appendsys_slist_prependsys_slist_peek_nextsys_slist_peek_next_no_checksys_slist_is_emptysys_slist_peek_tailsys_slist_peek_headz_slist_tail_setz_slist_head_setz_snode_next_setz_snode_next_peeksys_slist_initsys_slist_t_slistsys_snode_t_snodeSYS_SLIST_STATIC_INIT(ptr_to_list){NULL, NULL}SYS_SLIST_FOR_EACH_CONTAINER_SAFE(__sl,__cn,__cns,__n)Z_GENLIST_FOR_EACH_CONTAINER_SAFE(slist, __sl, __cn, __cns, __n)SYS_SLIST_FOR_EACH_CONTAINER(__sl,__cn,__n)Z_GENLIST_FOR_EACH_CONTAINER(slist, __sl, __cn, __n)SYS_SLIST_PEEK_NEXT_CONTAINER(__cn,__n)Z_GENLIST_PEEK_NEXT_CONTAINER(slist, __cn, __n)SYS_SLIST_PEEK_TAIL_CONTAINER(__sl,__cn,__n)Z_GENLIST_PEEK_TAIL_CONTAINER(slist, __sl, __cn, __n)SYS_SLIST_PEEK_HEAD_CONTAINER(__sl,__cn,__n)Z_GENLIST_PEEK_HEAD_CONTAINER(slist, __sl, __cn, __n)SYS_SLIST_CONTAINER(__ln,__cn,__n)Z_GENLIST_CONTAINER(__ln, __cn, __n)SYS_SLIST_FOR_EACH_NODE_SAFE(__sl,__sn,__sns)Z_GENLIST_FOR_EACH_NODE_SAFE(slist, __sl, __sn, __sns)SYS_SLIST_ITERATE_FROM_NODE(__sl,__sn)Z_GENLIST_ITERATE_FROM_NODE(slist, __sl, __sn)SYS_SLIST_FOR_EACH_NODE(__sl,__sn)Z_GENLIST_FOR_EACH_NODE(slist, __sl, __sn)ZEPHYR_INCLUDE_SYS_SLIST_H_/* ZEPHYR_INCLUDE_SYS_SLIST_H_ *//**
 * @brief Find and remove a node from a list
 *
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param node A pointer on the node to remove from the list
 *
 * @return true if node was removed
 *//**
 * @brief Remove a node
 *
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param prev_node A pointer on the previous node
 *        (can be NULL, which means the node is the list's head)
 * @param node A pointer on the node to remove
 *//**
 * @brief Fetch and remove the first node of the given list
 *
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 *//**
 * @brief Fetch and remove the first node of the given list
 *
 * List must be known to be non-empty.
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 *
 * @return A pointer to the first node of the list
 *//**
 * @brief Insert a node to the given list
 *
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param prev A pointer on the previous node
 * @param node A pointer on the node to insert
 *//**
 * @brief merge two slists, appending the second one to the first
 *
 * When the operation is completed, the appending list is empty.
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param list_to_append A pointer to the list to append.
 *//**
 * @brief Append a list to the given list
 *
 * Append a singly-linked, NULL-terminated list consisting of nodes containing
 * the pointer to the next node as the first element of a node, to @a list.
 * This and other sys_slist_*() functions are not thread safe.
 *
 * FIXME: Why are the element parameters void *?
 *
 * @param list A pointer on the list to affect
 * @param head A pointer to the first element of the list to append
 * @param tail A pointer to the last element of the list to append
 *//**
 * @brief Append a node to the given list
 *
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param node A pointer on the node to append
 *//**
 * @brief Prepend a node to the given list
 *
 * This and other sys_slist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param node A pointer on the node to prepend
 *//**
 * @brief Peek the next node from current node
 *
 * @param node A pointer on the node where to peek the next node
 *
 * @return a pointer on the next node (or NULL if none)
 *//**
 * @brief Peek the next node from current node, node is not NULL
 *
 * Faster then sys_slist_peek_next() if node is known not to be NULL.
 *
 * @param node A pointer on the node where to peek the next node
 *
 * @return a pointer on the next node (or NULL if none)
 *//**
 * @brief Test if the given list is empty
 *
 * @param list A pointer on the list to test
 *
 * @return a boolean, true if it's empty, false otherwise
 *//*
 * Derived, generated APIs
 *//**
 * @brief Peek the last node from the list
 *
 * @param list A point on the list to peek the last node from
 *
 * @return A pointer on the last node of the list (or NULL if none)
 *//**
 * @brief Peek the first node from the list
 *
 * @param list A point on the list to peek the first node from
 *
 * @return A pointer on the first node of the list (or NULL if none)
 *//**
 * @brief Statically initialize a single-linked list
 * @param ptr_to_list A pointer on the list to initialize
 *//**
 * @brief Initialize a list
 *
 * @param list A pointer on the list to initialize
 *//*
 * Required function definitions for the list_gen.h interface
 *
 * These are the only functions that do not treat the list/node pointers
 * as completely opaque types.
 *//**
 * @brief Provide the primitive to safely iterate on a list under a container
 * Note: __cn can be detached, it will not break the loop.
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SLIST_FOR_EACH_NODE_SAFE(l, c, cn, n) {
 *         <user code>
 *     }
 *
 * @param __sl A pointer on a sys_slist_t to iterate on
 * @param __cn A pointer to peek each entry of the list
 * @param __cns A pointer for the loop to run safely
 * @param __n The field name of sys_node_t within the container struct
 *//**
 * @brief Provide the primitive to iterate on a list under a container
 * Note: the loop is unsafe and thus __cn should not be detached
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SLIST_FOR_EACH_CONTAINER(l, c, n) {
 *         <user code>
 *     }
 *
 * @param __sl A pointer on a sys_slist_t to iterate on
 * @param __cn A pointer to peek each entry of the list
 * @param __n The field name of sys_node_t within the container struct
 *//**
 * @brief Provide the primitive to peek the next container
 *
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_node_t within the container struct
 *//**
 * @brief Provide the primitive to peek container of the list tail
 *
 * @param __sl A pointer on a sys_slist_t to peek
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_node_t within the container struct
 *//**
 * @brief Provide the primitive to peek container of the list head
 *
 * @param __sl A pointer on a sys_slist_t to peek
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_node_t within the container struct
 *//**
 * @brief Provide the primitive to resolve the container of a list node
 * Note: it is safe to use with NULL pointer nodes
 *
 * @param __ln A pointer on a sys_node_t to get its container
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_node_t within the container struct
 *//**
 * @brief Provide the primitive to safely iterate on a list
 * Note: __sn can be removed, it will not break the loop.
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SLIST_FOR_EACH_NODE_SAFE(l, n, s) {
 *         <user code>
 *     }
 *
 * This and other SYS_SLIST_*() macros are not thread safe.
 *
 * @param __sl A pointer on a sys_slist_t to iterate on
 * @param __sn A sys_snode_t pointer to peek each node of the list
 * @param __sns A sys_snode_t pointer for the loop to run safely
 *//**
 * @brief Provide the primitive to iterate on a list, from a node in the list
 * Note: the loop is unsafe and thus __sn should not be removed
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SLIST_ITERATE_FROM_NODE(l, n) {
 *         <user code>
 *     }
 *
 * Like SYS_SLIST_FOR_EACH_NODE(), but __dn already contains a node in the list
 * where to start searching for the next entry from. If NULL, it starts from
 * the head.
 *
 * This and other SYS_SLIST_*() macros are not thread safe.
 *
 * @param __sl A pointer on a sys_slist_t to iterate on
 * @param __sn A sys_snode_t pointer to peek each node of the list
 *             it contains the starting node, or NULL to start from the head
 *//**
 * @brief Provide the primitive to iterate on a list
 * Note: the loop is unsafe and thus __sn should not be removed
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SLIST_FOR_EACH_NODE(l, n) {
 *         <user code>
 *     }
 *
 * This and other SYS_SLIST_*() macros are not thread safe.
 *
 * @param __sl A pointer on a sys_slist_t to iterate on
 * @param __sn A sys_snode_t pointer to peek each node of the list
 *//** Single-linked list structure. *//** Single-linked list node structure. *//**
  * @file
  * @defgroup single-linked-list_apis Single-linked list
  * @ingroup datastructure_apis
  *
  * @brief Single-linked list implementation.
  *
  * Single-linked list implementation using inline macros/functions.
  * This API is not thread safe, and thus if a list is used across threads,
  * calls to functions must be protected with synchronization primitives.
  * @{
  */prev_nodelist_to_appendparentchildsys_sflist_lensys_sflist_t *_sflist *sflistsfnodesys_sfnode_t *_sfnode *sys_sflist_find_and_removesys_sflist_removesys_sflist_getsys_sflist_get_not_emptysys_sflist_insertsys_sflist_merge_sflistsys_sflist_append_listsys_sflist_appendsys_sflist_prependsys_sflist_peek_nextsys_sflist_peek_next_no_checksys_sflist_is_emptysys_sfnode_flags_set(flags & ~SYS_SFLIST_FLAGS_MASK) == 0UL"flags too large"sys_sfnode_initsys_sfnode_flags_getSYS_SFLIST_FLAGS_MASKsys_sflist_peek_tailsys_sflist_peek_headz_sflist_tail_setz_sflist_head_setz_sfnode_next_setcur_flagsz_sfnode_next_peek4294967292~SYS_SFLIST_FLAGS_MASKsys_sflist_initsys_sflist_t_sflistsys_sfnode_t_sfnodeunative_tnext_and_flags0x3ULSYS_SFLIST_STATIC_INIT(ptr_to_list)SYS_SFLIST_FOR_EACH_CONTAINER_SAFE(__sl,__cn,__cns,__n)Z_GENLIST_FOR_EACH_CONTAINER_SAFE(sflist, __sl, __cn, __cns, __n)SYS_SFLIST_FOR_EACH_CONTAINER(__sl,__cn,__n)Z_GENLIST_FOR_EACH_CONTAINER(sflist, __sl, __cn, __n)SYS_SFLIST_PEEK_NEXT_CONTAINER(__cn,__n)Z_GENLIST_PEEK_NEXT_CONTAINER(sflist, __cn, __n)SYS_SFLIST_PEEK_TAIL_CONTAINER(__sl,__cn,__n)Z_GENLIST_PEEK_TAIL_CONTAINER(sflist, __sl, __cn, __n)SYS_SFLIST_PEEK_HEAD_CONTAINER(__sl,__cn,__n)Z_GENLIST_PEEK_HEAD_CONTAINER(sflist, __sl, __cn, __n)SYS_SFLIST_CONTAINER(__ln,__cn,__n)SYS_SFLIST_FOR_EACH_NODE_SAFE(__sl,__sn,__sns)Z_GENLIST_FOR_EACH_NODE_SAFE(sflist, __sl, __sn, __sns)SYS_SFLIST_ITERATE_FROM_NODE(__sl,__sn)Z_GENLIST_ITERATE_FROM_NODE(sflist, __sl, __sn)SYS_SFLIST_FOR_EACH_NODE(__sl,__sn)Z_GENLIST_FOR_EACH_NODE(sflist, __sl, __sn)ZEPHYR_INCLUDE_SYS_SFLIST_H_/* ZEPHYR_INCLUDE_SYS_SFLIST_H_ *//**
 * @brief Find and remove a node from a list
 *
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param node A pointer on the node to remove from the list
 *
 * @return true if node was removed
 *//**
 * @brief Remove a node
 *
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param prev_node A pointer on the previous node
 *        (can be NULL, which means the node is the list's head)
 * @param node A pointer on the node to remove
 *//**
 * @brief Fetch and remove the first node of the given list
 *
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 *//**
 * @brief Fetch and remove the first node of the given list
 *
 * List must be known to be non-empty.
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 *
 * @return A pointer to the first node of the list
 *//**
 * @brief Insert a node to the given list
 *
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param prev A pointer on the previous node
 * @param node A pointer on the node to insert
 *//**
 * @brief merge two sflists, appending the second one to the first
 *
 * When the operation is completed, the appending list is empty.
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param list_to_append A pointer to the list to append.
 *//**
 * @brief Append a list to the given list
 *
 * Append a singly-linked, NULL-terminated list consisting of nodes containing
 * the pointer to the next node as the first element of a node, to @a list.
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * FIXME: Why are the element parameters void *?
 *
 * @param list A pointer on the list to affect
 * @param head A pointer to the first element of the list to append
 * @param tail A pointer to the last element of the list to append
 *//**
 * @brief Append a node to the given list
 *
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param node A pointer on the node to append
 *//**
 * @brief Prepend a node to the given list
 *
 * This and other sys_sflist_*() functions are not thread safe.
 *
 * @param list A pointer on the list to affect
 * @param node A pointer on the node to prepend
 *//**
 * @brief Peek the next node from current node, node is not NULL
 *
 * Faster then sys_sflist_peek_next() if node is known not to be NULL.
 *
 * @param node A pointer on the node where to peek the next node
 *
 * @return a pointer on the next node (or NULL if none)
 *//**
 * @brief Set flags value for an sflist node
 *
 * Set a flags value for this slist node, which can be a value between
 * 0 and 3. These flags will persist even if the node is moved around
 * within a list, removed, or transplanted to a different slist.
 *
 * @param node A pointer to the node to set the flags on
 * @param flags A value between 0 and 3 to set the flags value
 *//**
 * @brief Initialize an sflist node
 *
 * Set an initial flags value for this slist node, which can be a value between
 * 0 and 3. These flags will persist even if the node is moved around
 * within a list, removed, or transplanted to a different slist.
 *
 * This is ever so slightly faster than sys_sfnode_flags_set() and should
 * only be used on a node that hasn't been added to any list.
 *
 * @param node A pointer to the node to set the flags on
 * @param flags A value between 0 and 3 to set the flags value
 *//**
 * @brief Fetch flags value for a particular sfnode
 *
 * @param node A pointer to the node to fetch flags from
 * @return The value of flags, which will be between 0 and 3
 *//*
 * APIs specific to sflist type
 *//**
 * @brief Statically initialize a flagged single-linked list
 * @param ptr_to_list A pointer on the list to initialize
 *//**
 * @brief Provide the primitive to safely iterate on a list under a container
 * Note: __cn can be detached, it will not break the loop.
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SFLIST_FOR_EACH_NODE_SAFE(l, c, cn, n) {
 *         <user code>
 *     }
 *
 * @param __sl A pointer on a sys_sflist_t to iterate on
 * @param __cn A pointer to peek each entry of the list
 * @param __cns A pointer for the loop to run safely
 * @param __n The field name of sys_sfnode_t within the container struct
 *//**
 * @brief Provide the primitive to iterate on a list under a container
 * Note: the loop is unsafe and thus __cn should not be detached
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SFLIST_FOR_EACH_CONTAINER(l, c, n) {
 *         <user code>
 *     }
 *
 * @param __sl A pointer on a sys_sflist_t to iterate on
 * @param __cn A pointer to peek each entry of the list
 * @param __n The field name of sys_sfnode_t within the container struct
 *//**
 * @brief Provide the primitive to peek the next container
 *
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_sfnode_t within the container struct
 *//**
 * @brief Provide the primitive to peek container of the list tail
 *
 * @param __sl A pointer on a sys_sflist_t to peek
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_sfnode_t within the container struct
 *//**
 * @brief Provide the primitive to peek container of the list head
 *
 * @param __sl A pointer on a sys_sflist_t to peek
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_sfnode_t within the container struct
 *//**
 * @brief Provide the primitive to resolve the container of a list node
 * Note: it is safe to use with NULL pointer nodes
 *
 * @param __ln A pointer on a sys_sfnode_t to get its container
 * @param __cn Container struct type pointer
 * @param __n The field name of sys_sfnode_t within the container struct
 *//**
 * @brief Provide the primitive to safely iterate on a list
 * Note: __sn can be removed, it will not break the loop.
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SFLIST_FOR_EACH_NODE_SAFE(l, n, s) {
 *         <user code>
 *     }
 *
 * This and other SYS_SFLIST_*() macros are not thread safe.
 *
 * @param __sl A pointer on a sys_sflist_t to iterate on
 * @param __sn A sys_sfnode_t pointer to peek each node of the list
 * @param __sns A sys_sfnode_t pointer for the loop to run safely
 *//**
 * @brief Provide the primitive to iterate on a list, from a node in the list
 * Note: the loop is unsafe and thus __sn should not be removed
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SFLIST_ITERATE_FROM_NODE(l, n) {
 *         <user code>
 *     }
 *
 * Like SYS_SFLIST_FOR_EACH_NODE(), but __dn already contains a node in the list
 * where to start searching for the next entry from. If NULL, it starts from
 * the head.
 *
 * This and other SYS_SFLIST_*() macros are not thread safe.
 *
 * @param __sl A pointer on a sys_sflist_t to iterate on
 * @param __sn A sys_sfnode_t pointer to peek each node of the list
 *             it contains the starting node, or NULL to start from the head
 *//**
 * @brief Provide the primitive to iterate on a list
 * Note: the loop is unsafe and thus __sn should not be removed
 *
 * User _MUST_ add the loop statement curly braces enclosing its own code:
 *
 *     SYS_SFLIST_FOR_EACH_NODE(l, n) {
 *         <user code>
 *     }
 *
 * This and other SYS_SFLIST_*() macros are not thread safe.
 *
 * @param __sl A pointer on a sys_sflist_t to iterate on
 * @param __sn A sys_sfnode_t pointer to peek each node of the list
 *//** Flagged single-linked list structure. *//** Flagged single-linked list node structure. *//**
  * @file
  * @defgroup flagged-single-linked-list_apis Flagged Single-linked list
  * @ingroup datastructure_apis
  *
  * @brief Flagged single-linked list implementation.
  *
  * Similar to @ref single-linked-list_apis with the added ability to define
  * two bits of user "flags" for each node. They can be accessed and modified
  * using the sys_sfnode_flags_get() and sys_sfnode_flags_set() APIs.
  *
  * Flagged single-linked list implementation using inline macros/functions.
  * This API is not thread safe, and thus if a list is used across threads,
  * calls to functions must be protected with synchronization primitives.
  *
  * @{
  */k_obj_core_stats_enablek_obj_core *k_obj_core_stats_disablek_obj_core_stats_resetk_obj_core_stats_queryk_obj_core_stats_rawk_obj_core_stats_deregisterk_obj_core_stats_registerk_obj_core_unlinkk_obj_core_init_and_linkk_obj_type *k_obj_core_linkk_obj_core_initk_obj_type_walk_unlockedk_obj_type_walk_lockedk_obj_type_findz_obj_type_initk_obj_core_stats_desck_obj_corek_obj_typeenabledisableresetqueryrawobj_core_offsetquery_sizeraw_sizez_obj_type_listK_OBJ_CORE_LINK(objp)do { } while (0)K_OBJ_CORE_INIT(objp,type)K_OBJ_TYPE_TIMER_IDK_OBJ_TYPE_ID_GEN("TIMR")K_OBJ_TYPE_THREAD_IDK_OBJ_TYPE_ID_GEN("THRD")K_OBJ_TYPE_STACK_IDK_OBJ_TYPE_ID_GEN("STCK")K_OBJ_TYPE_SEM_IDK_OBJ_TYPE_ID_GEN("SEM4")K_OBJ_TYPE_PIPE_IDK_OBJ_TYPE_ID_GEN("PIPE")K_OBJ_TYPE_MUTEX_IDK_OBJ_TYPE_ID_GEN("MUTX")K_OBJ_TYPE_MSGQ_IDK_OBJ_TYPE_ID_GEN("MSGQ")K_OBJ_TYPE_MEM_SLAB_IDK_OBJ_TYPE_ID_GEN("SLAB")K_OBJ_TYPE_MBOX_IDK_OBJ_TYPE_ID_GEN("MBOX")K_OBJ_TYPE_MEM_BLOCK_IDK_OBJ_TYPE_ID_GEN("MBLK")K_OBJ_TYPE_LIFO_IDK_OBJ_TYPE_ID_GEN("LIFO")K_OBJ_TYPE_KERNEL_IDK_OBJ_TYPE_ID_GEN("KRNL")K_OBJ_TYPE_FIFO_IDK_OBJ_TYPE_ID_GEN("FIFO")K_OBJ_TYPE_EVENT_IDK_OBJ_TYPE_ID_GEN("EVNT")K_OBJ_TYPE_CPU_IDK_OBJ_TYPE_ID_GEN("CPU_")K_OBJ_TYPE_CONDVAR_IDK_OBJ_TYPE_ID_GEN("COND")K_OBJ_TYPE_ID_GEN(s)((s[0] << 24) | (s[1] << 16) | (s[2] << 8) | (s[3]))K_OBJ_CORE(kobj)(&((kobj)->obj_core))__KERNEL_OBJ_CORE_H__CONFIG_OBJ_CORECONFIG_OBJ_CORE_STATS/* __KERNEL_OBJ_CORE_H__ *//**
 * @brief Reset the stats associated with the kernel object
 *
 * This function resumes the gathering of statistics associated with the kernel
 * object core specified by @a obj_core.
 *
 * @param obj_core Pointer to kernel object core
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Stop gathering the stats associated with the kernel object
 *
 * This function temporarily stops the gathering of statistics associated with
 * the kernel object core specified by @a obj_core. The gathering of statistics
 * can be resumed by invoking :c:func :`k_obj_core_stats_enable`.
 *
 * @param obj_core Pointer to kernel object core
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Reset the stats associated with the kernel object
 *
 * This function resets the statistics associated with the kernel object core
 * specified by @a obj_core.
 *
 * @param obj_core Pointer to kernel object core
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Retrieve the statistics associated with the kernel object
 *
 * This function copies the statistics associated with the kernel object core
 * specified by @a obj_core into the buffer @a stats. Unlike the raw statistics
 * this may report calculated values such as averages.  Note that the size of
 * the buffer (@a stats_len) must match the size specified by the kernel object
 * type's statistics descriptor.
 *
 * @param obj_core Pointer to kernel object core
 * @param stats Pointer to memory buffer into which to copy the queried stats
 * @param stats_len Length of the memory buffer
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Retrieve the raw statistics associated with the kernel object
 *
 * This function copies the raw statistics associated with the kernel object
 * core specified by @a obj_core into the buffer @a stats. Note that the size
 * of the buffer (@a stats_len) must match the size specified by the kernel
 * object type's statistics descriptor.
 *
 * @param obj_core Pointer to kernel object core
 * @param stats Pointer to memory buffer into which to copy raw stats
 * @param stats_len Length of the memory buffer
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Deregister kernel object from gathering statistics
 *
 * Deregistering a kernel object core from gathering statistics prevents it
 * from gathering any more statistics. It is expected to be invoked at the end
 * of a kernel object's life cycle.
 *
 * @param obj_core Pointer to kernel object core
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Register kernel object for gathering statistics
 *
 * Before a kernel object can gather statistics, it must be registered to do
 * so. Registering will also automatically enable the kernel object to gather
 * its statistics.
 *
 * @param obj_core Pointer to kernel object core
 * @param stats Pointer to raw kernel statistics
 * @param stats_len Size of raw kernel statistics buffer
 *
 * @retval 0 on success
 * @retval -errno on failure
 *//**
 * @brief Initialize the object core for statistics
 *
 * This routine initializes the object core to operate within the object core
 * statistics framework.
 *
 * @param obj_core Pointer to the object core
 * @param stats Pointer to the object's raw statistics
 *//**
 * @brief Initialize the object type's stats descriptor
 *
 * This routine initializes the object type's stats descriptor.
 *
 * @param type Pointer to the object type
 * @param stats_desc Pointer to the object core statistics descriptor
 *//**
 * @defgroup obj_core_stats_apis Object Core Statistics APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Unlink the kernel object from the kernel object type list
 *
 * Kernel objects can be unlinked from their respective kernel object type
 * lists. If on a list, it must be done at the end of the kernel object's life
 * cycle.
 *
 * @param obj_core Pointer to the kernel object
 *//**
 * @brief Automatically link the kernel object after initializing it
 *
 * A useful wrapper to both initialize the core of the kernel object and
 * automatically link it into the kernel object type's list of objects.
 *
 * @param obj_core Pointer to the kernel object to initialize
 * @param type Pointer to the kernel object type
 *//**
 * @brief Link the kernel object to the kernel object type list
 *
 * A kernel object can be optionally linked into the kernel object type's
 * list of objects. A kernel object must have been initialized before it
 * can be linked. Linked kernel objects can be traversed and have information
 * extracted from them by system tools.
 *
 * @param obj_core Pointer to the kernel object
 *//**
 * @brief Initialize the core of the kernel object
 *
 * Initializing the kernel object core associates it with the specified
 * kernel object type.
 *
 * @param obj_core Pointer to the kernel object to initialize
 * @param type Pointer to the kernel object type
 *//**
 * @brief Walk the object type's list of object cores
 *
 * This function is similar to k_obj_type_walk_locked() except that it walks
 * the list without obtaining the global spinlock. No synchronization is
 * provided here. Mutation of the list of objects while this function is in
 * progress must be prevented at the application layer, otherwise
 * undefined/unreliable behavior, corruption and/or crashes may result.
 *
 * The callback function shall either return non-zero to stop further walking,
 * or it shall return 0 to continue walking.
 *
 * @param type  Pointer to the object type
 * @param func  Callback to invoke on each object core of the object type
 * @param data  Custom data passed to the callback
 *
 * @retval non-zero if walk is terminated by the callback; otherwise 0
 *//**
 * @brief Walk the object type's list of object cores
 *
 * This function takes a global spinlock and walks the object type's list
 * of object cores and invokes the callback function on each element while
 * holding that lock. Although this will ensure that the list is not modified,
 * one can expect a significant penalty in terms of performance and latency.
 *
 * The callback function shall either return non-zero to stop further walking,
 * or it shall return 0 to continue walking.
 *
 * @param type  Pointer to the object type
 * @param func  Callback to invoke on each object core of the object type
 * @param data  Custom data passed to the callback
 *
 * @retval non-zero if walk is terminated by the callback; otherwise 0
 *//**
 * @brief Find a specific object type by ID
 *
 * Given an object type ID, this function searches for the object type that
 * is associated with the specified type ID @a type_id.
 *
 * @param type_id  Type ID associated with object type
 *
 * @retval NULL if object type not found
 * @retval Pointer to object type if found
 *//**
 * @brief Initialize a specific object type
 *
 * Initializes a specific object type and links it into the object core
 * framework.
 *
 * @param type Pointer to the object type to initialize
 * @param id A means to identify the object type
 * @param off Offset of object core within the structure
 *
 * @retval Pointer to initialized object type
 *//**< Pointer to kernel object's stats *//**< Object type to which object belongs *//**< Object node within object type's list *//** Object core structure *//** Pointer to object core statistics descriptor *//**< Offset to obj_core field *//**< Unique type ID *//**< List of objects of this object type *//**< Node within list of object types *//** Object type structure *//** Function pointer to enable object's statistics gathering *//** Function pointer to disable object's statistics gathering *//** Function pointer to reset object's statistics *//** Function pointer to retrieve reported statistics *//** Function pointer to retrieve internal representation of stats *//**< Stats buffer size used for reporting *//**< Internal representation stats buffer size *//** Object core statistics descriptor *//**
 * Tools may use this list as an entry point to identify all registered
 * object types and the object cores linked to them.
 *//** Timer object type *//** Thread object type *//** Stack object type *//** Semaphore object type *//** Pipe object type *//** Mutex object type *//** Message queue object type *//** Memory slab object type *//** Mailbox object type *//** Memory block object type *//** LIFO object type *//** Kernel object type *//** FIFO object type *//** Event object type *//** CPU object type *//** Condition variable object type *//* Known kernel object types *//**
 * @brief Generate new object type IDs based on a 4 letter string
 *//**
 * @brief Convert kernel object pointer into its object core pointer
 *//**
 * @defgroup obj_core_apis Object Core APIs
 * @ingroup kernel_apis
 * @{
 *//*
 * Copyright (c) 2023, Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */obj_corestats_lentype_idoffsys_memory_statsmax_allocated_bytesallocated_bytesfree_bytesZEPHYR_INCLUDE_SYS_MEM_STATS_H_/* ZEPHYR_INCLUDE_SYS_MEM_STATS_H_ *//* A common structure used to report runtime memory usage statistics *//**
 * @file
 *
 * @brief Memory Statistics
 */<zephyr/sys/mem_stats.h>sys_heap_print_infosys_heap *sys_heap_stressz_heap_stress_result *sys_heap_validatesys_heap_usable_sizesys_heap_aligned_reallocsys_heap_freesys_heap_aligned_allocsys_heap_allocsys_heap_initz_heap_stress_resultsys_heapz_heapaccumulated_in_use_bytestotal_freessuccessful_allocstotal_allocsinit_bytesinit_memz_heap *heapsys_heap_realloc(heap,ptr,bytes)sys_heap_aligned_realloc(heap, ptr, 0, bytes)ZEPHYR_INCLUDE_SYS_SYS_HEAP_H_CONFIG_SYS_HEAP_RUNTIME_STATS/* ZEPHYR_INCLUDE_SYS_SYS_HEAP_H_ *//** @brief Print heap internal structure information to the console
 *
 * Print information on the heap structure such as its size, chunk buckets,
 * chunk list and some statistics for debugging purpose.
 *
 * @param heap Heap to print information about
 * @param dump_chunks True to print the entire heap chunk list
 *//** @brief sys_heap stress test rig
 *
 * Test rig for heap allocation validation.  This will loop for @a
 * op_count cycles, in each iteration making a random choice to
 * allocate or free a pointer of randomized (power law) size based on
 * heuristics designed to keep the heap in a state where it is near @a
 * target_percent full.  Allocation and free operations are provided
 * by the caller as callbacks (i.e. this can in theory test any heap).
 * Results, including counts of frees and successful/unsuccessful
 * allocations, are returned via the @a result struct.
 *
 * @param alloc_fn Callback to perform an allocation.  Passes back the @a
 *              arg parameter as a context handle.
 * @param free_fn Callback to perform a free of a pointer returned from
 *             @a alloc.  Passes back the @a arg parameter as a
 *             context handle.
 * @param arg Context handle to pass back to the callbacks
 * @param total_bytes Size of the byte array the heap was initialized in
 * @param op_count How many iterations to test
 * @param scratch_mem A pointer to scratch memory to be used by the
 *                    test.  Should be about 1/2 the size of the heap
 *                    for tests that need to stress fragmentation.
 * @param scratch_bytes Size of the memory pointed to by @a scratch_mem
 * @param target_percent Percentage fill value (1-100) to which the
 *                       random allocation choices will seek.  High
 *                       values will result in significant allocation
 *                       failures and a very fragmented heap.
 * @param result Struct into which to store test results.
 *//** @brief Validate heap integrity
 *
 * Validates the internal integrity of a sys_heap.  Intended for unit
 * test and validation code, though potentially useful as a user API
 * for applications with complicated runtime reliability requirements.
 * Note: this cannot catch every possible error, but if it returns
 * true then the heap is in a consistent state and can correctly
 * handle any sys_heap_alloc() request and free any live pointer
 * returned from a previous allocation.
 *
 * @param heap Heap to validate
 * @return true, if the heap is valid, otherwise false
 *//** @brief Return allocated memory size
 *
 * Returns the size, in bytes, of a block returned from a successful
 * sys_heap_alloc() or sys_heap_alloc_aligned() call.  The value
 * returned is the size of the heap-managed memory, which may be
 * larger than the number of bytes requested due to allocation
 * granularity.  The heap code is guaranteed to make no access to this
 * region of memory until a subsequent sys_heap_free() on the same
 * pointer.
 *
 * @param heap Heap containing the block
 * @param mem Pointer to memory allocated from this heap
 * @return Size in bytes of the memory region
 *//** @brief Expand the size of an existing allocation
 *
 * Returns a pointer to a new memory region with the same contents,
 * but a different allocated size.  If the new allocation can be
 * expanded in place, the pointer returned will be identical.
 * Otherwise the data will be copies to a new block and the old one
 * will be freed as per sys_heap_free().  If the specified size is
 * smaller than the original, the block will be truncated in place and
 * the remaining memory returned to the heap.  If the allocation of a
 * new block fails, then NULL will be returned and the old block will
 * not be freed or modified.
 *
 * @note The return of a NULL on failure is a different behavior than
 * POSIX realloc(), which specifies that the original pointer will be
 * returned (i.e. it is not possible to safely detect realloc()
 * failure in POSIX, but it is here).
 *
 * @param heap Heap from which to allocate
 * @param ptr Original pointer returned from a previous allocation
 * @param align Alignment in bytes, must be a power of two
 * @param bytes Number of bytes requested for the new block
 * @return Pointer to memory the caller can now use, or NULL
 *//** @brief Free memory into a sys_heap
 *
 * De-allocates a pointer to memory previously returned from
 * sys_heap_alloc such that it can be used for other purposes.  The
 * caller must not use the memory region after entry to this function.
 *
 * @note The sys_heap implementation is not internally synchronized.
 * No two sys_heap functions should operate on the same heap at the
 * same time.  All locking must be provided by the user.
 *
 * @param heap Heap to which to return the memory
 * @param mem A pointer previously returned from sys_heap_alloc()
 *//** @brief Allocate aligned memory from a sys_heap
 *
 * Behaves in all ways like sys_heap_alloc(), except that the returned
 * memory (if available) will have a starting address in memory which
 * is a multiple of the specified power-of-two alignment value in
 * bytes.  With align=0 this behaves exactly like sys_heap_alloc().
 * The resulting memory can be returned to the heap using sys_heap_free().
 *
 * @param heap Heap from which to allocate
 * @param align Alignment in bytes, must be a power of two
 * @param bytes Number of bytes requested
 * @return Pointer to memory the caller can now use
 *//** @brief Allocate memory from a sys_heap
 *
 * Returns a pointer to a block of unused memory in the heap.  This
 * memory will not otherwise be used until it is freed with
 * sys_heap_free().  If no memory can be allocated, NULL will be
 * returned.  The allocated memory is guaranteed to have a starting
 * address which is a multiple of sizeof(void *).  If a bigger alignment
 * is necessary then sys_heap_aligned_alloc() should be used instead.
 *
 * @note The sys_heap implementation is not internally synchronized.
 * No two sys_heap functions should operate on the same heap at the
 * same time.  All locking must be provided by the user.
 *
 * @param heap Heap from which to allocate
 * @param bytes Number of bytes requested
 * @return Pointer to memory the caller can now use
 *//** @brief Initialize sys_heap
 *
 * Initializes a sys_heap struct to manage the specified memory.
 *
 * @param heap Heap to initialize
 * @param mem Untyped pointer to unused memory
 * @param bytes Size of region pointed to by @a mem
 *//**
 * @brief Reset the maximum heap usage.
 *
 * Set the statistic measuring the maximum number of allocated bytes to the
 * current number of allocated bytes.
 *
 * @param heap Pointer to sys_heap
 * @return -EINVAL if null pointer was passed, otherwise 0
 *//**
 * @brief Get the runtime statistics of a sys_heap
 *
 * @param heap Pointer to specified sys_heap
 * @param stats_t Pointer to struct to copy statistics into
 * @return -EINVAL if null pointers, otherwise 0
 *//* Note: the init_mem/bytes fields are for the static initializer to
 * have somewhere to put the arguments.  The actual heap metadata at
 * runtime lives in the heap memory itself and this struct simply
 * functions as an opaque pointer.  Would be good to clean this up and
 * put the two values somewhere else, though it would make
 * SYS_HEAP_DEFINE a little hairy to write.
 *//* Simple, fast heap implementation.
 *
 * A more or less conventional segregated fit allocator with
 * power-of-two buckets.
 *
 * Excellent space efficiency.  Chunks can be split arbitrarily in 8
 * byte units.  Overhead is only four bytes per allocated chunk (eight
 * bytes for heaps >256kb or on 64 bit systems), plus a log2-sized
 * array of 2-word bucket headers.  No coarse alignment restrictions
 * on blocks, they can be split and merged (in units of 8 bytes)
 * arbitrarily.
 *
 * Simple API.  Initialize at runtime with any blob of memory and not
 * a macro-generated, carefully aligned static array.  Allocate and
 * free by user pointer and not an opaque block handle.
 *
 * Good fragmentation resistance.  Freed blocks are always immediately
 * merged with adjacent free blocks.  Allocations are attempted from a
 * sample of the smallest bucket that might fit, falling back rapidly
 * to the smallest block guaranteed to fit.  Split memory remaining in
 * the chunk is always returned immediately to the heap for other
 * allocation.
 *
 * Excellent performance with firmly bounded runtime.  All operations
 * are constant time (though there is a search of the smallest bucket
 * that has a compile-time-configurable upper bound, setting this to
 * extreme values results in an effectively linear search of the
 * list), objectively fast (~hundred instructions) and and amenable to
 * locked operation.
 */dump_chunksalloc_fnfree_fnargtotal_bytesop_countscratch_memscratch_bytestarget_percentresultmemptrbytes_cpu_arch_t_cpu_archZEPHYR_INCLUDE_ARCH_STRUCTS_H_/* ZEPHYR_INCLUDE_ARCH_STRUCTS_H_ *//* typedefs to be used with GEN_OFFSET_SYM(), etc. *//* This struct will have a size 0 in C which is not allowed in C++ (it'll have a size 1). To
	 * prevent this, we add a 1 byte dummy variable.
	 *//* Per CPU architecture specifics (empty) *//* Default definitions when no architecture specific definitions exist. *//*
 * The purpose of this file is to provide essential/minimal architecture-
 * specific structure definitions to be included in generic kernel
 * structures.
 *
 * The following rules must be observed:
 *  1. arch/structs.h shall not depend on kernel.h both directly and
 *     indirectly (i.e. it shall not include any header files that include
 *     kernel.h in their dependency chain).
 *  2. kernel.h shall imply arch/structs.h via kernel_structs.h , such that
 *     it shall not be necessary to include arch/structs.h explicitly when
 *     kernel.h is included.
 *//*
 * Copyright (c) BayLibre SAS
 *
 * SPDX-License-Identifier: Apache-2.0
 */k_cycle_statstrack_usagetotalZEPHYR_INCLUDE_KERNEL_STATS_H_defined(CONFIG_SCHED_THREAD_USAGE_ANALYSIS) || defined(__DOXYGEN__)/**< true if gathering usage stats *//**< \# of usage windows *//**< \# of cycles in longest usage window *//**< \# of cycles in current usage window *//**
	 * @name Fields available when CONFIG_SCHED_THREAD_USAGE_ANALYSIS is selected.
	 * @{
	 *//**< total usage in cycles *//**
 * Structure used to track internal statistics about both thread
 * and CPU usage.
 *//*
 * Copyright (c) 2021,2023, Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/kernel/obj_core.h><zephyr/kernel/stats.h><zephyr/arch/structs.h><zephyr/sys/sys_heap.h><zephyr/kernel/internal/sched_priq.h><zephyr/sys/atomic.h>z_priq_rb_lessthank_thread_timeslice_fn_t_kernel_tz_kernel_cpu_t_cpu_ready_q_t_ready_q_timeout_timeout_func_t_wait_q_tready_qcpusarchidle_threadcurrentirq_stacknestedrunqcachedtickswaitq_cpus_active_kernelZ_WAIT_Q_INIT(wait_q){ { { .lessthan_fn = z_priq_rb_lessthan } } }_current_kernel.cpus[0].current_current_cpu(&_kernel.cpus[0])_PREEMPT_THRESHOLD(_NON_PREEMPT_THRESHOLD - 1U)_NON_PREEMPT_THRESHOLD0x0080U(BIT(7))_THREAD_SUSPENDING(BIT(6))_THREAD_ABORTING(BIT(5))(BIT(4))(BIT(3))(BIT(2))(BIT(1))(BIT(0))ZEPHYR_KERNEL_INCLUDE_KERNEL_STRUCTS_H_defined(CONFIG_SCHED_DUMB)defined(CONFIG_SCHED_SCALABLE)defined(CONFIG_SCHED_MULTIQ)CONFIG_SCHED_CPU_MASK_PIN_ONLY(CONFIG_NUM_METAIRQ_PRIORITIES > 0) &&                                                         \defined(CONFIG_FPU_SHARING)CONFIG_SCHED_THREAD_USAGE_ALLCONFIG_OBJ_CORE_SYSTEMCONFIG_PMCONFIG_FPU_SHARINGdefined(CONFIG_THREAD_MONITOR)defined(CONFIG_SMP) && defined(CONFIG_SCHED_IPI_SUPPORTED)/* ZEPHYR_KERNEL_INCLUDE_KERNEL_STRUCTS_H_ *//* Can't use k_ticks_t for header dependency reasons *//* kernel timeout record *//* kernel wait queue record *//* True if the current context can be preempted and migrated to
 * another SMP CPU.
 *//* Need to signal an IPI at the next scheduling point *//* singly linked list of ALL threads *//* thread that owns the FP regs *//*
	 * A 'current_sse' field does not exist in addition to the 'current_fp'
	 * field since it's not possible to divide the IA-32 non-integer
	 * registers into 2 distinct blocks owned by differing threads.  In
	 * other words, given that the 'fxnsave/fxrstor' instructions
	 * save/restore both the X87 FPU and XMM registers, it's not possible
	 * for a thread to only "own" the XMM registers.
	 *//*
	 * ready queue: can be big, keep after small fields, since some
	 * assembly (e.g. ARC) are limited in the encoding of the offset
	 *//* Number of ticks for kernel idling *//* Per CPU architecture specifics *//*
	 * [usage0] is used as a timestamp to mark the beginning of an
	 * execution window. [0] is a special value indicating that it
	 * has been stopped (but not disabled).
	 *//* True when _current is allowed to context switch *//* Coop thread preempted by current metairq, or NULL *//* one assigned idle thread per CPU *//* currently scheduled thread *//* interrupt stack pointer base *//* nested interrupt count *//* always contains next thread to run: cannot be NULL *//* highest value of _thread_base.preempt at which a thread is preemptible *//* lowest value of _thread_base.preempt at which a thread is non-preemptible *//* Magic value in lowest bytes of the stack *//* end - states *//* Thread is present in the ready queue *//* Thread is in the process of suspending *//* Thread is in the process of aborting *//* Thread is suspended *//* Thread has terminated *//* Thread has not yet started *//* Thread is waiting on an object *//* Not a real thread *//* states: common uses low bits, arch-specific use high bits *//*
 * Bitmask definitions for the struct k_thread.thread_state field.
 *
 * Must be before kernel_arch_data.h because it might need them to be already
 * defined.
 *//*
 * The purpose of this file is to provide essential/minimal kernel structure
 * definitions, so that they can be used without including kernel.h.
 *
 * The following rules must be observed:
 *  1. kernel_structs.h shall not depend on kernel.h both directly and
 *    indirectly (i.e. it shall not include any header files that include
 *    kernel.h in their dependency chain).
 *  2. kernel.h shall imply kernel_structs.h, such that it shall not be
 *    necessary to include kernel_structs.h explicitly when kernel.h is
 *    included.
 *//*
 * Copyright (c) 2016 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */sys_kernel_version_getSYS_KERNEL_VER_PATCHLEVEL(ver)(((ver) >> 8) & 0xFF)SYS_KERNEL_VER_MINOR(ver)(((ver) >> 16) & 0xFF)SYS_KERNEL_VER_MAJOR(ver)(((ver) >> 24) & 0xFF)ZEPHYR_INCLUDE_KERNEL_VERSION_H_/* ZEPHYR_INCLUDE_KERNEL_VERSION_H_ *//**
 * @brief Return the kernel version of the present build
 *
 * The kernel version is a four-byte value, whose format is described in the
 * file "kernel_version.h".
 *
 * @return kernel version
 *//* kernel version routines *//**
 * @defgroup version_apis Version APIs
 * @ingroup kernel_apis
 * @{
 *
 * The kernel version has been converted from a string to a four-byte
 * quantity that is divided into two parts.
 *
 * Part 1: The three most significant bytes represent the kernel's
 * numeric version, x.y.z. These fields denote:
 *       x -- major release
 *       y -- minor release
 *       z -- patchlevel release
 * Each of these elements must therefore be in the range 0 to 255, inclusive.
 *
 * Part 2: The least significant byte is reserved for future use.
 *//* kernel version support */__OBSOLETE_MATH_DEFAULT_SUPPORTS_ERREXCEPT__IEEE_LITTLE_ENDIAN_DBL_EQ_FLT_LDBL_EQ_DBL__IEEE_BIG_ENDIAN!defined(__IEEE_BIG_ENDIAN) && !defined(__IEEE_LITTLE_ENDIAN)defined(__ORDER_BIG_ENDIAN__) && defined(__ORDER_LITTLE_ENDIAN__) && defined(__FLOAT_WORD_ORDER__)__FLOAT_WORD_ORDER__ == __ORDER_BIG_ENDIAN____SIZEOF_DOUBLE__ == 4_SIZEOF_LONG_DOUBLE__ == 4defined(__SIZEOF_LONG_DOUBLE__)defined(__SIZEOF_DOUBLE__) && defined(__SIZEOF_LONG_DOUBLE__)__SIZEOF_DOUBLE__ == __SIZEOF_LONG_DOUBLE__defined(__SIZEOF_FLOAT__) && defined(__SIZEOF_DOUBLE__)__SIZEOF_FLOAT__ == __SIZEOF_DOUBLE__(defined(__arm__) || defined(__thumb__)) && !defined(__MAVERICK__)(__ARM_FP & 4) && !(__ARM_FP & 8)defined(__VFP_FP__) || defined(__SOFTFP__)__ARMEL____SOFTFP__defined (__aarch64__)defined (__AARCH64EL__)__ARM_FP__epiphany____hppa____nds32____big_endian____SPU____sparc____LITTLE_ENDIAN_DATA__defined(__m68k__) || defined(__mc68000__)defined(__mc68hc11__) || defined(__mc68hc12__) || defined(__mc68hc1x__)__HAVE_SHORT_DOUBLE__defined (__H8300__) || defined (__H8300H__) || defined (__H8300S__) || defined (__H8500__) || defined (__H8300SX__)defined (__xc16x__) || defined (__xc16xL__) || defined (__xc16xS__)__sh____LITTLE_ENDIAN__defined(__SH2E__) || defined(__SH3E__) || defined(__SH4_SINGLE_ONLY__) || defined(__SH2A_SINGLE_ONLY__)_AM29K_WIN32__riscvdefined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_BIG_ENDIAN__)__riscv_flen__powerpc___SOFT_FLOAT__i960____lm32____M32R____nvptx__defined(_C4x) || defined(_C3x)__TMS320C6X___BIG_ENDIAN__TIC80____MIPSEL____MIPSEB____MMIX____D30V____W65__defined(__Z8001__) || defined(__Z8002__)__m88k____mn10300____mn10200____v800__v850__D10V____DOUBLE__ == 32__PPC__(defined(_BIG_ENDIAN) && _BIG_ENDIAN) || (defined(_AIX) && _AIX)(defined(_LITTLE_ENDIAN) && _LITTLE_ENDIAN) || (defined(__sun__) && __sun__) || (defined(_WIN32) && _WIN32)__xstormy16____arc____CRX____CSKY____CSKYBE____fr30____FT32____mcore____mt____frv____moxie____MOXIE_BIG_ENDIAN____ia64____BIG_ENDIAN____AVR__!defined(__SIZEOF_DOUBLE__) || __SIZEOF_DOUBLE__ == 4defined(__or1k__) || defined(__OR1K__) || defined(__OR1KND__)__IP2K____iq2000____MAVERICK____m32c____CRIS____BFIN____mep____MICROBLAZE____MICROBLAZEEL____MSP430____PRU____RL78____RL78_64BIT_DOUBLES____RX____RX_BIG_ENDIAN____RX_64BIT_DOUBLES____RX_16BIT_INTS__(defined(__CR16__) || defined(__CR16C__) ||defined(__CR16CP__))__NIOS2____nios2_big_endian____VISIUM__(defined(__XTENSA__))__XTENSA_EB____XTENSA_EL____AMDGCN___DOUBLE_IS_32BITS__OBSOLETE_MATH_DEFAULT_FLOAT__OBSOLETE_MATH_DEFAULT_DOUBLE__FLOAT_WORD_ORDER____FLOAT_WORD_ORDER__ == __ORDER_LITTLE_ENDIAN____SIZEOF_DOUBLE____SIZEOF_FLOAT____SIZEOF_LONG_DOUBLE__/* not __IEEE_BIG_ENDIAN *//* not __IEEE_LITTLE_ENDIAN *//* Use __FLOAT_WORD_ORDER__ if we don't have
 * more specific platform knowledge
 *//* New math code requires 64-bit doubles *//* 16 Bit INT *//* __MAVERICK__ *//* __ARMEL__ *//* must be __ARMEB__ *//* necv70 was __IEEE_LITTLE_ENDIAN. *//*
 * Macros for use in ieeefp.h. We can't just define the real ones here
 * (like those above) as we have name space issues when this is *not*
 * included via generic the ieeefp.h.
 *//* As per ISO/IEC TS 18661 '__FLT_EVAL_METHOD__' will be defined to 16
   (if compiling with +fp16 support) so it can't be used by math.h to
   define float_t and double_t.  For values of '__FLT_EVAL_METHOD__'
   other than 0, 1, 2 the definition of float_t and double_t is
   implementation-defined.  *//* ARM traditionally used big-endian words; and within those words the
   byte ordering was big or little endian depending upon the target.
   Modern floating-point formats are naturally ordered; in this case
   __VFP_FP__ will be defined, even if soft-float.  *//* arm with hard fp and soft dp cannot use new float code *//* This file can define macros to choose variations of the IEEE float
   format:

   _FLT_LARGEST_EXPONENT_IS_NORMAL

	Defined if the float format uses the largest exponent for finite
	numbers rather than NaN and infinity representations.  Such a
	format cannot represent NaNs or infinities at all, but it's FLT_MAX
	is twice the IEEE value.

   _FLT_NO_DENORMALS

	Defined if the float format does not support IEEE denormals.  Every
	float with a zero exponent is taken to be a zero representation.
 
   ??? At the moment, there are no equivalent macros above for doubles and
   the macros are not fully supported by --enable-newlib-hw-fp.

   __IEEE_BIG_ENDIAN

        Defined if the float format is big endian.  This is mutually exclusive
        with __IEEE_LITTLE_ENDIAN.

   __IEEE_LITTLE_ENDIAN
 
        Defined if the float format is little endian.  This is mutually exclusive
        with __IEEE_BIG_ENDIAN.

   Note that one of __IEEE_BIG_ENDIAN or __IEEE_LITTLE_ENDIAN must be specified for a
   platform or error will occur.

   __IEEE_BYTES_LITTLE_ENDIAN

        This flag is used in conjunction with __IEEE_BIG_ENDIAN to describe a situation 
	whereby multiple words of an IEEE floating point are in big endian order, but the
	words themselves are little endian with respect to the bytes.

   _DOUBLE_IS_32BITS 

        This is used on platforms that support double by using the 32-bit IEEE
        float type.

   _FLOAT_ARG

        This represents what type a float arg is passed as.  It is used when the type is
        not promoted to double.
	

   __OBSOLETE_MATH_DEFAULT

	Default value for __OBSOLETE_MATH if that's not set by the user.
	It should be set here based on predefined feature macros.

   __OBSOLETE_MATH

	If set to 1 then some new math code will be disabled and older libm
	code will be used instead.  This is necessary because the new math
	code does not support all targets, it assumes that the toolchain has
	ISO C99 support (hexfloat literals, standard fenv semantics), the
	target has IEEE-754 conforming binary32 float and binary64 double
	(not mixed endian) representation, standard SNaN representation,
	double and single precision arithmetics has similar latency and it
	has no legacy SVID matherr support, only POSIX errno and fenv
	exception based error handling.
*//*
Copyright (C) 1991 DJ Delorie
All rights reserved.

Redistribution, modification, and use in source and binary forms is permitted
provided that the above copyright notice and following paragraph are
duplicated in all such forms.

This file is distributed WITHOUT ANY WARRANTY; without even the implied
warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
 */DECIMAL_DIG__DECIMAL_DIG__FLT_EVAL_METHOD__FLT_EVAL_METHOD__FLT_ROUNDSLDBL_MIN__LDBL_MIN__DBL_MIN__DBL_MIN__FLT_MIN__FLT_MIN__LDBL_EPSILON__LDBL_EPSILON__DBL_EPSILON__DBL_EPSILON__FLT_EPSILON__FLT_EPSILON__LDBL_MAX__LDBL_MAX__DBL_MAX__DBL_MAX__FLT_MAX__FLT_MAX__LDBL_MAX_10_EXP__LDBL_MAX_10_EXP__DBL_MAX_10_EXP__DBL_MAX_10_EXP__FLT_MAX_10_EXP__FLT_MAX_10_EXP__LDBL_MAX_EXP__LDBL_MAX_EXP__DBL_MAX_EXP__DBL_MAX_EXP__FLT_MAX_EXP__FLT_MAX_EXP__LDBL_MIN_10_EXP__LDBL_MIN_10_EXP__DBL_MIN_10_EXP__DBL_MIN_10_EXP__FLT_MIN_10_EXP__FLT_MIN_10_EXP__LDBL_MIN_EXP__LDBL_MIN_EXP__DBL_MIN_EXP__DBL_MIN_EXP__FLT_MIN_EXP__FLT_MIN_EXP__LDBL_DIG__LDBL_DIG__DBL_DIG__DBL_DIG__FLT_DIG__FLT_DIG__LDBL_MANT_DIG__LDBL_MANT_DIG__DBL_MANT_DIG__DBL_MANT_DIG__FLT_MANT_DIG__FLT_MANT_DIG__FLT_RADIX__FLT_RADIX___FLOAT_H___(defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L) \__STDC_WANT_IEC_60559_TYPES_EXT____FLT_HAS_QUIET_NAN____DBL_HAS_QUIET_NAN____LDBL_HAS_QUIET_NAN____FLT16_MANT_DIG____FLT32_MANT_DIG____FLT64_MANT_DIG____FLT128_MANT_DIG____FLT32X_MANT_DIG____FLT64X_MANT_DIG____FLT128X_MANT_DIG____DEC32_MANT_DIG__(defined __STDC_WANT_DEC_FP__ \__STDC_WANT_DEC_FP__(defined __STDC_WANT_IEC_60559_DFP_EXT__ \/* _FLOAT_H___ *//* __DEC32_MANT_DIG__ *//* C2X *//* Signaling NaN in each decimal floating-point type.  *//* Quiet NaN in type _Decimal32.  *//* Infinity in type _Decimal32.  *//* __STDC_WANT_IEC_60559_DFP_EXT__ || C2X.  *//* Minimum subnormal positive floating-point number. *//* __STDC_WANT_DEC_FP__.  *//* __STDC_WANT_DEC_FP__ || __STDC_WANT_IEC_60559_DFP_EXT__ || C2X.  *//* The floating-point expression evaluation method.
         -1  indeterminate
         0  evaluate all operations and constants just to the range and
            precision of the type
         1  evaluate operations and constants of type _Decimal32 
	    and _Decimal64 to the range and precision of the _Decimal64 
            type, evaluate _Decimal128 operations and constants to the 
	    range and precision of the _Decimal128 type;
	 2  evaluate all operations and constants to the range and
	    precision of the _Decimal128 type.  *//* Minimum normalized positive floating-point number. *//* The difference between 1 and the least value greater than 1 that is
   representable in the given floating point type. *//* Maximum representable finite decimal floating-point number
   (there are 6, 15, and 33 9s after the decimal points respectively). *//* Maximum exponent. *//* Minimum exponent. *//* Number of base-FLT_RADIX digits in the significand, p.  *//* C2X; formerly Technical Report 24732, extension for decimal
   floating-point arithmetic: Characteristic of decimal floating types
   <float.h>, and TS 18661-2.  *//* __STDC_WANT_IEC_60559_TYPES_EXT__.  *//* __FLT128X_MANT_DIG__.  *//* __FLT64X_MANT_DIG__.  *//* __FLT32X_MANT_DIG__.  *//* __FLT128_MANT_DIG__.  *//* __FLT64_MANT_DIG__.  *//* __FLT32_MANT_DIG__.  *//* __FLT16_MANT_DIG__.  *//* Constants for _FloatN and _FloatNx types from TS 18661-3.  See
   comments above for their semantics.  *//* Number of decimal digits for which conversions between decimal
   character strings and binary formats, in both directions, are
   correctly rounded.  *//* Signaling NaN, if supported for each type.  All formats supported
   by GCC support either both quiet and signaling NaNs, or neither
   kind of NaN.  *//* Quiet NaN, if supported for float.  *//* Infinity in type float, or overflow if infinity not supported.  *//* Whether each type matches an IEC 60559 format (1 for format, 2 for
   format and operations).  *//* Maximum finite positive value with MANT_DIG digits in the
   significand taking their maximum value.  *//* C11 *//* Minimum positive values, including subnormals.  *//* Whether types support subnormal numbers.  *//* Versions of DECIMAL_DIG for each floating-point type.  *//* C99 *//* Number of decimal digits, n, such that any floating-point number in the
   widest supported floating type with pmax radix b digits can be rounded
   to a floating-point number with n decimal digits and back again without
   change to the value,

	pmax * log10(b)			if b is a power of 10
	ceil(1 + pmax * log10(b))	otherwise
*//* The floating-point expression evaluation method.  The precise
   definitions of these values are generalised to include support for
   the interchange and extended types defined in ISO/IEC TS 18661-3.
   Prior to this (for C99/C11) the definitions were:

	-1  indeterminate
	 0  evaluate all operations and constants just to the range and
	    precision of the type
	 1  evaluate operations and constants of type float and double
	    to the range and precision of the double type, evaluate
	    long double operations and constants to the range and
	    precision of the long double type
	 2  evaluate all operations and constants to the range and
	    precision of the long double type

   The TS 18661-3 definitions are:

	-1  indeterminate
	 0  evaluate all operations and constants, whose semantic type has
	    at most the range and precision of float, to the range and
	    precision of float; evaluate all other operations and constants
	    to the range and precision of the semantic type.
	 1  evaluate all operations and constants, whose semantic type has
	    at most the range and precision of double, to the range and
	    precision of double; evaluate all other operations and constants
	    to the range and precision of the semantic type.
	 2  evaluate all operations and constants, whose semantic type has
	    at most the range and precision of long double, to the range and
	    precision of long double; evaluate all other operations and
	    constants to the range and precision of the semantic type.
	 N  where _FloatN  is a supported interchange floating type
	    evaluate all operations and constants, whose semantic type has
	    at most the range and precision of the _FloatN type, to the
	    range and precision of the _FloatN type; evaluate all other
	    operations and constants to the range and precision of the
	    semantic type.
	 N + 1, where _FloatNx is a supported extended floating type
	    evaluate operations and constants, whose semantic type has at
	    most the range and precision of the _FloatNx type, to the range
	    and precision of the _FloatNx type; evaluate all other
	    operations and constants to the range and precision of the
	    semantic type.

   The compiler predefines two macros:

      __FLT_EVAL_METHOD__
      Which, depending on the value given for
      -fpermitted-flt-eval-methods, may be limited to only those values
      for FLT_EVAL_METHOD defined in C99/C11.

     __FLT_EVAL_METHOD_TS_18661_3__
      Which always permits the values for FLT_EVAL_METHOD defined in
      ISO/IEC TS 18661-3.

     Here we want to use __FLT_EVAL_METHOD__, unless
     __STDC_WANT_IEC_60559_TYPES_EXT__ is defined, in which case the user
     is specifically asking for the ISO/IEC TS 18661-3 types, so we use
     __FLT_EVAL_METHOD_TS_18661_3__.

   ??? This ought to change with the setting of the fp control word;
   the value provided by the compiler assumes the widest setting.  *//* ??? This is supposed to change with calls to fesetround in <fenv.h>.  *//* Addition rounds to 0: zero, 1: nearest, 2: +inf, 3: -inf, -1: unknown.  *//* Minimum normalized positive floating-point number, b**(emin - 1).  *//* The difference between 1 and the least value greater than 1 that is
   representable in the given floating point type, b**1-p.  *//* Maximum representable finite floating-point number,

	(1 - b**-p) * b**emax
*//* Maximum integer such that 10 raised to that power is in the range of
   representable finite floating-point numbers,

	floor(log10((1 - b**-p) * b**emax))
*//* Maximum int x such that FLT_RADIX**(x-1) is a representable float, emax.  *//* Minimum negative integer such that 10 raised to that power is in the
   range of normalized floating-point numbers,

	ceil(log10(b) * (emin - 1))
*//* Minimum int x such that FLT_RADIX**(x-1) is a normalized float, emin *//* Number of decimal digits, q, such that any floating-point number with q
   decimal digits can be rounded into a floating-point number with p radix b
   digits and back again without change to the q decimal digits,

	p * log10(b)			if b is a power of 10
	floor((p - 1) * log10(b))	otherwise
*//* Radix of exponent representation, b. *//*
 * ISO C Standard:  5.2.4.2.2  Characteristics of floating types <float.h>
 *//* Copyright (C) 2002-2022 Free Software Foundation, Inc.

This file is part of GCC.

GCC is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3, or (at your option)
any later version.

GCC is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

Under Section 7 of GPL version 3, you are granted additional
permissions described in the GCC Runtime Library Exception, version
3.1, as published by the Free Software Foundation.

You should have received a copy of the GNU General Public License and
a copy of the GCC Runtime Library Exception along with this program;
see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
<http://www.gnu.org/licenses/>.  */<float.h><machine/ieeefp.h>_HAVE_LONG_DOUBLE_MATH_REENT_THREAD_LOCALNEWLIB_THREAD_LOCAL__thread__IMPORT__EXPORT__RAND_MAX_POINTER_INT_FLOAT_RET__SYS_CONFIG_H____aarch64__defined(__H8500__) || defined(__W65__)defined(__Z8001__) || defined(__Z8002__) || defined(__H8500__) || defined(__W65__) || defined (__mn10200__) || defined (__AVR__) || defined (__MSP430__)defined (__H8300__) || defined (__H8300H__) || defined(__H8300S__) || defined (__H8300SX__)__INT32__defined(__D10V__)___AM29K____unix__defined(__linux__) || defined(__RDOS__)__LARGE64_FILESdefined(__v850) && !defined(__rtems__)defined(__PPC__)defined(_CALL_SYSV)__SPE__defined (__MICROBLAZE__) && !defined(__rtems__)_REENT_SMALLdefined(__mips__) && !defined(__rtems__)defined __MSP430____MSP430X_LARGE__defined(__r8c_cpu__) || defined(__m16c_cpu__)defined(__or1k__) || defined(__or1knd__)defined (__alpha__) || (defined (__sparc__) && defined(__arch64__)) \__INT_MAX__ == 32767defined(__CYGWIN__)defined(__rtems__)__INT_MAX__ == 32767 || defined (_WIN32)_USE_LONG_TIME_T_WANT_USE_GDTOA_USE_GDTOA_WANT_REENT_BACKWARD_BINARY_COMPAT_REENT_BACKWARD_BINARY_COMPAT_MB_EXTENDED_CHARSETS_ALLLDBL_MANT_DIG == DBL_MANT_DIG && LDBL_MIN_EXP == DBL_MIN_EXP && \defined (_LDBL_EQ_DBL) || defined (__CYGWIN__) || (defined(__SIZEOF_LONG_DOUBLE__) && __SIZEOF_LONG_DOUBLE__ <= 8) || (LDBL_MANT_DIG == 64 || LDBL_MANT_DIG == 113)(-1021)(-16381)/* __SYS_CONFIG_H__ *//* Newlib doesn't fully support long double math functions so far.
   On platforms where long double equals double the long double functions
   simply call the double functions.  On Cygwin the long double functions
   are implemented independently from newlib to be able to use optimized
   assembler functions despite using the Microsoft x86_64 ABI. *//* Figure out if long double is the same size as double. If the system
 * doesn't provide long double, then those values will be undefined
 * and cpp will substitute 0 for them in the test
 *//* If _MB_EXTENDED_CHARSETS_ALL is set, we want all of the extended
   charsets.  The extended charsets add a few functions and a couple
   of tables of a few K each. *//* See if small reent asked for at configuration time and
   is not chosen by the platform by default.  *//* End of block that should be kept in sync with GCC's limits.h.  *//* This block should be kept in sync with GCC's limits.h.  The point
   of having these definitions here is to not include limits.h, which
   would pollute the user namespace, while still using types of the
   the correct widths when deciding how to define __int32_t and
   __int64_t.  *//* __m32c__ *//* Xilinx XMK uses Unix98 mutex *//* Configure small REENT structure for Xilinx MicroBlaze platforms *//* For the PowerPC eabi, force the _impure_ptr to be in .sdata *//* we use some glibc header files so turn on glibc large file feature *//* we want the reentrancy structure to be returned by a function *//* in other words, go32 *//* CR16C *//* INT32 *//* 16 bit integer machines *//* ???  This conditional is true for the h8500 and the w65, defining H8300
   in those cases probably isn't the right thing to do.  *//* exceptions first *//* POSIX defs *//* floating point macros *//*
Copyright (c) 1982, 1986, 1993
The Regents of the University of California.  All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1. Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
3. Neither the name of the University nor the names of its contributors
may be used to endorse or promote products derived from this software
without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.
 */<sys/config.h>_NOINLINE_STATIC_NOINLINE static_NOINLINE_ELIDABLE_INLINEstatic __inline___ATTRIBUTE(attrs)__attribute__ (attrs)_LONG_DOUBLE_NOTHROW__attribute__ ((__nothrow__))_END_STD_C_BEGIN_STD_C_ANSIDECL_H_!(defined(_BEGIN_STD_C) && defined(_END_STD_C))_HAVE_STD_CXX__GNUC_PREREQ (3, 3)defined(__GNUC__) && !defined(__GNUC_STDC_INLINE__)__GNUC_PREREQ (3, 1)__GNUC_STDC_INLINE__/* _ANSIDECL_H_ *//* On non-GNU compilers and GCC prior to version 3.1 the compiler can't be
   trusted not to inline if it is static. *//* We're using GCC in C99 mode, or an unknown compiler which
  we just have to hope obeys the C99 semantics of inline.  *//* We're using GCC, but without the new C99-compatible behaviour.  *//*  The traditional meaning of 'extern inline' for GCC is not
  to emit the function body unless the address is explicitly
  taken.  However this behaviour is changing to match the C99
  standard, which uses 'extern inline' to indicate that the
  function body *must* be emitted.  Likewise, a function declared
  without either 'extern' or 'static' defaults to extern linkage
  (C99 6.2.2p5), and the compiler may choose whether to use the
  inline version or call the extern linkage version (6.7.4p6).
  If we are using GCC, but do not have the new behaviour, we need
  to use extern inline; if we are using a new GCC with the
  C99-compatible behaviour, or a non-GCC compiler (which we will
  have to hope is C99, since there is no other way to achieve the
  effect of omitting the function if it isn't referenced) we use
  'static inline', which c99 defines to mean more-or-less the same
  as the Gnu C 'extern inline'.  *//* Support gcc's __attribute__ facility.  *//*  ISO C++.  *//* To get a strict ANSI C environment, define macro __STRICT_ANSI__.  This will
   "comment out" the non-ANSI parts of the ANSI header files (non-ANSI header
   files aren't affected).  *//* Provide support for both ANSI and non-ANSI environments.  *//*
Copyright (c) 1991, 1993
The Regents of the University of California.  All rights reserved.
c) UNIX System Laboratories, Inc.
All or some portions of this file are derived from material licensed
to the University of California by American Telephone and Telegraph
Co. or Unix System Laboratories, Inc. and are reproduced herein with
the permission of UNIX System Laboratories, Inc.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1. Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.
3. Neither the name of the University nor the names of its contributors
may be used to endorse or promote products derived from this software
without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.
 */"_ansi.h"wcstoumaxconst wchar_tconst wchar_t *const wchar_t *__restrict__wchar_t *wchar_t **int **wchar_t **__restrict__wcstoimaxstrtoumaxconst char *__restrict__char **__restrict__strtoimaximaxdivimaxabsimaxdiv_tremquotSCNxPTR__SCNPTR(x)SCNuPTR__SCNPTR(u)SCNoPTR__SCNPTR(o)SCNiPTR__SCNPTR(i)SCNdPTR__SCNPTR(d)PRIXPTR__PRIPTR(X)PRIxPTR__PRIPTR(x)PRIuPTR__PRIPTR(u)PRIoPTR__PRIPTR(o)PRIiPTR__PRIPTR(i)PRIdPTR__PRIPTR(d)__STRINGIFY(l ## x)SCNxMAX__SCNMAX(x)SCNuMAX__SCNMAX(u)SCNoMAX__SCNMAX(o)SCNiMAX__SCNMAX(i)SCNdMAX__SCNMAX(d)PRIXMAX__PRIMAX(X)PRIxMAX__PRIMAX(x)PRIuMAX__PRIMAX(u)PRIoMAX__PRIMAX(o)PRIiMAX__PRIMAX(i)PRIdMAX__PRIMAX(d)__STRINGIFY(ll ## x)SCNxFAST64__SCN64FAST(x)SCNuFAST64__SCN64FAST(u)SCNoFAST64__SCN64FAST(o)SCNiFAST64__SCN64FAST(i)SCNdFAST64__SCN64FAST(d)PRIXFAST64__PRI64FAST(X)PRIxFAST64__PRI64FAST(x)PRIuFAST64__PRI64FAST(u)PRIoFAST64__PRI64FAST(o)PRIiFAST64__PRI64FAST(i)PRIdFAST64__PRI64FAST(d)SCNxLEAST64__SCN64LEAST(x)SCNuLEAST64__SCN64LEAST(u)SCNoLEAST64__SCN64LEAST(o)SCNiLEAST64__SCN64LEAST(i)SCNdLEAST64__SCN64LEAST(d)PRIXLEAST64__PRI64LEAST(X)PRIxLEAST64__PRI64LEAST(x)PRIuLEAST64__PRI64LEAST(u)PRIoLEAST64__PRI64LEAST(o)PRIiLEAST64__PRI64LEAST(i)PRIdLEAST64__PRI64LEAST(d)SCNx64__SCN64(x)SCNu64__SCN64(u)SCNo64__SCN64(o)SCNi64__SCN64(i)SCNd64__SCN64(d)PRIX64__PRI64(X)PRIx64__PRI64(x)PRIu64__PRI64(u)PRIo64__PRI64(o)PRIi64__PRI64(i)PRId64__PRI64(d)__FAST64 __STRINGIFY(x)__LEAST64 __STRINGIFY(x)__INT64 __STRINGIFY(x)SCNxFAST32__SCN32FAST(x)SCNuFAST32__SCN32FAST(u)SCNoFAST32__SCN32FAST(o)SCNiFAST32__SCN32FAST(i)SCNdFAST32__SCN32FAST(d)PRIXFAST32__PRI32FAST(X)PRIxFAST32__PRI32FAST(x)PRIuFAST32__PRI32FAST(u)PRIoFAST32__PRI32FAST(o)PRIiFAST32__PRI32FAST(i)PRIdFAST32__PRI32FAST(d)SCNxLEAST32__SCN32LEAST(x)SCNuLEAST32__SCN32LEAST(u)SCNoLEAST32__SCN32LEAST(o)SCNiLEAST32__SCN32LEAST(i)SCNdLEAST32__SCN32LEAST(d)PRIXLEAST32__PRI32LEAST(X)PRIxLEAST32__PRI32LEAST(x)PRIuLEAST32__PRI32LEAST(u)PRIoLEAST32__PRI32LEAST(o)PRIiLEAST32__PRI32LEAST(i)PRIdLEAST32__PRI32LEAST(d)SCNx32__SCN32(x)SCNu32__SCN32(u)SCNo32__SCN32(o)SCNi32__SCN32(i)SCNd32__SCN32(d)PRIX32__PRI32(X)PRIx32__PRI32(x)PRIu32__PRI32(u)PRIo32__PRI32(o)PRIi32__PRI32(i)PRId32__PRI32(d)__FAST32 __STRINGIFY(x)__LEAST32 __STRINGIFY(x)__INT32 __STRINGIFY(x)SCNxFAST16__SCN16FAST(x)SCNuFAST16__SCN16FAST(u)SCNoFAST16__SCN16FAST(o)SCNiFAST16__SCN16FAST(i)SCNdFAST16__SCN16FAST(d)PRIXFAST16__PRI16FAST(X)PRIxFAST16__PRI16FAST(x)PRIuFAST16__PRI16FAST(u)PRIoFAST16__PRI16FAST(o)PRIiFAST16__PRI16FAST(i)PRIdFAST16__PRI16FAST(d)SCNxLEAST16__SCN16LEAST(x)SCNuLEAST16__SCN16LEAST(u)SCNoLEAST16__SCN16LEAST(o)SCNiLEAST16__SCN16LEAST(i)SCNdLEAST16__SCN16LEAST(d)PRIXLEAST16__PRI16LEAST(X)PRIxLEAST16__PRI16LEAST(x)PRIuLEAST16__PRI16LEAST(u)PRIoLEAST16__PRI16LEAST(o)PRIiLEAST16__PRI16LEAST(i)PRIdLEAST16__PRI16LEAST(d)SCNx16__SCN16(x)SCNu16__SCN16(u)SCNo16__SCN16(o)SCNi16__SCN16(i)SCNd16__SCN16(d)PRIX16__PRI16(X)PRIx16__PRI16(x)PRIu16__PRI16(u)PRIo16__PRI16(o)PRIi16__PRI16(i)PRId16__PRI16(d)__FAST16 __STRINGIFY(x)__LEAST16 __STRINGIFY(x)__INT16 __STRINGIFY(x)SCNxFAST8__SCN8FAST(x)SCNuFAST8__SCN8FAST(u)SCNoFAST8__SCN8FAST(o)SCNiFAST8__SCN8FAST(i)SCNdFAST8__SCN8FAST(d)PRIXFAST8__PRI8FAST(X)PRIxFAST8__PRI8FAST(x)PRIuFAST8__PRI8FAST(u)PRIoFAST8__PRI8FAST(o)PRIiFAST8__PRI8FAST(i)PRIdFAST8__PRI8FAST(d)SCNxLEAST8__SCN8LEAST(x)SCNuLEAST8__SCN8LEAST(u)SCNoLEAST8__SCN8LEAST(o)SCNiLEAST8__SCN8LEAST(i)SCNdLEAST8__SCN8LEAST(d)PRIXLEAST8__PRI8LEAST(X)PRIxLEAST8__PRI8LEAST(x)PRIuLEAST8__PRI8LEAST(u)PRIoLEAST8__PRI8LEAST(o)PRIiLEAST8__PRI8LEAST(i)PRIdLEAST8__PRI8LEAST(d)SCNx8__SCN8(x)SCNu8__SCN8(u)SCNo8__SCN8(o)SCNi8__SCN8(i)SCNd8__SCN8(d)PRIX8__PRI8(X)PRIx8__PRI8(x)PRIu8__PRI8(u)PRIo8__PRI8(o)PRIi8__PRI8(i)PRId8__PRI8(d)__FAST8 __STRINGIFY(x)__LEAST8 __STRINGIFY(x)__INT8 __STRINGIFY(x)__STRINGIFY(a)#a_INTTYPES_Hdefined(_WANT_IO_C99_FORMATS)defined (_INTPTR_EQ_LONGLONG)defined (_INTPTR_EQ_LONG)/* ptr types *//* max-bit types *//* 64-bit types *//* 32-bit types *//* 16-bit types *//* _WANT_IO_C99_FORMATS *//* Macros below are only enabled for a newlib built with C99 I/O format support. *//* NOTICE: scanning 8-bit types requires use of the hh specifier
 * which is only supported on newlib platforms that
 * are built with C99 I/O format support enabled.  If the flag in
 * newlib.h hasn't been set during configuration to indicate this, the 8-bit
 * scanning format macros are disabled here as they result in undefined
 * behaviour which can include memory overwrite.  Overriding the flag after the
 * library has been built is not recommended as it will expose the underlying
 * undefined behaviour.
 *//* 8-bit types *//**
 *  @file  inttypes.h
 */__numer__denomer_MACHINE__TYPES_H/*
 *  Copyright (c) 2005 Ralf Corsepious  <ralf.corsepius@rtems.org>
 */wint_t__need_wint_t<machine/_types.h>__useconds_t__suseconds_t__nlink_t__nl_item__socklen_t__sa_family_t__timer_t__daddr_t__clockid_t__time_t__clock_t_iconv_t_mbstate_t__ssize_t_ssize_t_fpos_t__key_t__loff_t__off_t_off64_t__mode_t__ino_t__id_t__gid_t__uid_t__dev_t__pid_t_off_t__fsfilcnt_t__fsblkcnt_t__blksize_t__blkcnt_t__value__count__wchb__wch_TIMER_T_unsigned long_CLOCKID_T__TIME_T__CLOCK_T__SYS__TYPES_Hdefined (__ARMCC_VERSION) && (__ARMCC_VERSION >= 6100100)__machine_blkcnt_t_defined__machine_blksize_t_defined__machine_fsblkcnt_t_defined__machine_fsfilcnt_t_defined__machine_off_t_defineddefined(__XMK__)__machine_dev_t_defined__linux__machine_uid_t_defined__machine_gid_t_defined__machine_id_t_defined__machine_ino_t_defined(defined(__i386__) && (defined(GO32) || defined(__MSDOS__))) || \__machine_mode_t_defineddefined(__i386__) && (defined(GO32) || defined(__MSDOS__))defined(__sparc__) && !defined(__sparc_v9__)__machine_off64_t_defineddefined(__CYGWIN__) && !defined(__LP64__)__machine_key_t_defined__machine_fpos_t_defined__machine_fpos64_t_defined__machine_size_t_defineddefined(__INT_MAX__) && __INT_MAX__ == 2147483647__machine_ssize_t_defined__machine_mbstate_t_defined__machine_iconv_t_defined__machine_clock_t_defineddefined(_USE_LONG_TIME_T) || __LONG_MAX__ > 0x7fffffffL__machine_clockid_t_defined__machine_daddr_t_defined__machine_sa_family_t_defined__machine_socklen_t_defined/* _SYS__TYPES_H *//* microseconds (unsigned) *//* microseconds (signed) *//* clock() *//* Iconv descriptor type *//* Value so far.  *//* Conversion state information.  *//* If __SIZE_TYPE__ is defined (gcc) we define ssize_t based on size_t.
   We simply change "unsigned" to "signed" for this single definition
   to make sure ssize_t and size_t only differ by their signedness. *//* Defined by GCC provided <stddef.h> *//* (and must be `long' for now) *//* XXX must match off_t in <sys/types.h> *//*
 * We need fpos_t for the following, but it doesn't have a leading "_",
 * so we use _fpos_t instead.
 *//* The Arm Compiler doesn't define wint_t as part of stddef.h so
 * define it here.
 *//* This file defines various typedefs needed by the system calls that support
   the C library.  Basically, they're just the POSIX versions with an '_'
   prepended.  Targets shall use <machine/_types.h> to define their own
   internal types if desired.

   There are three define patterns used for type definitions.  Lets assume
   xyz_t is a user type.

   The internal type definition uses __machine_xyz_t_defined.  It is defined by
   <machine/_types.h> to disable a default definition in <sys/_types.h>. It
   must not be used in other files.

   User type definitions are guarded by __xyz_t_defined in glibc and
   _XYZ_T_DECLARED in BSD compatible systems.
*//* ANSI C namespace clean utility typedefs */_SYS_TYPES_Hdefined(__XMK__) && defined(___int64_t_defined)/* !_SYS_TYPES_H *//*
 * Newlib targets may provide an own version of this file in their machine
 * directory to add custom user types for <sys/types.h>.
 */<machine/types.h><sys/_types.h><_ansi.h>sbintime_tsuseconds_tuseconds_ttimer_tclockid_tnlink_tmode_tssize_tkey_tpid_tgid_tuid_tdev_toff_tino_tid_tfsfilcnt_tfsblkcnt_tcaddr_tdaddr_ttime_tclock_tblksize_tblkcnt_tregister_tu_int64_tu_int32_tu_int16_tu_int8_t__ULong__Long__need_inttypes_SUSECONDS_T_DECLARED_USECONDS_T_DECLARED_TIMER_T_DECLARED__timer_t_defined_CLOCKID_T_DECLARED__clockid_t_defined_NLINK_T_DECLARED_MODE_T_DECLARED_SSIZE_T_DECLARED_KEY_T_DECLARED_PID_T_DECLARED_GID_T_DECLARED_UID_T_DECLARED_DEV_T_DECLARED_OFF_T_DECLARED_INO_T_DECLARED_ID_T_DECLARED_FSBLKCNT_T_DECLARED__caddr_t_defined_TIME_T_DECLARED__time_t_defined_CLOCK_T_DECLARED__clock_t_defined_BLKSIZE_T_DECLARED_BLKCNT_T_DECLARED__BIT_TYPES_DEFINED___IN_ADDR_T_DECLARED_IN_PORT_T_DECLARED_BSDTYPES_DEFINED__u_char_defined__u_short_defined__u_int_defined__u_long_defined!defined(__clock_t_defined) && !defined(_CLOCK_T_DECLARED)!defined(__time_t_defined) && !defined(_TIME_T_DECLARED)!defined(__clockid_t_defined) && !defined(_CLOCKID_T_DECLARED)!defined(__timer_t_defined) && !defined(_TIMER_T_DECLARED)/* _SYS_TYPES_H *//* !__need_inttypes *//* link count *//* permissions *//* IPC key *//* process id *//* group id *//* user id *//* device number or struct cdev *//* file offset *//*
 * All these should be machine specific - right now they are all broken.
 * However, for all of Cygnus' embedded targets, we want them to all be
 * the same.  Otherwise things like sizeof (struct stat) might depend on
 * how the file was compiled (e.g. -mint16 vs -mint32, etc.).
 *//* __i386__ && (GO32 || __MSDOS__) *//* inode number *//* can hold a uid_t or pid_t *//* for statvfs() *//* System V compatibility *//* __MISC_VISIBLE *//* also defined in mingw/gmon.h and in w32api/winsock[2].h *//* __BSD_VISIBLE *//* base type for internet address *//* BSD types permitted by POSIX and always exposed as in Glibc.  Only provided
   for backward compatibility with BSD code.  The uintN_t standard types should
   be preferred in new code. *//* unified sys/types.h: 
   start with sef's sysvi386 version.
   merge go32 version -- a few ifdefs.
   h8300hms, h8300xray, and sysvnecv70 disagree on the following types:

   typedef int gid_t;
   typedef int uid_t;
   typedef int dev_t;
   typedef int ino_t;
   typedef int mode_t;
   typedef int caddr_t;

   however, these aren't "reasonable" values, the sysvi386 ones make far 
   more sense, and should work sufficiently well (in particular, h8300 
   doesn't have a stat, and the necv70 doesn't matter.) -- eichin
 */<sys/types.h>__printf_floatugetdelimsize_t *__restrict__FILE *__file *FILE *__restrict__getlinetmpnamtmpfilesetvbufsetlinebufsetbuffersetbufrewindrenameremoveperrorfilenoftelloftellfsetposfpos_t *fseekofseekfmemopenfdopenfreopenfopenfgetposferrorfeofclearerrfreadgetsfgetsvsscanfsscanfvfscanfvscanffscanfscanfungetcgetchargetcfgetcfwriteputsfputsvasprintfasprintfvsnprintfvsprintfsnprintfsprintfvfprintfvprintffprintfputcharputcfputcfflushfclosefdevopenfpos_tFILE__FILE__file_ext__file_close__file__ungetc_tseekcfileclosefileflushgetputungetFILE *conststderrstdoutstdinprintf_float(x)((double) (x))TMP_MAXP_tmpdirL_tmpnamBUFSIZSEEK_ENDSEEK_CURSEEK_SETferror(s)((s)->flags & __SERR)feof(s)((s)->flags & __SEOF)clearerr(s)((s)->flags &= ~(__SERR | __SEOF))getchar()fgetc(stdin)getc(__stream)fgetc(__stream)putchar(__c)fputc(__c, stdout)putc(__c,__stream)fputc(__c, __stream)__SCANF_ATTRIBUTE__(__s,_f)__FORMAT_ATTRIBUTE__(scanf, __s, __f)__PRINTF_ATTRIBUTE__(__s,__f)__FORMAT_ATTRIBUTE__(printf, __s, __f)__FORMAT_ATTRIBUTE__(__a,__s,__f)__attribute__((__format__ (__a, __s, __f)))fdev_close(f)(fflush(f))FDEV_SETUP_STREAM(p,g,fl,f){ .flags = (f), .put = (p), .get = (g), .flush = (fl), }_FDEV_EOF(-2)_FDEV_ERR_FDEV_SETUP_RW(__SRD|__SWR)_FDEV_SETUP_WRITE__SWR_FDEV_SETUP_READ__SRDfdev_setup_stream(stream,p,g,fl,f)do { (stream)->flags = f; (stream)->put = p; (stream)->get = g; (stream)->flush = fl; } while(0)_IONBF_IOLBF_IOFBFEOFPICOLIBC_STDIO_GLOBALS__FILE_definedFDEV_SETUP_EXT(put,get,flush,close,_seek,_setvbuf,rwflag){ .cfile = FDEV_SETUP_CLOSE(put, get, flush, close, (rwflag) | __SEXT), .seek = (_seek), .setvbuf = (_setvbuf), }FDEV_SETUP_CLOSE(put,get,flush,_close,rwflag){ .file = FDEV_SETUP_STREAM(put, get, flush, (rwflag) | __SCLOSE), .close = (_close), }__SWIDE0x0080__SBUF0x0040__SEXT0x0020__SCLOSE0x0010__SEOF0x0008__SERR0x00040x00020x0001__PICOLIBC_UNGETC_SIZE__need_ssize_t_STDIO_H_defined(__riscv) || defined(__MICROBLAZE__)__PICOLIBC_UNGETC_SIZE == 4__PICOLIBC_UNGETC_SIZE == 2!defined(__FILE_defined)PICOLIBC_FLOAT_PRINTF_SCANF/* _STDIO_H_ *//*@}*//*
 * We don't have any way of knowing any underlying POSIX limits,
 * so just use a reasonably small value here
 *//*
 * tmpnam files are created in the current directory
 *//*
 * The format of tmpnam names is TXXXXXX, which works with mktemp
 *//* only mentioned for libstdc++ support, not implemented in library *//* set file offset to EOF plus offset *//* set file offset to current plus offset *//* set file offset to offset *//* fast inlined version of ferror() *//* fast inlined version of feof() *//* fast inlined version of clearerr() *//**
 * Return code for an end-of-file condition during device read.
 *
 * To be used in the get function of fdevopen().
 *//**
 * Return code for an error condition during device read.
 *
 * To be used in the get function of fdevopen().
 *//**< fdev_setup_stream() with read/write intent *//**< fdev_setup_stream() with write intent *//**< fdev_setup_stream() with read intent *//* setvbuf should set unbuffered *//* setvbuf should set line buffered *//* setvbuf should set fully buffered *//**
   This symbol is defined when stdin/stdout/stderr are global
   variables. When undefined, the old __iob array is used which
   contains the pointers instead
*//**
   \c FILE is the opaque structure that is passed around between the
   various standard IO functions.
*//*@{*//* close file struct *//* function to close file *//* main file struct *//*
 * This variant includes a 'close' function which is
 * invoked from fclose when the __SCLOSE bit is set
 *//* function to flush output to device *//* function to read one char from device *//* function to write one char to device *//* wchar output mode *//* struct is __file_bufio *//* struct is __file_ext *//* struct is __file_close *//* found EOF *//* found error *//* OK to write *//* OK to read *//* flags, see below *//* ungetc() buffer *//*
 * Use 32-bit ungetc storage when doing atomic ungetc on RISC-V and
 * MicroBlaze, which have 4-byte swap intrinsics but not 2-byte swap
 * intrinsics. This increases the size of the __file struct by four
 * bytes.
 *//*
 * This is an internal structure of the library that is subject to be
 * changed without warnings at any time.  Please do *never* reference
 * elements of it beyond by using the official interfaces provided.
 *//* Copyright (c) 2002, 2005, 2007 Joerg Wunsch
   All rights reserved.

   Portions of documentation Copyright (c) 1990, 1991, 1993
   The Regents of the University of California.

   All rights reserved.

   Redistribution and use in source and binary forms, with or without
   modification, are permitted provided that the following conditions are met:

   * Redistributions of source code must retain the above copyright
     notice, this list of conditions and the following disclaimer.

   * Redistributions in binary form must reproduce the above copyright
     notice, this list of conditions and the following disclaimer in
     the documentation and/or other materials provided with the
     distribution.

   * Neither the name of the copyright holders nor the names of
     contributors may be used to endorse or promote products derived
     from this software without specific prior written permission.

  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
  POSSIBILITY OF SUCH DAMAGE.

  $Id: stdio.h 2527 2016-10-27 20:41:22Z joerg_wunsch $
*/lineptrdelimstreamsmodeoldpathnewpathpathnameoffsetwhencemallocpath__stream__ptr__size__nmemb__str__buf__fmtap__ap__cstrp__s__n__put__get__flush<stdio.h>vprintkprintkvsnprintk(str,size,fmt,ap)vsnprintf(str, size, fmt, ap)snprintk(__VA_ARGS__...)snprintf(__VA_ARGS__)ZEPHYR_INCLUDE_SYS_PRINTK_H_/**
 *
 * @brief Print kernel debugging message.
 *
 * This routine prints a kernel debugging message to the system console.
 * Output is send immediately, without any mutual exclusion or buffering.
 *
 * A basic set of conversion specifier characters are supported:
 *   - signed decimal: \%d, \%i
 *   - unsigned decimal: \%u
 *   - unsigned hexadecimal: \%x (\%X is treated as \%x)
 *   - pointer: \%p
 *   - string: \%s
 *   - character: \%c
 *   - percent: \%\%
 *
 * Field width (with or without leading zeroes) is supported.
 * Length attributes h, hh, l, ll and z are supported. However, integral
 * values with %lld and %lli are only printed if they fit in a long
 * otherwise 'ERR' is printed. Full 64-bit values may be printed with %llx.
 * Flags and precision attributes are not supported.
 *
 * @param fmt Format string.
 * @param ... Optional list of format arguments.
 *//*
 * Copyright (c) 2010-2012, 2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* printk.h - low-level debug output */ZEPHYR_INCLUDE_ARCH_CPU_H_defined(CONFIG_NIOS2)defined(CONFIG_XTENSA)defined(CONFIG_MIPS)/* ZEPHYR_INCLUDE_ARCH_CPU_H_ *//* cpu.h - automatically selects the correct arch.h file to include */irq_offloadirq_offload_routine_tZEPHYR_INCLUDE_IRQ_OFFLOAD_H_/* _SW_IRQ_H_ *//**
 * @brief Run a function in interrupt context
 *
 * This function synchronously runs the provided function in interrupt
 * context, passing in the supplied device. Useful for test code
 * which needs to show that kernel objects work correctly in interrupt
 * context.
 *
 * Additionally, when CONFIG_IRQ_OFFLOAD_NESTED is set by the
 * architecture, this routine works to synchronously invoke a nested
 * interrupt when called from an ISR context (i.e. when k_is_in_isr()
 * is true).  Note that not all platforms will have hardware support
 * for this capability, and even on those some interrupts may be
 * running at unpreemptible priorities.
 *
 * @param routine The function to run
 * @param parameter Argument to pass to the function when it is run as an
 * interrupt
 *//**
 * @file
 * @brief IRQ Offload interface
 *//*
 * Copyright (c) 2015 Intel corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */arch_num_cpusZEPHYR_INCLUDE_ARCH_X86_ARCH_INLINES_H_/* ZEPHYR_INCLUDE_ARCH_X86_ARCH_INLINES_H_ *//*
	 * Placeholder implementation to be replaced with an architecture
	 * specific call to get processor ID
	 *//*
 * Copyright (c) 2019 Intel Corporation
 * Copyright (c) 2019 Stephanos Ioannidis <root@stephanos.io>
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/arch/x86/arch_inlines.h>ZEPHYR_INCLUDE_ARCH_INLINES_H_defined(CONFIG_X86) || defined(CONFIG_X86_64)/* ZEPHYR_INCLUDE_ARCH_INLINES_H_ *//*
 * Copyright (c) 2019 Stephanos Ioannidis <root@stephanos.io>
 *
 * SPDX-License-Identifier: Apache-2.0
 *//*
 * arch_inlines.h - automatically selects the correct arch_inlines.h file to
 *   include based on the selected architecture.
 */<zephyr/arch/arch_inlines.h><zephyr/irq_offload.h>arch_spin_relaxarch_cohere_stacksold_threadold_switch_handlenew_threadarch_mem_coherentarch_irq_is_usedarch_irq_set_usedarch_irq_allocatearch_irq_disconnect_dynamicarch_irq_connect_dynamicarch_irq_is_enabledarch_irq_enablearch_irq_disablearch_cpu_activearch_start_cpuarch_cpustart_tk_thread_entry_tk_thread_stack_tk_mem_domainZEPHYR_INCLUDE_SYS_ARCH_INTERFACE_H_CONFIG_PCIECONFIG_IRQ_OFFLOADCONFIG_ARCH_MEM_DOMAIN_DATACONFIG_ARCH_MEM_DOMAIN_SYNCHRONOUS_APICONFIG_ARCH_HAS_COHERENCECONFIG_KERNEL_COHERENCECONFIG_GDBSTUBCONFIG_TIMING_FUNCTIONSCONFIG_PCIE_MSI_MULTI_VECTORarch_irq_unlockedarch_irq_unlockarch_irq_lockarch_k_cycle_get_64arch_k_cycle_get_32z_thread_stack_element/* ZEPHYR_INCLUDE_SYS_ARCH_INTERFACE_H_ *//**
 * @brief Perform architecture specific processing within spin loops
 *
 * This is invoked from busy loops with IRQs disabled such as the contended
 * spinlock loop. The default implementation is a weak function that calls
 * arch_nop(). Architectures may implement this function to perform extra
 * checks or power management tricks if needed.
 *//* CONFIG_PCIE_MSI_MULTI_VECTOR *//**
 * @brief Connect an MSI vector to the given routine
 *
 * @param vector The MSI vector to connect to
 * @param routine Interrupt service routine
 * @param parameter ISR parameter
 * @param flags Arch-specific IRQ configuration flag
 *
 * @return True on success, false otherwise
 *//**
 * @brief Allocate vector(s) for the endpoint MSI message(s).
 *
 * @param priority the MSI vectors base interrupt priority
 * @param vectors an array to fill with allocated MSI vectors
 * @param n_vector the size of MSI vectors array
 *
 * @return The number of allocated MSI vectors
 *//* CONFIG_TIMING_FUNCTIONS *//**
 * @brief Get frequency of counter used (in MHz).
 *
 * @return Frequency of counter used for timing in MHz.
 *
 * @see timing_freq_get_mhz()
 *//**
 * @brief Convert number of @p cycles into nanoseconds with averaging.
 *
 * @param cycles Number of cycles
 * @param count Times of accumulated cycles to average over
 * @return Converted time value
 *
 * @see timing_cycles_to_ns_avg()
 *//**
 * @brief Convert number of @p cycles into nanoseconds.
 *
 * @param cycles Number of cycles
 * @return Converted time value
 *
 * @see timing_cycles_to_ns()
 *//**
 * @brief Get frequency of counter used (in Hz).
 *
 * @return Frequency of counter used for timing in Hz.
 *
 * @see timing_freq_get()
 *//**
 * @brief Get number of cycles between @p start and @p end.
 *
 * For some architectures or SoCs, the raw numbers from counter need
 * to be scaled to obtain actual number of cycles, or may roll over
 * internally.  This function computes a positive-definite interval
 * between two returned cycle values.
 *
 * @param start Pointer to counter at start of a measured execution.
 * @param end Pointer to counter at stop of a measured execution.
 * @return Number of cycles between start and end.
 *
 * @see timing_cycles_get()
 *//**
 * @brief Return timing counter.
 *
 * @note Any call to arch_timing_counter_get() must be done between
 * calls to arch_timing_start() and arch_timing_stop(), and on the
 * same CPU core.
 *
 * @note Not all platforms have a timing counter with 64 bit precision.  It
 * is possible to see this value "go backwards" due to internal
 * rollover.  Timing code must be prepared to address the rollover
 * (with platform-dependent code, e.g. by casting to a uint32_t before
 * subtraction) or by using arch_timing_cycles_get() which is required
 * to understand the distinction.
 *
 * @return Timing counter.
 *
 * @see timing_counter_get()
 *//**
 * @brief Signal the end of the timing information gathering.
 *
 * Signal to the timing subsystem that timing information
 * is no longer being gathered from this point forward.
 *
 * @note Any call to arch_timing_counter_get() must be done between
 * calls to arch_timing_start() and arch_timing_stop(), and on the
 * same CPU core.
 *
 * @see timing_stop()
 *//**
 * @brief Signal the start of the timing information gathering.
 *
 * Signal to the timing subsystem that timing information
 * will be gathered from this point forward.
 *
 * @note Any call to arch_timing_counter_get() must be done between
 * calls to arch_timing_start() and arch_timing_stop(), and on the
 * same CPU core.
 *
 * @see timing_start()
 *//**
 * @brief Initialize the timing subsystem.
 *
 * Perform the necessary steps to initialize the timing subsystem.
 *
 * @see timing_init()
 *//**
 * @ingroup arch-timing
 * @{
 *//**
 * @brief Remove breakpoint or watchpoint.
 *
 * @param ctx GDB context
 * @param type Breakpoint or watchpoint type
 * @param addr Address of breakpoint or watchpoint
 * @param kind Size of breakpoint/watchpoint in bytes
 *
 * @retval 0  Operation successful
 * @retval -1 Error encountered
 * @retval -2 Not supported
 *//**
 * @brief Add breakpoint or watchpoint.
 *
 * @param ctx GDB context
 * @param type Breakpoint or watchpoint type
 * @param addr Address of breakpoint or watchpoint
 * @param kind Size of breakpoint/watchpoint in bytes
 *
 * @retval 0  Operation successful
 * @retval -1 Error encountered
 * @retval -2 Not supported
 *//**
 * @brief Take a hexadecimal string and update one register.
 *
 * This takes in a hexadecimal string as presented from GDB,
 * and updates one CPU registers with new value.
 *
 * @param ctx    GDB context
 * @param hex    Input hexadecimal string.
 * @param hexlen Length of hexadecimal string.
 * @param regno  Register number
 *
 * @return Length of hexadecimal string parsed.
 *         Return 0 if error or not supported.
 *//**
 * @brief Read one register, and outputs as hexadecimal string.
 *
 * This reads one CPU register and outputs as hexadecimal string.
 * The output string must be parsable by GDB.
 *
 * @param ctx    GDB context
 * @param buf    Buffer to output hexadecimal string.
 * @param buflen Length of buffer.
 * @param regno  Register number
 *
 * @return Length of hexadecimal string written.
 *         Return 0 if error or not supported.
 *//**
 * @brief Take a hexadecimal string and update all registers.
 *
 * This takes in a hexadecimal string as presented from GDB,
 * and updates all CPU registers with new values.
 *
 * @param ctx    GDB context
 * @param hex    Input hexadecimal string.
 * @param hexlen Length of hexadecimal string.
 *
 * @return Length of hexadecimal string parsed.
 *         Return 0 if error or not supported.
 *//**
 * @brief Read all registers, and outputs as hexadecimal string.
 *
 * This reads all CPU registers and outputs as hexadecimal string.
 * The output string must be parsable by GDB.
 *
 * @param ctx    GDB context
 * @param buf    Buffer to output hexadecimal string.
 * @param buflen Length of buffer.
 *
 * @return Length of hexadecimal string written.
 *         Return 0 if error or not supported.
 *//**
 * @brief Continue with one step
 *
 * Continue software execution until reaches the next statement.
 *//**
 * @brief Continue running program
 *
 * Continue software execution.
 *//**
 * @brief Architecture layer debug start
 *
 * This function is called by @c gdb_init()
 *//**
 * @defgroup arch-gdbstub Architecture-specific gdbstub APIs
 * @ingroup arch-interface
 * @{
 *//**
 * @brief Ensure cache coherence prior to context switch
 *
 * Required when ARCH_HAS_COHERENCE is true.  On cache-incoherent
 * multiprocessor architectures, thread stacks are cached by default
 * for performance reasons.  They must therefore be flushed
 * appropriately on context switch.  The rules are:
 *
 * 1. The region containing live data in the old stack (generally the
 *    bytes between the current stack pointer and the top of the stack
 *    memory) must be flushed to underlying storage so a new CPU that
 *    runs the same thread sees the correct data.  This must happen
 *    before the assignment of the switch_handle field in the thread
 *    struct which signals the completion of context switch.
 *
 * 2. Any data areas to be read from the new stack (generally the same
 *    as the live region when it was saved) should be invalidated (and
 *    NOT flushed!) in the data cache.  This is because another CPU
 *    may have run or re-initialized the thread since this CPU
 *    suspended it, and any data present in cache will be stale.
 *
 * @note The kernel will call this function during interrupt exit when
 * a new thread has been chosen to run, and also immediately before
 * entering arch_switch() to effect a code-driven context switch.  In
 * the latter case, it is very likely that more data will be written
 * to the old_thread stack region after this function returns but
 * before the completion of the switch.  Simply flushing naively here
 * is not sufficient on many architectures and coordination with the
 * arch_switch() implementation is likely required.
 *
 * @param old_thread The old thread to be flushed before being allowed
 *                   to run on other CPUs.
 * @param old_switch_handle The switch handle to be stored into
 *                          old_thread (it will not be valid until the
 *                          cache is flushed so is not present yet).
 *                          This will be NULL if inside z_swap()
 *                          (because the arch_switch() has not saved it
 *                          yet).
 * @param new_thread The new thread to be invalidated before it runs locally.
 *//**
 * @brief Detect memory coherence type
 *
 * Required when ARCH_HAS_COHERENCE is true.  This function returns
 * true if the byte pointed to lies within an architecture-defined
 * "coherence region" (typically implemented with uncached memory) and
 * can safely be used in multiprocessor code without explicit flush or
 * invalidate operations.
 *
 * @note The result is for only the single byte at the specified
 * address, this API is not required to check region boundaries or to
 * expect aligned pointers.  The expectation is that the code above
 * will have queried the appropriate address(es).
 *//**
 * @brief Safely take the length of a potentially bad string
 *
 * This must not fault, instead the @p err parameter must have -1 written to it.
 * This function otherwise should work exactly like libc strnlen(). On success
 * @p err should be set to 0.
 *
 * @param s String to measure
 * @param maxsize Max length of the string
 * @param err Error value to write
 * @return Length of the string, not counting NULL byte, up to maxsize
 *//**
 * @brief Induce a kernel oops that appears to come from a specific location
 *
 * Normally, k_oops() generates an exception that appears to come from the
 * call site of the k_oops() itself.
 *
 * However, when validating arguments to a system call, if there are problems
 * we want the oops to appear to come from where the system call was invoked
 * and not inside the validation function.
 *
 * @param ssf System call stack frame pointer. This gets passed as an argument
 *            to _k_syscall_handler_t functions and its contents are completely
 *            architecture specific.
 *//**
 * Perform a one-way transition from supervisor to kernel mode.
 *
 * Implementations of this function must do the following:
 *
 * - Reset the thread's stack pointer to a suitable initial value. We do not
 *   need any prior context since this is a one-way operation.
 * - Set up any kernel stack region for the CPU to use during privilege
 *   elevation
 * - Put the CPU in whatever its equivalent of user mode is
 * - Transfer execution to arch_new_thread() passing along all the supplied
 *   arguments, in user mode.
 *
 * @param user_entry Entry point to start executing as a user thread
 * @param p1 1st parameter to user thread
 * @param p2 2nd parameter to user thread
 * @param p3 3rd parameter to user thread
 *//**
 * Get the optimal virtual region alignment to optimize the MMU table layout
 *
 * Some MMU HW requires some region to be aligned to some of the intermediate
 * block alignment in order to reduce table usage.
 * This call returns the optimal virtual address alignment in order to permit
 * such optimization in the following MMU mapping call.
 *
 * @param[in] phys Physical address of region to be mapped,
 *                 aligned to @kconfig{CONFIG_MMU_PAGE_SIZE}
 * @param[in] size Size of region to be mapped,
 *                 aligned to @kconfig{CONFIG_MMU_PAGE_SIZE}
 *
 * @return Alignment to apply on the virtual address of this region
 *//**
 * @brief Check memory region permissions
 *
 * Given a memory region, return whether the current memory management hardware
 * configuration would allow a user thread to read/write that region. Used by
 * system calls to validate buffers coming in from userspace.
 *
 * Notes:
 * The function is guaranteed to never return validation success, if the entire
 * buffer area is not user accessible.
 *
 * The function is guaranteed to correctly validate the permissions of the
 * supplied buffer, if the user access permissions of the entire buffer are
 * enforced by a single, enabled memory management region.
 *
 * In some architectures the validation will always return failure
 * if the supplied memory buffer spans multiple enabled memory management
 * regions (even if all such regions permit user access).
 *
 * @warning Buffer of size zero (0) has undefined behavior.
 *
 * @param addr start address of the buffer
 * @param size the size of the buffer
 * @param write If non-zero, additionally check if the area is writable.
 *	  Otherwise, just check if the memory can be read.
 *
 * @return nonzero if the permissions don't match.
 *//* CONFIG_ARCH_MEM_DOMAIN_SYNCHRONOUS_API *//**
 * @brief Add a partition to the memory domain
 *
 * Architecture-specific hook to manage internal data structures or hardware
 * state when a memory domain has a partition added.
 *
 * @param domain The memory domain structure
 * @param partition_id The partition that needs to be added
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 *//**
 * @brief Remove a partition from the memory domain (arch-specific)
 *
 * Architecture-specific hook to manage internal data structures or hardware
 * state when a memory domain has had a partition removed.
 *
 * The partition index data, and the number of partitions configured, are not
 * respectively cleared and decremented in the domain until after this function
 * runs.
 *
 * @param domain The memory domain structure
 * @param partition_id The partition index that needs to be deleted
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 * @retval -ENOENT if no matching partition found
 *//**
 * @brief Remove a thread from a memory domain (arch-specific)
 *
 * Architecture-specific hook to manage internal data structures or hardware
 * state when the provided thread has been removed from a memory domain.
 *
 * The thread's memory domain pointer will be the domain that the thread
 * is being removed from.
 *
 * @param thread Thread being removed from its memory domain
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 *//**
 * @brief Add a thread to a memory domain (arch-specific)
 *
 * Architecture-specific hook to manage internal data structures or hardware
 * state when the provided thread has been added to a memory domain.
 *
 * The thread->mem_domain_info.mem_domain pointer will be set to the domain to
 * be added to before this is called. Implementations may assume that the
 * thread is not already a member of this domain.
 *
 * @param thread Thread which needs to be configured.
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 * @retval -ENOSPC if running out of space in internal structures
 *                    (e.g. translation tables)
 *//* CONFIG_ARCH_MEM_DOMAIN_DATA *//**
 *
 * @brief Architecture-specific hook for memory domain initialization
 *
 * Perform any tasks needed to initialize architecture-specific data within
 * the memory domain, such as reserving memory for page tables. All members
 * of the provided memory domain aside from `arch` will be initialized when
 * this is called, but no threads will be a assigned yet.
 *
 * This function may fail if initializing the memory domain requires allocation,
 * such as for page tables.
 *
 * The associated function k_mem_domain_init() documents that making
 * multiple init calls to the same memory domain is undefined behavior,
 * but has no assertions in place to check this. If this matters, it may be
 * desirable to add checks for this in the implementation of this function.
 *
 * @param domain The memory domain to initialize
 * @retval 0 Success
 * @retval -ENOMEM Insufficient memory
 *//**
 * @brief Get the maximum number of partitions for a memory domain
 *
 * @return Max number of partitions, or -1 if there is no limit
 *//**
 * Indicate whether we are currently running in user mode
 *
 * @return True if the CPU is currently running with user permissions
 *//**
 * Invoke a system call with 6 arguments.
 *
 * @see arch_syscall_invoke0()
 *
 * @param arg1 First argument to the system call.
 * @param arg2 Second argument to the system call.
 * @param arg3 Third argument to the system call.
 * @param arg4 Fourth argument to the system call.
 * @param arg5 Fifth argument to the system call.
 * @param arg6 Sixth argument to the system call.
 * @param call_id System call ID, will be bounds-checked and used to reference
 *	          kernel-side dispatch table
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * Invoke a system call with 5 arguments.
 *
 * @see arch_syscall_invoke0()
 *
 * @param arg1 First argument to the system call.
 * @param arg2 Second argument to the system call.
 * @param arg3 Third argument to the system call.
 * @param arg4 Fourth argument to the system call.
 * @param arg5 Fifth argument to the system call.
 * @param call_id System call ID, will be bounds-checked and used to reference
 *	          kernel-side dispatch table
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * Invoke a system call with 4 arguments.
 *
 * @see arch_syscall_invoke0()
 *
 * @param arg1 First argument to the system call.
 * @param arg2 Second argument to the system call.
 * @param arg3 Third argument to the system call.
 * @param arg4 Fourth argument to the system call.
 * @param call_id System call ID, will be bounds-checked and used to reference
 *	          kernel-side dispatch table
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * Invoke a system call with 3 arguments.
 *
 * @see arch_syscall_invoke0()
 *
 * @param arg1 First argument to the system call.
 * @param arg2 Second argument to the system call.
 * @param arg3 Third argument to the system call.
 * @param call_id System call ID, will be bounds-checked and used to reference
 *	          kernel-side dispatch table
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * Invoke a system call with 2 arguments.
 *
 * @see arch_syscall_invoke0()
 *
 * @param arg1 First argument to the system call.
 * @param arg2 Second argument to the system call.
 * @param call_id System call ID, will be bounds-checked and used to reference
 *	          kernel-side dispatch table
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * Invoke a system call with 1 argument.
 *
 * @see arch_syscall_invoke0()
 *
 * @param arg1 First argument to the system call.
 * @param call_id System call ID, will be bounds-checked and used to reference
 *	          kernel-side dispatch table
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * Invoke a system call with 0 arguments.
 *
 * No general-purpose register state other than return value may be preserved
 * when transitioning from supervisor mode back down to user mode for
 * security reasons.
 *
 * It is required that all arguments be stored in registers when elevating
 * privileges from user to supervisor mode.
 *
 * Processing of the syscall takes place on a separate kernel stack. Interrupts
 * should be enabled when invoking the system call marshallers from the
 * dispatch table. Thread preemption may occur when handling system calls.
 *
 * Call IDs are untrusted and must be bounds-checked, as the value is used to
 * index the system call dispatch table, containing function pointers to the
 * specific system call code.
 *
 * @param call_id System call ID
 * @return Return value of the system call. Void system calls return 0 here.
 *//**
 * @defgroup arch-userspace Architecture-specific userspace APIs
 * @ingroup arch-interface
 * @{
 *//**
 * @brief Returns the number of CPUs
 *
 * For most systems this will be the same as CONFIG_MP_MAX_NUM_CPUS,
 * however some systems may determine this at runtime instead.
 *
 * @return the number of CPUs
 *//* CONFIG_SMP *//**
 * Broadcast an interrupt to all CPUs
 *
 * This will invoke z_sched_ipi() on other CPUs in the system.
 *//**
 * @brief Processor hardware ID
 *
 * Most multiprocessor architectures have a low-level unique ID value
 * associated with the current CPU that can be retrieved rapidly and
 * efficiently in kernel context.  Note that while the numbering of
 * the CPUs is guaranteed to be unique, the values are
 * platform-defined. In particular, they are not guaranteed to match
 * Zephyr's own sequential CPU IDs (even though on some platforms they
 * do).
 *
 * @note There is an inherent race with this API: the system may
 * preempt the current thread and migrate it to another CPU before the
 * value is used.  Safe usage requires knowing the migration is
 * impossible (e.g. because the code is in interrupt context, holds a
 * spinlock, or cannot migrate due to k_cpu_mask state).
 *
 * @return Unique ID for currently-executing CPU
 *//** Return the CPU struct for the currently executing CPU *//**
 * @defgroup arch-smp Architecture-specific SMP APIs
 * @ingroup arch-interface
 * @{
 *//* CONFIG_IRQ_OFFLOAD *//**
 * Run a function in interrupt context.
 *
 * Implementations should invoke an exception such that the kernel goes through
 * its interrupt handling dispatch path, to include switching to the interrupt
 * stack, and runs the provided routine and parameter.
 *
 * The only intended use-case for this function is for test code to simulate
 * the correctness of kernel APIs in interrupt handling context. This API
 * is not intended for real applications.
 *
 * @see irq_offload()
 *
 * @param routine Function to run in interrupt context
 * @param parameter Value to pass to the function when invoked
 *//**
 * @def ARCH_EXCEPT(reason_p)
 *
 * Generate a software induced fatal error.
 *
 * If the caller is running in user mode, only K_ERR_KERNEL_OOPS or
 * K_ERR_STACK_CHK_FAIL may be induced.
 *
 * This should ideally generate a software trap, with exception context
 * indicating state when this was invoked. General purpose register state at
 * the time of trap should not be disturbed from the calling context.
 *
 * @param reason_p K_ERR_ scoped reason code for the fatal error.
 *//**
 * @brief Arch-specific hook for checking if an IRQ is being used already
 *
 * @param irq the IRQ to check
 *
 * @return true if being, false otherwise
 *//**
 * @brief Arch-specific hook for declaring an IRQ being used
 *
 * Note: disable/enable IRQ relevantly inside the implementation of such
 * function to avoid concurrency issues.
 *
 * @param irq the IRQ to declare being used
 *//**
 * @brief Arch-specific hook for allocating IRQs
 *
 * Note: disable/enable IRQ relevantly inside the implementation of such
 * function to avoid concurrency issues. Also, an allocated IRQ is assumed
 * to be used thus a following @see arch_irq_is_used() should return true.
 *
 * @return The newly allocated IRQ or UINT_MAX on error.
 *//**
 * @def ARCH_ISR_DIRECT_DECLARE(name)
 *
 * @see ISR_DIRECT_DECLARE()
 *//**
 * @def ARCH_ISR_DIRECT_FOOTER(swap)
 *
 * @see ISR_DIRECT_FOOTER()
 *//**
 * @def ARCH_ISR_DIRECT_HEADER()
 *
 * @see ISR_DIRECT_HEADER()
 *//**
 * @def ARCH_ISR_DIRECT_PM()
 *
 * @see ISR_DIRECT_PM()
 *//**
 * @def ARCH_IRQ_DIRECT_CONNECT(irq_p, priority_p, isr_p, flags_p)
 *
 * @see IRQ_DIRECT_CONNECT()
 *//* CONFIG_PCIE *//**
 * @def ARCH_PCIE_IRQ_CONNECT(bdf, irq, pri, isr, arg, flags)
 *
 * @see PCIE_IRQ_CONNECT()
 *//**
 * @def ARCH_IRQ_CONNECT(irq, pri, isr, arg, flags)
 *
 * @see IRQ_CONNECT()
 *//**
 * Arch-specific hook to dynamically uninstall a shared interrupt.
 * If the interrupt is not being shared, then the associated
 * _sw_isr_table entry will be replaced by (NULL, z_irq_spurious)
 * (default entry).
 *
 * @param irq IRQ line number
 * @param priority Interrupt priority
 * @param routine Interrupt service routine
 * @param parameter ISR parameter
 * @param flags Arch-specific IRQ configuration flag
 *
 * @return 0 in case of success, negative value otherwise
 *//**
 * Arch-specific hook to install a dynamic interrupt.
 *
 * @param irq IRQ line number
 * @param priority Interrupt priority
 * @param routine Interrupt service routine
 * @param parameter ISR parameter
 * @param flags Arch-specific IRQ configuration flag
 *
 * @return The vector assigned to this interrupt
 *//**
 * Test if an interrupt line is enabled
 *
 * @see irq_is_enabled()
 *//**
 * Enable the specified interrupt line
 *
 * @see irq_enable()
 *//**
 * Disable the specified interrupt line
 *
 * @note: The behavior of interrupts that arrive after this call
 * returns and before the corresponding call to arch_irq_enable() is
 * undefined.  The hardware is not required to latch and deliver such
 * an interrupt, though on some architectures that may work.  Other
 * architectures will simply lose such an interrupt and never deliver
 * it.  Many drivers and subsystems are not tolerant of such dropped
 * interrupts and it is the job of the application layer to ensure
 * that behavior remains correct.
 *
 * @see irq_disable()
 *//**
 * Test if calling arch_irq_unlock() with this key would unlock irqs
 *
 * @param key value returned by arch_irq_lock()
 * @return true if interrupts were unlocked prior to the arch_irq_lock()
 * call that produced the key argument.
 *//**
 * Unlock interrupts on the current CPU
 *
 * @see irq_unlock()
 *//**
 * Lock interrupts on the current CPU
 *
 * @see irq_lock()
 *//**
 * @addtogroup arch-irq
 * @{
 *//**
 * @brief Return CPU power status
 *
 * @param cpu_num Integer number of the CPU
 *//**
 * @brief Start a numbered CPU on a MP-capable system
 *
 * This starts and initializes a specific CPU.  The main thread on startup is
 * running on CPU zero, other processors are numbered sequentially.  On return
 * from this function, the CPU is known to have begun operating and will enter
 * the provided function.  Its interrupts will be initialized but disabled such
 * that irq_unlock() with the provided key will work to enable them.
 *
 * Normally, in SMP mode this function will be called by the kernel
 * initialization and should not be used as a user API.  But it is defined here
 * for special-purpose apps which want Zephyr running on one core and to use
 * others for design-specific processing.
 *
 * @param cpu_num Integer number of the CPU
 * @param stack Stack memory for the CPU
 * @param sz Stack buffer size, in bytes
 * @param fn Function to begin running on the CPU.
 * @param arg Untyped argument to be passed to "fn"
 *//**
 * Per-cpu entry function
 *
 * @param data context parameter, implementation specific
 *//**
 * @addtogroup arch-smp
 * @{
 *//**
 * @brief Atomically re-enable interrupts and enter low power mode
 *
 * The requirements for arch_cpu_atomic_idle() are as follows:
 *
 * -# Enabling interrupts and entering a low-power mode needs to be
 *    atomic, i.e. there should be no period of time where interrupts are
 *    enabled before the processor enters a low-power mode.  See the comments
 *    in k_lifo_get(), for example, of the race condition that
 *    occurs if this requirement is not met.
 *
 * -# After waking up from the low-power mode, the interrupt lockout state
 *    must be restored as indicated in the 'key' input parameter.
 *
 * @see k_cpu_atomic_idle()
 *
 * @param key Lockout key returned by previous invocation of arch_irq_lock()
 *//**
 * @brief Power save idle routine
 *
 * This function will be called by the kernel idle loop or possibly within
 * an implementation of z_pm_save_idle in the kernel when the
 * '_pm_save_flag' variable is non-zero.
 *
 * Architectures that do not implement power management instructions may
 * immediately return, otherwise a power-saving instruction should be
 * issued to wait for an interrupt.
 *
 * @note The function is expected to return after the interrupt that has
 * caused the CPU to exit power-saving mode has been serviced, although
 * this is not a firm requirement.
 *
 * @see k_cpu_idle()
 *//**
 * @addtogroup arch-pm
 * @{
 *//**
 * @def ARCH_KERNEL_STACK_OBJ_ALIGN
 * @brief Required alignment of the lowest address of a kernel-only stack.
 *//**
 * @def ARCH_KERNEL_STACK_RESERVED
 * @brief MPU guard size for kernel-only stacks
 *
 * If MPU stack guards are used to catch stack overflows, specify the
 * amount of space reserved in kernel stack objects. If guard sizes are
 * context dependent, this should be in the minimum guard size, with
 * remaining space carved out if needed.
 *
 * Optional definition, defaults to 0.
 *
 * @see K_KERNEL_STACK_RESERVED
 *//**
 * @def ARCH_THREAD_STACK_SIZE_ADJUST(size)
 * @brief Round up a stack buffer size to alignment constraints
 *
 * Adjust a requested stack buffer size to the true size of its underlying
 * buffer, defined as the area usable for thread stack context and thread-
 * local storage.
 *
 * The size value passed here does not include storage reserved for platform
 * data.
 *
 * The returned value is either the same size provided (if already properly
 * aligned), or rounded up to satisfy alignment constraints.  Calculations
 * performed here *must* be idempotent.
 *
 * Optional definition. If undefined, stack buffer sizes are either:
 * - Rounded up to the next power of two if user mode is enabled on an arch
 *   with an MPU that requires such alignment
 * - Rounded up to ARCH_STACK_PTR_ALIGN
 *
 * @see Z_THREAD_STACK_SIZE_ADJUST
 *//**
 * @def ARCH_THREAD_STACK_OBJ_ALIGN(size)
 *
 * Required alignment of the lowest address of a stack object.
 *
 * Optional definition.
 *
 * @see Z_THREAD_STACK_OBJ_ALIGN
 *//**
 * @def ARCH_STACK_PTR_ALIGN
 *
 * Required alignment of the CPU's stack pointer register value, dictated by
 * hardware constraints and the ABI calling convention.
 *
 * @see Z_STACK_PTR_ALIGN
 *//**
 * @def ARCH_THREAD_STACK_RESERVED
 *
 * @see K_THREAD_STACK_RESERVED
 *//**
 * @addtogroup arch-threads
 * @{
 *//**
 * As for arch_k_cycle_get_32(), but with a 64 bit return value.  Not
 * all timer hardware has a 64 bit timer, this needs to be implemented
 * only if CONFIG_TIMER_HAS_64BIT_CYCLE_COUNTER is set.
 *
 * @see arch_k_cycle_get_32()
 *
 * @return The current cycle time.  This should count up monotonically
 * through the full 64 bit space, wrapping at 2^64-1.  Hardware with
 * fewer bits of precision in the timer is generally not expected to
 * implement this API.
 *//**
 * Obtain the current cycle count, in units specified by
 * CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC.  While this is historically
 * specified as part of the architecture API, in practice virtually
 * all platforms forward it to the sys_clock_cycle_get_32() API
 * provided by the timer driver.
 *
 * @see k_cycle_get_32()
 *
 * @return The current cycle time.  This should count up monotonically
 * through the full 32 bit space, wrapping at 0xffffffff.  Hardware
 * with fewer bits of precision in the timer is expected to synthesize
 * a 32 bit count.
 *//**
 * @defgroup arch-timing Architecture timing APIs
 * @ingroup arch-interface
 * @{
 *//* NOTE: We cannot pull in kernel.h here, need some forward declarations  *//**
 * @defgroup arch-interface Architecture Interface
 * @ingroup internal_api
 * @brief Internal kernel APIs with public scope
 *
 * Any public kernel APIs that are implemented as inline functions and need to
 * call architecture-specific API so will have the prototypes for the
 * architecture-specific APIs here. Architecture APIs that aren't used in this
 * way go in kernel/include/kernel_arch_interface.h.
 *
 * The set of architecture-specific APIs used internally by public macros and
 * inline functions in public headers are also specified and documented.
 *
 * For all macros and inline function prototypes described herein, <arch/cpu.h>
 * must eventually pull in full definitions for all of them (the actual macro
 * defines and inline function bodies)
 *
 * include/kernel.h and other public headers depend on definitions in this
 * header.
 *//*
 * Copyright (c) 2019 Intel Corporation.
 *
 * SPDX-License-Identifier: Apache-2.0
 */cpu_numszDT_COMPAT_intel_e1000_BUS_pcieDT_COMPAT_kvaser_pcican_BUS_pcieDT_FOREACH_OKAY_INST_VARGS_zephyr_ieee802154_uart_pipe(fn,__VA_ARGS__...)fn(0, __VA_ARGS__)DT_FOREACH_OKAY_INST_zephyr_ieee802154_uart_pipe(fn)fn(0)DT_FOREACH_OKAY_VARGS_zephyr_ieee802154_uart_pipe(fn,__VA_ARGS__...)fn(DT_N_S_ieee802154, __VA_ARGS__)DT_FOREACH_OKAY_zephyr_ieee802154_uart_pipe(fn)fn(DT_N_S_ieee802154)DT_FOREACH_OKAY_INST_VARGS_zephyr_sim_eeprom(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_zephyr_sim_eeprom(fn)DT_FOREACH_OKAY_VARGS_zephyr_sim_eeprom(fn,__VA_ARGS__...)fn(DT_N_S_eeprom0, __VA_ARGS__)DT_FOREACH_OKAY_zephyr_sim_eeprom(fn)fn(DT_N_S_eeprom0)DT_FOREACH_OKAY_INST_VARGS_zephyr_emu_eeprom(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_zephyr_emu_eeprom(fn)DT_FOREACH_OKAY_VARGS_zephyr_emu_eeprom(fn,__VA_ARGS__...)fn(DT_N_S_eeprom1, __VA_ARGS__)DT_FOREACH_OKAY_zephyr_emu_eeprom(fn)fn(DT_N_S_eeprom1)DT_FOREACH_OKAY_INST_VARGS_fixed_partitions(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_fixed_partitions(fn)DT_FOREACH_OKAY_VARGS_fixed_partitions(fn,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions, __VA_ARGS__)DT_FOREACH_OKAY_fixed_partitions(fn)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions)DT_FOREACH_OKAY_INST_VARGS_zephyr_sim_flash(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_zephyr_sim_flash(fn)DT_FOREACH_OKAY_VARGS_zephyr_sim_flash(fn,__VA_ARGS__...)fn(DT_N_S_sim_flash, __VA_ARGS__)DT_FOREACH_OKAY_zephyr_sim_flash(fn)fn(DT_N_S_sim_flash)DT_FOREACH_OKAY_INST_VARGS_intel_e1000(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_intel_e1000(fn)DT_FOREACH_OKAY_VARGS_intel_e1000(fn,__VA_ARGS__...)fn(DT_N_S_pcie0_S_eth0, __VA_ARGS__)DT_FOREACH_OKAY_intel_e1000(fn)fn(DT_N_S_pcie0_S_eth0)DT_FOREACH_OKAY_INST_VARGS_kvaser_pcican(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_kvaser_pcican(fn)DT_FOREACH_OKAY_VARGS_kvaser_pcican(fn,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0, __VA_ARGS__)DT_FOREACH_OKAY_kvaser_pcican(fn)fn(DT_N_S_pcie0_S_can0)DT_FOREACH_OKAY_INST_VARGS_intel_pcie(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_intel_pcie(fn)DT_FOREACH_OKAY_VARGS_intel_pcie(fn,__VA_ARGS__...)fn(DT_N_S_pcie0, __VA_ARGS__)DT_FOREACH_OKAY_intel_pcie(fn)fn(DT_N_S_pcie0)DT_FOREACH_OKAY_INST_VARGS_soc_nv_flash(fn,__VA_ARGS__...)fn(0, __VA_ARGS__) fn(1, __VA_ARGS__)DT_FOREACH_OKAY_INST_soc_nv_flash(fn)fn(0) fn(1)DT_FOREACH_OKAY_VARGS_soc_nv_flash(fn,__VA_ARGS__...)fn(DT_N_S_flash_500000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0, __VA_ARGS__)DT_FOREACH_OKAY_soc_nv_flash(fn)fn(DT_N_S_flash_500000) fn(DT_N_S_sim_flash_S_flash_sim_0)DT_FOREACH_OKAY_INST_VARGS_motorola_mc146818(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_motorola_mc146818(fn)DT_FOREACH_OKAY_VARGS_motorola_mc146818(fn,__VA_ARGS__...)fn(DT_N_S_soc_S_rtc_70, __VA_ARGS__)DT_FOREACH_OKAY_motorola_mc146818(fn)fn(DT_N_S_soc_S_rtc_70)DT_FOREACH_OKAY_INST_VARGS_intel_hpet(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_intel_hpet(fn)DT_FOREACH_OKAY_VARGS_intel_hpet(fn,__VA_ARGS__...)fn(DT_N_S_soc_S_hpet_fed00000, __VA_ARGS__)DT_FOREACH_OKAY_intel_hpet(fn)fn(DT_N_S_soc_S_hpet_fed00000)DT_FOREACH_OKAY_INST_VARGS_ns16550(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_ns16550(fn)DT_FOREACH_OKAY_VARGS_ns16550(fn,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_3f8, __VA_ARGS__) fn(DT_N_S_soc_S_uart_2f8, __VA_ARGS__)DT_FOREACH_OKAY_ns16550(fn)fn(DT_N_S_soc_S_uart_3f8) fn(DT_N_S_soc_S_uart_2f8)DT_FOREACH_OKAY_INST_VARGS_simple_bus(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_simple_bus(fn)DT_FOREACH_OKAY_VARGS_simple_bus(fn,__VA_ARGS__...)fn(DT_N_S_soc, __VA_ARGS__)DT_FOREACH_OKAY_simple_bus(fn)fn(DT_N_S_soc)DT_FOREACH_OKAY_INST_VARGS_intel_loapic(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_intel_loapic(fn)DT_FOREACH_OKAY_VARGS_intel_loapic(fn,__VA_ARGS__...)fn(DT_N_S_loapic_fee00000, __VA_ARGS__)DT_FOREACH_OKAY_intel_loapic(fn)fn(DT_N_S_loapic_fee00000)DT_FOREACH_OKAY_INST_VARGS_intel_ioapic(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_intel_ioapic(fn)DT_FOREACH_OKAY_VARGS_intel_ioapic(fn,__VA_ARGS__...)fn(DT_N_S_ioapic_fec00000, __VA_ARGS__)DT_FOREACH_OKAY_intel_ioapic(fn)fn(DT_N_S_ioapic_fec00000)DT_FOREACH_OKAY_INST_VARGS_intel_x86(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_intel_x86(fn)DT_FOREACH_OKAY_VARGS_intel_x86(fn,__VA_ARGS__...)fn(DT_N_S_cpus_S_cpu_0, __VA_ARGS__)DT_FOREACH_OKAY_intel_x86(fn)fn(DT_N_S_cpus_S_cpu_0)DT_FOREACH_OKAY_INST_VARGS_qemu_x86_emulator(fn,__VA_ARGS__...)DT_FOREACH_OKAY_INST_qemu_x86_emulator(fn)DT_FOREACH_OKAY_VARGS_qemu_x86_emulator(fn,__VA_ARGS__...)fn(DT_N, __VA_ARGS__)DT_FOREACH_OKAY_qemu_x86_emulator(fn)fn(DT_N)DT_N_INST_zephyr_ieee802154_uart_pipe_NUM_OKAYDT_N_INST_zephyr_sim_eeprom_NUM_OKAYDT_N_INST_zephyr_emu_eeprom_NUM_OKAYDT_N_INST_fixed_partitions_NUM_OKAYDT_N_INST_zephyr_sim_flash_NUM_OKAYDT_N_INST_intel_e1000_NUM_OKAYDT_N_INST_kvaser_pcican_NUM_OKAYDT_N_INST_intel_pcie_NUM_OKAYDT_N_INST_soc_nv_flash_NUM_OKAYDT_N_INST_motorola_mc146818_NUM_OKAYDT_N_INST_intel_hpet_NUM_OKAYDT_N_INST_ns16550_NUM_OKAYDT_N_INST_simple_bus_NUM_OKAYDT_N_INST_intel_loapic_NUM_OKAYDT_N_INST_intel_ioapic_NUM_OKAYDT_N_INST_intel_x86_NUM_OKAYDT_N_INST_qemu_x86_emulator_NUM_OKAYDT_COMPAT_HAS_OKAY_zephyr_ieee802154_uart_pipeDT_COMPAT_HAS_OKAY_zephyr_sim_eepromDT_COMPAT_HAS_OKAY_zephyr_emu_eepromDT_COMPAT_HAS_OKAY_fixed_partitionsDT_COMPAT_HAS_OKAY_zephyr_sim_flashDT_COMPAT_HAS_OKAY_intel_e1000DT_COMPAT_HAS_OKAY_kvaser_pcicanDT_COMPAT_HAS_OKAY_intel_pcieDT_COMPAT_HAS_OKAY_soc_nv_flashDT_COMPAT_HAS_OKAY_motorola_mc146818DT_COMPAT_HAS_OKAY_intel_hpetDT_COMPAT_HAS_OKAY_ns16550DT_COMPAT_HAS_OKAY_simple_busDT_COMPAT_HAS_OKAY_intel_loapicDT_COMPAT_HAS_OKAY_intel_ioapicDT_COMPAT_HAS_OKAY_intel_x86DT_COMPAT_HAS_OKAY_qemu_x86_emulatorDT_COMPAT_fixed_partitions_LABEL_eeprom_emu_EXISTSDT_COMPAT_fixed_partitions_LABEL_eeprom_emuDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000DT_COMPAT_fixed_partitions_LABEL_image_1_EXISTSDT_COMPAT_fixed_partitions_LABEL_image_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000DT_COMPAT_fixed_partitions_LABEL_image_0_EXISTSDT_COMPAT_fixed_partitions_LABEL_image_0DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000DT_COMPAT_fixed_partitions_LABEL_storage_EXISTSDT_COMPAT_fixed_partitions_LABEL_storageDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000DT_FOREACH_OKAY_VARGS_HELPER(fn,__VA_ARGS__...)fn(DT_N, __VA_ARGS__) fn(DT_N_S_chosen, __VA_ARGS__) fn(DT_N_S_aliases, __VA_ARGS__) fn(DT_N_S_cpus, __VA_ARGS__) fn(DT_N_S_cpus_S_cpu_0, __VA_ARGS__) fn(DT_N_S_ioapic_fec00000, __VA_ARGS__) fn(DT_N_S_loapic_fee00000, __VA_ARGS__) fn(DT_N_S_memory_0, __VA_ARGS__) fn(DT_N_S_soc, __VA_ARGS__) fn(DT_N_S_soc_S_uart_3f8, __VA_ARGS__) fn(DT_N_S_soc_S_uart_2f8, __VA_ARGS__) fn(DT_N_S_soc_S_hpet_fed00000, __VA_ARGS__) fn(DT_N_S_soc_S_rtc_70, __VA_ARGS__) fn(DT_N_S_flash_500000, __VA_ARGS__) fn(DT_N_S_pcie0, __VA_ARGS__) fn(DT_N_S_pcie0_S_can0, __VA_ARGS__) fn(DT_N_S_pcie0_S_can0_S_can_transceiver, __VA_ARGS__) fn(DT_N_S_pcie0_S_eth0, __VA_ARGS__) fn(DT_N_S_sim_flash, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000, __VA_ARGS__) fn(DT_N_S_eeprom1, __VA_ARGS__) fn(DT_N_S_eeprom0, __VA_ARGS__) fn(DT_N_S_ieee802154, __VA_ARGS__)DT_FOREACH_VARGS_HELPER(fn,__VA_ARGS__...)DT_FOREACH_OKAY_HELPER(fn)fn(DT_N) fn(DT_N_S_chosen) fn(DT_N_S_aliases) fn(DT_N_S_cpus) fn(DT_N_S_cpus_S_cpu_0) fn(DT_N_S_ioapic_fec00000) fn(DT_N_S_loapic_fee00000) fn(DT_N_S_memory_0) fn(DT_N_S_soc) fn(DT_N_S_soc_S_uart_3f8) fn(DT_N_S_soc_S_uart_2f8) fn(DT_N_S_soc_S_hpet_fed00000) fn(DT_N_S_soc_S_rtc_70) fn(DT_N_S_flash_500000) fn(DT_N_S_pcie0) fn(DT_N_S_pcie0_S_can0) fn(DT_N_S_pcie0_S_can0_S_can_transceiver) fn(DT_N_S_pcie0_S_eth0) fn(DT_N_S_sim_flash) fn(DT_N_S_sim_flash_S_flash_sim_0) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000) fn(DT_N_S_eeprom1) fn(DT_N_S_eeprom0) fn(DT_N_S_ieee802154)DT_FOREACH_HELPER(fn)DT_CHOSEN_zephyr_canbus_EXISTSDT_CHOSEN_zephyr_canbusDT_N_S_pcie0_S_can0DT_CHOSEN_zephyr_ieee802154_EXISTSDT_CHOSEN_zephyr_ieee802154DT_N_S_ieee802154DT_CHOSEN_zephyr_flash_controller_EXISTSDT_CHOSEN_zephyr_flash_controllerDT_N_S_sim_flashDT_CHOSEN_zephyr_code_partition_EXISTSDT_CHOSEN_zephyr_code_partitionDT_CHOSEN_zephyr_bt_mon_uart_EXISTSDT_CHOSEN_zephyr_bt_mon_uartDT_N_S_soc_S_uart_2f8DT_CHOSEN_zephyr_uart_pipe_EXISTSDT_CHOSEN_zephyr_uart_pipeDT_CHOSEN_zephyr_bt_uart_EXISTSDT_CHOSEN_zephyr_bt_uartDT_CHOSEN_zephyr_shell_uart_EXISTSDT_CHOSEN_zephyr_shell_uartDT_CHOSEN_zephyr_console_EXISTSDT_CHOSEN_zephyr_consoleDT_CHOSEN_zephyr_flash_EXISTSDT_CHOSEN_zephyr_flashDT_N_S_flash_500000DT_CHOSEN_zephyr_sram_EXISTSDT_CHOSEN_zephyr_sramDT_N_S_soc_S_uart_3f8_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_soc_S_uart_3f8_P_zephyr_pm_device_runtime_autoDT_N_S_soc_S_uart_3f8_P_wakeup_source_EXISTSDT_N_S_soc_S_uart_3f8_P_wakeup_sourceDT_N_S_soc_S_uart_3f8_P_interrupt_parent_EXISTSDT_N_S_soc_S_uart_3f8_P_interrupt_parent_LENDT_N_S_soc_S_uart_3f8_P_interrupt_parent_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_3f8, interrupt_parent, 0, __VA_ARGS__)DT_N_S_soc_S_uart_3f8_P_interrupt_parent_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_P_interrupt_parent_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_uart_3f8, interrupt_parent, 0)DT_N_S_soc_S_uart_3f8_P_interrupt_parent_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_uart_3f8_P_interrupt_parent_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_P_interrupt_parent_IDX_0_PHDT_N_S_ioapic_fec00000DT_N_S_soc_S_uart_3f8_P_interrupt_parent_IDX_0DT_N_S_soc_S_uart_3f8_P_interrupt_parentDT_N_S_soc_S_uart_3f8_P_interrupts_EXISTSDT_N_S_soc_S_uart_3f8_P_interrupts_IDX_2_EXISTSDT_N_S_soc_S_uart_3f8_P_interrupts_IDX_2DT_N_S_soc_S_uart_3f8_P_interrupts_IDX_1_EXISTSDT_N_S_soc_S_uart_3f8_P_interrupts_IDX_1DT_N_S_soc_S_uart_3f8_P_interrupts_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_P_interrupts_IDX_0DT_N_S_soc_S_uart_3f8_P_interrupts{4 , 256 , 3 }DT_N_S_soc_S_uart_3f8_P_reg_EXISTSDT_N_S_soc_S_uart_3f8_P_reg_IDX_1_EXISTSDT_N_S_soc_S_uart_3f8_P_reg_IDX_1DT_N_S_soc_S_uart_3f8_P_reg_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_P_reg_IDX_0DT_N_S_soc_S_uart_3f8_P_reg{1016 , 256 }DT_N_S_soc_S_uart_3f8_P_compatible_EXISTSDT_N_S_soc_S_uart_3f8_P_compatible_LENDT_N_S_soc_S_uart_3f8_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_3f8, compatible, 0, __VA_ARGS__)DT_N_S_soc_S_uart_3f8_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_uart_3f8, compatible, 0)DT_N_S_soc_S_uart_3f8_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_uart_3f8_P_compatible_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_P_compatible_IDX_0_STRING_UPPER_TOKENNS16550DT_N_S_soc_S_uart_3f8_P_compatible_IDX_0_STRING_TOKENns16550DT_N_S_soc_S_uart_3f8_P_compatible_IDX_0_STRING_UNQUOTEDDT_N_S_soc_S_uart_3f8_P_compatible_IDX_0"ns16550"DT_N_S_soc_S_uart_3f8_P_compatible{"ns16550"}DT_N_S_soc_S_uart_3f8_P_status_EXISTSDT_N_S_soc_S_uart_3f8_P_status_LENDT_N_S_soc_S_uart_3f8_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_3f8, status, 0, __VA_ARGS__)DT_N_S_soc_S_uart_3f8_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_uart_3f8, status, 0)DT_N_S_soc_S_uart_3f8_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_uart_3f8_P_status_ENUM_UPPER_TOKENOKAYDT_N_S_soc_S_uart_3f8_P_status_ENUM_TOKENDT_N_S_soc_S_uart_3f8_P_status_ENUM_VAL_okay_EXISTSDT_N_S_soc_S_uart_3f8_P_status_ENUM_IDXDT_N_S_soc_S_uart_3f8_P_status_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_P_status_IDX_0"okay"DT_N_S_soc_S_uart_3f8_P_status_STRING_UPPER_TOKENDT_N_S_soc_S_uart_3f8_P_status_STRING_TOKENDT_N_S_soc_S_uart_3f8_P_status_STRING_UNQUOTEDDT_N_S_soc_S_uart_3f8_P_statusDT_N_S_soc_S_uart_3f8_P_hw_flow_control_EXISTSDT_N_S_soc_S_uart_3f8_P_hw_flow_controlDT_N_S_soc_S_uart_3f8_P_current_speed_EXISTSDT_N_S_soc_S_uart_3f8_P_current_speed115200DT_N_S_soc_S_uart_3f8_P_clock_frequency_EXISTSDT_N_S_soc_S_uart_3f8_P_clock_frequency1843200DT_N_S_soc_S_uart_3f8_P_io_mapped_EXISTSDT_N_S_soc_S_uart_3f8_P_io_mappedDT_N_S_soc_S_uart_3f8_P_reg_shift_EXISTSDT_N_S_soc_S_uart_3f8_P_reg_shiftDT_N_S_soc_S_uart_3f8_PINCTRL_NUMDT_N_S_soc_S_uart_3f8_STATUS_okayDT_N_S_soc_S_uart_3f8_COMPAT_MATCHES_ns16550DT_N_S_soc_S_uart_3f8_IRQ_IDX_0_VAL_priority_EXISTSDT_N_S_soc_S_uart_3f8_IRQ_IDX_0_VAL_priorityDT_N_S_soc_S_uart_3f8_IRQ_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_IRQ_IDX_0_VAL_sense_EXISTSDT_N_S_soc_S_uart_3f8_IRQ_IDX_0_VAL_senseDT_N_S_soc_S_uart_3f8_IRQ_IDX_0_VAL_irq_EXISTSDT_N_S_soc_S_uart_3f8_IRQ_IDX_0_VAL_irqDT_N_S_soc_S_uart_3f8_IRQ_NUMDT_N_S_soc_S_uart_3f8_FOREACH_RANGE(fn)DT_N_S_soc_S_uart_3f8_RANGES_NUMDT_N_S_soc_S_uart_3f8_REG_IDX_0_VAL_SIZEDT_N_S_soc_S_uart_3f8_REG_IDX_0_VAL_ADDRESSDT_N_S_soc_S_uart_3f8_REG_IDX_0_EXISTSDT_N_S_soc_S_uart_3f8_REG_NUMDT_N_NODELABEL_uart0DT_N_INST_0_ns16550DT_N_ALIAS_uart_0DT_N_S_soc_S_uart_3f8_EXISTSDT_N_S_soc_S_uart_3f8_SUPPORTS_ORDSDT_N_S_soc_S_uart_3f8_REQUIRES_ORDS15, 23,DT_N_S_soc_S_uart_3f8_ORD_STR_SORTABLE00027DT_N_S_soc_S_uart_3f8_ORDDT_N_S_soc_S_uart_3f8_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD_SEP(fn,sep)DT_N_S_soc_S_uart_3f8_FOREACH_CHILD(fn)DT_N_S_soc_S_uart_3f8_CHILD_IDXDT_N_S_soc_S_uart_3f8_PARENTDT_N_S_socDT_N_S_soc_S_uart_3f8_FULL_NAME"uart@3f8"DT_N_S_soc_S_uart_3f8_PATH"/soc/uart@3f8"DT_N_S_soc_S_uart_2f8_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_soc_S_uart_2f8_P_zephyr_pm_device_runtime_autoDT_N_S_soc_S_uart_2f8_P_wakeup_source_EXISTSDT_N_S_soc_S_uart_2f8_P_wakeup_sourceDT_N_S_soc_S_uart_2f8_P_interrupt_parent_EXISTSDT_N_S_soc_S_uart_2f8_P_interrupt_parent_LENDT_N_S_soc_S_uart_2f8_P_interrupt_parent_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_2f8, interrupt_parent, 0, __VA_ARGS__)DT_N_S_soc_S_uart_2f8_P_interrupt_parent_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_P_interrupt_parent_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_uart_2f8, interrupt_parent, 0)DT_N_S_soc_S_uart_2f8_P_interrupt_parent_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_uart_2f8_P_interrupt_parent_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_P_interrupt_parent_IDX_0_PHDT_N_S_soc_S_uart_2f8_P_interrupt_parent_IDX_0DT_N_S_soc_S_uart_2f8_P_interrupt_parentDT_N_S_soc_S_uart_2f8_P_interrupts_EXISTSDT_N_S_soc_S_uart_2f8_P_interrupts_IDX_2_EXISTSDT_N_S_soc_S_uart_2f8_P_interrupts_IDX_2DT_N_S_soc_S_uart_2f8_P_interrupts_IDX_1_EXISTSDT_N_S_soc_S_uart_2f8_P_interrupts_IDX_1DT_N_S_soc_S_uart_2f8_P_interrupts_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_P_interrupts_IDX_0DT_N_S_soc_S_uart_2f8_P_interrupts{3 , 256 , 3 }DT_N_S_soc_S_uart_2f8_P_reg_EXISTSDT_N_S_soc_S_uart_2f8_P_reg_IDX_1_EXISTSDT_N_S_soc_S_uart_2f8_P_reg_IDX_1DT_N_S_soc_S_uart_2f8_P_reg_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_P_reg_IDX_0DT_N_S_soc_S_uart_2f8_P_reg{760 , 256 }DT_N_S_soc_S_uart_2f8_P_compatible_EXISTSDT_N_S_soc_S_uart_2f8_P_compatible_LENDT_N_S_soc_S_uart_2f8_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_2f8, compatible, 0, __VA_ARGS__)DT_N_S_soc_S_uart_2f8_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_uart_2f8, compatible, 0)DT_N_S_soc_S_uart_2f8_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_uart_2f8_P_compatible_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_P_compatible_IDX_0_STRING_UPPER_TOKENDT_N_S_soc_S_uart_2f8_P_compatible_IDX_0_STRING_TOKENDT_N_S_soc_S_uart_2f8_P_compatible_IDX_0_STRING_UNQUOTEDDT_N_S_soc_S_uart_2f8_P_compatible_IDX_0DT_N_S_soc_S_uart_2f8_P_compatibleDT_N_S_soc_S_uart_2f8_P_status_EXISTSDT_N_S_soc_S_uart_2f8_P_status_LENDT_N_S_soc_S_uart_2f8_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_2f8, status, 0, __VA_ARGS__)DT_N_S_soc_S_uart_2f8_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_uart_2f8, status, 0)DT_N_S_soc_S_uart_2f8_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_uart_2f8_P_status_ENUM_UPPER_TOKENDT_N_S_soc_S_uart_2f8_P_status_ENUM_TOKENDT_N_S_soc_S_uart_2f8_P_status_ENUM_VAL_okay_EXISTSDT_N_S_soc_S_uart_2f8_P_status_ENUM_IDXDT_N_S_soc_S_uart_2f8_P_status_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_P_status_IDX_0DT_N_S_soc_S_uart_2f8_P_status_STRING_UPPER_TOKENDT_N_S_soc_S_uart_2f8_P_status_STRING_TOKENDT_N_S_soc_S_uart_2f8_P_status_STRING_UNQUOTEDDT_N_S_soc_S_uart_2f8_P_statusDT_N_S_soc_S_uart_2f8_P_hw_flow_control_EXISTSDT_N_S_soc_S_uart_2f8_P_hw_flow_controlDT_N_S_soc_S_uart_2f8_P_current_speed_EXISTSDT_N_S_soc_S_uart_2f8_P_current_speedDT_N_S_soc_S_uart_2f8_P_clock_frequency_EXISTSDT_N_S_soc_S_uart_2f8_P_clock_frequencyDT_N_S_soc_S_uart_2f8_P_io_mapped_EXISTSDT_N_S_soc_S_uart_2f8_P_io_mappedDT_N_S_soc_S_uart_2f8_P_reg_shift_EXISTSDT_N_S_soc_S_uart_2f8_P_reg_shiftDT_N_S_soc_S_uart_2f8_PINCTRL_NUMDT_N_S_soc_S_uart_2f8_STATUS_okayDT_N_S_soc_S_uart_2f8_COMPAT_MATCHES_ns16550DT_N_S_soc_S_uart_2f8_IRQ_IDX_0_VAL_priority_EXISTSDT_N_S_soc_S_uart_2f8_IRQ_IDX_0_VAL_priorityDT_N_S_soc_S_uart_2f8_IRQ_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_IRQ_IDX_0_VAL_sense_EXISTSDT_N_S_soc_S_uart_2f8_IRQ_IDX_0_VAL_senseDT_N_S_soc_S_uart_2f8_IRQ_IDX_0_VAL_irq_EXISTSDT_N_S_soc_S_uart_2f8_IRQ_IDX_0_VAL_irqDT_N_S_soc_S_uart_2f8_IRQ_NUMDT_N_S_soc_S_uart_2f8_FOREACH_RANGE(fn)DT_N_S_soc_S_uart_2f8_RANGES_NUMDT_N_S_soc_S_uart_2f8_REG_IDX_0_VAL_SIZEDT_N_S_soc_S_uart_2f8_REG_IDX_0_VAL_ADDRESSDT_N_S_soc_S_uart_2f8_REG_IDX_0_EXISTSDT_N_S_soc_S_uart_2f8_REG_NUMDT_N_NODELABEL_uart1DT_N_INST_1_ns16550DT_N_ALIAS_uart_1DT_N_S_soc_S_uart_2f8_EXISTSDT_N_S_soc_S_uart_2f8_SUPPORTS_ORDSDT_N_S_soc_S_uart_2f8_REQUIRES_ORDSDT_N_S_soc_S_uart_2f8_ORD_STR_SORTABLE00026DT_N_S_soc_S_uart_2f8_ORDDT_N_S_soc_S_uart_2f8_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD_SEP(fn,sep)DT_N_S_soc_S_uart_2f8_FOREACH_CHILD(fn)DT_N_S_soc_S_uart_2f8_CHILD_IDXDT_N_S_soc_S_uart_2f8_PARENTDT_N_S_soc_S_uart_2f8_FULL_NAME"uart@2f8"DT_N_S_soc_S_uart_2f8_PATH"/soc/uart@2f8"DT_N_S_soc_S_rtc_70_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_soc_S_rtc_70_P_zephyr_pm_device_runtime_autoDT_N_S_soc_S_rtc_70_P_wakeup_source_EXISTSDT_N_S_soc_S_rtc_70_P_wakeup_sourceDT_N_S_soc_S_rtc_70_P_interrupt_parent_EXISTSDT_N_S_soc_S_rtc_70_P_interrupt_parent_LENDT_N_S_soc_S_rtc_70_P_interrupt_parent_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_rtc_70, interrupt_parent, 0, __VA_ARGS__)DT_N_S_soc_S_rtc_70_P_interrupt_parent_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_P_interrupt_parent_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_rtc_70, interrupt_parent, 0)DT_N_S_soc_S_rtc_70_P_interrupt_parent_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_rtc_70_P_interrupt_parent_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_P_interrupt_parent_IDX_0_PHDT_N_S_soc_S_rtc_70_P_interrupt_parent_IDX_0DT_N_S_soc_S_rtc_70_P_interrupt_parentDT_N_S_soc_S_rtc_70_P_interrupts_EXISTSDT_N_S_soc_S_rtc_70_P_interrupts_IDX_2_EXISTSDT_N_S_soc_S_rtc_70_P_interrupts_IDX_2DT_N_S_soc_S_rtc_70_P_interrupts_IDX_1_EXISTSDT_N_S_soc_S_rtc_70_P_interrupts_IDX_1DT_N_S_soc_S_rtc_70_P_interrupts_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_P_interrupts_IDX_0DT_N_S_soc_S_rtc_70_P_interrupts{8 , 256 , 3 }DT_N_S_soc_S_rtc_70_P_reg_EXISTSDT_N_S_soc_S_rtc_70_P_reg_IDX_3_EXISTSDT_N_S_soc_S_rtc_70_P_reg_IDX_3DT_N_S_soc_S_rtc_70_P_reg_IDX_2_EXISTSDT_N_S_soc_S_rtc_70_P_reg_IDX_2DT_N_S_soc_S_rtc_70_P_reg_IDX_1_EXISTSDT_N_S_soc_S_rtc_70_P_reg_IDX_1DT_N_S_soc_S_rtc_70_P_reg_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_P_reg_IDX_0DT_N_S_soc_S_rtc_70_P_reg{112 , 13 , 113 , 13 }DT_N_S_soc_S_rtc_70_P_compatible_EXISTSDT_N_S_soc_S_rtc_70_P_compatible_LENDT_N_S_soc_S_rtc_70_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_rtc_70, compatible, 0, __VA_ARGS__)DT_N_S_soc_S_rtc_70_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_rtc_70, compatible, 0)DT_N_S_soc_S_rtc_70_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_rtc_70_P_compatible_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_P_compatible_IDX_0_STRING_UPPER_TOKENMOTOROLA_MC146818DT_N_S_soc_S_rtc_70_P_compatible_IDX_0_STRING_TOKENmotorola_mc146818DT_N_S_soc_S_rtc_70_P_compatible_IDX_0_STRING_UNQUOTEDmotorola,mc146818DT_N_S_soc_S_rtc_70_P_compatible_IDX_0"motorola,mc146818"DT_N_S_soc_S_rtc_70_P_compatible{"motorola,mc146818"}DT_N_S_soc_S_rtc_70_P_status_EXISTSDT_N_S_soc_S_rtc_70_P_status_LENDT_N_S_soc_S_rtc_70_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_rtc_70, status, 0, __VA_ARGS__)DT_N_S_soc_S_rtc_70_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_rtc_70, status, 0)DT_N_S_soc_S_rtc_70_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_rtc_70_P_status_ENUM_UPPER_TOKENDT_N_S_soc_S_rtc_70_P_status_ENUM_TOKENDT_N_S_soc_S_rtc_70_P_status_ENUM_VAL_okay_EXISTSDT_N_S_soc_S_rtc_70_P_status_ENUM_IDXDT_N_S_soc_S_rtc_70_P_status_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_P_status_IDX_0DT_N_S_soc_S_rtc_70_P_status_STRING_UPPER_TOKENDT_N_S_soc_S_rtc_70_P_status_STRING_TOKENDT_N_S_soc_S_rtc_70_P_status_STRING_UNQUOTEDDT_N_S_soc_S_rtc_70_P_statusDT_N_S_soc_S_rtc_70_P_alarms_count_EXISTSDT_N_S_soc_S_rtc_70_P_alarms_countDT_N_S_soc_S_rtc_70_P_clock_frequency_EXISTSDT_N_S_soc_S_rtc_70_P_clock_frequency_ENUM_VAL_32768_EXISTSDT_N_S_soc_S_rtc_70_P_clock_frequency_ENUM_IDXDT_N_S_soc_S_rtc_70_P_clock_frequencyDT_N_S_soc_S_rtc_70_PINCTRL_NUMDT_N_S_soc_S_rtc_70_STATUS_okayDT_N_S_soc_S_rtc_70_COMPAT_MODEL_IDX_0"mc146818"DT_N_S_soc_S_rtc_70_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_COMPAT_VENDOR_IDX_0"Motorola, Inc."DT_N_S_soc_S_rtc_70_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_COMPAT_MATCHES_motorola_mc146818DT_N_S_soc_S_rtc_70_IRQ_IDX_0_VAL_priority_EXISTSDT_N_S_soc_S_rtc_70_IRQ_IDX_0_VAL_priorityDT_N_S_soc_S_rtc_70_IRQ_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_IRQ_IDX_0_VAL_sense_EXISTSDT_N_S_soc_S_rtc_70_IRQ_IDX_0_VAL_senseDT_N_S_soc_S_rtc_70_IRQ_IDX_0_VAL_irq_EXISTSDT_N_S_soc_S_rtc_70_IRQ_IDX_0_VAL_irqDT_N_S_soc_S_rtc_70_IRQ_NUMDT_N_S_soc_S_rtc_70_FOREACH_RANGE(fn)DT_N_S_soc_S_rtc_70_RANGES_NUMDT_N_S_soc_S_rtc_70_REG_IDX_1_VAL_SIZEDT_N_S_soc_S_rtc_70_REG_IDX_1_VAL_ADDRESSDT_N_S_soc_S_rtc_70_REG_IDX_1_EXISTSDT_N_S_soc_S_rtc_70_REG_IDX_0_VAL_SIZEDT_N_S_soc_S_rtc_70_REG_IDX_0_VAL_ADDRESSDT_N_S_soc_S_rtc_70_REG_IDX_0_EXISTSDT_N_S_soc_S_rtc_70_REG_NUMDT_N_NODELABEL_counterDT_N_S_soc_S_rtc_70DT_N_NODELABEL_rtcDT_N_INST_0_motorola_mc146818DT_N_ALIAS_rtcDT_N_S_soc_S_rtc_70_EXISTSDT_N_S_soc_S_rtc_70_SUPPORTS_ORDSDT_N_S_soc_S_rtc_70_REQUIRES_ORDSDT_N_S_soc_S_rtc_70_ORD_STR_SORTABLE00025DT_N_S_soc_S_rtc_70_ORDDT_N_S_soc_S_rtc_70_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_soc_S_rtc_70_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_soc_S_rtc_70_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_rtc_70_FOREACH_CHILD_SEP(fn,sep)DT_N_S_soc_S_rtc_70_FOREACH_CHILD(fn)DT_N_S_soc_S_rtc_70_CHILD_IDXDT_N_S_soc_S_rtc_70_PARENTDT_N_S_soc_S_rtc_70_FULL_NAME"rtc@70"DT_N_S_soc_S_rtc_70_PATH"/soc/rtc@70"DT_N_S_soc_S_hpet_fed00000_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_soc_S_hpet_fed00000_P_zephyr_pm_device_runtime_autoDT_N_S_soc_S_hpet_fed00000_P_wakeup_source_EXISTSDT_N_S_soc_S_hpet_fed00000_P_wakeup_sourceDT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_EXISTSDT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_LENDT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_hpet_fed00000, interrupt_parent, 0, __VA_ARGS__)DT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_hpet_fed00000, interrupt_parent, 0)DT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_IDX_0_PHDT_N_S_soc_S_hpet_fed00000_P_interrupt_parent_IDX_0DT_N_S_soc_S_hpet_fed00000_P_interrupt_parentDT_N_S_soc_S_hpet_fed00000_P_compatible_EXISTSDT_N_S_soc_S_hpet_fed00000_P_compatible_LENDT_N_S_soc_S_hpet_fed00000_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_hpet_fed00000, compatible, 0, __VA_ARGS__)DT_N_S_soc_S_hpet_fed00000_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_hpet_fed00000, compatible, 0)DT_N_S_soc_S_hpet_fed00000_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_hpet_fed00000_P_compatible_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_P_compatible_IDX_0_STRING_UPPER_TOKENINTEL_HPETDT_N_S_soc_S_hpet_fed00000_P_compatible_IDX_0_STRING_TOKENintel_hpetDT_N_S_soc_S_hpet_fed00000_P_compatible_IDX_0_STRING_UNQUOTEDintel,hpetDT_N_S_soc_S_hpet_fed00000_P_compatible_IDX_0"intel,hpet"DT_N_S_soc_S_hpet_fed00000_P_compatible{"intel,hpet"}DT_N_S_soc_S_hpet_fed00000_P_status_EXISTSDT_N_S_soc_S_hpet_fed00000_P_status_LENDT_N_S_soc_S_hpet_fed00000_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_hpet_fed00000, status, 0, __VA_ARGS__)DT_N_S_soc_S_hpet_fed00000_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc_S_hpet_fed00000, status, 0)DT_N_S_soc_S_hpet_fed00000_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_soc_S_hpet_fed00000_P_status_ENUM_UPPER_TOKENDT_N_S_soc_S_hpet_fed00000_P_status_ENUM_TOKENDT_N_S_soc_S_hpet_fed00000_P_status_ENUM_VAL_okay_EXISTSDT_N_S_soc_S_hpet_fed00000_P_status_ENUM_IDXDT_N_S_soc_S_hpet_fed00000_P_status_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_P_status_IDX_0DT_N_S_soc_S_hpet_fed00000_P_status_STRING_UPPER_TOKENDT_N_S_soc_S_hpet_fed00000_P_status_STRING_TOKENDT_N_S_soc_S_hpet_fed00000_P_status_STRING_UNQUOTEDDT_N_S_soc_S_hpet_fed00000_P_statusDT_N_S_soc_S_hpet_fed00000_P_no_legacy_irq_EXISTSDT_N_S_soc_S_hpet_fed00000_P_no_legacy_irqDT_N_S_soc_S_hpet_fed00000_P_interrupts_EXISTSDT_N_S_soc_S_hpet_fed00000_P_interrupts_IDX_2_EXISTSDT_N_S_soc_S_hpet_fed00000_P_interrupts_IDX_2DT_N_S_soc_S_hpet_fed00000_P_interrupts_IDX_1_EXISTSDT_N_S_soc_S_hpet_fed00000_P_interrupts_IDX_1DT_N_S_soc_S_hpet_fed00000_P_interrupts_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_P_interrupts_IDX_0DT_N_S_soc_S_hpet_fed00000_P_interrupts{2 , 0 , 4 }DT_N_S_soc_S_hpet_fed00000_P_reg_EXISTSDT_N_S_soc_S_hpet_fed00000_P_reg_IDX_1_EXISTSDT_N_S_soc_S_hpet_fed00000_P_reg_IDX_1DT_N_S_soc_S_hpet_fed00000_P_reg_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_P_reg_IDX_04275044352DT_N_S_soc_S_hpet_fed00000_P_reg{4275044352 , 1024 }DT_N_S_soc_S_hpet_fed00000_PINCTRL_NUMDT_N_S_soc_S_hpet_fed00000_STATUS_okayDT_N_S_soc_S_hpet_fed00000_COMPAT_MODEL_IDX_0"hpet"DT_N_S_soc_S_hpet_fed00000_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_COMPAT_VENDOR_IDX_0"Intel Corporation"DT_N_S_soc_S_hpet_fed00000_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_COMPAT_MATCHES_intel_hpetDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_VAL_priority_EXISTSDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_VAL_priorityDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_VAL_sense_EXISTSDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_VAL_senseDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_VAL_irq_EXISTSDT_N_S_soc_S_hpet_fed00000_IRQ_IDX_0_VAL_irqDT_N_S_soc_S_hpet_fed00000_IRQ_NUMDT_N_S_soc_S_hpet_fed00000_FOREACH_RANGE(fn)DT_N_S_soc_S_hpet_fed00000_RANGES_NUMDT_N_S_soc_S_hpet_fed00000_REG_IDX_0_VAL_SIZEDT_N_S_soc_S_hpet_fed00000_REG_IDX_0_VAL_ADDRESSDT_N_S_soc_S_hpet_fed00000_REG_IDX_0_EXISTSDT_N_S_soc_S_hpet_fed00000_REG_NUMDT_N_NODELABEL_hpetDT_N_S_soc_S_hpet_fed00000DT_N_INST_0_intel_hpetDT_N_S_soc_S_hpet_fed00000_EXISTSDT_N_S_soc_S_hpet_fed00000_SUPPORTS_ORDSDT_N_S_soc_S_hpet_fed00000_REQUIRES_ORDSDT_N_S_soc_S_hpet_fed00000_ORD_STR_SORTABLE00024DT_N_S_soc_S_hpet_fed00000_ORDDT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_soc_S_hpet_fed00000_FOREACH_CHILD(fn)DT_N_S_soc_S_hpet_fed00000_CHILD_IDXDT_N_S_soc_S_hpet_fed00000_PARENTDT_N_S_soc_S_hpet_fed00000_FULL_NAME"hpet@fed00000"DT_N_S_soc_S_hpet_fed00000_PATH"/soc/hpet@fed00000"DT_N_S_soc_P_ranges_EXISTSDT_N_S_soc_P_compatible_EXISTSDT_N_S_soc_P_compatible_LENDT_N_S_soc_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc, compatible, 0, __VA_ARGS__)DT_N_S_soc_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_soc, compatible, 0)DT_N_S_soc_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_soc_P_compatible_IDX_0_EXISTSDT_N_S_soc_P_compatible_IDX_0_STRING_UPPER_TOKENSIMPLE_BUSDT_N_S_soc_P_compatible_IDX_0_STRING_TOKENsimple_busDT_N_S_soc_P_compatible_IDX_0_STRING_UNQUOTEDsimple-busDT_N_S_soc_P_compatible_IDX_0"simple-bus"DT_N_S_soc_P_compatible{"simple-bus"}DT_N_S_soc_PINCTRL_NUMDT_N_S_soc_STATUS_okayDT_N_S_soc_COMPAT_MATCHES_simple_busDT_N_S_soc_IRQ_NUMDT_N_S_soc_FOREACH_RANGE(fn)DT_N_S_soc_RANGES_NUMDT_N_S_soc_REG_NUMDT_N_INST_0_simple_busDT_N_S_soc_EXISTSDT_N_S_soc_SUPPORTS_ORDS24, 25, 26, 27,DT_N_S_soc_REQUIRES_ORDS0,DT_N_S_soc_ORD_STR_SORTABLE00023DT_N_S_soc_ORDDT_N_S_soc_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_3f8, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc_S_uart_2f8, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc_S_hpet_fed00000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc_S_rtc_70, __VA_ARGS__)DT_N_S_soc_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)fn(DT_N_S_soc_S_uart_3f8, __VA_ARGS__) fn(DT_N_S_soc_S_uart_2f8, __VA_ARGS__) fn(DT_N_S_soc_S_hpet_fed00000, __VA_ARGS__) fn(DT_N_S_soc_S_rtc_70, __VA_ARGS__)DT_N_S_soc_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)fn(DT_N_S_soc_S_uart_3f8) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc_S_uart_2f8) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc_S_hpet_fed00000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc_S_rtc_70)DT_N_S_soc_FOREACH_CHILD_STATUS_OKAY(fn)fn(DT_N_S_soc_S_uart_3f8) fn(DT_N_S_soc_S_uart_2f8) fn(DT_N_S_soc_S_hpet_fed00000) fn(DT_N_S_soc_S_rtc_70)DT_N_S_soc_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_soc_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_soc_FOREACH_CHILD_SEP(fn,sep)DT_N_S_soc_FOREACH_CHILD(fn)DT_N_S_soc_CHILD_IDXDT_N_S_soc_PARENTDT_NDT_N_S_soc_FULL_NAME"soc"DT_N_S_soc_PATH"/soc"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_reg_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_reg_IDX_1_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_reg_IDX_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_reg_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_reg_IDX_0135168DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_reg{135168 , 65536 }DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_read_only_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_read_onlyDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_LENDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000, label, 0, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000, label, 0)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_FOREACH_PROP_ELEM(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_IDX_0"image-1"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_STRING_UPPER_TOKENIMAGE_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_STRING_TOKENimage_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_label_STRING_UNQUOTEDimage-1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_P_labelDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_PARTITION_IDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_PINCTRL_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_STATUS_okayDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_IRQ_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_RANGE(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_RANGES_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_REG_IDX_0_VAL_SIZEDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_REG_IDX_0_VAL_ADDRESSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_REG_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_REG_NUMDT_N_NODELABEL_slot1_partitionDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_SUPPORTS_ORDSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_REQUIRES_ORDS6,DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_ORD_STR_SORTABLE00022DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_ORDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FOREACH_CHILD(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_CHILD_IDXDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_PARENTDT_N_S_sim_flash_S_flash_sim_0_S_partitionsDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_FULL_NAME"partition@21000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000_PATH"/sim_flash/flash_sim@0/partitions/partition@21000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_reg_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_reg_IDX_1_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_reg_IDX_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_reg_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_reg_IDX_069632DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_reg{69632 , 65536 }DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_read_only_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_read_onlyDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_LENDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000, label, 0, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000, label, 0)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_FOREACH_PROP_ELEM(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_IDX_0"image-0"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_STRING_UPPER_TOKENIMAGE_0DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_STRING_TOKENimage_0DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_label_STRING_UNQUOTEDimage-0DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_P_labelDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_PARTITION_IDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_PINCTRL_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_STATUS_okayDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_IRQ_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_RANGE(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_RANGES_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_REG_IDX_0_VAL_SIZEDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_REG_IDX_0_VAL_ADDRESSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_REG_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_REG_NUMDT_N_NODELABEL_slot0_partitionDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_SUPPORTS_ORDSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_REQUIRES_ORDSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_ORD_STR_SORTABLE00021DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_ORDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FOREACH_CHILD(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_CHILD_IDXDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_PARENTDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_FULL_NAME"partition@11000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000_PATH"/sim_flash/flash_sim@0/partitions/partition@11000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_reg_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_reg_IDX_1_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_reg_IDX_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_reg_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_reg_IDX_0DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_reg{4096 , 65536 }DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_read_only_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_read_onlyDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_LENDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000, label, 0, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000, label, 0)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_FOREACH_PROP_ELEM(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_IDX_0"storage"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_STRING_UPPER_TOKENSTORAGEDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_STRING_TOKENstorageDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_label_STRING_UNQUOTEDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_P_labelDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_PARTITION_IDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_PINCTRL_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_STATUS_okayDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_IRQ_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_RANGE(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_RANGES_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_REG_IDX_0_VAL_SIZEDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_REG_IDX_0_VAL_ADDRESSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_REG_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_REG_NUMDT_N_NODELABEL_storage_partitionDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_SUPPORTS_ORDSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_REQUIRES_ORDSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_ORD_STR_SORTABLE00020DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_ORDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FOREACH_CHILD(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_CHILD_IDXDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_PARENTDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_FULL_NAME"partition@1000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000_PATH"/sim_flash/flash_sim@0/partitions/partition@1000"DT_N_S_pcie0_S_can0_S_can_transceiver_P_max_bitrate_EXISTSDT_N_S_pcie0_S_can0_S_can_transceiver_P_max_bitrateDT_N_S_pcie0_S_can0_S_can_transceiver_PINCTRL_NUMDT_N_S_pcie0_S_can0_S_can_transceiver_STATUS_okayDT_N_S_pcie0_S_can0_S_can_transceiver_IRQ_NUMDT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_RANGE(fn)DT_N_S_pcie0_S_can0_S_can_transceiver_RANGES_NUMDT_N_S_pcie0_S_can0_S_can_transceiver_REG_NUMDT_N_S_pcie0_S_can0_S_can_transceiver_BUSDT_N_S_pcie0DT_N_S_pcie0_S_can0_S_can_transceiver_BUS_pcieDT_N_S_pcie0_S_can0_S_can_transceiver_EXISTSDT_N_S_pcie0_S_can0_S_can_transceiver_SUPPORTS_ORDSDT_N_S_pcie0_S_can0_S_can_transceiver_REQUIRES_ORDS18,DT_N_S_pcie0_S_can0_S_can_transceiver_ORD_STR_SORTABLE00019DT_N_S_pcie0_S_can0_S_can_transceiver_ORDDT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD_SEP(fn,sep)DT_N_S_pcie0_S_can0_S_can_transceiver_FOREACH_CHILD(fn)DT_N_S_pcie0_S_can0_S_can_transceiver_CHILD_IDXDT_N_S_pcie0_S_can0_S_can_transceiver_PARENTDT_N_S_pcie0_S_can0_S_can_transceiver_FULL_NAME"can-transceiver"DT_N_S_pcie0_S_can0_S_can_transceiver_PATH"/pcie0/can0/can-transceiver"DT_N_S_pcie0_S_can0_P_device_id_EXISTSDT_N_S_pcie0_S_can0_P_device_id33798DT_N_S_pcie0_S_can0_P_vendor_id_EXISTSDT_N_S_pcie0_S_can0_P_vendor_idDT_N_S_pcie0_S_can0_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_pcie0_S_can0_P_zephyr_pm_device_runtime_autoDT_N_S_pcie0_S_can0_P_wakeup_source_EXISTSDT_N_S_pcie0_S_can0_P_wakeup_sourceDT_N_S_pcie0_S_can0_P_interrupt_parent_EXISTSDT_N_S_pcie0_S_can0_P_interrupt_parent_LENDT_N_S_pcie0_S_can0_P_interrupt_parent_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0, interrupt_parent, 0, __VA_ARGS__)DT_N_S_pcie0_S_can0_P_interrupt_parent_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_P_interrupt_parent_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0_S_can0, interrupt_parent, 0)DT_N_S_pcie0_S_can0_P_interrupt_parent_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_S_can0_P_interrupt_parent_IDX_0_EXISTSDT_N_S_pcie0_S_can0_P_interrupt_parent_IDX_0_PHDT_N_S_pcie0_S_can0_P_interrupt_parent_IDX_0DT_N_S_pcie0_S_can0_P_interrupt_parentDT_N_S_pcie0_S_can0_P_compatible_EXISTSDT_N_S_pcie0_S_can0_P_compatible_LENDT_N_S_pcie0_S_can0_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0, compatible, 0, __VA_ARGS__)DT_N_S_pcie0_S_can0_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0_S_can0, compatible, 0)DT_N_S_pcie0_S_can0_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_S_can0_P_compatible_IDX_0_EXISTSDT_N_S_pcie0_S_can0_P_compatible_IDX_0_STRING_UPPER_TOKENKVASER_PCICANDT_N_S_pcie0_S_can0_P_compatible_IDX_0_STRING_TOKENkvaser_pcicanDT_N_S_pcie0_S_can0_P_compatible_IDX_0_STRING_UNQUOTEDkvaser,pcicanDT_N_S_pcie0_S_can0_P_compatible_IDX_0"kvaser,pcican"DT_N_S_pcie0_S_can0_P_compatible{"kvaser,pcican"}DT_N_S_pcie0_S_can0_P_status_EXISTSDT_N_S_pcie0_S_can0_P_status_LENDT_N_S_pcie0_S_can0_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0, status, 0, __VA_ARGS__)DT_N_S_pcie0_S_can0_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0_S_can0, status, 0)DT_N_S_pcie0_S_can0_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_S_can0_P_status_ENUM_UPPER_TOKENDT_N_S_pcie0_S_can0_P_status_ENUM_TOKENDT_N_S_pcie0_S_can0_P_status_ENUM_VAL_okay_EXISTSDT_N_S_pcie0_S_can0_P_status_ENUM_IDXDT_N_S_pcie0_S_can0_P_status_IDX_0_EXISTSDT_N_S_pcie0_S_can0_P_status_IDX_0DT_N_S_pcie0_S_can0_P_status_STRING_UPPER_TOKENDT_N_S_pcie0_S_can0_P_status_STRING_TOKENDT_N_S_pcie0_S_can0_P_status_STRING_UNQUOTEDDT_N_S_pcie0_S_can0_P_statusDT_N_S_pcie0_S_can0_P_sjw_EXISTSDT_N_S_pcie0_S_can0_P_sjwDT_N_S_pcie0_S_can0_P_sample_point_EXISTSDT_N_S_pcie0_S_can0_P_sample_pointDT_N_S_pcie0_S_can0_P_bus_speed_EXISTSDT_N_S_pcie0_S_can0_P_bus_speed125000DT_N_S_pcie0_S_can0_P_interrupts_EXISTSDT_N_S_pcie0_S_can0_P_interrupts_IDX_2_EXISTSDT_N_S_pcie0_S_can0_P_interrupts_IDX_2DT_N_S_pcie0_S_can0_P_interrupts_IDX_1_EXISTSDT_N_S_pcie0_S_can0_P_interrupts_IDX_141216DT_N_S_pcie0_S_can0_P_interrupts_IDX_0_EXISTSDT_N_S_pcie0_S_can0_P_interrupts_IDX_0DT_N_S_pcie0_S_can0_P_interrupts{11 , 41216 , 3 }DT_N_S_pcie0_S_can0_PINCTRL_NUMDT_N_S_pcie0_S_can0_STATUS_okayDT_N_S_pcie0_S_can0_COMPAT_MODEL_IDX_0"pcican"DT_N_S_pcie0_S_can0_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_pcie0_S_can0_COMPAT_VENDOR_IDX_0"Kvaser"DT_N_S_pcie0_S_can0_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_pcie0_S_can0_COMPAT_MATCHES_kvaser_pcicanDT_N_S_pcie0_S_can0_IRQ_IDX_0_VAL_priority_EXISTSDT_N_S_pcie0_S_can0_IRQ_IDX_0_VAL_priorityDT_N_S_pcie0_S_can0_IRQ_IDX_0_EXISTSDT_N_S_pcie0_S_can0_IRQ_IDX_0_VAL_sense_EXISTSDT_N_S_pcie0_S_can0_IRQ_IDX_0_VAL_senseDT_N_S_pcie0_S_can0_IRQ_IDX_0_VAL_irq_EXISTSDT_N_S_pcie0_S_can0_IRQ_IDX_0_VAL_irqDT_N_S_pcie0_S_can0_IRQ_NUMDT_N_S_pcie0_S_can0_FOREACH_RANGE(fn)DT_N_S_pcie0_S_can0_RANGES_NUMDT_N_S_pcie0_S_can0_REG_NUMDT_N_S_pcie0_S_can0_BUSDT_N_S_pcie0_S_can0_BUS_pcieDT_N_NODELABEL_can0DT_N_INST_0_kvaser_pcicanDT_N_S_pcie0_S_can0_EXISTSDT_N_S_pcie0_S_can0_SUPPORTS_ORDS19,DT_N_S_pcie0_S_can0_REQUIRES_ORDS15, 16,DT_N_S_pcie0_S_can0_ORD_STR_SORTABLE00018DT_N_S_pcie0_S_can0_ORDDT_N_S_pcie0_S_can0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0_S_can_transceiver, __VA_ARGS__)DT_N_S_pcie0_S_can0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)fn(DT_N_S_pcie0_S_can0_S_can_transceiver)DT_N_S_pcie0_S_can0_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_pcie0_S_can0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_pcie0_S_can0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_can0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_pcie0_S_can0_FOREACH_CHILD(fn)DT_N_S_pcie0_S_can0_CHILD_IDXDT_N_S_pcie0_S_can0_PARENTDT_N_S_pcie0_S_can0_FULL_NAME"can0"DT_N_S_pcie0_S_can0_PATH"/pcie0/can0"DT_N_S_pcie0_S_eth0_P_device_id_EXISTSDT_N_S_pcie0_S_eth0_P_device_idDT_N_S_pcie0_S_eth0_P_vendor_id_EXISTSDT_N_S_pcie0_S_eth0_P_vendor_id32902DT_N_S_pcie0_S_eth0_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_pcie0_S_eth0_P_zephyr_pm_device_runtime_autoDT_N_S_pcie0_S_eth0_P_wakeup_source_EXISTSDT_N_S_pcie0_S_eth0_P_wakeup_sourceDT_N_S_pcie0_S_eth0_P_interrupt_parent_EXISTSDT_N_S_pcie0_S_eth0_P_interrupt_parent_LENDT_N_S_pcie0_S_eth0_P_interrupt_parent_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_eth0, interrupt_parent, 0, __VA_ARGS__)DT_N_S_pcie0_S_eth0_P_interrupt_parent_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_P_interrupt_parent_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0_S_eth0, interrupt_parent, 0)DT_N_S_pcie0_S_eth0_P_interrupt_parent_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_S_eth0_P_interrupt_parent_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_P_interrupt_parent_IDX_0_PHDT_N_S_pcie0_S_eth0_P_interrupt_parent_IDX_0DT_N_S_pcie0_S_eth0_P_interrupt_parentDT_N_S_pcie0_S_eth0_P_compatible_EXISTSDT_N_S_pcie0_S_eth0_P_compatible_LENDT_N_S_pcie0_S_eth0_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_eth0, compatible, 0, __VA_ARGS__)DT_N_S_pcie0_S_eth0_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0_S_eth0, compatible, 0)DT_N_S_pcie0_S_eth0_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_S_eth0_P_compatible_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_P_compatible_IDX_0_STRING_UPPER_TOKENINTEL_E1000DT_N_S_pcie0_S_eth0_P_compatible_IDX_0_STRING_TOKENintel_e1000DT_N_S_pcie0_S_eth0_P_compatible_IDX_0_STRING_UNQUOTEDintel,e1000DT_N_S_pcie0_S_eth0_P_compatible_IDX_0"intel,e1000"DT_N_S_pcie0_S_eth0_P_compatible{"intel,e1000"}DT_N_S_pcie0_S_eth0_P_status_EXISTSDT_N_S_pcie0_S_eth0_P_status_LENDT_N_S_pcie0_S_eth0_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_eth0, status, 0, __VA_ARGS__)DT_N_S_pcie0_S_eth0_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0_S_eth0, status, 0)DT_N_S_pcie0_S_eth0_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_S_eth0_P_status_ENUM_UPPER_TOKENDT_N_S_pcie0_S_eth0_P_status_ENUM_TOKENDT_N_S_pcie0_S_eth0_P_status_ENUM_VAL_okay_EXISTSDT_N_S_pcie0_S_eth0_P_status_ENUM_IDXDT_N_S_pcie0_S_eth0_P_status_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_P_status_IDX_0DT_N_S_pcie0_S_eth0_P_status_STRING_UPPER_TOKENDT_N_S_pcie0_S_eth0_P_status_STRING_TOKENDT_N_S_pcie0_S_eth0_P_status_STRING_UNQUOTEDDT_N_S_pcie0_S_eth0_P_statusDT_N_S_pcie0_S_eth0_P_interrupts_EXISTSDT_N_S_pcie0_S_eth0_P_interrupts_IDX_2_EXISTSDT_N_S_pcie0_S_eth0_P_interrupts_IDX_2DT_N_S_pcie0_S_eth0_P_interrupts_IDX_1_EXISTSDT_N_S_pcie0_S_eth0_P_interrupts_IDX_1DT_N_S_pcie0_S_eth0_P_interrupts_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_P_interrupts_IDX_0DT_N_S_pcie0_S_eth0_P_interrupts{11 , 256 , 3 }DT_N_S_pcie0_S_eth0_PINCTRL_NUMDT_N_S_pcie0_S_eth0_STATUS_okayDT_N_S_pcie0_S_eth0_COMPAT_MODEL_IDX_0"e1000"DT_N_S_pcie0_S_eth0_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_COMPAT_VENDOR_IDX_0DT_N_S_pcie0_S_eth0_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_COMPAT_MATCHES_intel_e1000DT_N_S_pcie0_S_eth0_IRQ_IDX_0_VAL_priority_EXISTSDT_N_S_pcie0_S_eth0_IRQ_IDX_0_VAL_priorityDT_N_S_pcie0_S_eth0_IRQ_IDX_0_EXISTSDT_N_S_pcie0_S_eth0_IRQ_IDX_0_VAL_sense_EXISTSDT_N_S_pcie0_S_eth0_IRQ_IDX_0_VAL_senseDT_N_S_pcie0_S_eth0_IRQ_IDX_0_VAL_irq_EXISTSDT_N_S_pcie0_S_eth0_IRQ_IDX_0_VAL_irqDT_N_S_pcie0_S_eth0_IRQ_NUMDT_N_S_pcie0_S_eth0_FOREACH_RANGE(fn)DT_N_S_pcie0_S_eth0_RANGES_NUMDT_N_S_pcie0_S_eth0_REG_NUMDT_N_S_pcie0_S_eth0_BUSDT_N_S_pcie0_S_eth0_BUS_pcieDT_N_NODELABEL_eth0DT_N_S_pcie0_S_eth0DT_N_INST_0_intel_e1000DT_N_S_pcie0_S_eth0_EXISTSDT_N_S_pcie0_S_eth0_SUPPORTS_ORDSDT_N_S_pcie0_S_eth0_REQUIRES_ORDSDT_N_S_pcie0_S_eth0_ORD_STR_SORTABLE00017DT_N_S_pcie0_S_eth0_ORDDT_N_S_pcie0_S_eth0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_pcie0_S_eth0_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_pcie0_S_eth0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_S_eth0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_pcie0_S_eth0_FOREACH_CHILD(fn)DT_N_S_pcie0_S_eth0_CHILD_IDXDT_N_S_pcie0_S_eth0_PARENTDT_N_S_pcie0_S_eth0_FULL_NAME"eth0"DT_N_S_pcie0_S_eth0_PATH"/pcie0/eth0"DT_N_S_pcie0_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_pcie0_P_zephyr_pm_device_runtime_autoDT_N_S_pcie0_P_wakeup_source_EXISTSDT_N_S_pcie0_P_wakeup_sourceDT_N_S_pcie0_P_compatible_EXISTSDT_N_S_pcie0_P_compatible_LENDT_N_S_pcie0_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0, compatible, 0, __VA_ARGS__)DT_N_S_pcie0_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_pcie0, compatible, 0)DT_N_S_pcie0_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_pcie0_P_compatible_IDX_0_EXISTSDT_N_S_pcie0_P_compatible_IDX_0_STRING_UPPER_TOKENINTEL_PCIEDT_N_S_pcie0_P_compatible_IDX_0_STRING_TOKENintel_pcieDT_N_S_pcie0_P_compatible_IDX_0_STRING_UNQUOTEDintel,pcieDT_N_S_pcie0_P_compatible_IDX_0"intel,pcie"DT_N_S_pcie0_P_compatible{"intel,pcie"}DT_N_S_pcie0_PINCTRL_NUMDT_N_S_pcie0_STATUS_okayDT_N_S_pcie0_COMPAT_MODEL_IDX_0"pcie"DT_N_S_pcie0_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_pcie0_COMPAT_VENDOR_IDX_0DT_N_S_pcie0_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_pcie0_COMPAT_MATCHES_intel_pcieDT_N_S_pcie0_IRQ_NUMDT_N_S_pcie0_FOREACH_RANGE(fn)DT_N_S_pcie0_RANGES_NUMDT_N_S_pcie0_REG_NUMDT_N_NODELABEL_pcie0DT_N_INST_0_intel_pcieDT_N_S_pcie0_EXISTSDT_N_S_pcie0_SUPPORTS_ORDS17, 18,DT_N_S_pcie0_REQUIRES_ORDSDT_N_S_pcie0_ORD_STR_SORTABLE00016DT_N_S_pcie0_ORDDT_N_S_pcie0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_pcie0_S_eth0, __VA_ARGS__)DT_N_S_pcie0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)fn(DT_N_S_pcie0_S_can0, __VA_ARGS__) fn(DT_N_S_pcie0_S_eth0, __VA_ARGS__)DT_N_S_pcie0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)fn(DT_N_S_pcie0_S_can0) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_pcie0_S_eth0)DT_N_S_pcie0_FOREACH_CHILD_STATUS_OKAY(fn)fn(DT_N_S_pcie0_S_can0) fn(DT_N_S_pcie0_S_eth0)DT_N_S_pcie0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_pcie0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_pcie0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_pcie0_FOREACH_CHILD(fn)DT_N_S_pcie0_CHILD_IDXDT_N_S_pcie0_PARENTDT_N_S_pcie0_FULL_NAME"pcie0"DT_N_S_pcie0_PATH"/pcie0"DT_N_S_ioapic_fec00000_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_ioapic_fec00000_P_zephyr_pm_device_runtime_autoDT_N_S_ioapic_fec00000_P_wakeup_source_EXISTSDT_N_S_ioapic_fec00000_P_wakeup_sourceDT_N_S_ioapic_fec00000_P_compatible_EXISTSDT_N_S_ioapic_fec00000_P_compatible_LENDT_N_S_ioapic_fec00000_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_ioapic_fec00000, compatible, 0, __VA_ARGS__)DT_N_S_ioapic_fec00000_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_ioapic_fec00000_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_ioapic_fec00000, compatible, 0)DT_N_S_ioapic_fec00000_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_ioapic_fec00000_P_compatible_IDX_0_EXISTSDT_N_S_ioapic_fec00000_P_compatible_IDX_0_STRING_UPPER_TOKENINTEL_IOAPICDT_N_S_ioapic_fec00000_P_compatible_IDX_0_STRING_TOKENintel_ioapicDT_N_S_ioapic_fec00000_P_compatible_IDX_0_STRING_UNQUOTEDintel,ioapicDT_N_S_ioapic_fec00000_P_compatible_IDX_0"intel,ioapic"DT_N_S_ioapic_fec00000_P_compatible{"intel,ioapic"}DT_N_S_ioapic_fec00000_P_interrupt_controller_EXISTSDT_N_S_ioapic_fec00000_P_interrupt_controllerDT_N_S_ioapic_fec00000_P_reg_EXISTSDT_N_S_ioapic_fec00000_P_reg_IDX_1_EXISTSDT_N_S_ioapic_fec00000_P_reg_IDX_1DT_N_S_ioapic_fec00000_P_reg_IDX_0_EXISTSDT_N_S_ioapic_fec00000_P_reg_IDX_04273995776DT_N_S_ioapic_fec00000_P_reg{4273995776 , 4096 }DT_N_S_ioapic_fec00000_PINCTRL_NUMDT_N_S_ioapic_fec00000_STATUS_okayDT_N_S_ioapic_fec00000_COMPAT_MODEL_IDX_0"ioapic"DT_N_S_ioapic_fec00000_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_ioapic_fec00000_COMPAT_VENDOR_IDX_0DT_N_S_ioapic_fec00000_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_ioapic_fec00000_COMPAT_MATCHES_intel_ioapicDT_N_S_ioapic_fec00000_IRQ_NUMDT_N_S_ioapic_fec00000_FOREACH_RANGE(fn)DT_N_S_ioapic_fec00000_RANGES_NUMDT_N_S_ioapic_fec00000_REG_IDX_0_VAL_SIZEDT_N_S_ioapic_fec00000_REG_IDX_0_VAL_ADDRESSDT_N_S_ioapic_fec00000_REG_IDX_0_EXISTSDT_N_S_ioapic_fec00000_REG_NUMDT_N_NODELABEL_intcDT_N_INST_0_intel_ioapicDT_N_S_ioapic_fec00000_EXISTSDT_N_S_ioapic_fec00000_SUPPORTS_ORDS17, 18, 24, 25, 26, 27,DT_N_S_ioapic_fec00000_REQUIRES_ORDSDT_N_S_ioapic_fec00000_ORD_STR_SORTABLE00015DT_N_S_ioapic_fec00000_ORDDT_N_S_ioapic_fec00000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_ioapic_fec00000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_ioapic_fec00000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_ioapic_fec00000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_ioapic_fec00000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_ioapic_fec00000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_ioapic_fec00000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_ioapic_fec00000_FOREACH_CHILD(fn)DT_N_S_ioapic_fec00000_CHILD_IDXDT_N_S_ioapic_fec00000_PARENTDT_N_S_ioapic_fec00000_FULL_NAME"ioapic@fec00000"DT_N_S_ioapic_fec00000_PATH"/ioapic@fec00000"DT_N_S_cpus_S_cpu_0_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_cpus_S_cpu_0_P_zephyr_pm_device_runtime_autoDT_N_S_cpus_S_cpu_0_P_wakeup_source_EXISTSDT_N_S_cpus_S_cpu_0_P_wakeup_sourceDT_N_S_cpus_S_cpu_0_P_reg_EXISTSDT_N_S_cpus_S_cpu_0_P_reg_IDX_0_EXISTSDT_N_S_cpus_S_cpu_0_P_reg_IDX_0DT_N_S_cpus_S_cpu_0_P_reg{0 }DT_N_S_cpus_S_cpu_0_P_compatible_EXISTSDT_N_S_cpus_S_cpu_0_P_compatible_LENDT_N_S_cpus_S_cpu_0_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_cpus_S_cpu_0, compatible, 0, __VA_ARGS__)DT_N_S_cpus_S_cpu_0_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_cpus_S_cpu_0_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_cpus_S_cpu_0, compatible, 0)DT_N_S_cpus_S_cpu_0_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_cpus_S_cpu_0_P_compatible_IDX_0_EXISTSDT_N_S_cpus_S_cpu_0_P_compatible_IDX_0_STRING_UPPER_TOKENINTEL_X86DT_N_S_cpus_S_cpu_0_P_compatible_IDX_0_STRING_TOKENintel_x86DT_N_S_cpus_S_cpu_0_P_compatible_IDX_0_STRING_UNQUOTEDintel,x86DT_N_S_cpus_S_cpu_0_P_compatible_IDX_0"intel,x86"DT_N_S_cpus_S_cpu_0_P_compatible{"intel,x86"}DT_N_S_cpus_S_cpu_0_P_d_cache_line_size_EXISTSDT_N_S_cpus_S_cpu_0_P_d_cache_line_sizeDT_N_S_cpus_S_cpu_0_PINCTRL_NUMDT_N_S_cpus_S_cpu_0_STATUS_okayDT_N_S_cpus_S_cpu_0_COMPAT_MODEL_IDX_0DT_N_S_cpus_S_cpu_0_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_cpus_S_cpu_0_COMPAT_VENDOR_IDX_0DT_N_S_cpus_S_cpu_0_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_cpus_S_cpu_0_COMPAT_MATCHES_intel_x86DT_N_S_cpus_S_cpu_0_IRQ_NUMDT_N_S_cpus_S_cpu_0_FOREACH_RANGE(fn)DT_N_S_cpus_S_cpu_0_RANGES_NUMDT_N_S_cpus_S_cpu_0_REG_IDX_0_VAL_ADDRESSDT_N_S_cpus_S_cpu_0_REG_IDX_0_EXISTSDT_N_S_cpus_S_cpu_0_REG_NUMDT_N_INST_0_intel_x86DT_N_S_cpus_S_cpu_0DT_N_S_cpus_S_cpu_0_EXISTSDT_N_S_cpus_S_cpu_0_SUPPORTS_ORDSDT_N_S_cpus_S_cpu_0_REQUIRES_ORDS13,DT_N_S_cpus_S_cpu_0_ORD_STR_SORTABLE00014DT_N_S_cpus_S_cpu_0_ORDDT_N_S_cpus_S_cpu_0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_cpus_S_cpu_0_FOREACH_CHILD(fn)DT_N_S_cpus_S_cpu_0_CHILD_IDXDT_N_S_cpus_S_cpu_0_PARENTDT_N_S_cpusDT_N_S_cpus_S_cpu_0_FULL_NAME"cpu@0"DT_N_S_cpus_S_cpu_0_PATH"/cpus/cpu@0"DT_N_S_cpus_PINCTRL_NUMDT_N_S_cpus_STATUS_okayDT_N_S_cpus_IRQ_NUMDT_N_S_cpus_FOREACH_RANGE(fn)DT_N_S_cpus_RANGES_NUMDT_N_S_cpus_REG_NUMDT_N_S_cpus_EXISTSDT_N_S_cpus_SUPPORTS_ORDS14,DT_N_S_cpus_REQUIRES_ORDSDT_N_S_cpus_ORD_STR_SORTABLE00013DT_N_S_cpus_ORDDT_N_S_cpus_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_cpus_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_cpus_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_cpus_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_cpus_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_cpus_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_cpus_FOREACH_CHILD_SEP(fn,sep)DT_N_S_cpus_FOREACH_CHILD(fn)DT_N_S_cpus_CHILD_IDXDT_N_S_cpus_PARENTDT_N_S_cpus_FULL_NAME"cpus"DT_N_S_cpus_PATH"/cpus"DT_N_S_memory_0_P_reg_EXISTSDT_N_S_memory_0_P_reg_IDX_1_EXISTSDT_N_S_memory_0_P_reg_IDX_1DT_N_S_memory_0_P_reg_IDX_0_EXISTSDT_N_S_memory_0_P_reg_IDX_0DT_N_S_memory_0_P_reg{0 , 33554432 }DT_N_S_memory_0_PINCTRL_NUMDT_N_S_memory_0_STATUS_okayDT_N_S_memory_0_IRQ_NUMDT_N_S_memory_0_FOREACH_RANGE(fn)DT_N_S_memory_0_RANGES_NUMDT_N_S_memory_0_REG_IDX_0_VAL_SIZEDT_N_S_memory_0_REG_IDX_0_VAL_ADDRESSDT_N_S_memory_0_REG_IDX_0_EXISTSDT_N_S_memory_0_REG_NUMDT_N_NODELABEL_dram0DT_N_S_memory_0_EXISTSDT_N_S_memory_0_SUPPORTS_ORDSDT_N_S_memory_0_REQUIRES_ORDSDT_N_S_memory_0_ORD_STR_SORTABLE00012DT_N_S_memory_0_ORDDT_N_S_memory_0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_memory_0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_memory_0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_memory_0_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_memory_0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_memory_0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_memory_0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_memory_0_FOREACH_CHILD(fn)DT_N_S_memory_0_CHILD_IDXDT_N_S_memory_0_PARENTDT_N_S_memory_0_FULL_NAME"memory@0"DT_N_S_memory_0_PATH"/memory@0"DT_N_S_loapic_fee00000_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_loapic_fee00000_P_zephyr_pm_device_runtime_autoDT_N_S_loapic_fee00000_P_wakeup_source_EXISTSDT_N_S_loapic_fee00000_P_wakeup_sourceDT_N_S_loapic_fee00000_P_compatible_EXISTSDT_N_S_loapic_fee00000_P_compatible_LENDT_N_S_loapic_fee00000_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_loapic_fee00000, compatible, 0, __VA_ARGS__)DT_N_S_loapic_fee00000_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_loapic_fee00000_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_loapic_fee00000, compatible, 0)DT_N_S_loapic_fee00000_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_loapic_fee00000_P_compatible_IDX_0_EXISTSDT_N_S_loapic_fee00000_P_compatible_IDX_0_STRING_UPPER_TOKENINTEL_LOAPICDT_N_S_loapic_fee00000_P_compatible_IDX_0_STRING_TOKENintel_loapicDT_N_S_loapic_fee00000_P_compatible_IDX_0_STRING_UNQUOTEDintel,loapicDT_N_S_loapic_fee00000_P_compatible_IDX_0"intel,loapic"DT_N_S_loapic_fee00000_P_compatible{"intel,loapic"}DT_N_S_loapic_fee00000_P_interrupt_controller_EXISTSDT_N_S_loapic_fee00000_P_interrupt_controllerDT_N_S_loapic_fee00000_P_reg_EXISTSDT_N_S_loapic_fee00000_P_reg_IDX_1_EXISTSDT_N_S_loapic_fee00000_P_reg_IDX_1DT_N_S_loapic_fee00000_P_reg_IDX_0_EXISTSDT_N_S_loapic_fee00000_P_reg_IDX_04276092928DT_N_S_loapic_fee00000_P_reg{4276092928 , 4096 }DT_N_S_loapic_fee00000_PINCTRL_NUMDT_N_S_loapic_fee00000_STATUS_okayDT_N_S_loapic_fee00000_COMPAT_MODEL_IDX_0"loapic"DT_N_S_loapic_fee00000_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_loapic_fee00000_COMPAT_VENDOR_IDX_0DT_N_S_loapic_fee00000_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_loapic_fee00000_COMPAT_MATCHES_intel_loapicDT_N_S_loapic_fee00000_IRQ_NUMDT_N_S_loapic_fee00000_FOREACH_RANGE(fn)DT_N_S_loapic_fee00000_RANGES_NUMDT_N_S_loapic_fee00000_REG_IDX_0_VAL_SIZEDT_N_S_loapic_fee00000_REG_IDX_0_VAL_ADDRESSDT_N_S_loapic_fee00000_REG_IDX_0_EXISTSDT_N_S_loapic_fee00000_REG_NUMDT_N_NODELABEL_intc_loapicDT_N_S_loapic_fee00000DT_N_INST_0_intel_loapicDT_N_S_loapic_fee00000_EXISTSDT_N_S_loapic_fee00000_SUPPORTS_ORDSDT_N_S_loapic_fee00000_REQUIRES_ORDSDT_N_S_loapic_fee00000_ORD_STR_SORTABLE00011DT_N_S_loapic_fee00000_ORDDT_N_S_loapic_fee00000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_loapic_fee00000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_loapic_fee00000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_loapic_fee00000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_loapic_fee00000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_loapic_fee00000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_loapic_fee00000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_loapic_fee00000_FOREACH_CHILD(fn)DT_N_S_loapic_fee00000_CHILD_IDXDT_N_S_loapic_fee00000_PARENTDT_N_S_loapic_fee00000_FULL_NAME"loapic@fee00000"DT_N_S_loapic_fee00000_PATH"/loapic@fee00000"DT_N_S_ieee802154_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_ieee802154_P_zephyr_pm_device_runtime_autoDT_N_S_ieee802154_P_wakeup_source_EXISTSDT_N_S_ieee802154_P_wakeup_sourceDT_N_S_ieee802154_P_compatible_EXISTSDT_N_S_ieee802154_P_compatible_LENDT_N_S_ieee802154_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_ieee802154, compatible, 0, __VA_ARGS__)DT_N_S_ieee802154_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_ieee802154_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_ieee802154, compatible, 0)DT_N_S_ieee802154_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_ieee802154_P_compatible_IDX_0_EXISTSDT_N_S_ieee802154_P_compatible_IDX_0_STRING_UPPER_TOKENZEPHYR_IEEE802154_UART_PIPEDT_N_S_ieee802154_P_compatible_IDX_0_STRING_TOKENzephyr_ieee802154_uart_pipeDT_N_S_ieee802154_P_compatible_IDX_0_STRING_UNQUOTEDzephyr,ieee802154-uart-pipeDT_N_S_ieee802154_P_compatible_IDX_0"zephyr,ieee802154-uart-pipe"DT_N_S_ieee802154_P_compatible{"zephyr,ieee802154-uart-pipe"}DT_N_S_ieee802154_PINCTRL_NUMDT_N_S_ieee802154_STATUS_okayDT_N_S_ieee802154_COMPAT_MODEL_IDX_0"ieee802154-uart-pipe"DT_N_S_ieee802154_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_ieee802154_COMPAT_VENDOR_IDX_0"Zephyr-specific binding"DT_N_S_ieee802154_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_ieee802154_COMPAT_MATCHES_zephyr_ieee802154_uart_pipeDT_N_S_ieee802154_IRQ_NUMDT_N_S_ieee802154_FOREACH_RANGE(fn)DT_N_S_ieee802154_RANGES_NUMDT_N_S_ieee802154_REG_NUMDT_N_NODELABEL_ieee802154DT_N_INST_0_zephyr_ieee802154_uart_pipeDT_N_S_ieee802154_EXISTSDT_N_S_ieee802154_SUPPORTS_ORDSDT_N_S_ieee802154_REQUIRES_ORDSDT_N_S_ieee802154_ORD_STR_SORTABLE00010DT_N_S_ieee802154_ORDDT_N_S_ieee802154_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_ieee802154_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_ieee802154_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_ieee802154_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_ieee802154_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_ieee802154_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_ieee802154_FOREACH_CHILD_SEP(fn,sep)DT_N_S_ieee802154_FOREACH_CHILD(fn)DT_N_S_ieee802154_CHILD_IDXDT_N_S_ieee802154_PARENTDT_N_S_ieee802154_FULL_NAME"ieee802154"DT_N_S_ieee802154_PATH"/ieee802154"DT_N_S_flash_500000_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_flash_500000_P_zephyr_pm_device_runtime_autoDT_N_S_flash_500000_P_wakeup_source_EXISTSDT_N_S_flash_500000_P_wakeup_sourceDT_N_S_flash_500000_P_reg_EXISTSDT_N_S_flash_500000_P_reg_IDX_1_EXISTSDT_N_S_flash_500000_P_reg_IDX_14194304DT_N_S_flash_500000_P_reg_IDX_0_EXISTSDT_N_S_flash_500000_P_reg_IDX_05242880DT_N_S_flash_500000_P_reg{5242880 , 4194304 }DT_N_S_flash_500000_P_compatible_EXISTSDT_N_S_flash_500000_P_compatible_LENDT_N_S_flash_500000_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_flash_500000, compatible, 0, __VA_ARGS__)DT_N_S_flash_500000_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_flash_500000_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_flash_500000, compatible, 0)DT_N_S_flash_500000_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_flash_500000_P_compatible_IDX_0_EXISTSDT_N_S_flash_500000_P_compatible_IDX_0_STRING_UPPER_TOKENSOC_NV_FLASHDT_N_S_flash_500000_P_compatible_IDX_0_STRING_TOKENsoc_nv_flashDT_N_S_flash_500000_P_compatible_IDX_0_STRING_UNQUOTEDsoc-nv-flashDT_N_S_flash_500000_P_compatible_IDX_0"soc-nv-flash"DT_N_S_flash_500000_P_compatible{"soc-nv-flash"}DT_N_S_flash_500000_PINCTRL_NUMDT_N_S_flash_500000_STATUS_okayDT_N_S_flash_500000_COMPAT_MATCHES_soc_nv_flashDT_N_S_flash_500000_IRQ_NUMDT_N_S_flash_500000_FOREACH_RANGE(fn)DT_N_S_flash_500000_RANGES_NUMDT_N_S_flash_500000_REG_IDX_0_VAL_SIZEDT_N_S_flash_500000_REG_IDX_0_VAL_ADDRESSDT_N_S_flash_500000_REG_IDX_0_EXISTSDT_N_S_flash_500000_REG_NUMDT_N_NODELABEL_flash0DT_N_INST_0_soc_nv_flashDT_N_S_flash_500000_EXISTSDT_N_S_flash_500000_SUPPORTS_ORDSDT_N_S_flash_500000_REQUIRES_ORDSDT_N_S_flash_500000_ORD_STR_SORTABLE00009DT_N_S_flash_500000_ORDDT_N_S_flash_500000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_flash_500000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_flash_500000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_flash_500000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_flash_500000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_flash_500000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_flash_500000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_flash_500000_FOREACH_CHILD(fn)DT_N_S_flash_500000_CHILD_IDXDT_N_S_flash_500000_PARENTDT_N_S_flash_500000_FULL_NAME"flash@500000"DT_N_S_flash_500000_PATH"/flash@500000"DT_N_S_eeprom1_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_eeprom1_P_zephyr_pm_device_runtime_autoDT_N_S_eeprom1_P_wakeup_source_EXISTSDT_N_S_eeprom1_P_wakeup_sourceDT_N_S_eeprom1_P_compatible_EXISTSDT_N_S_eeprom1_P_compatible_LENDT_N_S_eeprom1_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_eeprom1, compatible, 0, __VA_ARGS__)DT_N_S_eeprom1_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom1_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_eeprom1, compatible, 0)DT_N_S_eeprom1_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_eeprom1_P_compatible_IDX_0_EXISTSDT_N_S_eeprom1_P_compatible_IDX_0_STRING_UPPER_TOKENZEPHYR_EMU_EEPROMDT_N_S_eeprom1_P_compatible_IDX_0_STRING_TOKENzephyr_emu_eepromDT_N_S_eeprom1_P_compatible_IDX_0_STRING_UNQUOTEDzephyr,emu-eepromDT_N_S_eeprom1_P_compatible_IDX_0"zephyr,emu-eeprom"DT_N_S_eeprom1_P_compatible{"zephyr,emu-eeprom"}DT_N_S_eeprom1_P_status_EXISTSDT_N_S_eeprom1_P_status_LENDT_N_S_eeprom1_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_eeprom1, status, 0, __VA_ARGS__)DT_N_S_eeprom1_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom1_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_eeprom1, status, 0)DT_N_S_eeprom1_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_eeprom1_P_status_ENUM_UPPER_TOKENDT_N_S_eeprom1_P_status_ENUM_TOKENDT_N_S_eeprom1_P_status_ENUM_VAL_okay_EXISTSDT_N_S_eeprom1_P_status_ENUM_IDXDT_N_S_eeprom1_P_status_IDX_0_EXISTSDT_N_S_eeprom1_P_status_IDX_0DT_N_S_eeprom1_P_status_STRING_UPPER_TOKENDT_N_S_eeprom1_P_status_STRING_TOKENDT_N_S_eeprom1_P_status_STRING_UNQUOTEDDT_N_S_eeprom1_P_statusDT_N_S_eeprom1_P_read_only_EXISTSDT_N_S_eeprom1_P_read_onlyDT_N_S_eeprom1_P_partition_erase_EXISTSDT_N_S_eeprom1_P_partition_eraseDT_N_S_eeprom1_P_rambuf_EXISTSDT_N_S_eeprom1_P_rambufDT_N_S_eeprom1_P_partition_EXISTSDT_N_S_eeprom1_P_partition_LENDT_N_S_eeprom1_P_partition_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_eeprom1, partition, 0, __VA_ARGS__)DT_N_S_eeprom1_P_partition_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom1_P_partition_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_eeprom1, partition, 0)DT_N_S_eeprom1_P_partition_FOREACH_PROP_ELEM(fn)DT_N_S_eeprom1_P_partition_IDX_0_EXISTSDT_N_S_eeprom1_P_partition_IDX_0_PHDT_N_S_eeprom1_P_partition_IDX_0DT_N_S_eeprom1_P_partitionDT_N_S_eeprom1_P_pagesize_EXISTSDT_N_S_eeprom1_P_pagesizeDT_N_S_eeprom1_P_size_EXISTSDT_N_S_eeprom1_P_sizeDT_N_S_eeprom1_PINCTRL_NUMDT_N_S_eeprom1_STATUS_okayDT_N_S_eeprom1_COMPAT_MODEL_IDX_0"emu-eeprom"DT_N_S_eeprom1_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_eeprom1_COMPAT_VENDOR_IDX_0DT_N_S_eeprom1_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_eeprom1_COMPAT_MATCHES_zephyr_emu_eepromDT_N_S_eeprom1_IRQ_NUMDT_N_S_eeprom1_FOREACH_RANGE(fn)DT_N_S_eeprom1_RANGES_NUMDT_N_S_eeprom1_REG_NUMDT_N_NODELABEL_eeprom1DT_N_S_eeprom1DT_N_INST_0_zephyr_emu_eepromDT_N_ALIAS_eeprom_1DT_N_S_eeprom1_EXISTSDT_N_S_eeprom1_SUPPORTS_ORDSDT_N_S_eeprom1_REQUIRES_ORDS0, 7,DT_N_S_eeprom1_ORD_STR_SORTABLE00008DT_N_S_eeprom1_ORDDT_N_S_eeprom1_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_eeprom1_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom1_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_eeprom1_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_eeprom1_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_eeprom1_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom1_FOREACH_CHILD_SEP(fn,sep)DT_N_S_eeprom1_FOREACH_CHILD(fn)DT_N_S_eeprom1_CHILD_IDXDT_N_S_eeprom1_PARENTDT_N_S_eeprom1_FULL_NAME"eeprom1"DT_N_S_eeprom1_PATH"/eeprom1"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_reg_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_reg_IDX_1_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_reg_IDX_1DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_reg_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_reg_IDX_0200704DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_reg{200704 , 65536 }DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_read_only_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_read_onlyDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_LENDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000, label, 0, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000, label, 0)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_FOREACH_PROP_ELEM(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_IDX_0"eeprom-emu"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_STRING_UPPER_TOKENEEPROM_EMUDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_STRING_TOKENeeprom_emuDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_label_STRING_UNQUOTEDeeprom-emuDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_P_labelDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_PARTITION_IDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_PINCTRL_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_STATUS_okayDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_IRQ_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_RANGE(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_RANGES_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_REG_IDX_0_VAL_SIZEDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_REG_IDX_0_VAL_ADDRESSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_REG_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_REG_NUMDT_N_NODELABEL_eepromemu_partitionDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_SUPPORTS_ORDS8,DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_REQUIRES_ORDSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_ORD_STR_SORTABLE00007DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_ORDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FOREACH_CHILD(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_CHILD_IDXDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_PARENTDT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_FULL_NAME"partition@31000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000_PATH"/sim_flash/flash_sim@0/partitions/partition@31000"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_PINCTRL_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_STATUS_okayDT_N_S_sim_flash_S_flash_sim_0_S_partitions_COMPAT_MATCHES_fixed_partitionsDT_N_S_sim_flash_S_flash_sim_0_S_partitions_IRQ_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_RANGE(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_RANGES_NUMDT_N_S_sim_flash_S_flash_sim_0_S_partitions_REG_NUMDT_N_INST_0_fixed_partitionsDT_N_S_sim_flash_S_flash_sim_0_S_partitions_EXISTSDT_N_S_sim_flash_S_flash_sim_0_S_partitions_SUPPORTS_ORDS7, 20, 21, 22,DT_N_S_sim_flash_S_flash_sim_0_S_partitions_REQUIRES_ORDS5,DT_N_S_sim_flash_S_flash_sim_0_S_partitions_ORD_STR_SORTABLE00006DT_N_S_sim_flash_S_flash_sim_0_S_partitions_ORDDT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000, __VA_ARGS__) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_STATUS_OKAY(fn)fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000) fn(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FOREACH_CHILD(fn)DT_N_S_sim_flash_S_flash_sim_0_S_partitions_CHILD_IDXDT_N_S_sim_flash_S_flash_sim_0_S_partitions_PARENTDT_N_S_sim_flash_S_flash_sim_0DT_N_S_sim_flash_S_flash_sim_0_S_partitions_FULL_NAME"partitions"DT_N_S_sim_flash_S_flash_sim_0_S_partitions_PATH"/sim_flash/flash_sim@0/partitions"DT_N_S_sim_flash_S_flash_sim_0_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_zephyr_pm_device_runtime_autoDT_N_S_sim_flash_S_flash_sim_0_P_wakeup_source_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_wakeup_sourceDT_N_S_sim_flash_S_flash_sim_0_P_reg_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_reg_IDX_1_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_reg_IDX_1DT_N_S_sim_flash_S_flash_sim_0_P_reg_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_reg_IDX_0DT_N_S_sim_flash_S_flash_sim_0_P_reg{0 , 1048576 }DT_N_S_sim_flash_S_flash_sim_0_P_compatible_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_compatible_LENDT_N_S_sim_flash_S_flash_sim_0_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0, compatible, 0, __VA_ARGS__)DT_N_S_sim_flash_S_flash_sim_0_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0, compatible, 0)DT_N_S_sim_flash_S_flash_sim_0_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_sim_flash_S_flash_sim_0_P_compatible_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_compatible_IDX_0_STRING_UPPER_TOKENDT_N_S_sim_flash_S_flash_sim_0_P_compatible_IDX_0_STRING_TOKENDT_N_S_sim_flash_S_flash_sim_0_P_compatible_IDX_0_STRING_UNQUOTEDDT_N_S_sim_flash_S_flash_sim_0_P_compatible_IDX_0DT_N_S_sim_flash_S_flash_sim_0_P_compatibleDT_N_S_sim_flash_S_flash_sim_0_P_write_block_size_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_write_block_sizeDT_N_S_sim_flash_S_flash_sim_0_P_erase_block_size_EXISTSDT_N_S_sim_flash_S_flash_sim_0_P_erase_block_sizeDT_N_S_sim_flash_S_flash_sim_0_PINCTRL_NUMDT_N_S_sim_flash_S_flash_sim_0_STATUS_okayDT_N_S_sim_flash_S_flash_sim_0_COMPAT_MATCHES_soc_nv_flashDT_N_S_sim_flash_S_flash_sim_0_IRQ_NUMDT_N_S_sim_flash_S_flash_sim_0_FOREACH_RANGE(fn)DT_N_S_sim_flash_S_flash_sim_0_RANGES_NUMDT_N_S_sim_flash_S_flash_sim_0_REG_IDX_0_VAL_SIZEDT_N_S_sim_flash_S_flash_sim_0_REG_IDX_0_VAL_ADDRESSDT_N_S_sim_flash_S_flash_sim_0_REG_IDX_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_REG_NUMDT_N_NODELABEL_flash_sim0DT_N_INST_1_soc_nv_flashDT_N_S_sim_flash_S_flash_sim_0_EXISTSDT_N_S_sim_flash_S_flash_sim_0_SUPPORTS_ORDSDT_N_S_sim_flash_S_flash_sim_0_REQUIRES_ORDS4,DT_N_S_sim_flash_S_flash_sim_0_ORD_STR_SORTABLE00005DT_N_S_sim_flash_S_flash_sim_0_ORDDT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_S_flash_sim_0_FOREACH_CHILD(fn)DT_N_S_sim_flash_S_flash_sim_0_CHILD_IDXDT_N_S_sim_flash_S_flash_sim_0_PARENTDT_N_S_sim_flash_S_flash_sim_0_FULL_NAME"flash_sim@0"DT_N_S_sim_flash_S_flash_sim_0_PATH"/sim_flash/flash_sim@0"DT_N_S_sim_flash_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_sim_flash_P_zephyr_pm_device_runtime_autoDT_N_S_sim_flash_P_wakeup_source_EXISTSDT_N_S_sim_flash_P_wakeup_sourceDT_N_S_sim_flash_P_compatible_EXISTSDT_N_S_sim_flash_P_compatible_LENDT_N_S_sim_flash_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash, compatible, 0, __VA_ARGS__)DT_N_S_sim_flash_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_sim_flash, compatible, 0)DT_N_S_sim_flash_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_sim_flash_P_compatible_IDX_0_EXISTSDT_N_S_sim_flash_P_compatible_IDX_0_STRING_UPPER_TOKENZEPHYR_SIM_FLASHDT_N_S_sim_flash_P_compatible_IDX_0_STRING_TOKENzephyr_sim_flashDT_N_S_sim_flash_P_compatible_IDX_0_STRING_UNQUOTEDzephyr,sim-flashDT_N_S_sim_flash_P_compatible_IDX_0"zephyr,sim-flash"DT_N_S_sim_flash_P_compatible{"zephyr,sim-flash"}DT_N_S_sim_flash_P_erase_value_EXISTSDT_N_S_sim_flash_P_erase_valueDT_N_S_sim_flash_PINCTRL_NUMDT_N_S_sim_flash_STATUS_okayDT_N_S_sim_flash_COMPAT_MODEL_IDX_0"sim-flash"DT_N_S_sim_flash_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_sim_flash_COMPAT_VENDOR_IDX_0DT_N_S_sim_flash_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_sim_flash_COMPAT_MATCHES_zephyr_sim_flashDT_N_S_sim_flash_IRQ_NUMDT_N_S_sim_flash_FOREACH_RANGE(fn)DT_N_S_sim_flash_RANGES_NUMDT_N_S_sim_flash_REG_NUMDT_N_NODELABEL_sim_flashDT_N_INST_0_zephyr_sim_flashDT_N_S_sim_flash_EXISTSDT_N_S_sim_flash_SUPPORTS_ORDSDT_N_S_sim_flash_REQUIRES_ORDSDT_N_S_sim_flash_ORD_STR_SORTABLE00004DT_N_S_sim_flash_ORDDT_N_S_sim_flash_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_sim_flash_S_flash_sim_0, __VA_ARGS__)DT_N_S_sim_flash_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)fn(DT_N_S_sim_flash_S_flash_sim_0)DT_N_S_sim_flash_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_sim_flash_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_sim_flash_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_sim_flash_FOREACH_CHILD_SEP(fn,sep)DT_N_S_sim_flash_FOREACH_CHILD(fn)DT_N_S_sim_flash_CHILD_IDXDT_N_S_sim_flash_PARENTDT_N_S_sim_flash_FULL_NAME"sim_flash"DT_N_S_sim_flash_PATH"/sim_flash"DT_N_S_eeprom0_P_zephyr_pm_device_runtime_auto_EXISTSDT_N_S_eeprom0_P_zephyr_pm_device_runtime_autoDT_N_S_eeprom0_P_wakeup_source_EXISTSDT_N_S_eeprom0_P_wakeup_sourceDT_N_S_eeprom0_P_compatible_EXISTSDT_N_S_eeprom0_P_compatible_LENDT_N_S_eeprom0_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_eeprom0, compatible, 0, __VA_ARGS__)DT_N_S_eeprom0_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom0_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_eeprom0, compatible, 0)DT_N_S_eeprom0_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_S_eeprom0_P_compatible_IDX_0_EXISTSDT_N_S_eeprom0_P_compatible_IDX_0_STRING_UPPER_TOKENZEPHYR_SIM_EEPROMDT_N_S_eeprom0_P_compatible_IDX_0_STRING_TOKENzephyr_sim_eepromDT_N_S_eeprom0_P_compatible_IDX_0_STRING_UNQUOTEDzephyr,sim-eepromDT_N_S_eeprom0_P_compatible_IDX_0"zephyr,sim-eeprom"DT_N_S_eeprom0_P_compatible{"zephyr,sim-eeprom"}DT_N_S_eeprom0_P_status_EXISTSDT_N_S_eeprom0_P_status_LENDT_N_S_eeprom0_P_status_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_eeprom0, status, 0, __VA_ARGS__)DT_N_S_eeprom0_P_status_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom0_P_status_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N_S_eeprom0, status, 0)DT_N_S_eeprom0_P_status_FOREACH_PROP_ELEM(fn)DT_N_S_eeprom0_P_status_ENUM_UPPER_TOKENDT_N_S_eeprom0_P_status_ENUM_TOKENDT_N_S_eeprom0_P_status_ENUM_VAL_okay_EXISTSDT_N_S_eeprom0_P_status_ENUM_IDXDT_N_S_eeprom0_P_status_IDX_0_EXISTSDT_N_S_eeprom0_P_status_IDX_0DT_N_S_eeprom0_P_status_STRING_UPPER_TOKENDT_N_S_eeprom0_P_status_STRING_TOKENDT_N_S_eeprom0_P_status_STRING_UNQUOTEDDT_N_S_eeprom0_P_statusDT_N_S_eeprom0_P_read_only_EXISTSDT_N_S_eeprom0_P_read_onlyDT_N_S_eeprom0_P_size_EXISTSDT_N_S_eeprom0_P_sizeDT_N_S_eeprom0_PINCTRL_NUMDT_N_S_eeprom0_STATUS_okayDT_N_S_eeprom0_COMPAT_MODEL_IDX_0"sim-eeprom"DT_N_S_eeprom0_COMPAT_MODEL_IDX_0_EXISTSDT_N_S_eeprom0_COMPAT_VENDOR_IDX_0DT_N_S_eeprom0_COMPAT_VENDOR_IDX_0_EXISTSDT_N_S_eeprom0_COMPAT_MATCHES_zephyr_sim_eepromDT_N_S_eeprom0_IRQ_NUMDT_N_S_eeprom0_FOREACH_RANGE(fn)DT_N_S_eeprom0_RANGES_NUMDT_N_S_eeprom0_REG_NUMDT_N_NODELABEL_eeprom0DT_N_S_eeprom0DT_N_INST_0_zephyr_sim_eepromDT_N_ALIAS_eeprom_0DT_N_S_eeprom0_EXISTSDT_N_S_eeprom0_SUPPORTS_ORDSDT_N_S_eeprom0_REQUIRES_ORDSDT_N_S_eeprom0_ORD_STR_SORTABLE00003DT_N_S_eeprom0_ORDDT_N_S_eeprom0_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_eeprom0_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom0_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_eeprom0_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_eeprom0_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_eeprom0_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_eeprom0_FOREACH_CHILD_SEP(fn,sep)DT_N_S_eeprom0_FOREACH_CHILD(fn)DT_N_S_eeprom0_CHILD_IDXDT_N_S_eeprom0_PARENTDT_N_S_eeprom0_FULL_NAME"eeprom0"DT_N_S_eeprom0_PATH"/eeprom0"DT_N_S_chosen_PINCTRL_NUMDT_N_S_chosen_STATUS_okayDT_N_S_chosen_IRQ_NUMDT_N_S_chosen_FOREACH_RANGE(fn)DT_N_S_chosen_RANGES_NUMDT_N_S_chosen_REG_NUMDT_N_S_chosen_EXISTSDT_N_S_chosen_SUPPORTS_ORDSDT_N_S_chosen_REQUIRES_ORDSDT_N_S_chosen_ORD_STR_SORTABLE00002DT_N_S_chosen_ORDDT_N_S_chosen_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_chosen_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_chosen_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_chosen_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_chosen_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_chosen_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_chosen_FOREACH_CHILD_SEP(fn,sep)DT_N_S_chosen_FOREACH_CHILD(fn)DT_N_S_chosen_CHILD_IDXDT_N_S_chosen_PARENTDT_N_S_chosen_FULL_NAME"chosen"DT_N_S_chosen_PATH"/chosen"DT_N_S_aliases_PINCTRL_NUMDT_N_S_aliases_STATUS_okayDT_N_S_aliases_IRQ_NUMDT_N_S_aliases_FOREACH_RANGE(fn)DT_N_S_aliases_RANGES_NUMDT_N_S_aliases_REG_NUMDT_N_S_aliases_EXISTSDT_N_S_aliases_SUPPORTS_ORDSDT_N_S_aliases_REQUIRES_ORDSDT_N_S_aliases_ORD_STR_SORTABLE00001DT_N_S_aliases_ORDDT_N_S_aliases_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_aliases_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)DT_N_S_aliases_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)DT_N_S_aliases_FOREACH_CHILD_STATUS_OKAY(fn)DT_N_S_aliases_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_S_aliases_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_S_aliases_FOREACH_CHILD_SEP(fn,sep)DT_N_S_aliases_FOREACH_CHILD(fn)DT_N_S_aliases_CHILD_IDXDT_N_S_aliases_PARENTDT_N_S_aliases_FULL_NAME"aliases"DT_N_S_aliases_PATH"/aliases"DT_N_P_compatible_EXISTSDT_N_P_compatible_LENDT_N_P_compatible_FOREACH_PROP_ELEM_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N, compatible, 0, __VA_ARGS__)DT_N_P_compatible_FOREACH_PROP_ELEM_VARGS(fn,__VA_ARGS__...)DT_N_P_compatible_FOREACH_PROP_ELEM_SEP(fn,sep)fn(DT_N, compatible, 0)DT_N_P_compatible_FOREACH_PROP_ELEM(fn)DT_N_P_compatible_IDX_0_EXISTSDT_N_P_compatible_IDX_0_STRING_UPPER_TOKENQEMU_X86_EMULATORDT_N_P_compatible_IDX_0_STRING_TOKENqemu_x86_emulatorDT_N_P_compatible_IDX_0_STRING_UNQUOTEDqemu,x86_emulatorDT_N_P_compatible_IDX_0"qemu,x86_emulator"DT_N_P_compatible{"qemu,x86_emulator"}DT_N_PINCTRL_NUMDT_N_STATUS_okayDT_N_COMPAT_MODEL_IDX_0"x86_emulator"DT_N_COMPAT_MODEL_IDX_0_EXISTSDT_N_COMPAT_VENDOR_IDX_0"QEMU, a generic and open source machine emulator and virtualizer"DT_N_COMPAT_VENDOR_IDX_0_EXISTSDT_N_COMPAT_MATCHES_qemu_x86_emulatorDT_N_IRQ_NUMDT_N_FOREACH_RANGE(fn)DT_N_RANGES_NUMDT_N_REG_NUMDT_N_INST_0_qemu_x86_emulatorDT_N_EXISTSDT_N_SUPPORTS_ORDS1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 15, 16, 23,DT_N_REQUIRES_ORDSDT_N_ORD_STR_SORTABLE00000DT_N_ORDDT_N_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(fn,sep,__VA_ARGS__...)fn(DT_N_S_chosen, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_aliases, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_cpus, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_ioapic_fec00000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_loapic_fee00000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_memory_0, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_flash_500000, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_pcie0, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_eeprom1, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_eeprom0, __VA_ARGS__) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_ieee802154, __VA_ARGS__)DT_N_FOREACH_CHILD_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)fn(DT_N_S_chosen, __VA_ARGS__) fn(DT_N_S_aliases, __VA_ARGS__) fn(DT_N_S_cpus, __VA_ARGS__) fn(DT_N_S_ioapic_fec00000, __VA_ARGS__) fn(DT_N_S_loapic_fee00000, __VA_ARGS__) fn(DT_N_S_memory_0, __VA_ARGS__) fn(DT_N_S_soc, __VA_ARGS__) fn(DT_N_S_flash_500000, __VA_ARGS__) fn(DT_N_S_pcie0, __VA_ARGS__) fn(DT_N_S_sim_flash, __VA_ARGS__) fn(DT_N_S_eeprom1, __VA_ARGS__) fn(DT_N_S_eeprom0, __VA_ARGS__) fn(DT_N_S_ieee802154, __VA_ARGS__)DT_N_FOREACH_CHILD_STATUS_OKAY_SEP(fn,sep)fn(DT_N_S_chosen) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_aliases) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_cpus) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_ioapic_fec00000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_loapic_fee00000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_memory_0) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_soc) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_flash_500000) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_pcie0) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_sim_flash) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_eeprom1) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_eeprom0) DT_DEBRACKET_INTERNAL sep fn(DT_N_S_ieee802154)DT_N_FOREACH_CHILD_STATUS_OKAY(fn)fn(DT_N_S_chosen) fn(DT_N_S_aliases) fn(DT_N_S_cpus) fn(DT_N_S_ioapic_fec00000) fn(DT_N_S_loapic_fee00000) fn(DT_N_S_memory_0) fn(DT_N_S_soc) fn(DT_N_S_flash_500000) fn(DT_N_S_pcie0) fn(DT_N_S_sim_flash) fn(DT_N_S_eeprom1) fn(DT_N_S_eeprom0) fn(DT_N_S_ieee802154)DT_N_FOREACH_CHILD_SEP_VARGS(fn,sep,__VA_ARGS__...)DT_N_FOREACH_CHILD_VARGS(fn,__VA_ARGS__...)DT_N_FOREACH_CHILD_SEP(fn,sep)DT_N_FOREACH_CHILD(fn)DT_N_FULL_NAME"/"DT_N_PATHDT_DEBRACKET_INTERNAL(__VA_ARGS__...)/*
 * Bus information for status "okay" nodes of each compatible
 *//*
 * Macros for status "okay" instances of each compatible
 *//*
 * Macros for compatibles with status "okay" nodes
 *//* Macros for iterating over all nodes and enabled nodes *//*
 * Chosen nodes
 *//* 0x3 *//* 0x100 *//* 0x4 *//* 0x3f8 *//* Generic property macros: *//* Pin control (pinctrl-<i>, pinctrl-names) properties: *//* Macros for properties that are special in the specification: *//* Existence and alternate IDs: *//* Ordinals for what depends directly on this node: *//* /soc *//* /ioapic@fec00000 *//* Ordinals for what this node depends on directly: *//* Node's dependency ordinal: *//* Helper macros for child nodes of this node. *//* Node's index in its parent's list of children: *//* Node parent (/soc) identifier: *//* Node's name with unit-address: *//* Node's full path: *//*
 * Devicetree node: /soc/uart@3f8
 *
 * Node identifier: DT_N_S_soc_S_uart_3f8
 *
 * Binding (compatible = ns16550):
 *   $ZEPHYR_BASE/dts/bindings/serial/ns16550.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x2f8 *//*
 * Devicetree node: /soc/uart@2f8
 *
 * Node identifier: DT_N_S_soc_S_uart_2f8
 *
 * Binding (compatible = ns16550):
 *   $ZEPHYR_BASE/dts/bindings/serial/ns16550.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x8 *//* 0xd *//* 0x71 *//* 0x70 *//*
 * Devicetree node: /soc/rtc@70
 *
 * Node identifier: DT_N_S_soc_S_rtc_70
 *
 * Binding (compatible = motorola,mc146818):
 *   $ZEPHYR_BASE/dts/bindings/rtc/motorola,mc146818.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x0 *//* 0x2 *//* 0x400 *//* 0xfed00000 *//*
 * Devicetree node: /soc/hpet@fed00000
 *
 * Node identifier: DT_N_S_soc_S_hpet_fed00000
 *
 * Binding (compatible = intel,hpet):
 *   $ZEPHYR_BASE/dts/bindings/timer/intel,hpet.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* /soc/uart@3f8 *//* /soc/uart@2f8 *//* /soc/rtc@70 *//* /soc/hpet@fed00000 *//* / *//* Node parent (/) identifier: *//*
 * Devicetree node: /soc
 *
 * Node identifier: DT_N_S_soc
 *//* 0x10000 *//* 0x21000 *//* fixed-partitions identifier: *//* /sim_flash/flash_sim@0/partitions *//* Node parent (/sim_flash/flash_sim@0/partitions) identifier: *//*
 * Devicetree node: /sim_flash/flash_sim@0/partitions/partition@21000
 *
 * Node identifier: DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x11000 *//*
 * Devicetree node: /sim_flash/flash_sim@0/partitions/partition@11000
 *
 * Node identifier: DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x1000 *//*
 * Devicetree node: /sim_flash/flash_sim@0/partitions/partition@1000
 *
 * Node identifier: DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* Bus info (controller: '/pcie0', type: '['pcie']') *//* /pcie0/can0 *//* Node parent (/pcie0/can0) identifier: *//*
 * Devicetree node: /pcie0/can0/can-transceiver
 *
 * Node identifier: DT_N_S_pcie0_S_can0_S_can_transceiver
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0xa100 *//* 0xb *//* /pcie0/can0/can-transceiver *//* /pcie0 *//* Node parent (/pcie0) identifier: *//*
 * Devicetree node: /pcie0/can0
 *
 * Node identifier: DT_N_S_pcie0_S_can0
 *
 * Binding (compatible = kvaser,pcican):
 *   $ZEPHYR_BASE/dts/bindings/can/kvaser,pcican.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//*
 * Devicetree node: /pcie0/eth0
 *
 * Node identifier: DT_N_S_pcie0_S_eth0
 *
 * Binding (compatible = intel,e1000):
 *   $ZEPHYR_BASE/dts/bindings/ethernet/intel,e1000.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* /pcie0/eth0 *//*
 * Devicetree node: /pcie0
 *
 * Node identifier: DT_N_S_pcie0
 *
 * Binding (compatible = intel,pcie):
 *   $ZEPHYR_BASE/dts/bindings/pcie/host/intel,pcie.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0xfec00000 *//*
 * Devicetree node: /ioapic@fec00000
 *
 * Node identifier: DT_N_S_ioapic_fec00000
 *
 * Binding (compatible = intel,ioapic):
 *   $ZEPHYR_BASE/dts/bindings/interrupt-controller/intel,ioapic.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* /cpus *//* Node parent (/cpus) identifier: *//*
 * Devicetree node: /cpus/cpu@0
 *
 * Node identifier: DT_N_S_cpus_S_cpu_0
 *
 * Binding (compatible = intel,x86):
 *   $ZEPHYR_BASE/dts/bindings/cpu/intel,x86.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* (No generic property macros) *//* /cpus/cpu@0 *//*
 * Devicetree node: /cpus
 *
 * Node identifier: DT_N_S_cpus
 *//* 0x2000000 *//*
 * Devicetree node: /memory@0
 *
 * Node identifier: DT_N_S_memory_0
 *//* 0xfee00000 *//*
 * Devicetree node: /loapic@fee00000
 *
 * Node identifier: DT_N_S_loapic_fee00000
 *
 * Binding (compatible = intel,loapic):
 *   $ZEPHYR_BASE/dts/bindings/interrupt-controller/intel,loapic.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//*
 * Devicetree node: /ieee802154
 *
 * Node identifier: DT_N_S_ieee802154
 *
 * Binding (compatible = zephyr,ieee802154-uart-pipe):
 *   $ZEPHYR_BASE/dts/bindings/ieee802154/zephyr,ieee802154-uart-pipe.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x400000 *//* 0x500000 *//*
 * Devicetree node: /flash@500000
 *
 * Node identifier: DT_N_S_flash_500000
 *
 * Binding (compatible = soc-nv-flash):
 *   $ZEPHYR_BASE/dts/bindings/mtd/soc-nv-flash.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* /sim_flash/flash_sim@0/partitions/partition@31000 *//*
 * Devicetree node: /eeprom1
 *
 * Node identifier: DT_N_S_eeprom1
 *
 * Binding (compatible = zephyr,emu-eeprom):
 *   $ZEPHYR_BASE/dts/bindings/mtd/zephyr,emu-eeprom.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x31000 *//* /eeprom1 *//*
 * Devicetree node: /sim_flash/flash_sim@0/partitions/partition@31000
 *
 * Node identifier: DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* /sim_flash/flash_sim@0/partitions/partition@21000 *//* /sim_flash/flash_sim@0/partitions/partition@11000 *//* /sim_flash/flash_sim@0/partitions/partition@1000 *//* /sim_flash/flash_sim@0 *//* Node parent (/sim_flash/flash_sim@0) identifier: *//*
 * Devicetree node: /sim_flash/flash_sim@0/partitions
 *
 * Node identifier: DT_N_S_sim_flash_S_flash_sim_0_S_partitions
 *
 * Binding (compatible = fixed-partitions):
 *   $ZEPHYR_BASE/dts/bindings/mtd/fixed-partitions.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//* 0x100000 *//* /sim_flash *//* Node parent (/sim_flash) identifier: *//*
 * Devicetree node: /sim_flash/flash_sim@0
 *
 * Node identifier: DT_N_S_sim_flash_S_flash_sim_0
 *
 * Binding (compatible = soc-nv-flash):
 *   $ZEPHYR_BASE/dts/bindings/mtd/soc-nv-flash.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//*
 * Devicetree node: /sim_flash
 *
 * Node identifier: DT_N_S_sim_flash
 *
 * Binding (compatible = zephyr,sim-flash):
 *   $ZEPHYR_BASE/dts/bindings/flash_controller/zephyr,sim-flash.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//*
 * Devicetree node: /eeprom0
 *
 * Node identifier: DT_N_S_eeprom0
 *
 * Binding (compatible = zephyr,sim-eeprom):
 *   $ZEPHYR_BASE/dts/bindings/mtd/zephyr,sim-eeprom.yaml
 *
 * (Descriptions have moved to the Devicetree Bindings Index
 * in the documentation.)
 *//*
 * Devicetree node: /chosen
 *
 * Node identifier: DT_N_S_chosen
 *//*
 * Devicetree node: /aliases
 *
 * Node identifier: DT_N_S_aliases
 *//* /memory@0 *//* /loapic@fee00000 *//* /ieee802154 *//* /flash@500000 *//* /eeprom0 *//* /chosen *//* /aliases *//*
 * Devicetree node: /
 *
 * Node identifier: DT_N
 *//* Used to remove brackets from around a single argument *//*
 * Generated by gen_defines.py
 *
 * DTS input file:
 *   /home/haojie/zephyrproject/zephyr/build/zephyr/zephyr.dts.pre
 *
 * Directories with bindings:
 *   $ZEPHYR_BASE/dts/bindings
 *
 * Node dependency ordering (ordinal and path):
 *   0   /
 *   1   /aliases
 *   2   /chosen
 *   3   /eeprom0
 *   4   /sim_flash
 *   5   /sim_flash/flash_sim@0
 *   6   /sim_flash/flash_sim@0/partitions
 *   7   /sim_flash/flash_sim@0/partitions/partition@31000
 *   8   /eeprom1
 *   9   /flash@500000
 *   10  /ieee802154
 *   11  /loapic@fee00000
 *   12  /memory@0
 *   13  /cpus
 *   14  /cpus/cpu@0
 *   15  /ioapic@fec00000
 *   16  /pcie0
 *   17  /pcie0/eth0
 *   18  /pcie0/can0
 *   19  /pcie0/can0/can-transceiver
 *   20  /sim_flash/flash_sim@0/partitions/partition@1000
 *   21  /sim_flash/flash_sim@0/partitions/partition@11000
 *   22  /sim_flash/flash_sim@0/partitions/partition@21000
 *   23  /soc
 *   24  /soc/hpet@fed00000
 *   25  /soc/rtc@70
 *   26  /soc/uart@2f8
 *   27  /soc/uart@3f8
 *
 * Definitions derived from these nodes in dependency order are next,
 * followed by /chosen nodes.
 */irq_get_levelmask2BIT_MASK(CONFIG_2ND_LEVEL_INTERRUPT_BITS)65280mask3BIT_MASK(CONFIG_3RD_LEVEL_INTERRUPT_BITS)(CONFIG_1ST_LEVEL_INTERRUPT_BITS + CONFIG_2ND_LEVEL_INTERRUPT_BITS)16711680CONFIG_3RD_LEVEL_INTERRUPTS_XXXXCONFIG_3RD_LEVEL_INTERRUPTS_XXXXCONFIG_3RD_LEVEL_INTERRUPTS 1CONFIG_2ND_LEVEL_INTERRUPTS_XXXXCONFIG_2ND_LEVEL_INTERRUPTS_XXXXCONFIG_2ND_LEVEL_INTERRUPTS 1ZEPHYR_INCLUDE_IRQ_MULTILEVEL_H_defined(CONFIG_2ND_LEVEL_INTERRUPTS)defined(CONFIG_3RD_LEVEL_INTERRUPTS)/* ZEPHYR_INCLUDE_IRQ_MULTILEVEL_H_ *//**
 * @brief Returns the parent IRQ of the level 3 raw IRQ number
 *
 *
 * The parent of a 3rd level interrupt is in the 2nd byte
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 3rd level IRQ parent
 *//**
 * @brief Converts irq from level 1 to level 3 format
 *
 *
 * This routine converts the input into the level 3 irq number format
 *
 * @note Values >= 0xFF are invalid
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 3rd level IRQ number
 *//**
 * @brief Preprocessor macro to convert `irq` from level 1 to level 3 format
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 3rd level IRQ number
 *//**
 * @brief Return the 3rd level interrupt number
 *
 *
 * This routine returns the third level irq number of the zephyr irq
 * number passed in
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 3rd level IRQ number
 *//**
 * @brief Returns the parent IRQ of the level 2 raw IRQ number
 *
 *
 * The parent of a 2nd level interrupt is in the 1st byte
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 2nd level IRQ parent
 *//**
 * @brief Converts irq from level 1 to level 2 format
 *
 *
 * This routine converts the input into the level 2 irq number format
 *
 * @note Values >= 0xFF are invalid
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 2nd level IRQ number
 *//**
 * @brief Preprocessor macro to convert `irq` from level 1 to level 2 format
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 2nd level IRQ number
 *//**
 * @brief Return the 2nd level interrupt number
 *
 * This routine returns the second level irq number of the zephyr irq
 * number passed in
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 2nd level IRQ number
 *//**
 * @brief Return IRQ level
 * This routine returns the interrupt level number of the provided interrupt.
 *
 * @param irq IRQ number in its zephyr format
 *
 * @return 1 if IRQ level 1, 2 if IRQ level 2, 3 if IRQ level 3
 *//**
 * @file
 * @brief Public interface for multi-level interrupts
 *//*
 * Copyright (c) 2023 Meta
 *
 * SPDX-License-Identifier: Apache-2.0
 */DT_INST_IO_CHANNELS_INPUT(inst)DT_INST_IO_CHANNELS_INPUT_BY_IDX(inst, 0)DT_INST_IO_CHANNELS_INPUT_BY_NAME(inst,name)DT_IO_CHANNELS_INPUT_BY_NAME(DT_DRV_INST(inst), name)DT_INST_IO_CHANNELS_INPUT_BY_IDX(inst,idx)DT_IO_CHANNELS_INPUT_BY_IDX(DT_DRV_INST(inst), idx)DT_IO_CHANNELS_INPUT(node_id)DT_IO_CHANNELS_INPUT_BY_IDX(node_id, 0)DT_IO_CHANNELS_INPUT_BY_NAME(node_id,name)DT_PHA_BY_NAME(node_id, io_channels, name, input)DT_IO_CHANNELS_INPUT_BY_IDX(node_id,idx)DT_PHA_BY_IDX(node_id, io_channels, idx, input)DT_INST_IO_CHANNELS_CTLR(inst)DT_INST_IO_CHANNELS_CTLR_BY_IDX(inst, 0)DT_INST_IO_CHANNELS_CTLR_BY_NAME(inst,name)DT_IO_CHANNELS_CTLR_BY_NAME(DT_DRV_INST(inst), name)DT_INST_IO_CHANNELS_CTLR_BY_IDX(inst,idx)DT_IO_CHANNELS_CTLR_BY_IDX(DT_DRV_INST(inst), idx)DT_IO_CHANNELS_CTLR(node_id)DT_IO_CHANNELS_CTLR_BY_IDX(node_id, 0)DT_IO_CHANNELS_CTLR_BY_NAME(node_id,name)DT_PHANDLE_BY_NAME(node_id, io_channels, name)DT_IO_CHANNELS_CTLR_BY_IDX(node_id,idx)DT_PHANDLE_BY_IDX(node_id, io_channels, idx)ZEPHYR_INCLUDE_DEVICETREE_IO_CHANNELS_H_/* ZEPHYR_INCLUDE_DEVICETREE_IO_CHANNELS_H_ *//**
 * @brief Equivalent to DT_INST_IO_CHANNELS_INPUT_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the input cell in the specifier at index 0
 *//**
 * @brief Get an input cell from the "DT_DRV_INST(inst)" io-channels
 *        property by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of an io-channels element
 *             as defined by the instance's io-channel-names property
 * @return the input cell in the specifier at the named element
 * @see DT_IO_CHANNELS_INPUT_BY_NAME()
 *//**
 * @brief Get an input cell from the "DT_DRV_INST(inst)" io-channels
 *        property at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into io-channels property
 * @return the input cell in the specifier at index "idx"
 * @see DT_IO_CHANNELS_INPUT_BY_IDX()
 *//**
 * @brief Equivalent to DT_IO_CHANNELS_INPUT_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with an io-channels property
 * @return the input cell in the specifier at index 0
 * @see DT_IO_CHANNELS_INPUT_BY_IDX()
 *//**
 * @brief Get an io-channels specifier input cell by name
 *
 * This macro only works for io-channels specifiers with cells named
 * "input". Refer to the node's binding to check if necessary.
 *
 * Example devicetree fragment:
 *
 *     adc1: adc@... {
 *             compatible = "vnd,adc";
 *             #io-channel-cells = <1>;
 *     };
 *
 *     adc2: adc@... {
 *             compatible = "vnd,adc";
 *             #io-channel-cells = <1>;
 *     };
 *
 *     n: node {
 *             io-channels = <&adc1 10>, <&adc2 20>;
 *             io-channel-names = "SENSOR", "BANDGAP";
 *     };
 *
 * Bindings fragment for the vnd,adc compatible:
 *
 *    io-channel-cells:
 *      - input
 *
 * Example usage:
 *
 *     DT_IO_CHANNELS_INPUT_BY_NAME(DT_NODELABEL(n), sensor) // 10
 *     DT_IO_CHANNELS_INPUT_BY_NAME(DT_NODELABEL(n), bandgap) // 20
 *
 * @param node_id node identifier for a node with an io-channels property
 * @param name lowercase-and-underscores name of an io-channels element
 *             as defined by the node's io-channel-names property
 * @return the input cell in the specifier at the named element
 * @see DT_PHA_BY_NAME()
 *//**
 * @brief Get an io-channels specifier input cell at an index
 *
 * This macro only works for io-channels specifiers with cells named
 * "input". Refer to the node's binding to check if necessary.
 *
 * Example devicetree fragment:
 *
 *     adc1: adc@... {
 *             compatible = "vnd,adc";
 *             #io-channel-cells = <1>;
 *     };
 *
 *     adc2: adc@... {
 *             compatible = "vnd,adc";
 *             #io-channel-cells = <1>;
 *     };
 *
 *     n: node {
 *             io-channels = <&adc1 10>, <&adc2 20>;
 *     };
 *
 * Bindings fragment for the vnd,adc compatible:
 *
 *    io-channel-cells:
 *      - input
 *
 * Example usage:
 *
 *     DT_IO_CHANNELS_INPUT_BY_IDX(DT_NODELABEL(n), 0) // 10
 *     DT_IO_CHANNELS_INPUT_BY_IDX(DT_NODELABEL(n), 1) // 20
 *
 * @param node_id node identifier for a node with an io-channels property
 * @param idx logical index into io-channels property
 * @return the input cell in the specifier at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_IO_CHANNELS_CTLR_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the node identifier for the node referenced at index 0
 *         in the node's "io-channels" property
 * @see DT_IO_CHANNELS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier from a DT_DRV_COMPAT instance's io-channels
 *        property by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of an io-channels element
 *             as defined by the node's io-channel-names property
 * @return the node identifier for the node referenced at the named element
 * @see DT_IO_CHANNELS_CTLR_BY_NAME()
 *//**
 * @brief Get the node identifier from a DT_DRV_COMPAT instance's io-channels
 *        property at an index
 *
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into io-channels property
 * @return the node identifier for the node referenced at index "idx"
 * @see DT_IO_CHANNELS_CTLR_BY_IDX()
 *//**
 * @brief Equivalent to DT_IO_CHANNELS_CTLR_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with an io-channels property
 * @return the node identifier for the node referenced at index 0
 *         in the node's "io-channels" property
 * @see DT_IO_CHANNELS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the node referenced by an
 *        io-channels property by name
 *
 * Example devicetree fragment:
 *
 *     adc1: adc@... { ... };
 *
 *     adc2: adc@... { ... };
 *
 *     n: node {
 *             io-channels = <&adc1 10>, <&adc2 20>;
 *             io-channel-names = "SENSOR", "BANDGAP";
 *     };
 *
 * Example usage:
 *
 *  DT_IO_CHANNELS_CTLR_BY_NAME(DT_NODELABEL(n), sensor) // DT_NODELABEL(adc1)
 *  DT_IO_CHANNELS_CTLR_BY_NAME(DT_NODELABEL(n), bandgap) // DT_NODELABEL(adc2)
 *
 * @param node_id node identifier for a node with an io-channels property
 * @param name lowercase-and-underscores name of an io-channels element
 *             as defined by the node's io-channel-names property
 * @return the node identifier for the node referenced at the named element
 * @see DT_PHANDLE_BY_NAME()
 *//**
 *
 * @brief Get the node identifier for the node referenced by an
 *        io-channels property at an index
 *
 * Example devicetree fragment:
 *
 *     adc1: adc@... { ... };
 *
 *     adc2: adc@... { ... };
 *
 *     n: node {
 *             io-channels = <&adc1 10>, <&adc2 20>;
 *     };
 *
 * Example usage:
 *
 *     DT_IO_CHANNELS_CTLR_BY_IDX(DT_NODELABEL(n), 0) // DT_NODELABEL(adc1)
 *     DT_IO_CHANNELS_CTLR_BY_IDX(DT_NODELABEL(n), 1) // DT_NODELABEL(adc2)
 *
 * @param node_id node identifier for a node with an io-channels property
 * @param idx logical index into io-channels property
 * @return the node identifier for the node referenced at index "idx"
 * @see DT_PROP_BY_PHANDLE_IDX()
 *//**
 * @defgroup devicetree-io-channels Devicetree IO Channels API
 * @ingroup devicetree
 * @{
 *//*
 * Copyright (c) 2020, Linaro Ltd.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file
 * @brief IO channels devicetree macro public API header file.
 *//home/haojie/zephyrproject/zephyr/include/zephyr/devicetreeDT_INST_CLOCKS_CELL(inst,cell)DT_INST_CLOCKS_CELL_BY_IDX(inst, 0, cell)DT_INST_CLOCKS_CELL_BY_NAME(inst,name,cell)DT_CLOCKS_CELL_BY_NAME(DT_DRV_INST(inst), name, cell)DT_INST_CLOCKS_CELL_BY_IDX(inst,idx,cell)DT_CLOCKS_CELL_BY_IDX(DT_DRV_INST(inst), idx, cell)DT_INST_CLOCKS_CTLR_BY_NAME(inst,name)DT_CLOCKS_CTLR_BY_NAME(DT_DRV_INST(inst), name)DT_INST_CLOCKS_CTLR(inst)DT_INST_CLOCKS_CTLR_BY_IDX(inst, 0)DT_INST_CLOCKS_CTLR_BY_IDX(inst,idx)DT_CLOCKS_CTLR_BY_IDX(DT_DRV_INST(inst), idx)DT_INST_NUM_CLOCKS(inst)DT_NUM_CLOCKS(DT_DRV_INST(inst))DT_INST_CLOCKS_HAS_NAME(inst,name)DT_CLOCKS_HAS_NAME(DT_DRV_INST(inst), name)DT_INST_CLOCKS_HAS_IDX(inst,idx)DT_CLOCKS_HAS_IDX(DT_DRV_INST(inst), idx)DT_CLOCKS_CELL(node_id,cell)DT_CLOCKS_CELL_BY_IDX(node_id, 0, cell)DT_CLOCKS_CELL_BY_NAME(node_id,name,cell)DT_PHA_BY_NAME(node_id, clocks, name, cell)DT_CLOCKS_CELL_BY_IDX(node_id,idx,cell)DT_PHA_BY_IDX(node_id, clocks, idx, cell)DT_CLOCKS_CTLR_BY_NAME(node_id,name)DT_PHANDLE_BY_NAME(node_id, clocks, name)DT_CLOCKS_CTLR(node_id)DT_CLOCKS_CTLR_BY_IDX(node_id, 0)DT_CLOCKS_CTLR_BY_IDX(node_id,idx)DT_PHANDLE_BY_IDX(node_id, clocks, idx)DT_NUM_CLOCKS(node_id)DT_PROP_LEN(node_id, clocks)DT_CLOCKS_HAS_NAME(node_id,name)DT_PROP_HAS_NAME(node_id, clocks, name)DT_CLOCKS_HAS_IDX(node_id,idx)DT_PROP_HAS_IDX(node_id, clocks, idx)ZEPHYR_INCLUDE_DEVICETREE_CLOCKS_H_/* ZEPHYR_INCLUDE_DEVICETREE_CLOCKS_H_ *//**
 * @brief Equivalent to DT_INST_CLOCKS_CELL_BY_IDX(inst, 0, cell)
 * @param inst DT_DRV_COMPAT instance number
 * @param cell lowercase-and-underscores cell name
 * @return the value of the cell inside the specifier at index 0
 *//**
 * @brief Get a DT_DRV_COMPAT instance's clock specifier's cell value by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a clocks element
 *             as defined by the node's clock-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_CLOCKS_CELL_BY_NAME()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's clock specifier's cell value
 *        at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into clocks property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_CLOCKS_CELL_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        clocks phandle-array property by name
 *
 * @param inst instance number
 * @param name lowercase-and-underscores name of a clocks element
 *             as defined by the node's clock-names property
 * @return the node identifier for the clock controller referenced by
 *         the named element
 * @see DT_CLOCKS_CTLR_BY_NAME()
 *//**
 * @brief Equivalent to DT_INST_CLOCKS_CTLR_BY_IDX(inst, 0)
 * @param inst instance number
 * @return a node identifier for the clocks controller at index 0
 *         in "clocks"
 * @see DT_CLOCKS_CTLR()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        "clocks" phandle-array property at an index
 *
 * @param inst instance number
 * @param idx logical index into "clocks"
 * @return the node identifier for the clock controller referenced at
 *         index "idx"
 * @see DT_CLOCKS_CTLR_BY_IDX()
 *//**
 * @brief Equivalent to DT_NUM_CLOCKS(DT_DRV_INST(inst))
 * @param inst instance number
 * @return number of elements in the clocks property
 *//**
 * @brief Equivalent to DT_CLOCK_HAS_NAME(DT_DRV_INST(inst), name)
 * @param inst DT_DRV_COMPAT instance number; may or may not have any clock-names property.
 * @param name lowercase-and-underscores clock-names cell value name to check
 * @return 1 if the clock name exists, 0 otherwise
 *//**
 * @brief Equivalent to DT_CLOCKS_HAS_IDX(DT_DRV_INST(inst), idx)
 * @param inst DT_DRV_COMPAT instance number; may or may not have any clocks property
 * @param idx index of a clocks property phandle-array whose existence to check
 * @return 1 if the index exists, 0 otherwise
 *//**
 * @brief Equivalent to DT_CLOCKS_CELL_BY_IDX(node_id, 0, cell)
 * @param node_id node identifier for a node with a clocks property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index 0
 * @see DT_CLOCKS_CELL_BY_IDX()
 *//**
 * @brief Get a clock specifier's cell value by name
 *
 * Example devicetree fragment:
 *
 *     clk1: clock-controller@... {
 *             compatible = "vnd,clock";
 *             #clock-cells = < 2 >;
 *     };
 *
 *     n: node {
 *             clocks = < &clk1 10 20 >, < &clk1 30 40 >;
 *             clock-names = "alpha", "beta";
 *     };
 *
 * Bindings fragment for the vnd,clock compatible:
 *
 *     clock-cells:
 *       - bus
 *       - bits
 *
 * Example usage:
 *
 *     DT_CLOCKS_CELL_BY_NAME(DT_NODELABEL(n), alpha, bus) // 10
 *     DT_CLOCKS_CELL_BY_NAME(DT_NODELABEL(n), beta, bits) // 40
 *
 * @param node_id node identifier for a node with a clocks property
 * @param name lowercase-and-underscores name of a clocks element
 *             as defined by the node's clock-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_PHA_BY_NAME()
 *//**
 * @brief Get a clock specifier's cell value at an index
 *
 * Example devicetree fragment:
 *
 *     clk1: clock-controller@... {
 *             compatible = "vnd,clock";
 *             #clock-cells = < 2 >;
 *     };
 *
 *     n: node {
 *             clocks = < &clk1 10 20 >, < &clk1 30 40 >;
 *     };
 *
 * Bindings fragment for the vnd,clock compatible:
 *
 *     clock-cells:
 *       - bus
 *       - bits
 *
 * Example usage:
 *
 *     DT_CLOCKS_CELL_BY_IDX(DT_NODELABEL(n), 0, bus) // 10
 *     DT_CLOCKS_CELL_BY_IDX(DT_NODELABEL(n), 1, bits) // 40
 *
 * @param node_id node identifier for a node with a clocks property
 * @param idx logical index into clocks property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        clocks phandle-array property by name
 *
 * Example devicetree fragment:
 *
 *     clk1: clock-controller@... { ... };
 *
 *     clk2: clock-controller@... { ... };
 *
 *     n: node {
 *             clocks = <&clk1 10 20>, <&clk2 30 40>;
 *             clock-names = "alpha", "beta";
 *     };
 *
 * Example usage:
 *
 *     DT_CLOCKS_CTLR_BY_NAME(DT_NODELABEL(n), beta) // DT_NODELABEL(clk2)
 *
 * @param node_id node identifier
 * @param name lowercase-and-underscores name of a clocks element
 *             as defined by the node's clock-names property
 * @return the node identifier for the clock controller referenced by name
 * @see DT_PHANDLE_BY_NAME()
 *//**
 * @brief Equivalent to DT_CLOCKS_CTLR_BY_IDX(node_id, 0)
 * @param node_id node identifier
 * @return a node identifier for the clocks controller at index 0
 *         in "clocks"
 * @see DT_CLOCKS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        "clocks" phandle-array property at an index
 *
 * Example devicetree fragment:
 *
 *     clk1: clock-controller@... { ... };
 *
 *     clk2: clock-controller@... { ... };
 *
 *     n: node {
 *             clocks = <&clk1 10 20>, <&clk2 30 40>;
 *     };
 *
 * Example usage:
 *
 *     DT_CLOCKS_CTLR_BY_IDX(DT_NODELABEL(n), 0)) // DT_NODELABEL(clk1)
 *     DT_CLOCKS_CTLR_BY_IDX(DT_NODELABEL(n), 1)) // DT_NODELABEL(clk2)
 *
 * @param node_id node identifier
 * @param idx logical index into "clocks"
 * @return the node identifier for the clock controller referenced at
 *         index "idx"
 * @see DT_PHANDLE_BY_IDX()
 *//**
 * @brief Get the number of elements in a clocks property
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             clocks = <&foo>, <&bar>;
 *     };
 *
 *     n2: node-2 {
 *             clocks = <&foo>;
 *     };
 *
 * Example usage:
 *
 *     DT_NUM_CLOCKS(DT_NODELABEL(n1)) // 2
 *     DT_NUM_CLOCKS(DT_NODELABEL(n2)) // 1
 *
 * @param node_id node identifier with a clocks property
 * @return number of elements in the property
 *//**
 * @brief Test if a node has a clock-names array property holds a given name
 *
 * This expands to 1 if the name is available as clocks-name array property cell.
 * Otherwise, it expands to 0.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             clocks = <...>, <...>;
 *             clock-names = "alpha", "beta";
 *     };
 *
 *     n2: node-2 {
 *             clocks = <...>;
 *             clock-names = "alpha";
 *     };
 *
 * Example usage:
 *
 *     DT_CLOCKS_HAS_NAME(DT_NODELABEL(n1), alpha) // 1
 *     DT_CLOCKS_HAS_NAME(DT_NODELABEL(n1), beta)  // 1
 *     DT_CLOCKS_HAS_NAME(DT_NODELABEL(n2), beta)  // 0
 *
 * @param node_id node identifier; may or may not have any clock-names property.
 * @param name lowercase-and-underscores clock-names cell value name to check
 * @return 1 if the clock name exists, 0 otherwise
 *//**
 * @brief Test if a node has a clocks phandle-array property at a given index
 *
 * This expands to 1 if the given index is valid clocks property phandle-array index.
 * Otherwise, it expands to 0.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             clocks = <...>, <...>;
 *     };
 *
 *     n2: node-2 {
 *             clocks = <...>;
 *     };
 *
 * Example usage:
 *
 *     DT_CLOCKS_HAS_IDX(DT_NODELABEL(n1), 0) // 1
 *     DT_CLOCKS_HAS_IDX(DT_NODELABEL(n1), 1) // 1
 *     DT_CLOCKS_HAS_IDX(DT_NODELABEL(n1), 2) // 0
 *     DT_CLOCKS_HAS_IDX(DT_NODELABEL(n2), 1) // 0
 *
 * @param node_id node identifier; may or may not have any clocks property
 * @param idx index of a clocks property phandle-array whose existence to check
 * @return 1 if the index exists, 0 otherwise
 *//**
 * @defgroup devicetree-clocks Devicetree Clocks API
 * @ingroup devicetree
 * @{
 *//**
 * @file
 * @brief Clocks Devicetree macro public API header file.
 */DT_INST_GPIO_FLAGS(inst,gpio_pha)DT_INST_GPIO_FLAGS_BY_IDX(inst, gpio_pha, 0)DT_INST_GPIO_FLAGS_BY_IDX(inst,gpio_pha,idx)DT_GPIO_FLAGS_BY_IDX(DT_DRV_INST(inst), gpio_pha, idx)DT_INST_GPIO_PIN(inst,gpio_pha)DT_INST_GPIO_PIN_BY_IDX(inst, gpio_pha, 0)DT_INST_GPIO_PIN_BY_IDX(inst,gpio_pha,idx)DT_GPIO_PIN_BY_IDX(DT_DRV_INST(inst), gpio_pha, idx)DT_INST_GPIO_LABEL(inst,gpio_pha)DT_INST_GPIO_LABEL_BY_IDX(inst, gpio_pha, 0) __DEPRECATED_MACRODT_INST_GPIO_LABEL_BY_IDX(inst,gpio_pha,idx)DT_GPIO_LABEL_BY_IDX(DT_DRV_INST(inst), gpio_pha, idx) __DEPRECATED_MACRODT_GPIO_HOG_FLAGS_BY_IDX(node_id,idx)COND_CODE_1(IS_ENABLED(DT_CAT4(node_id, _GPIO_HOGS_IDX_, idx, _VAL_flags_EXISTS)), (DT_CAT4(node_id, _GPIO_HOGS_IDX_, idx, _VAL_flags)), (0))DT_GPIO_HOG_PIN_BY_IDX(node_id,idx)DT_CAT4(node_id, _GPIO_HOGS_IDX_, idx, _VAL_pin)DT_NUM_GPIO_HOGS(node_id)COND_CODE_1(IS_ENABLED(DT_CAT(node_id, _GPIO_HOGS_EXISTS)), (DT_CAT(node_id, _GPIO_HOGS_NUM)), (0))DT_GPIO_FLAGS(node_id,gpio_pha)DT_GPIO_FLAGS_BY_IDX(node_id, gpio_pha, 0)DT_GPIO_FLAGS_BY_IDX(node_id,gpio_pha,idx)DT_PHA_BY_IDX_OR(node_id, gpio_pha, idx, flags, 0)DT_GPIO_PIN(node_id,gpio_pha)DT_GPIO_PIN_BY_IDX(node_id, gpio_pha, 0)DT_GPIO_PIN_BY_IDX(node_id,gpio_pha,idx)DT_PHA_BY_IDX(node_id, gpio_pha, idx, pin)DT_GPIO_LABEL(node_id,gpio_pha)DT_GPIO_LABEL_BY_IDX(node_id, gpio_pha, 0) __DEPRECATED_MACRODT_GPIO_LABEL_BY_IDX(node_id,gpio_pha,idx)DT_PROP(DT_GPIO_CTLR_BY_IDX(node_id, gpio_pha, idx), label) __DEPRECATED_MACRODT_GPIO_CTLR(node_id,gpio_pha)DT_GPIO_CTLR_BY_IDX(node_id, gpio_pha, 0)DT_GPIO_CTLR_BY_IDX(node_id,gpio_pha,idx)DT_PHANDLE_BY_IDX(node_id, gpio_pha, idx)ZEPHYR_INCLUDE_DEVICETREE_GPIO_H_/* ZEPHYR_INCLUDE_DEVICETREE_GPIO_H_ *//**
 * @brief Equivalent to DT_INST_GPIO_FLAGS_BY_IDX(inst, gpio_pha, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return the flags cell value at index 0, or zero if there is none
 * @see DT_INST_GPIO_FLAGS_BY_IDX()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's GPIO specifier's flags cell
 *        at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the flags cell value at index "idx", or zero if there is none
 * @see DT_GPIO_FLAGS_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_GPIO_PIN_BY_IDX(inst, gpio_pha, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return the pin cell value at index 0
 * @see DT_INST_GPIO_PIN_BY_IDX()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's GPIO specifier's pin cell value
 *        at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the pin cell value at index "idx"
 * @see DT_GPIO_PIN_BY_IDX()
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_INST_GPIO_CTLR(node, gpio_pha)).
 *
 * @brief Equivalent to DT_INST_GPIO_LABEL_BY_IDX(inst, gpio_pha, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return the label property of the node referenced at index 0
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_INST_GPIO_CTLR_BY_IDX(node, gpio_pha, idx)).
 *
 * @brief Get a label property from a DT_DRV_COMPAT instance's GPIO
 *        property at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the label property of the node referenced at index "idx"
 *//**
 * @brief Get a GPIO hog specifier's flags cell at an index
 *
 * This macro expects GPIO specifiers with cells named "flags".
 * If there is no "flags" cell in the GPIO specifier, zero is returned.
 * Refer to the node's binding to check specifier cell names if necessary.
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *       compatible = "vnd,gpio";
 *       #gpio-cells = <2>;
 *
 *       n1: node-1 {
 *               gpio-hog;
 *               gpios = <0 GPIO_ACTIVE_HIGH>, <1 GPIO_ACTIVE_LOW>;
 *               output-high;
 *       };
 *
 *       n2: node-2 {
 *               gpio-hog;
 *               gpios = <3 GPIO_ACTIVE_HIGH>;
 *               output-low;
 *       };
 *     };
 *
 * Bindings fragment for the vnd,gpio compatible:
 *
 *     gpio-cells:
 *       - pin
 *       - flags
 *
 * Example usage:
 *
 *     DT_GPIO_HOG_FLAGS_BY_IDX(DT_NODELABEL(n1), 0) // GPIO_ACTIVE_HIGH
 *     DT_GPIO_HOG_FLAGS_BY_IDX(DT_NODELABEL(n1), 1) // GPIO_ACTIVE_LOW
 *     DT_GPIO_HOG_FLAGS_BY_IDX(DT_NODELABEL(n2), 0) // GPIO_ACTIVE_HIGH
 *
 * @param node_id node identifier
 * @param idx logical index into "gpios"
 * @return the flags cell value at index "idx", or zero if there is none
 *//**
 * @brief Get a GPIO hog specifier's pin cell at an index
 *
 * This macro only works for GPIO specifiers with cells named "pin".
 * Refer to the node's binding to check if necessary.
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *       compatible = "vnd,gpio";
 *       #gpio-cells = <2>;
 *
 *       n1: node-1 {
 *               gpio-hog;
 *               gpios = <0 GPIO_ACTIVE_HIGH>, <1 GPIO_ACTIVE_LOW>;
 *               output-high;
 *       };
 *
 *       n2: node-2 {
 *               gpio-hog;
 *               gpios = <3 GPIO_ACTIVE_HIGH>;
 *               output-low;
 *       };
 *     };
 *
 * Bindings fragment for the vnd,gpio compatible:
 *
 *     gpio-cells:
 *       - pin
 *       - flags
 *
 * Example usage:
 *
 *     DT_GPIO_HOG_PIN_BY_IDX(DT_NODELABEL(n1), 0) // 0
 *     DT_GPIO_HOG_PIN_BY_IDX(DT_NODELABEL(n1), 1) // 1
 *     DT_GPIO_HOG_PIN_BY_IDX(DT_NODELABEL(n2), 0) // 3
 *
 * @param node_id node identifier
 * @param idx logical index into "gpios"
 * @return the pin cell value at index "idx"
 *//**
 * @brief Get the number of GPIO hogs in a node
 *
 * This expands to the number of hogged GPIOs, or zero if there are none.
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *       compatible = "vnd,gpio";
 *       #gpio-cells = <2>;
 *
 *       n1: node-1 {
 *               gpio-hog;
 *               gpios = <0 GPIO_ACTIVE_HIGH>, <1 GPIO_ACTIVE_LOW>;
 *               output-high;
 *       };
 *
 *       n2: node-2 {
 *               gpio-hog;
 *               gpios = <3 GPIO_ACTIVE_HIGH>;
 *               output-low;
 *       };
 *     };
 *
 * Bindings fragment for the vnd,gpio compatible:
 *
 *     gpio-cells:
 *       - pin
 *       - flags
 *
 * Example usage:
 *
 *     DT_NUM_GPIO_HOGS(DT_NODELABEL(n1)) // 2
 *     DT_NUM_GPIO_HOGS(DT_NODELABEL(n2)) // 1
 *
 * @param node_id node identifier; may or may not be a GPIO hog node.
 * @return number of hogged GPIOs in the node
 *//**
 * @brief Equivalent to DT_GPIO_FLAGS_BY_IDX(node_id, gpio_pha, 0)
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return the flags cell value at index 0, or zero if there is none
 * @see DT_GPIO_FLAGS_BY_IDX()
 *//**
 * @brief Get a GPIO specifier's flags cell at an index
 *
 * This macro expects GPIO specifiers with cells named "flags".
 * If there is no "flags" cell in the GPIO specifier, zero is returned.
 * Refer to the node's binding to check specifier cell names if necessary.
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *             compatible = "vnd,gpio";
 *             #gpio-cells = <2>;
 *     };
 *
 *     gpio2: gpio@... {
 *             compatible = "vnd,gpio";
 *             #gpio-cells = <2>;
 *     };
 *
 *     n: node {
 *             gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                     <&gpio2 30 GPIO_ACTIVE_HIGH>;
 *     };
 *
 * Bindings fragment for the vnd,gpio compatible:
 *
 *     gpio-cells:
 *       - pin
 *       - flags
 *
 * Example usage:
 *
 *     DT_GPIO_FLAGS_BY_IDX(DT_NODELABEL(n), gpios, 0) // GPIO_ACTIVE_LOW
 *     DT_GPIO_FLAGS_BY_IDX(DT_NODELABEL(n), gpios, 1) // GPIO_ACTIVE_HIGH
 *
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the flags cell value at index "idx", or zero if there is none
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Equivalent to DT_GPIO_PIN_BY_IDX(node_id, gpio_pha, 0)
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return the pin cell value at index 0
 * @see DT_GPIO_PIN_BY_IDX()
 *//**
 * @brief Get a GPIO specifier's pin cell at an index
 *
 * This macro only works for GPIO specifiers with cells named "pin".
 * Refer to the node's binding to check if necessary.
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *             compatible = "vnd,gpio";
 *             #gpio-cells = <2>;
 *     };
 *
 *     gpio2: gpio@... {
 *             compatible = "vnd,gpio";
 *             #gpio-cells = <2>;
 *     };
 *
 *     n: node {
 *             gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                     <&gpio2 30 GPIO_ACTIVE_HIGH>;
 *     };
 *
 * Bindings fragment for the vnd,gpio compatible:
 *
 *     gpio-cells:
 *       - pin
 *       - flags
 *
 * Example usage:
 *
 *     DT_GPIO_PIN_BY_IDX(DT_NODELABEL(n), gpios, 0) // 10
 *     DT_GPIO_PIN_BY_IDX(DT_NODELABEL(n), gpios, 1) // 30
 *
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the pin cell value at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_GPIO_CTLR(node, gpio_pha)).
 *
 * @brief Equivalent to DT_GPIO_LABEL_BY_IDX(node_id, gpio_pha, 0)
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return the label property of the node referenced at index 0
 * @see DT_GPIO_LABEL_BY_IDX()
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_GPIO_CTLR_BY_IDX(node, gpio_pha, idx)).
 *
 * @brief Get a label property from a gpio phandle-array property
 *        at an index
 *
 * It's an error if the GPIO controller node referenced by the phandle
 * in node_id's "gpio_pha" property at index "idx" has no label
 * property.
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *             label = "GPIO_1";
 *     };
 *
 *     gpio2: gpio@... {
 *             label = "GPIO_2";
 *     };
 *
 *     n: node {
 *             gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                     <&gpio2 30 GPIO_ACTIVE_HIGH>;
 *     };
 *
 * Example usage:
 *
 *     DT_GPIO_LABEL_BY_IDX(DT_NODELABEL(n), gpios, 1) // "GPIO_2"
 *
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the label property of the node referenced at index "idx"
 * @see DT_PHANDLE_BY_IDX()
 *//**
 * @brief Equivalent to DT_GPIO_CTLR_BY_IDX(node_id, gpio_pha, 0)
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @return a node identifier for the gpio controller at index 0
 *         in "gpio_pha"
 * @see DT_GPIO_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        gpio phandle-array property at an index
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... { };
 *
 *     gpio2: gpio@... { };
 *
 *     n: node {
 *             gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                     <&gpio2 30 GPIO_ACTIVE_HIGH>;
 *     };
 *
 * Example usage:
 *
 *     DT_GPIO_CTLR_BY_IDX(DT_NODELABEL(n), gpios, 1) // DT_NODELABEL(gpio2)
 *
 * @param node_id node identifier
 * @param gpio_pha lowercase-and-underscores GPIO property with
 *        type "phandle-array"
 * @param idx logical index into "gpio_pha"
 * @return the node identifier for the gpio controller referenced at
 *         index "idx"
 * @see DT_PHANDLE_BY_IDX()
 *//**
 * @defgroup devicetree-gpio Devicetree GPIO API
 * @ingroup devicetree
 * @{
 *//*
 * Copyright (c) 2020, Linaro Ltd.
 * Copyright (c) 2020 Nordic Semiconductor
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file
 * @brief GPIO Devicetree macro public API header file.
 */DT_INST_SPI_DEV_CS_GPIOS_FLAGS(inst)DT_SPI_DEV_CS_GPIOS_FLAGS(DT_DRV_INST(inst))DT_INST_SPI_DEV_CS_GPIOS_PIN(inst)DT_SPI_DEV_CS_GPIOS_PIN(DT_DRV_INST(inst))DT_INST_SPI_DEV_CS_GPIOS_LABEL(inst)DT_SPI_DEV_CS_GPIOS_LABEL(DT_DRV_INST(inst)) __DEPRECATED_MACRODT_INST_SPI_DEV_CS_GPIOS_CTLR(inst)DT_SPI_DEV_CS_GPIOS_CTLR(DT_DRV_INST(inst))DT_INST_SPI_DEV_HAS_CS_GPIOS(inst)DT_SPI_DEV_HAS_CS_GPIOS(DT_DRV_INST(inst))DT_SPI_DEV_CS_GPIOS_FLAGS(spi_dev)DT_GPIO_FLAGS_BY_IDX(DT_BUS(spi_dev), cs_gpios, DT_REG_ADDR(spi_dev))DT_SPI_DEV_CS_GPIOS_PIN(spi_dev)DT_GPIO_PIN_BY_IDX(DT_BUS(spi_dev), cs_gpios, DT_REG_ADDR(spi_dev))DT_SPI_DEV_CS_GPIOS_LABEL(spi_dev)DT_GPIO_LABEL_BY_IDX(DT_BUS(spi_dev), cs_gpios, DT_REG_ADDR(spi_dev)) __DEPRECATED_MACRODT_SPI_DEV_CS_GPIOS_CTLR(spi_dev)DT_GPIO_CTLR_BY_IDX(DT_BUS(spi_dev), cs_gpios, DT_REG_ADDR(spi_dev))DT_SPI_DEV_HAS_CS_GPIOS(spi_dev)DT_SPI_HAS_CS_GPIOS(DT_BUS(spi_dev))DT_SPI_NUM_CS_GPIOS(spi)COND_CODE_1(DT_SPI_HAS_CS_GPIOS(spi), (DT_PROP_LEN(spi, cs_gpios)), (0))DT_SPI_HAS_CS_GPIOS(spi)DT_NODE_HAS_PROP(spi, cs_gpios)ZEPHYR_INCLUDE_DEVICETREE_SPI_H_/* ZEPHYR_INCLUDE_DEVICETREE_SPI_H_ *//**
 * @brief DT_SPI_DEV_CS_GPIOS_FLAGS(DT_DRV_INST(inst)).
 * @param inst DT_DRV_COMPAT instance number
 * @return flags value of the instance's chip select GPIO specifier,
 *         or zero if there is none
 * @see DT_SPI_DEV_CS_GPIOS_FLAGS()
 *//**
 * @brief Equivalent to DT_SPI_DEV_CS_GPIOS_PIN(DT_DRV_INST(inst)).
 * @param inst DT_DRV_COMPAT instance number
 * @return pin number of the instance's chip select GPIO
 * @see DT_SPI_DEV_CS_GPIOS_PIN()
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_INST_SPI_DEV_CS_GPIOS_CTLR(node)).
 *
 * @brief Get GPIO controller name for a SPI device instance
 * This is equivalent to DT_SPI_DEV_CS_GPIOS_LABEL(DT_DRV_INST(inst)).
 * @param inst DT_DRV_COMPAT instance number
 * @return label property of the instance's chip select GPIO controller
 * @see DT_SPI_DEV_CS_GPIOS_LABEL()
 *//**
 * @brief Get GPIO controller node identifier for a SPI device instance
 * This is equivalent to DT_SPI_DEV_CS_GPIOS_CTLR(DT_DRV_INST(inst)).
 * @param inst DT_DRV_COMPAT instance number
 * @return node identifier for instance's chip select GPIO controller
 * @see DT_SPI_DEV_CS_GPIOS_CTLR()
 *//**
 * @brief Equivalent to DT_SPI_DEV_HAS_CS_GPIOS(DT_DRV_INST(inst)).
 * @param inst DT_DRV_COMPAT instance number
 * @return 1 if the instance's bus has a CS pin at index
 *         DT_INST_REG_ADDR(inst), 0 otherwise
 * @see DT_SPI_DEV_HAS_CS_GPIOS()
 *//**
 * @brief Get a SPI device's chip select GPIO flags
 *
 * Example devicetree fragment:
 *
 *     spi1: spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>;
 *
 *             a: spi-dev-a@0 {
 *                     reg = <0>;
 *             };
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_DEV_CS_GPIOS_FLAGS(DT_NODELABEL(a)) // GPIO_ACTIVE_LOW
 *
 * If the GPIO specifier for spi_dev's entry in its bus node's
 * cs-gpios property has no flags cell, this expands to zero.
 *
 * @param spi_dev a SPI device node identifier
 * @return flags value of spi_dev's chip select GPIO specifier, or
 *         zero if there is none
 *//**
 * @brief Get a SPI device's chip select GPIO pin number
 *
 * It's an error if the GPIO specifier for spi_dev's entry in its
 * bus node's cs-gpios property has no pin cell.
 *
 * Example devicetree fragment:
 *
 *     spi1: spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                        <&gpio2 20 GPIO_ACTIVE_LOW>;
 *
 *             a: spi-dev-a@0 {
 *                     reg = <0>;
 *             };
 *
 *             b: spi-dev-b@1 {
 *                     reg = <1>;
 *             };
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_DEV_CS_GPIOS_PIN(DT_NODELABEL(a)) // 10
 *     DT_SPI_DEV_CS_GPIOS_PIN(DT_NODELABEL(b)) // 20
 *
 * @param spi_dev a SPI device node identifier
 * @return pin number of spi_dev's chip select GPIO
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_SPI_DEV_CS_GPIOS_CTLR(node)).
 *
 * @brief Get a SPI device's chip select GPIO controller's label property
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... {
 *             label = "GPIO_1";
 *     };
 *
 *     gpio2: gpio@... {
 *             label = "GPIO_2";
 *     };
 *
 *     spi1: spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                        <&gpio2 20 GPIO_ACTIVE_LOW>;
 *
 *             a: spi-dev-a@0 {
 *                     reg = <0>;
 *             };
 *
 *             b: spi-dev-b@1 {
 *                     reg = <1>;
 *             };
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_DEV_CS_GPIOS_LABEL(DT_NODELABEL(a)) // "GPIO_1"
 *     DT_SPI_DEV_CS_GPIOS_LABEL(DT_NODELABEL(b)) // "GPIO_2"
 *
 * @param spi_dev a SPI device node identifier
 * @return label property of spi_dev's chip select GPIO controller
 *//**
 * @brief Get a SPI device's chip select GPIO controller's node identifier
 *
 * Example devicetree fragment:
 *
 *     gpio1: gpio@... { ... };
 *
 *     gpio2: gpio@... { ... };
 *
 *     spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                        <&gpio2 20 GPIO_ACTIVE_LOW>;
 *
 *             a: spi-dev-a@0 {
 *                     reg = <0>;
 *             };
 *
 *             b: spi-dev-b@1 {
 *                     reg = <1>;
 *             };
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_DEV_CS_GPIOS_CTLR(DT_NODELABEL(a)) // DT_NODELABEL(gpio1)
 *     DT_SPI_DEV_CS_GPIOS_CTLR(DT_NODELABEL(b)) // DT_NODELABEL(gpio2)
 *
 * @param spi_dev a SPI device node identifier
 * @return node identifier for spi_dev's chip select GPIO controller
 *//**
 * @brief Does a SPI device have a chip select line configured?
 * Example devicetree fragment:
 *
 *     spi1: spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                        <&gpio2 20 GPIO_ACTIVE_LOW>;
 *
 *             a: spi-dev-a@0 {
 *                     reg = <0>;
 *             };
 *
 *             b: spi-dev-b@1 {
 *                     reg = <1>;
 *             };
 *     };
 *
 *     spi2: spi@... {
 *             compatible = "vnd,spi";
 *             c: spi-dev-c@0 {
 *                     reg = <0>;
 *             };
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_DEV_HAS_CS_GPIOS(DT_NODELABEL(a)) // 1
 *     DT_SPI_DEV_HAS_CS_GPIOS(DT_NODELABEL(b)) // 1
 *     DT_SPI_DEV_HAS_CS_GPIOS(DT_NODELABEL(c)) // 0
 *
 * @param spi_dev a SPI device node identifier
 * @return 1 if spi_dev's bus node DT_BUS(spi_dev) has a chip select
 *         pin at index DT_REG_ADDR(spi_dev), 0 otherwise
 *//**
 * @brief Number of chip select GPIOs in a SPI controller's cs-gpios property
 *
 * Example devicetree fragment:
 *
 *     spi1: spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                        <&gpio2 20 GPIO_ACTIVE_LOW>;
 *     };
 *
 *     spi2: spi@... {
 *             compatible = "vnd,spi";
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_NUM_CS_GPIOS(DT_NODELABEL(spi1)) // 2
 *     DT_SPI_NUM_CS_GPIOS(DT_NODELABEL(spi2)) // 0
 *
 * @param spi a SPI bus controller node identifier
 * @return Logical length of spi's cs-gpios property, or 0 if "spi" doesn't
 *         have a cs-gpios property
 *//**
 * @brief Does a SPI controller node have chip select GPIOs configured?
 *
 * SPI bus controllers use the "cs-gpios" property for configuring
 * chip select GPIOs. Its value is a phandle-array which specifies the
 * chip select lines.
 *
 * Example devicetree fragment:
 *
 *     spi1: spi@... {
 *             compatible = "vnd,spi";
 *             cs-gpios = <&gpio1 10 GPIO_ACTIVE_LOW>,
 *                        <&gpio2 20 GPIO_ACTIVE_LOW>;
 *     };
 *
 *     spi2: spi@... {
 *             compatible = "vnd,spi";
 *     };
 *
 * Example usage:
 *
 *     DT_SPI_HAS_CS_GPIOS(DT_NODELABEL(spi1)) // 1
 *     DT_SPI_HAS_CS_GPIOS(DT_NODELABEL(spi2)) // 0
 *
 * @param spi a SPI bus controller node identifier
 * @return 1 if "spi" has a cs-gpios property, 0 otherwise
 *//**
 * @defgroup devicetree-spi Devicetree SPI API
 * @ingroup devicetree
 * @{
 *//*
 * Copyright (c) 2020 Nordic Semiconductor
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file
 * @brief SPI Devicetree macro public API header file.
 */DT_INST_DMAS_HAS_NAME(inst,name)DT_DMAS_HAS_NAME(DT_DRV_INST(inst), name)DT_DMAS_HAS_NAME(node_id,name)DT_PROP_HAS_NAME(node_id, dmas, name)DT_INST_DMAS_HAS_IDX(inst,idx)DT_DMAS_HAS_IDX(DT_DRV_INST(inst), idx)DT_DMAS_HAS_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _P_dmas_IDX_, idx, _EXISTS))DT_INST_DMAS_CELL_BY_NAME(inst,name,cell)DT_DMAS_CELL_BY_NAME(DT_DRV_INST(inst), name, cell)DT_DMAS_CELL_BY_NAME(node_id,name,cell)DT_PHA_BY_NAME(node_id, dmas, name, cell)DT_INST_DMAS_CELL_BY_IDX(inst,idx,cell)DT_PHA_BY_IDX(DT_DRV_INST(inst), dmas, idx, cell)DT_DMAS_CELL_BY_IDX(node_id,idx,cell)DT_PHA_BY_IDX(node_id, dmas, idx, cell)DT_INST_DMAS_CTLR(inst)DT_INST_DMAS_CTLR_BY_IDX(inst, 0)DT_INST_DMAS_CTLR_BY_NAME(inst,name)DT_DMAS_CTLR_BY_NAME(DT_DRV_INST(inst), name)DT_INST_DMAS_CTLR_BY_IDX(inst,idx)DT_DMAS_CTLR_BY_IDX(DT_DRV_INST(inst), idx)DT_DMAS_CTLR(node_id)DT_DMAS_CTLR_BY_IDX(node_id, 0)DT_DMAS_CTLR_BY_NAME(node_id,name)DT_PHANDLE_BY_NAME(node_id, dmas, name)DT_DMAS_CTLR_BY_IDX(node_id,idx)DT_PHANDLE_BY_IDX(node_id, dmas, idx)ZEPHYR_INCLUDE_DEVICETREE_DMAS_H_/* ZEPHYR_INCLUDE_DEVICETREE_DMAS_H_ *//**
 * @brief Does a DT_DRV_COMPAT instance's dmas property have a named element?
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a dmas element
 *             as defined by the node's dma-names property
 * @return 1 if the dmas property has the named element, 0 otherwise
 *//**
 * @brief Does a dmas property have a named element?
 * @param node_id node identifier for a node with a dmas property
 * @param name lowercase-and-underscores name of a dmas element
 *             as defined by the node's dma-names property
 * @return 1 if the dmas property has the named element, 0 otherwise
 *//**
 * @brief Is index "idx" valid for a DT_DRV_COMPAT instance's dmas property?
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into dmas property
 * @return 1 if the "dmas" property has a specifier at index "idx", 0 otherwise
 *//**
 * @brief Is index "idx" valid for a dmas property?
 * @param node_id node identifier for a node with a dmas property
 * @param idx logical index into dmas property
 * @return 1 if the "dmas" property has index "idx", 0 otherwise
 *//**
 * @brief Get a DT_DRV_COMPAT instance's DMA specifier's cell value by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a dmas element
 *             as defined by the node's dma-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_DMAS_CELL_BY_NAME()
 *//**
 * @brief Get a DMA specifier's cell value by name
 *
 * Example devicetree fragment:
 *
 *     dma1: dma@... {
 *             compatible = "vnd,dma";
 *             #dma-cells = <2>;
 *     };
 *
 *     dma2: dma@... {
 *             compatible = "vnd,dma";
 *             #dma-cells = <2>;
 *     };
 *
 *     n: node {
 *		dmas = <&dma1 1 0x400>,
 *		       <&dma2 6 0x404>;
 *		dma-names = "tx", "rx";
 *     };
 *
 * Bindings fragment for the vnd,dma compatible:
 *
 *     dma-cells:
 *       - channel
 *       - config
 *
 * Example usage:
 *
 *     DT_DMAS_CELL_BY_NAME(DT_NODELABEL(n), tx, channel) // 1
 *     DT_DMAS_CELL_BY_NAME(DT_NODELABEL(n), rx, channel) // 6
 *     DT_DMAS_CELL_BY_NAME(DT_NODELABEL(n), tx, config) // 0x400
 *     DT_DMAS_CELL_BY_NAME(DT_NODELABEL(n), rx, config) // 0x404
 *
 * @param node_id node identifier for a node with a dmas property
 * @param name lowercase-and-underscores name of a dmas element
 *             as defined by the node's dma-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_PHA_BY_NAME()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's DMA specifier's cell value at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into dmas property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_DMAS_CELL_BY_IDX()
 *//**
 * @brief Get a DMA specifier's cell value at an index
 *
 * Example devicetree fragment:
 *
 *     dma1: dma@... {
 *             compatible = "vnd,dma";
 *             #dma-cells = <2>;
 *     };
 *
 *     dma2: dma@... {
 *             compatible = "vnd,dma";
 *             #dma-cells = <2>;
 *     };
 *
 *     n: node {
 *		dmas = <&dma1 1 0x400>,
 *		       <&dma2 6 0x404>;
 *     };
 *
 * Bindings fragment for the vnd,dma compatible:
 *
 *     dma-cells:
 *       - channel
 *       - config
 *
 * Example usage:
 *
 *     DT_DMAS_CELL_BY_IDX(DT_NODELABEL(n), 0, channel) // 1
 *     DT_DMAS_CELL_BY_IDX(DT_NODELABEL(n), 1, channel) // 6
 *     DT_DMAS_CELL_BY_IDX(DT_NODELABEL(n), 0, config) // 0x400
 *     DT_DMAS_CELL_BY_IDX(DT_NODELABEL(n), 1, config) // 0x404
 *
 * @param node_id node identifier for a node with a dmas property
 * @param idx logical index into dmas property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_DMAS_CTLR_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the node identifier for the DMA controller at index 0
 *         in the instance's "dmas" property
 * @see DT_DMAS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the DMA controller from a
 *        DT_DRV_COMPAT instance's dmas property by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a dmas element
 *             as defined by the node's dma-names property
 * @return the node identifier for the DMA controller in the named element
 * @see DT_DMAS_CTLR_BY_NAME()
 *//**
 * @brief Get the node identifier for the DMA controller from a
 *        DT_DRV_COMPAT instance's dmas property at an index
 *
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into dmas property
 * @return the node identifier for the DMA controller referenced at
 *         index "idx"
 * @see DT_DMAS_CTLR_BY_IDX()
 *//**
 * @brief Equivalent to DT_DMAS_CTLR_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with a dmas property
 * @return the node identifier for the DMA controller at index 0
 *         in the node's "dmas" property
 * @see DT_DMAS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the DMA controller from a
 *        dmas property by name
 *
 * Example devicetree fragment:
 *
 *     dma1: dma@... { ... };
 *
 *     dma2: dma@... { ... };
 *
 *     n: node {
 *		dmas = <&dma1 1 2 0x400 0x3>,
 *			<&dma2 6 3 0x404 0x5>;
 *		dma-names = "tx", "rx";
 *     };
 *
 * Example usage:
 *
 *     DT_DMAS_CTLR_BY_NAME(DT_NODELABEL(n), tx) // DT_NODELABEL(dma1)
 *     DT_DMAS_CTLR_BY_NAME(DT_NODELABEL(n), rx) // DT_NODELABEL(dma2)
 *
 * @param node_id node identifier for a node with a dmas property
 * @param name lowercase-and-underscores name of a dmas element
 *             as defined by the node's dma-names property
 * @return the node identifier for the DMA controller in the named element
 * @see DT_PHANDLE_BY_NAME()
 *//**
 * @brief Get the node identifier for the DMA controller from a
 *        dmas property at an index
 *
 * Example devicetree fragment:
 *
 *     dma1: dma@... { ... };
 *
 *     dma2: dma@... { ... };
 *
 *     n: node {
 *		dmas = <&dma1 1 2 0x400 0x3>,
 *			<&dma2 6 3 0x404 0x5>;
 *     };
 *
 * Example usage:
 *
 *     DT_DMAS_CTLR_BY_IDX(DT_NODELABEL(n), 0) // DT_NODELABEL(dma1)
 *     DT_DMAS_CTLR_BY_IDX(DT_NODELABEL(n), 1) // DT_NODELABEL(dma2)
 *
 * @param node_id node identifier for a node with a dmas property
 * @param idx logical index into dmas property
 * @return the node identifier for the DMA controller referenced at
 *         index "idx"
 * @see DT_PROP_BY_PHANDLE_IDX()
 *//**
 * @defgroup devicetree-dmas Devicetree DMA API
 * @ingroup devicetree
 * @{
 *//**
 * @file
 * @brief DMA Devicetree macro public API header file.
 */DT_INST_PWMS_FLAGS(inst)DT_INST_PWMS_FLAGS_BY_IDX(inst, 0)DT_INST_PWMS_FLAGS_BY_NAME(inst,name)DT_INST_PWMS_CELL_BY_NAME(inst, name, flags)DT_INST_PWMS_FLAGS_BY_IDX(inst,idx)DT_INST_PWMS_CELL_BY_IDX(inst, idx, flags)DT_INST_PWMS_PERIOD(inst)DT_INST_PWMS_PERIOD_BY_IDX(inst, 0)DT_INST_PWMS_PERIOD_BY_NAME(inst,name)DT_INST_PWMS_CELL_BY_NAME(inst, name, period)DT_INST_PWMS_PERIOD_BY_IDX(inst,idx)DT_INST_PWMS_CELL_BY_IDX(inst, idx, period)DT_INST_PWMS_CHANNEL(inst)DT_INST_PWMS_CHANNEL_BY_IDX(inst, 0)DT_INST_PWMS_CHANNEL_BY_NAME(inst,name)DT_INST_PWMS_CELL_BY_NAME(inst, name, channel)DT_INST_PWMS_CHANNEL_BY_IDX(inst,idx)DT_INST_PWMS_CELL_BY_IDX(inst, idx, channel)DT_INST_PWMS_CELL(inst,cell)DT_INST_PWMS_CELL_BY_IDX(inst, 0, cell)DT_INST_PWMS_CELL_BY_NAME(inst,name,cell)DT_PWMS_CELL_BY_NAME(DT_DRV_INST(inst), name, cell)DT_INST_PWMS_CELL_BY_IDX(inst,idx,cell)DT_PWMS_CELL_BY_IDX(DT_DRV_INST(inst), idx, cell)DT_INST_PWMS_CTLR(inst)DT_INST_PWMS_CTLR_BY_IDX(inst, 0)DT_INST_PWMS_CTLR_BY_NAME(inst,name)DT_PWMS_CTLR_BY_NAME(DT_DRV_INST(inst), name)DT_INST_PWMS_CTLR_BY_IDX(inst,idx)DT_PWMS_CTLR_BY_IDX(DT_DRV_INST(inst), idx)DT_PWMS_FLAGS(node_id)DT_PWMS_FLAGS_BY_IDX(node_id, 0)DT_PWMS_FLAGS_BY_NAME(node_id,name)DT_PHA_BY_NAME_OR(node_id, pwms, name, flags, 0)DT_PWMS_FLAGS_BY_IDX(node_id,idx)DT_PHA_BY_IDX_OR(node_id, pwms, idx, flags, 0)DT_PWMS_PERIOD(node_id)DT_PWMS_PERIOD_BY_IDX(node_id, 0)DT_PWMS_PERIOD_BY_NAME(node_id,name)DT_PWMS_CELL_BY_NAME(node_id, name, period)DT_PWMS_PERIOD_BY_IDX(node_id,idx)DT_PWMS_CELL_BY_IDX(node_id, idx, period)DT_PWMS_CHANNEL(node_id)DT_PWMS_CHANNEL_BY_IDX(node_id, 0)DT_PWMS_CHANNEL_BY_NAME(node_id,name)DT_PWMS_CELL_BY_NAME(node_id, name, channel)DT_PWMS_CHANNEL_BY_IDX(node_id,idx)DT_PWMS_CELL_BY_IDX(node_id, idx, channel)DT_PWMS_CELL(node_id,cell)DT_PWMS_CELL_BY_IDX(node_id, 0, cell)DT_PWMS_CELL_BY_NAME(node_id,name,cell)DT_PHA_BY_NAME(node_id, pwms, name, cell)DT_PWMS_CELL_BY_IDX(node_id,idx,cell)DT_PHA_BY_IDX(node_id, pwms, idx, cell)DT_PWMS_CTLR(node_id)DT_PWMS_CTLR_BY_IDX(node_id, 0)DT_PWMS_CTLR_BY_NAME(node_id,name)DT_PHANDLE_BY_NAME(node_id, pwms, name)DT_PWMS_CTLR_BY_IDX(node_id,idx)DT_PHANDLE_BY_IDX(node_id, pwms, idx)ZEPHYR_INCLUDE_DEVICETREE_PWMS_H_/* ZEPHYR_INCLUDE_DEVICETREE_PWMS_H_ *//**
 * @brief Equivalent to DT_INST_PWMS_FLAGS_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the flags cell value at index 0, or zero if there is none
 * @see DT_INST_PWMS_FLAGS_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_NAME(inst, name, flags)
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the flags cell value in the specifier at the named element,
 *         or zero if there is none
 * @see DT_INST_PWMS_CELL_BY_NAME()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_IDX(inst, idx, flags)
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into pwms property
 * @return the flags cell value at index "idx", or zero if there is none
 * @see DT_INST_PWMS_CELL_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_PWMS_PERIOD_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the period cell value at index 0
 * @see DT_INST_PWMS_PERIOD_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_NAME(inst, name, period)
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the period cell value in the specifier at the named element
 * @see DT_INST_PWMS_CELL_BY_NAME()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_IDX(inst, idx, period)
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into pwms property
 * @return the period cell value at index "idx"
 * @see DT_INST_PWMS_CELL_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CHANNEL_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the channel cell value at index 0
 * @see DT_INST_PWMS_CHANNEL_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_NAME(inst, name, channel)
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the channel cell value in the specifier at the named element
 * @see DT_INST_PWMS_CELL_BY_NAME()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_IDX(inst, idx, channel)
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into pwms property
 * @return the channel cell value at index "idx"
 * @see DT_INST_PWMS_CELL_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_PWMS_CELL_BY_IDX(inst, 0, cell)
 * @param inst DT_DRV_COMPAT instance number
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index 0
 *//**
 * @brief Get a DT_DRV_COMPAT instance's PWM specifier's cell value by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_PWMS_CELL_BY_NAME()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's PWM specifier's cell value
 *        at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into pwms property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 *//**
 * @brief Equivalent to DT_INST_PWMS_CTLR_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the node identifier for the PWM controller at index 0
 *         in the instance's "pwms" property
 * @see DT_PWMS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the PWM controller from a
 *        DT_DRV_COMPAT instance's pwms property by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the node identifier for the PWM controller in the named element
 * @see DT_PWMS_CTLR_BY_NAME()
 *//**
 * @brief Get the node identifier for the PWM controller from a
 *        DT_DRV_COMPAT instance's pwms property at an index
 *
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into pwms property
 * @return the node identifier for the PWM controller referenced at
 *         index "idx"
 * @see DT_PWMS_CTLR_BY_IDX()
 *//**
 * @brief Equivalent to DT_PWMS_FLAGS_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with a pwms property
 * @return the flags cell value at index 0, or zero if there is none
 * @see DT_PWMS_FLAGS_BY_IDX()
 *//**
 * @brief Get a PWM specifier's flags cell value by name
 *
 * This macro expects PWM specifiers with cells named "flags".
 * If there is no "flags" cell in the PWM specifier, zero is returned.
 * Refer to the node's binding to check specifier cell names if necessary.
 *
 * This is equivalent to DT_PWMS_CELL_BY_NAME(node_id, name, flags) if
 * there is a flags cell, but expands to zero if there is none.
 *
 * @param node_id node identifier for a node with a pwms property
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the flags cell value in the specifier at the named element,
 *         or zero if there is none
 * @see DT_PWMS_CELL_BY_NAME()
 *//**
 * @brief Get a PWM specifier's flags cell value at an index
 *
 * This macro expects PWM specifiers with cells named "flags".
 * If there is no "flags" cell in the PWM specifier, zero is returned.
 * Refer to the node's binding to check specifier cell names if necessary.
 *
 * This is equivalent to DT_PWMS_CELL_BY_IDX(node_id, idx, flags).
 *
 * @param node_id node identifier for a node with a pwms property
 * @param idx logical index into pwms property
 * @return the flags cell value at index "idx", or zero if there is none
 * @see DT_PWMS_CELL_BY_IDX()
 *//**
 * @brief Equivalent to DT_PWMS_PERIOD_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with a pwms property
 * @return the period cell value at index 0
 * @see DT_PWMS_PERIOD_BY_IDX()
 *//**
 * @brief Get a PWM specifier's period cell value by name
 *
 * This macro only works for PWM specifiers with cells named "period".
 * Refer to the node's binding to check if necessary.
 *
 * This is equivalent to DT_PWMS_CELL_BY_NAME(node_id, name, period).
 *
 * @param node_id node identifier for a node with a pwms property
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the period cell value in the specifier at the named element
 * @see DT_PWMS_CELL_BY_NAME()
 *//**
 * @brief Get PWM specifier's period cell value at an index
 *
 * This macro only works for PWM specifiers with cells named "period".
 * Refer to the node's binding to check if necessary.
 *
 * This is equivalent to DT_PWMS_CELL_BY_IDX(node_id, idx, period).
 *
 * @param node_id node identifier for a node with a pwms property
 * @param idx logical index into pwms property
 * @return the period cell value at index "idx"
 * @see DT_PWMS_CELL_BY_IDX()
 *//**
 * @brief Equivalent to DT_PWMS_CHANNEL_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with a pwms property
 * @return the channel cell value at index 0
 * @see DT_PWMS_CHANNEL_BY_IDX()
 *//**
 * @brief Get a PWM specifier's channel cell value by name
 *
 * This macro only works for PWM specifiers with cells named "channel".
 * Refer to the node's binding to check if necessary.
 *
 * This is equivalent to DT_PWMS_CELL_BY_NAME(node_id, name, channel).
 *
 * @param node_id node identifier for a node with a pwms property
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the channel cell value in the specifier at the named element
 * @see DT_PWMS_CELL_BY_NAME()
 *//**
 * @brief Get a PWM specifier's channel cell value at an index
 *
 * This macro only works for PWM specifiers with cells named "channel".
 * Refer to the node's binding to check if necessary.
 *
 * This is equivalent to DT_PWMS_CELL_BY_IDX(node_id, idx, channel).
 *
 * @param node_id node identifier for a node with a pwms property
 * @param idx logical index into pwms property
 * @return the channel cell value at index "idx"
 * @see DT_PWMS_CELL_BY_IDX()
 *//**
 * @brief Equivalent to DT_PWMS_CELL_BY_IDX(node_id, 0, cell)
 * @param node_id node identifier for a node with a pwms property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index 0
 * @see DT_PWMS_CELL_BY_IDX()
 *//**
 * @brief Get a PWM specifier's cell value by name
 *
 * Example devicetree fragment:
 *
 *     pwm1: pwm-controller@... {
 *             compatible = "vnd,pwm";
 *             #pwm-cells = <2>;
 *     };
 *
 *     pwm2: pwm-controller@... {
 *             compatible = "vnd,pwm";
 *             #pwm-cells = <2>;
 *     };
 *
 *     n: node {
 *             pwms = <&pwm1 1 200000 PWM_POLARITY_NORMAL>,
 *                    <&pwm2 3 100000 PWM_POLARITY_INVERTED>;
 *             pwm-names = "alpha", "beta";
 *     };
 *
 * Bindings fragment for the "vnd,pwm" compatible:
 *
 *     pwm-cells:
 *       - channel
 *       - period
 *       - flags
 *
 * Example usage:
 *
 *     DT_PWMS_CELL_BY_NAME(DT_NODELABEL(n), alpha, channel) // 1
 *     DT_PWMS_CELL_BY_NAME(DT_NODELABEL(n), beta, channel)  // 3
 *     DT_PWMS_CELL_BY_NAME(DT_NODELABEL(n), alpha, period)  // 200000
 *     DT_PWMS_CELL_BY_NAME(DT_NODELABEL(n), beta, period)   // 100000
 *     DT_PWMS_CELL_BY_NAME(DT_NODELABEL(n), alpha, flags)   // PWM_POLARITY_NORMAL
 *     DT_PWMS_CELL_BY_NAME(DT_NODELABEL(n), beta, flags)    // PWM_POLARITY_INVERTED
 *
 * @param node_id node identifier for a node with a pwms property
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_PHA_BY_NAME()
 *//**
 * @brief Get PWM specifier's cell value at an index
 *
 * Example devicetree fragment:
 *
 *     pwm1: pwm-controller@... {
 *             compatible = "vnd,pwm";
 *             #pwm-cells = <2>;
 *     };
 *
 *     pwm2: pwm-controller@... {
 *             compatible = "vnd,pwm";
 *             #pwm-cells = <2>;
 *     };
 *
 *     n: node {
 *             pwms = <&pwm1 1 200000 PWM_POLARITY_NORMAL>,
 *                    <&pwm2 3 100000 PWM_POLARITY_INVERTED>;
 *     };
 *
 * Bindings fragment for the "vnd,pwm" compatible:
 *
 *     pwm-cells:
 *       - channel
 *       - period
 *       - flags
 *
 * Example usage:
 *
 *     DT_PWMS_CELL_BY_IDX(DT_NODELABEL(n), 0, channel) // 1
 *     DT_PWMS_CELL_BY_IDX(DT_NODELABEL(n), 1, channel) // 3
 *     DT_PWMS_CELL_BY_IDX(DT_NODELABEL(n), 0, period)  // 200000
 *     DT_PWMS_CELL_BY_IDX(DT_NODELABEL(n), 1, period)  // 100000
 *     DT_PWMS_CELL_BY_IDX(DT_NODELABEL(n), 0, flags)   // PWM_POLARITY_NORMAL
 *     DT_PWMS_CELL_BY_IDX(DT_NODELABEL(n), 1, flags)   // PWM_POLARITY_INVERTED
 *
 * @param node_id node identifier for a node with a pwms property
 * @param idx logical index into pwms property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Equivalent to DT_PWMS_CTLR_BY_IDX(node_id, 0)
 * @param node_id node identifier for a node with a pwms property
 * @return the node identifier for the PWM controller at index 0
 *         in the node's "pwms" property
 * @see DT_PWMS_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the PWM controller from a
 *        pwms property by name
 *
 * Example devicetree fragment:
 *
 *     pwm1: pwm-controller@... { ... };
 *
 *    pwm2: pwm-controller@... { ... };
 *
 *     n: node {
 *             pwms = <&pwm1 1 PWM_POLARITY_NORMAL>,
 *                    <&pwm2 3 PWM_POLARITY_INVERTED>;
 *             pwm-names = "alpha", "beta";
 *     };
 *
 * Example usage:
 *
 *     DT_PWMS_CTLR_BY_NAME(DT_NODELABEL(n), alpha) // DT_NODELABEL(pwm1)
 *     DT_PWMS_CTLR_BY_NAME(DT_NODELABEL(n), beta)  // DT_NODELABEL(pwm2)
 *
 * @param node_id node identifier for a node with a pwms property
 * @param name lowercase-and-underscores name of a pwms element
 *             as defined by the node's pwm-names property
 * @return the node identifier for the PWM controller in the named element
 * @see DT_PHANDLE_BY_NAME()
 *//**
 * @brief Get the node identifier for the PWM controller from a
 *        pwms property at an index
 *
 * Example devicetree fragment:
 *
 *     pwm1: pwm-controller@... { ... };
 *
 *     pwm2: pwm-controller@... { ... };
 *
 *     n: node {
 *             pwms = <&pwm1 1 PWM_POLARITY_NORMAL>,
 *                    <&pwm2 3 PWM_POLARITY_INVERTED>;
 *     };
 *
 * Example usage:
 *
 *     DT_PWMS_CTLR_BY_IDX(DT_NODELABEL(n), 0) // DT_NODELABEL(pwm1)
 *     DT_PWMS_CTLR_BY_IDX(DT_NODELABEL(n), 1) // DT_NODELABEL(pwm2)
 *
 * @param node_id node identifier for a node with a pwms property
 * @param idx logical index into pwms property
 * @return the node identifier for the PWM controller referenced at
 *         index "idx"
 * @see DT_PROP_BY_PHANDLE_IDX()
 *//**
 * @defgroup devicetree-pwms Devicetree PWMs API
 * @ingroup devicetree
 * @{
 *//**
 * @file
 * @brief PWMs Devicetree macro public API header file.
 */DT_FIXED_PARTITION_ADDR(node_id)(DT_REG_ADDR(DT_MEM_FROM_FIXED_PARTITION(node_id)) + DT_REG_ADDR(node_id))DT_MTD_FROM_FIXED_PARTITION(node_id)COND_CODE_1(DT_NODE_EXISTS(DT_MEM_FROM_FIXED_PARTITION(node_id)), (DT_PARENT(DT_MEM_FROM_FIXED_PARTITION(node_id))), (DT_GPARENT(node_id)))DT_MEM_FROM_FIXED_PARTITION(node_id)COND_CODE_1(DT_NODE_HAS_COMPAT(DT_GPARENT(node_id), soc_nv_flash), (DT_GPARENT(node_id)), (DT_INVALID_NODE))DT_FIXED_PARTITION_ID(node_id)DT_CAT(node_id, _PARTITION_ID)DT_FIXED_PARTITION_EXISTS(node_id)DT_NODE_HAS_COMPAT(DT_PARENT(node_id), fixed_partitions)DT_HAS_FIXED_PARTITION_LABEL(label)IS_ENABLED(DT_CAT3(DT_COMPAT_fixed_partitions_LABEL_, label, _EXISTS))DT_NODE_BY_FIXED_PARTITION_LABEL(label)DT_CAT(DT_COMPAT_fixed_partitions_LABEL_, label)ZEPHYR_INCLUDE_DEVICETREE_FIXED_PARTITION_H_/* ZEPHYR_INCLUDE_DEVICETREE_FIXED_PARTITION_H_ *//**
 * @brief Get the absolute address of a fixed partition
 *
 * Example devicetree fragment:
 *
 *     &flash_controller {
 *             flash@1000000 {
 *                     compatible = "soc-nv-flash";
 *                     partitions {
 *                             compatible = "fixed-partitions";
 *                             storage_partition: partition@3a000 {
 *                                     label = "storage";
 *                             };
 *                     };
 *             };
 *     };
 *
 * Here, the "storage" partition is seen to belong to flash memory
 * starting at address 0x1000000. The partition's unit address of
 * 0x3a000 represents an offset inside that flash memory.
 *
 * Example usage:
 *
 *     DT_FIXED_PARTITION_ADDR(DT_NODELABEL(storage_partition)) // 0x103a000
 *
 * This macro can only be used with partitions of internal memory
 * addressable by the CPU. Otherwise, it may produce a compile-time
 * error, such as: `'__REG_IDX_0_VAL_ADDRESS' undeclared`.
 *
 * @param node_id node identifier for a fixed-partitions child node
 * @return the partition's offset plus the base address of the flash
 * node containing it.
 *//**
 * @brief Get the node identifier of the flash controller for a partition
 * @param node_id node identifier for a fixed-partitions child node
 * @return the node identifier of the memory technology device that
 * contains the fixed-partitions node.
 *//**
 * @brief Get the node identifier of the flash memory for a partition
 * @param node_id node identifier for a fixed-partitions child node
 * @return the node identifier of the internal memory that contains the
 * fixed-partitions node, or @ref DT_INVALID_NODE if it doesn't exist.
 *//**
 * @brief Get a numeric identifier for a fixed partition
 * @param node_id node identifier for a fixed-partitions child node
 * @return the partition's ID, a unique zero-based index number
 *//**
 * @brief Test if fixed-partition compatible node exists
 *
 * @param node_id DTS node to test
 * @return 1 if node exists and is fixed-partition compatible, 0 otherwise.
 *//**
 * @brief Test if a fixed partition with a given label property exists
 * @param label lowercase-and-underscores label property value
 * @return 1 if any "fixed-partitions" child node has the given label,
 *         0 otherwise.
 *//**
 * @brief Get a node identifier for a fixed partition with
 *        a given label property
 *
 * Example devicetree fragment:
 *
 *     flash@... {
 *              partitions {
 *                      compatible = "fixed-partitions";
 *                      boot_partition: partition@0 {
 *                              label = "mcuboot";
 *                      };
 *                      slot0_partition: partition@c000 {
 *                              label = "image-0";
 *                      };
 *                      ...
 *              };
 *     };
 *
 * Example usage:
 *
 *     DT_NODE_BY_FIXED_PARTITION_LABEL(mcuboot) // node identifier for boot_partition
 *     DT_NODE_BY_FIXED_PARTITION_LABEL(image_0) // node identifier for slot0_partition
 *
 * @param label lowercase-and-underscores label property value
 * @return a node identifier for the partition with that label property
 *//**
 * @defgroup devicetree-fixed-partition Devicetree Fixed Partition API
 * @ingroup devicetree
 * @{
 *//**
 * @file
 * @brief Flash Devicetree macro public API header file.
 */DT_INST_SUPPORTS_DEP_ORDS(inst)DT_SUPPORTS_DEP_ORDS(DT_DRV_INST(inst))DT_INST_REQUIRES_DEP_ORDS(inst)DT_REQUIRES_DEP_ORDS(DT_DRV_INST(inst))DT_INST_DEP_ORD(inst)DT_DEP_ORD(DT_DRV_INST(inst))DT_SUPPORTS_DEP_ORDS(node_id)DT_CAT(node_id, _SUPPORTS_ORDS)DT_REQUIRES_DEP_ORDS(node_id)DT_CAT(node_id, _REQUIRES_ORDS)DT_DEP_ORD_STR_SORTABLE(node_id)DT_CAT(node_id, _ORD_STR_SORTABLE)DT_DEP_ORD(node_id)DT_CAT(node_id, _ORD)ZEPHYR_INCLUDE_DEVICETREE_ORDINALS_H_/* ZEPHYR_INCLUDE_DEVICETREE_ORDINALS_H_ *//**
 * @brief Get a list of dependency ordinals of what depends directly on a
 *        DT_DRV_COMPAT instance
 *
 * Equivalent to DT_SUPPORTS_DEP_ORDS(DT_DRV_INST(inst)).
 *
 * @param inst instance number
 * @return a list of node identifiers for the nodes that depend directly
 *         on the instance
 *//**
 * @brief Get a list of dependency ordinals of a DT_DRV_COMPAT instance's
 *        direct dependencies
 *
 * Equivalent to DT_REQUIRES_DEP_ORDS(DT_DRV_INST(inst)).
 *
 * @param inst instance number
 * @return a list of dependency ordinals for the nodes the instance depends
 *         on directly
 *//**
 * @brief Get a DT_DRV_COMPAT instance's dependency ordinal
 *
 * Equivalent to DT_DEP_ORD(DT_DRV_INST(inst)).
 *
 * @param inst instance number
 * @return The instance's dependency ordinal
 *//**
 * @brief Get a list of dependency ordinals of what depends directly on a node
 *
 * There is a comma after each ordinal in the expansion, **including**
 * the last one:
 *
 *     DT_SUPPORTS_DEP_ORDS(my_node) // supported_ord_1, ..., supported_ord_n,
 *
 * DT_SUPPORTS_DEP_ORDS() may expand to nothing. This happens when @p node_id
 * refers to a leaf node that nothing else depends on.
 *
 * @param node_id Node identifier
 * @return a list of dependency ordinals, with each ordinal followed
 *         by a comma (<tt>,</tt>), or an empty expansion
 *//**
 * @brief Get a list of dependency ordinals of a node's direct dependencies
 *
 * There is a comma after each ordinal in the expansion, **including**
 * the last one:
 *
 *     DT_REQUIRES_DEP_ORDS(my_node) // required_ord_1, ..., required_ord_n,
 *
 * The one case DT_REQUIRES_DEP_ORDS() expands to nothing is when
 * given the root node identifier @p DT_ROOT as argument. The root has
 * no direct dependencies; every other node at least depends on its
 * parent.
 *
 * @param node_id Node identifier
 * @return a list of dependency ordinals, with each ordinal followed
 *         by a comma (<tt>,</tt>), or an empty expansion
 *//**
 * @brief Get a node's dependency ordinal in string sortable form
 * @param node_id Node identifier
 * @return the node's dependency ordinal as a zero-padded integer literal
 *//**
 * @brief Get a node's dependency ordinal
 * @param node_id Node identifier
 * @return the node's dependency ordinal as an integer literal
 *//**
 * @defgroup devicetree-dep-ord Dependency tracking
 * @ingroup devicetree
 * @{
 *//**
 * @file
 * @brief Devicetree node dependency ordinals
 *//*
 * Copyright (c) 2020 Nordic Semiconductor ASA
 * SPDX-License-Identifier: Apache-2.0
 */DT_INST_PINCTRL_HAS_NAME(inst,name)DT_PINCTRL_HAS_NAME(DT_DRV_INST(inst), name)DT_INST_PINCTRL_HAS_IDX(inst,pc_idx)DT_PINCTRL_HAS_IDX(DT_DRV_INST(inst), pc_idx)DT_INST_NUM_PINCTRL_STATES(inst)DT_NUM_PINCTRL_STATES(DT_DRV_INST(inst))DT_INST_NUM_PINCTRLS_BY_NAME(inst,name)DT_NUM_PINCTRLS_BY_NAME(DT_DRV_INST(inst), name)DT_INST_NUM_PINCTRLS_BY_IDX(inst,pc_idx)DT_NUM_PINCTRLS_BY_IDX(DT_DRV_INST(inst), pc_idx)DT_INST_PINCTRL_IDX_TO_NAME_UPPER_TOKEN(inst,pc_idx)DT_PINCTRL_IDX_TO_NAME_UPPER_TOKEN(DT_DRV_INST(inst), pc_idx)DT_INST_PINCTRL_IDX_TO_NAME_TOKEN(inst,pc_idx)DT_PINCTRL_IDX_TO_NAME_TOKEN(DT_DRV_INST(inst), pc_idx)DT_INST_PINCTRL_NAME_TO_IDX(inst,name)DT_PINCTRL_NAME_TO_IDX(DT_DRV_INST(inst), name)DT_INST_PINCTRL_BY_NAME(inst,name,idx)DT_PINCTRL_BY_NAME(DT_DRV_INST(inst), name, idx)DT_INST_PINCTRL_0(inst,idx)DT_PINCTRL_BY_IDX(DT_DRV_INST(inst), 0, idx)DT_INST_PINCTRL_BY_IDX(inst,pc_idx,idx)DT_PINCTRL_BY_IDX(DT_DRV_INST(inst), pc_idx, idx)DT_PINCTRL_HAS_NAME(node_id,name)IS_ENABLED(DT_CAT4(node_id, _PINCTRL_NAME_, name, _EXISTS))DT_PINCTRL_HAS_IDX(node_id,pc_idx)IS_ENABLED(DT_CAT4(node_id, _PINCTRL_IDX_, pc_idx, _EXISTS))DT_NUM_PINCTRL_STATES(node_id)DT_CAT(node_id, _PINCTRL_NUM)DT_NUM_PINCTRLS_BY_NAME(node_id,name)DT_NUM_PINCTRLS_BY_IDX(node_id, DT_PINCTRL_NAME_TO_IDX(node_id, name))DT_NUM_PINCTRLS_BY_IDX(node_id,pc_idx)DT_CAT4(node_id, _P_pinctrl_, pc_idx, _LEN)DT_PINCTRL_IDX_TO_NAME_UPPER_TOKEN(node_id,pc_idx)DT_CAT4(node_id, _PINCTRL_IDX_, pc_idx, _UPPER_TOKEN)DT_PINCTRL_IDX_TO_NAME_TOKEN(node_id,pc_idx)DT_CAT4(node_id, _PINCTRL_IDX_, pc_idx, _TOKEN)DT_PINCTRL_NAME_TO_IDX(node_id,name)DT_CAT4(node_id, _PINCTRL_NAME_, name, _IDX)DT_PINCTRL_BY_NAME(node_id,name,idx)DT_CAT6(node_id, _PINCTRL_NAME_, name, _IDX_, idx, _PH)DT_PINCTRL_0(node_id,idx)DT_PINCTRL_BY_IDX(node_id, 0, idx)DT_PINCTRL_BY_IDX(node_id,pc_idx,idx)DT_CAT6(node_id, _P_pinctrl_, pc_idx, _IDX_, idx, _PH)ZEPHYR_INCLUDE_DEVICETREE_PINCTRL_H_/* ZEPHYR_INCLUDE_DEVICETREE_PINCTRL_H_ *//**
 * @brief Test if a DT_DRV_COMPAT instance has a pinctrl property with a name
 *
 * This is equivalent to DT_PINCTRL_HAS_NAME(DT_DRV_INST(inst), name).
 *
 * @param inst instance number
 * @param name lowercase-and-underscores pinctrl property name to check
 * @return 1 if the property exists, 0 otherwise
 *//**
 * @brief Test if a DT_DRV_COMPAT instance has a pinctrl property
 *        with an index
 *
 * This is equivalent to DT_PINCTRL_HAS_IDX(DT_DRV_INST(inst), pc_idx).
 *
 * @param inst instance number
 * @param pc_idx index of a pinctrl property whose existence to check
 * @return 1 if the property exists, 0 otherwise
 *//**
 * @brief Get the number of pinctrl properties in a DT_DRV_COMPAT instance
 *
 * This is equivalent to DT_NUM_PINCTRL_STATES(DT_DRV_INST(inst)).
 *
 * @param inst instance number
 * @return number of pinctrl properties in the instance
 *//**
 * @brief Like DT_INST_NUM_PINCTRLS_BY_IDX(), but by name instead
 *
 * This is equivalent to DT_NUM_PINCTRLS_BY_NAME(DT_DRV_INST(inst),
 * name).
 *
 * @param inst instance number
 * @param name lowercase-and-underscores name of the pinctrl property
 * @return number of phandles in the property with that name
 *//**
 * @brief Get the number of phandles in a pinctrl property
 *        for a DT_DRV_COMPAT instance
 *
 * This is equivalent to DT_NUM_PINCTRLS_BY_IDX(DT_DRV_INST(inst),
 * pc_idx).
 *
 * @param inst instance number
 * @param pc_idx index of the pinctrl property itself
 * @return number of phandles in the property with that index
 *//**
 * @brief Convert a pinctrl index to its name as an uppercased token
 *
 * This is equivalent to
 * DT_PINCTRL_IDX_TO_NAME_UPPER_TOKEN(DT_DRV_INST(inst), idx).
 *
 * @param inst instance number
 * @param pc_idx index of the pinctrl property itself
 * @return name of the pin control property as an uppercase token
 *//**
 * @brief Convert a pinctrl index to its name as an uppercased token
 *
 * This is equivalent to
 * DT_PINCTRL_IDX_TO_NAME_TOKEN(DT_DRV_INST(inst), pc_idx).
 *
 * @param inst instance number
 * @param pc_idx index of the pinctrl property itself
 * @return name of the pin control property as a token
 *//**
 * @brief Convert a pinctrl name to its corresponding index
 *        for a DT_DRV_COMPAT instance
 *
 * This is equivalent to DT_PINCTRL_NAME_TO_IDX(DT_DRV_INST(inst),
 * name).
 *
 * @param inst instance number
 * @param name lowercase-and-underscores name of the pinctrl whose index to get
 * @return integer literal for the index of the pinctrl property with that name
 *//**
 * @brief Get a node identifier for a phandle inside a pinctrl node
 *        for a DT_DRV_COMPAT instance
 *
 * This is equivalent to DT_PINCTRL_BY_NAME(DT_DRV_INST(inst), name, idx).
 *
 * @param inst instance number
 * @param name lowercase-and-underscores pinctrl property name
 * @param idx index into the value of the named pinctrl property
 * @return node identifier for the phandle at that index in the pinctrl
 *         property
 *//**
 * @brief Get a node identifier from a pinctrl-0 property for a
 *        DT_DRV_COMPAT instance
 *
 * This is equivalent to:
 *
 *     DT_PINCTRL_BY_IDX(DT_DRV_INST(inst), 0, idx)
 *
 * It is provided for convenience since pinctrl-0 is commonly used.
 *
 * @param inst instance number
 * @param idx index into the pinctrl-0 property
 * @return node identifier for the phandle at index idx in the pinctrl-0
 *         property of that instance
 *//**
 * @brief Get a node identifier for a phandle in a pinctrl property by index
 *        for a DT_DRV_COMPAT instance
 *
 * This is equivalent to DT_PINCTRL_BY_IDX(DT_DRV_INST(inst), pc_idx, idx).
 *
 * @param inst instance number
 * @param pc_idx index of the pinctrl property itself
 * @param idx index into the value of the pinctrl property
 * @return node identifier for the phandle at index 'idx' in 'pinctrl-'pc_idx''
 *//**
 * @brief Test if a node has a pinctrl property with a name
 *
 * This expands to 1 if the named pinctrl property exists.
 * Otherwise, it expands to 0.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             pinctrl-0 = <...>;
 *             pinctrl-names = "default";
 *     };
 *
 *     n2: node-2 {
 *     };
 *
 * Example usage:
 *
 *     DT_PINCTRL_HAS_NAME(DT_NODELABEL(n1), default) // 1
 *     DT_PINCTRL_HAS_NAME(DT_NODELABEL(n1), sleep)   // 0
 *     DT_PINCTRL_HAS_NAME(DT_NODELABEL(n2), default) // 0
 *
 * @param node_id node identifier; may or may not have any pinctrl properties
 * @param name lowercase-and-underscores pinctrl property name to check
 * @return 1 if the property exists, 0 otherwise
 *//**
 * @brief Test if a node has a pinctrl property with an index
 *
 * This expands to 1 if the pinctrl-'idx' property exists.
 * Otherwise, it expands to 0.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             pinctrl-0 = <...>;
 *             pinctrl-1 = <...>;
 *     };
 *
 *     n2: node-2 {
 *     };
 *
 * Example usage:
 *
 *     DT_PINCTRL_HAS_IDX(DT_NODELABEL(n1), 0) // 1
 *     DT_PINCTRL_HAS_IDX(DT_NODELABEL(n1), 1) // 1
 *     DT_PINCTRL_HAS_IDX(DT_NODELABEL(n1), 2) // 0
 *     DT_PINCTRL_HAS_IDX(DT_NODELABEL(n2), 0) // 0
 *
 * @param node_id node identifier; may or may not have any pinctrl properties
 * @param pc_idx index of a pinctrl property whose existence to check
 * @return 1 if the property exists, 0 otherwise
 *//**
 * @brief Get the number of pinctrl properties in a node
 *
 * This expands to 0 if there are no pinctrl-i properties.
 * Otherwise, it expands to the number of such properties.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             pinctrl-0 = <...>;
 *             pinctrl-1 = <...>;
 *     };
 *
 *     n2: node-2 {
 *     };
 *
 * Example usage:
 *
 *     DT_NUM_PINCTRL_STATES(DT_NODELABEL(n1)) // 2
 *     DT_NUM_PINCTRL_STATES(DT_NODELABEL(n2)) // 0
 *
 * @param node_id node identifier; may or may not have any pinctrl properties
 * @return number of pinctrl properties in the node
 *//**
 * @brief Like DT_NUM_PINCTRLS_BY_IDX(), but by name instead
 *
 * Example devicetree fragment:
 *
 *     n: node {
 *             pinctrl-0 = <&foo &bar>;
 *             pinctrl-1 = <&baz>
 *             pinctrl-names = "default", "sleep";
 *     };
 *
 * Example usage:
 *
 *     DT_NUM_PINCTRLS_BY_NAME(DT_NODELABEL(n), default) // 2
 *     DT_NUM_PINCTRLS_BY_NAME(DT_NODELABEL(n), sleep)   // 1
 *
 * @param node_id node identifier with a pinctrl property
 * @param name lowercase-and-underscores name name of the pinctrl property
 * @return number of phandles in the property with that name
 *//**
 * @brief Get the number of phandles in a pinctrl property
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             pinctrl-0 = <&foo &bar>;
 *     };
 *
 *     n2: node-2 {
 *             pinctrl-0 = <&baz>;
 *     };
 *
 * Example usage:
 *
 *     DT_NUM_PINCTRLS_BY_IDX(DT_NODELABEL(n1), 0) // 2
 *     DT_NUM_PINCTRLS_BY_IDX(DT_NODELABEL(n2), 0) // 1
 *
 * @param node_id node identifier with a pinctrl property
 * @param pc_idx index of the pinctrl property itself
 * @return number of phandles in the property with that index
 *//**
 * @brief Like DT_PINCTRL_IDX_TO_NAME_TOKEN(), but with an uppercased result
 *
 * This does the a similar conversion as
 * DT_PINCTRL_IDX_TO_NAME_TOKEN(node_id, pc_idx). The only difference
 * is that alphabetical characters in the result are uppercased.
 *
 * Example devicetree fragment:
 *
 *     n: node {
 *             pinctrl-0 = <...>;
 *             pinctrl-1 = <...>;
 *             pinctrl-names = "default", "f.o.o2";
 *     };
 *
 * Example usage:
 *
 *     DT_PINCTRL_IDX_TO_NAME_TOKEN(DT_NODELABEL(n), 0) // DEFAULT
 *     DT_PINCTRL_IDX_TO_NAME_TOKEN(DT_NODELABEL(n), 1) // F_O_O2
 *
 * The same caveats and restrictions that apply to
 * DT_STRING_UPPER_TOKEN()'s return value also apply here.
 *//**
 * @brief Convert a pinctrl property index to its name as a token
 *
 * This allows you to get a pinctrl property's name, and "remove the
 * quotes" from it.
 *
 * DT_PINCTRL_IDX_TO_NAME_TOKEN() can only be used if the node has a
 * pinctrl-'pc_idx' property and a pinctrl-names property element for
 * that index. It is an error to use it in other circumstances.
 *
 * Example devicetree fragment:
 *
 *     n: node {
 *             pinctrl-0 = <...>;
 *             pinctrl-1 = <...>;
 *             pinctrl-names = "default", "f.o.o2";
 *     };
 *
 * Example usage:
 *
 *     DT_PINCTRL_IDX_TO_NAME_TOKEN(DT_NODELABEL(n), 0) // default
 *     DT_PINCTRL_IDX_TO_NAME_TOKEN(DT_NODELABEL(n), 1) // f_o_o2
 *
 * The same caveats and restrictions that apply to DT_STRING_TOKEN()'s
 * return value also apply here.
 *
 * @param node_id node identifier
 * @param pc_idx index of a pinctrl property in that node
 * @return name of the pinctrl property, as a token, without any quotes
 *         and with non-alphanumeric characters converted to underscores
 *//**
 * @brief Convert a pinctrl name to its corresponding index
 *
 * Example devicetree fragment:
 *
 *     n: node {
 *             pinctrl-0 = <&foo &bar>;
 *             pinctrl-1 = <&baz &blub>;
 *             pinctrl-names = "default", "sleep";
 *     };
 *
 * Example usage:
 *
 *     DT_PINCTRL_NAME_TO_IDX(DT_NODELABEL(n), default) // 0
 *     DT_PINCTRL_NAME_TO_IDX(DT_NODELABEL(n), sleep)   // 1
 *
 * @param node_id node identifier with a named pinctrl property
 * @param name lowercase-and-underscores name name of the pinctrl whose index to get
 * @return integer literal for the index of the pinctrl property with that name
 *//**
 * @brief Get a node identifier for a phandle inside a pinctrl node by name
 *
 * Example devicetree fragment:
 *
 *     n: node {
 *             pinctrl-0 = <&foo &bar>;
 *             pinctrl-1 = <&baz &blub>;
 *             pinctrl-names = "default", "sleep";
 *     };
 *
 * Example usage:
 *
 *     DT_PINCTRL_BY_NAME(DT_NODELABEL(n), default, 1) // DT_NODELABEL(bar)
 *     DT_PINCTRL_BY_NAME(DT_NODELABEL(n), sleep, 0) // DT_NODELABEL(baz)
 *
 * @param node_id node with a named pinctrl property
 * @param name lowercase-and-underscores pinctrl property name
 * @param idx index into the value of the named pinctrl property
 * @return node identifier for the phandle at that index in the pinctrl
 *         property
 *//**
 * @brief Get a node identifier from a pinctrl-0 property
 *
 * This is equivalent to:
 *
 *     DT_PINCTRL_BY_IDX(node_id, 0, idx)
 *
 * It is provided for convenience since pinctrl-0 is commonly used.
 *
 * @param node_id node with a pinctrl-0 property
 * @param idx index into the pinctrl-0 property
 * @return node identifier for the phandle at index idx in the pinctrl-0
 *         property of that node
 *//**
 * @brief Get a node identifier for a phandle in a pinctrl property by index
 *
 * Example devicetree fragment:
 *
 *     n: node {
 *             pinctrl-0 = <&foo &bar>;
 *             pinctrl-1 = <&baz &blub>;
 *     }
 *
 * Example usage:
 *
 *     DT_PINCTRL_BY_IDX(DT_NODELABEL(n), 0, 1) // DT_NODELABEL(bar)
 *     DT_PINCTRL_BY_IDX(DT_NODELABEL(n), 1, 0) // DT_NODELABEL(baz)
 *
 * @param node_id node with a pinctrl-'pc_idx' property
 * @param pc_idx index of the pinctrl property itself
 * @param idx index into the value of the pinctrl property
 * @return node identifier for the phandle at index 'idx' in 'pinctrl-'pc_idx''
 *//**
 * @defgroup devicetree-pinctrl Pin control
 * @ingroup devicetree
 * @{
 *//**
 * @file
 * @brief Devicetree pin control helpers
 *//*
 * Copyright (c) 2021 Nordic Semiconductor ASA
 * SPDX-License-Identifier: Apache-2.0
 */DT_INST_CAN_TRANSCEIVER_MAX_BITRATE(inst,max)DT_CAN_TRANSCEIVER_MAX_BITRATE(DT_DRV_INST(inst), max)DT_CAN_TRANSCEIVER_MAX_BITRATE(node_id,max)COND_CODE_1(DT_NODE_HAS_PROP(node_id, phys), MIN(DT_PROP(DT_PHANDLE(node_id, phys), max_bitrate), max), MIN(DT_PROP_OR(DT_CHILD(node_id, can_transceiver), max_bitrate, max), max))ZEPHYR_INCLUDE_DEVICETREE_CAN_H_/* ZEPHYR_INCLUDE_DEVICETREE_CAN_H_ *//**
 * @brief Get the maximum transceiver bitrate for a DT_DRV_COMPAT CAN controller
 * @param inst DT_DRV_COMPAT instance number
 * @param max maximum bitrate supported by the CAN controller
 * @return the maximum bitrate supported by the CAN controller/transceiver combination
 * @see DT_CAN_TRANSCEIVER_MAX_BITRATE()
 *//**
 * @brief Get the maximum transceiver bitrate for a CAN controller
 *
 * The bitrate will be limited to the maximum bitrate supported by the CAN
 * controller. If no CAN transceiver is present in the devicetree, the maximum
 * bitrate will be that of the CAN controller.
 *
 * Example devicetree fragment:
 *
 *     transceiver0: can-phy0 {
 *             compatible = "vnd,can-transceiver";
 *             max-bitrate = <1000000>;
 *             #phy-cells = <0>;
 *     };
 *
 *     can0: can@... {
 *             compatible = "vnd,can-controller";
 *             phys = <&transceiver0>;
 *     };
 *
 *     can1: can@... {
 *             compatible = "vnd,can-controller";
 *
 *             can-transceiver {
 *                     max-bitrate = <2000000>;
 *             };
 *     };
 *
 * Example usage:
 *
 *     DT_CAN_TRANSCEIVER_MAX_BITRATE(DT_NODELABEL(can0), 5000000) // 1000000
 *     DT_CAN_TRANSCEIVER_MAX_BITRATE(DT_NODELABEL(can1), 5000000) // 2000000
 *     DT_CAN_TRANSCEIVER_MAX_BITRATE(DT_NODELABEL(can1), 1000000) // 1000000
 *
 * @param node_id node identifier
 * @param max maximum bitrate supported by the CAN controller
 * @return the maximum bitrate supported by the CAN controller/transceiver combination
 *//**
 * @defgroup devicetree-can Devicetree CAN API
 * @ingroup devicetree
 * @{
 *//*
 * Copyright (c) 2022 Vestas Wind Systems A/S
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file
 * @brief CAN devicetree macro public API header file.
 */DT_INST_RESET_ID(inst)DT_INST_RESET_ID_BY_IDX(inst, 0)DT_INST_RESET_ID_BY_IDX(inst,idx)DT_RESET_ID_BY_IDX(DT_DRV_INST(inst), idx)DT_RESET_ID(node_id)DT_RESET_ID_BY_IDX(node_id, 0)DT_RESET_ID_BY_IDX(node_id,idx)DT_PHA_BY_IDX(node_id, resets, idx, id)DT_INST_RESET_CELL(inst,cell)DT_INST_RESET_CELL_BY_IDX(inst, 0, cell)DT_INST_RESET_CELL_BY_NAME(inst,name,cell)DT_RESET_CELL_BY_NAME(DT_DRV_INST(inst), name, cell)DT_INST_RESET_CELL_BY_IDX(inst,idx,cell)DT_RESET_CELL_BY_IDX(DT_DRV_INST(inst), idx, cell)DT_INST_RESET_CTLR_BY_NAME(inst,name)DT_RESET_CTLR_BY_NAME(DT_DRV_INST(inst), name)DT_INST_RESET_CTLR(inst)DT_INST_RESET_CTLR_BY_IDX(inst, 0)DT_INST_RESET_CTLR_BY_IDX(inst,idx)DT_RESET_CTLR_BY_IDX(DT_DRV_INST(inst), idx)DT_RESET_CELL(node_id,cell)DT_RESET_CELL_BY_IDX(node_id, 0, cell)DT_RESET_CELL_BY_NAME(node_id,name,cell)DT_PHA_BY_NAME(node_id, resets, name, cell)DT_RESET_CELL_BY_IDX(node_id,idx,cell)DT_PHA_BY_IDX(node_id, resets, idx, cell)DT_RESET_CTLR_BY_NAME(node_id,name)DT_PHANDLE_BY_NAME(node_id, resets, name)DT_RESET_CTLR(node_id)DT_RESET_CTLR_BY_IDX(node_id, 0)DT_RESET_CTLR_BY_IDX(node_id,idx)DT_PHANDLE_BY_IDX(node_id, resets, idx)ZEPHYR_INCLUDE_DEVICETREE_RESET_H_/* ZEPHYR_INCLUDE_DEVICETREE_RESET_H_ *//**
 * @brief Equivalent to DT_INST_RESET_ID_BY_IDX(inst, 0)
 * @param inst DT_DRV_COMPAT instance number
 * @return the id cell value at index 0
 * @see DT_INST_RESET_ID_BY_IDX()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's Reset Controller specifier's id cell value
 *        at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into "resets"
 * @return the id cell value at index "idx"
 * @see DT_RESET_ID_BY_IDX()
 *//**
 * @brief Equivalent to DT_RESET_ID_BY_IDX(node_id, 0)
 * @param node_id node identifier
 * @return the id cell value at index 0
 * @see DT_RESET_ID_BY_IDX()
 *//**
 * @brief Get a Reset Controller specifier's id cell at an index
 *
 * This macro only works for Reset Controller specifiers with cells named "id".
 * Refer to the node's binding to check if necessary.
 *
 * Example devicetree fragment:
 *
 *     reset: reset-controller@... {
 *             compatible = "vnd,reset";
 *             #reset-cells = <1>;
 *     };
 *
 *     n: node {
 *             resets = <&reset 10>;
 *     };
 *
 * Bindings fragment for the vnd,reset compatible:
 *
 *     reset-cells:
 *       - id
 *
 * Example usage:
 *
 *     DT_RESET_ID_BY_IDX(DT_NODELABEL(n), 0) // 10
 *
 * @param node_id node identifier
 * @param idx logical index into "resets"
 * @return the id cell value at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Equivalent to DT_INST_RESET_CELL_BY_IDX(inst, 0, cell)
 * @param inst DT_DRV_COMPAT instance number
 * @param cell lowercase-and-underscores cell name
 * @return the value of the cell inside the specifier at index 0
 *//**
 * @brief Get a DT_DRV_COMPAT instance's reset specifier's cell value by name
 * @param inst DT_DRV_COMPAT instance number
 * @param name lowercase-and-underscores name of a resets element
 *             as defined by the node's reset-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_RESET_CELL_BY_NAME()
 *//**
 * @brief Get a DT_DRV_COMPAT instance's reset specifier's cell value
 *        at an index
 * @param inst DT_DRV_COMPAT instance number
 * @param idx logical index into resets property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_RESET_CELL_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        resets phandle-array property by name
 *
 * @param inst instance number
 * @param name lowercase-and-underscores name of a resets element
 *             as defined by the node's reset-names property
 * @return the node identifier for the reset controller referenced by
 *         the named element
 * @see DT_RESET_CTLR_BY_NAME()
 *//**
 * @brief Equivalent to DT_INST_RESET_CTLR_BY_IDX(inst, 0)
 * @param inst instance number
 * @return a node identifier for the reset controller at index 0
 *         in "resets"
 * @see DT_RESET_CTLR()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        "resets" phandle-array property at an index
 *
 * @param inst instance number
 * @param idx logical index into "resets"
 * @return the node identifier for the reset controller referenced at
 *         index "idx"
 * @see DT_RESET_CTLR_BY_IDX()
 *//**
 * @brief Equivalent to DT_RESET_CELL_BY_IDX(node_id, 0, cell)
 * @param node_id node identifier for a node with a resets property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index 0
 * @see DT_RESET_CELL_BY_IDX()
 *//**
 * @brief Get a reset specifier's cell value by name
 *
 * Example devicetree fragment:
 *
 *     reset: reset-controller@... {
 *             compatible = "vnd,reset";
 *             #reset-cells = <1>;
 *     };
 *
 *     n: node {
 *             resets = <&reset 10>;
 *             reset-names = "alpha";
 *     };
 *
 * Bindings fragment for the vnd,reset compatible:
 *
 *     reset-cells:
 *       - id
 *
 * Example usage:
 *
 *     DT_RESET_CELL_BY_NAME(DT_NODELABEL(n), alpha, id) // 10
 *
 * @param node_id node identifier for a node with a resets property
 * @param name lowercase-and-underscores name of a resets element
 *             as defined by the node's reset-names property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value in the specifier at the named element
 * @see DT_PHA_BY_NAME()
 *//**
 * @brief Get a reset specifier's cell value at an index
 *
 * Example devicetree fragment:
 *
 *     reset: reset-controller@... {
 *             compatible = "vnd,reset";
 *             #reset-cells = <1>;
 *     };
 *
 *     n: node {
 *             resets = <&reset 10>;
 *     };
 *
 * Bindings fragment for the vnd,reset compatible:
 *
 *     reset-cells:
 *       - id
 *
 * Example usage:
 *
 *     DT_RESET_CELL_BY_IDX(DT_NODELABEL(n), 0, id) // 10
 *
 * @param node_id node identifier for a node with a resets property
 * @param idx logical index into resets property
 * @param cell lowercase-and-underscores cell name
 * @return the cell value at index "idx"
 * @see DT_PHA_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        resets phandle-array property by name
 *
 * Example devicetree fragment:
 *
 *     reset1: reset-controller@... { ... };
 *
 *     reset2: reset-controller@... { ... };
 *
 *     n: node {
 *             resets = <&reset1 10>, <&reset2 20>;
 *             reset-names = "alpha", "beta";
 *     };
 *
 * Example usage:
 *
 *     DT_RESET_CTLR_BY_NAME(DT_NODELABEL(n), alpha) // DT_NODELABEL(reset1)
 *     DT_RESET_CTLR_BY_NAME(DT_NODELABEL(n), beta) // DT_NODELABEL(reset2)
 *
 * @param node_id node identifier
 * @param name lowercase-and-underscores name of a resets element
 *             as defined by the node's reset-names property
 * @return the node identifier for the reset controller referenced by name
 * @see DT_PHANDLE_BY_NAME()
 *//**
 * @brief Equivalent to DT_RESET_CTLR_BY_IDX(node_id, 0)
 * @param node_id node identifier
 * @return a node identifier for the reset controller at index 0
 *         in "resets"
 * @see DT_RESET_CTLR_BY_IDX()
 *//**
 * @brief Get the node identifier for the controller phandle from a
 *        "resets" phandle-array property at an index
 *
 * Example devicetree fragment:
 *
 *     reset1: reset-controller@... { ... };
 *
 *     reset2: reset-controller@... { ... };
 *
 *     n: node {
 *             resets = <&reset1 10>, <&reset2 20>;
 *     };
 *
 * Example usage:
 *
 *     DT_RESET_CTLR_BY_IDX(DT_NODELABEL(n), 0)) // DT_NODELABEL(reset1)
 *     DT_RESET_CTLR_BY_IDX(DT_NODELABEL(n), 1)) // DT_NODELABEL(reset2)
 *
 * @param node_id node identifier
 * @param idx logical index into "resets"
 * @return the node identifier for the reset controller referenced at
 *         index "idx"
 * @see DT_PHANDLE_BY_IDX()
 *//**
 * @defgroup devicetree-reset-controller Devicetree Reset Controller API
 * @ingroup devicetree
 * @{
 *//*
 * Copyright (c) 2022, Andrei-Edward Popa
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file
 * @brief Reset Controller Devicetree macro public API header file.
 */DT_MBOX_CHANNEL_BY_NAME(node_id,name)DT_PHA_BY_NAME_OR(node_id, mboxes, name, channel, 0)DT_MBOX_CTLR_BY_NAME(node_id,name)DT_PHANDLE_BY_NAME(node_id, mboxes, name)ZEPHYR_INCLUDE_DEVICETREE_MBOX_H_/* ZEPHYR_INCLUDE_DEVICETREE_MBOX_H_ *//**
 * @brief Get a MBOX channel value by name
 *
 * Example devicetree fragment:
 *
 *     mbox1: mbox@... {
 *             #mbox-cells = <1>;
 *     };
 *
 *     n: node {
 *		mboxes = <&mbox1 1>,
 *		         <&mbox1 6>;
 *		mbox-names = "tx", "rx";
 *     };
 *
 * Bindings fragment for the mbox compatible:
 *
 *     mbox-cells:
 *       - channel
 *
 * Example usage:
 *
 *     DT_MBOX_CHANNEL_BY_NAME(DT_NODELABEL(n), tx) // 1
 *     DT_MBOX_CHANNEL_BY_NAME(DT_NODELABEL(n), rx) // 6
 *
 * @param node_id node identifier for a node with a mboxes property
 * @param name lowercase-and-underscores name of a mboxes element
 *             as defined by the node's mbox-names property
 *
 * @return the channel value in the specifier at the named element or 0 if no
 *         channels are supported
 *
 * @see DT_PHA_BY_NAME_OR()
 *//**
 * @brief Get the node identifier for the MBOX controller from a mboxes
 *	  property by name
 *
 * Example devicetree fragment:
 *
 *     mbox1: mbox-controller@... { ... };
 *
 *     n: node {
 *             mboxes = <&mbox1 8>,
 *                      <&mbox1 9>;
 *             mbox-names = "tx", "rx";
 *     };
 *
 * Example usage:
 *
 *     DT_MBOX_CTLR_BY_NAME(DT_NODELABEL(n), tx) // DT_NODELABEL(mbox1)
 *     DT_MBOX_CTLR_BY_NAME(DT_NODELABEL(n), rx) // DT_NODELABEL(mbox1)
 *
 * @param node_id node identifier for a node with a mboxes property
 * @param name lowercase-and-underscores name of a mboxes element
 *             as defined by the node's mbox-names property
 *
 * @return the node identifier for the MBOX controller in the named element
 *
 * @see DT_PHANDLE_BY_NAME()
 *//**
 * @defgroup devicetree-mbox Devicetree MBOX API
 * @ingroup devicetree
 * @{
 *//*
 * Copyright (c) 2022 Carlo Caione <ccaione@baylibre.com>
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file
 * @brief MBOX Devicetree macro public API header file.
 */<zephyr/devicetree/mbox.h><zephyr/devicetree/reset.h><zephyr/devicetree/can.h><zephyr/devicetree/pinctrl.h><zephyr/devicetree/ordinals.h><zephyr/devicetree/fixed-partitions.h><zephyr/devicetree/pwms.h><zephyr/devicetree/dma.h><zephyr/devicetree/spi.h><zephyr/devicetree/gpio.h><zephyr/devicetree/clocks.h><zephyr/devicetree/io-channels.h><zephyr/irq_multilevel.h><devicetree_generated.h>DT_U64_C(_v)UINT64_C(_v)DT_INST_NODE_HAS_PROP_AND_OR(inst,prop)DT_INST_NODE_HAS_PROP(inst, prop) ||DT_NODE_HAS_STATUS_INTERNAL(node_id,status)IS_ENABLED(DT_CAT3(node_id, _STATUS_, status))DT_DASH_PREFIX(name)_ ## nameDT_DASH(__VA_ARGS__...)MACRO_MAP_CAT(DT_DASH_PREFIX, __VA_ARGS__)DT_CAT8(a1,a2,a3,a4,a5,a6,a7,a8)a1 ## a2 ## a3 ## a4 ## a5 ## a6 ## a7 ## a8DT_CAT7(a1,a2,a3,a4,a5,a6,a7)a1 ## a2 ## a3 ## a4 ## a5 ## a6 ## a7DT_CAT6(a1,a2,a3,a4,a5,a6)a1 ## a2 ## a3 ## a4 ## a5 ## a6DT_CAT5(a1,a2,a3,a4,a5)a1 ## a2 ## a3 ## a4 ## a5DT_CAT4(a1,a2,a3,a4)a1 ## a2 ## a3 ## a4DT_CAT3(a1,a2,a3)a1 ## a2 ## a3DT_CAT(a1,a2)a1 ## a2DT_S_PREFIX(name)_S_ ## nameDT_PATH_INTERNAL(__VA_ARGS__...)UTIL_CAT(DT_ROOT, MACRO_MAP_CAT(DT_S_PREFIX, __VA_ARGS__))DT_INST_IRQ_HAS_NAME(inst,name)DT_IRQ_HAS_NAME(DT_DRV_INST(inst), name)DT_INST_IRQ_HAS_CELL(inst,cell)DT_INST_IRQ_HAS_CELL_AT_IDX(inst, 0, cell)DT_INST_IRQ_HAS_CELL_AT_IDX(inst,idx,cell)DT_IRQ_HAS_CELL_AT_IDX(DT_DRV_INST(inst), idx, cell)DT_INST_IRQ_HAS_IDX(inst,idx)DT_IRQ_HAS_IDX(DT_DRV_INST(inst), idx)DT_INST_PHA_HAS_CELL(inst,pha,cell)DT_INST_PHA_HAS_CELL_AT_IDX(inst, pha, 0, cell)DT_INST_PHA_HAS_CELL_AT_IDX(inst,pha,idx,cell)DT_PHA_HAS_CELL_AT_IDX(DT_DRV_INST(inst), pha, idx, cell)DT_INST_NODE_HAS_PROP(inst,prop)DT_NODE_HAS_PROP(DT_DRV_INST(inst), prop)DT_INST_FOREACH_PROP_ELEM_SEP_VARGS(inst,prop,fn,sep,__VA_ARGS__...)DT_FOREACH_PROP_ELEM_SEP_VARGS(DT_DRV_INST(inst), prop, fn, sep, __VA_ARGS__)DT_INST_FOREACH_PROP_ELEM_VARGS(inst,prop,fn,__VA_ARGS__...)DT_FOREACH_PROP_ELEM_VARGS(DT_DRV_INST(inst), prop, fn, __VA_ARGS__)DT_INST_FOREACH_PROP_ELEM_SEP(inst,prop,fn,sep)DT_FOREACH_PROP_ELEM_SEP(DT_DRV_INST(inst), prop, fn, sep)DT_INST_FOREACH_PROP_ELEM(inst,prop,fn)DT_FOREACH_PROP_ELEM(DT_DRV_INST(inst), prop, fn)DT_INST_FOREACH_STATUS_OKAY_VARGS(fn,__VA_ARGS__...)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(DT_DRV_COMPAT), (UTIL_CAT(DT_FOREACH_OKAY_INST_VARGS_, DT_DRV_COMPAT)(fn, __VA_ARGS__)), ())DT_INST_FOREACH_STATUS_OKAY(fn)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(DT_DRV_COMPAT), (UTIL_CAT(DT_FOREACH_OKAY_INST_, DT_DRV_COMPAT)(fn)), ())DT_ANY_INST_HAS_PROP_STATUS_OKAY(prop)(DT_INST_FOREACH_STATUS_OKAY_VARGS(DT_INST_NODE_HAS_PROP_AND_OR, prop) 0)DT_ANY_INST_ON_BUS_STATUS_OKAY(bus)DT_HAS_COMPAT_ON_BUS_STATUS_OKAY(DT_DRV_COMPAT, bus)DT_HAS_COMPAT_ON_BUS_STATUS_OKAY(compat,bus)IS_ENABLED(UTIL_CAT(DT_CAT(DT_COMPAT_, compat), _BUS_ ## bus))DT_INST_STRING_UNQUOTED_OR(inst,name,default_value)DT_STRING_UNQUOTED_OR(DT_DRV_INST(inst), name, default_value)DT_INST_STRING_UPPER_TOKEN_OR(inst,name,default_value)DT_STRING_UPPER_TOKEN_OR(DT_DRV_INST(inst), name, default_value)DT_INST_STRING_TOKEN_OR(inst,name,default_value)DT_STRING_TOKEN_OR(DT_DRV_INST(inst), name, default_value)DT_INST_ON_BUS(inst,bus)DT_ON_BUS(DT_DRV_INST(inst), bus)DT_INST_BUS_LABEL(inst)DT_BUS_LABEL(DT_DRV_INST(inst)) __DEPRECATED_MACRODT_INST_BUS(inst)DT_BUS(DT_DRV_INST(inst))DT_INST_IRQN_BY_IDX(inst,idx)DT_IRQN_BY_IDX(DT_DRV_INST(inst), idx)DT_INST_IRQN(inst)DT_IRQN(DT_DRV_INST(inst))DT_INST_IRQ(inst,cell)DT_INST_IRQ_BY_IDX(inst, 0, cell)DT_INST_IRQ_BY_NAME(inst,name,cell)DT_IRQ_BY_NAME(DT_DRV_INST(inst), name, cell)DT_INST_IRQ_BY_IDX(inst,idx,cell)DT_IRQ_BY_IDX(DT_DRV_INST(inst), idx, cell)DT_INST_REG_SIZE(inst)DT_INST_REG_SIZE_BY_IDX(inst, 0)DT_INST_REG_ADDR_U64(inst)DT_U64_C(DT_INST_REG_ADDR(inst))DT_INST_REG_ADDR(inst)DT_INST_REG_ADDR_BY_IDX(inst, 0)DT_INST_REG_SIZE_BY_NAME(inst,name)DT_REG_SIZE_BY_NAME(DT_DRV_INST(inst), name)DT_INST_REG_ADDR_BY_NAME_U64(inst,name)DT_U64_C(DT_INST_REG_ADDR_BY_NAME(inst, name))DT_INST_REG_ADDR_BY_NAME(inst,name)DT_REG_ADDR_BY_NAME(DT_DRV_INST(inst), name)DT_INST_REG_SIZE_BY_IDX(inst,idx)DT_REG_SIZE_BY_IDX(DT_DRV_INST(inst), idx)DT_INST_REG_ADDR_BY_IDX(inst,idx)DT_REG_ADDR_BY_IDX(DT_DRV_INST(inst), idx)DT_INST_REG_HAS_IDX(inst,idx)DT_REG_HAS_IDX(DT_DRV_INST(inst), idx)DT_INST_PHANDLE(inst,prop)DT_INST_PHANDLE_BY_IDX(inst, prop, 0)DT_INST_PHANDLE_BY_IDX(inst,prop,idx)DT_PHANDLE_BY_IDX(DT_DRV_INST(inst), prop, idx)DT_INST_PHANDLE_BY_NAME(inst,pha,name)DT_PHANDLE_BY_NAME(DT_DRV_INST(inst), pha, name)DT_INST_PHA_BY_NAME_OR(inst,pha,name,cell,default_value)DT_PHA_BY_NAME_OR(DT_DRV_INST(inst), pha, name, cell, default_value)DT_INST_PHA_BY_NAME(inst,pha,name,cell)DT_PHA_BY_NAME(DT_DRV_INST(inst), pha, name, cell)DT_INST_PHA_OR(inst,pha,cell,default_value)DT_INST_PHA_BY_IDX_OR(inst, pha, 0, cell, default_value)DT_INST_PHA(inst,pha,cell)DT_INST_PHA_BY_IDX(inst, pha, 0, cell)DT_INST_PHA_BY_IDX_OR(inst,pha,idx,cell,default_value)DT_PHA_BY_IDX_OR(DT_DRV_INST(inst), pha, idx, cell, default_value)DT_INST_PHA_BY_IDX(inst,pha,idx,cell)DT_PHA_BY_IDX(DT_DRV_INST(inst), pha, idx, cell)DT_INST_PROP_BY_PHANDLE_IDX(inst,phs,idx,prop)DT_PROP_BY_PHANDLE_IDX(DT_DRV_INST(inst), phs, idx, prop)DT_INST_PROP_BY_PHANDLE(inst,ph,prop)DT_INST_PROP_BY_PHANDLE_IDX(inst, ph, 0, prop)DT_INST_STRING_UNQUOTED_BY_IDX(inst,prop,idx)DT_STRING_UNQUOTED_BY_IDX(DT_DRV_INST(inst), prop, idx)DT_INST_STRING_UPPER_TOKEN_BY_IDX(inst,prop,idx)DT_STRING_UPPER_TOKEN_BY_IDX(DT_DRV_INST(inst), prop, idx)DT_INST_STRING_TOKEN_BY_IDX(inst,prop,idx)DT_STRING_TOKEN_BY_IDX(DT_DRV_INST(inst), prop, idx)DT_INST_STRING_UNQUOTED(inst,prop)DT_STRING_UNQUOTED(DT_DRV_INST(inst), prop)DT_INST_STRING_UPPER_TOKEN(inst,prop)DT_STRING_UPPER_TOKEN(DT_DRV_INST(inst), prop)DT_INST_STRING_TOKEN(inst,prop)DT_STRING_TOKEN(DT_DRV_INST(inst), prop)DT_INST_LABEL(inst)DT_INST_PROP(inst, label) __DEPRECATED_MACRODT_INST_PROP_LEN_OR(inst,prop,default_value)DT_PROP_LEN_OR(DT_DRV_INST(inst), prop, default_value)DT_INST_PROP_OR(inst,prop,default_value)DT_PROP_OR(DT_DRV_INST(inst), prop, default_value)DT_INST_PROP_BY_IDX(inst,prop,idx)DT_PROP_BY_IDX(DT_DRV_INST(inst), prop, idx)DT_INST_PROP_HAS_NAME(inst,prop,name)DT_PROP_HAS_NAME(DT_DRV_INST(inst), prop, name)DT_INST_PROP_HAS_IDX(inst,prop,idx)DT_PROP_HAS_IDX(DT_DRV_INST(inst), prop, idx)DT_INST_PROP_LEN(inst,prop)DT_PROP_LEN(DT_DRV_INST(inst), prop)DT_INST_PROP(inst,prop)DT_PROP(DT_DRV_INST(inst), prop)DT_INST_ENUM_HAS_VALUE(inst,prop,value)DT_ENUM_HAS_VALUE(DT_DRV_INST(inst), prop, value)DT_INST_ENUM_IDX_OR(inst,prop,default_idx_value)DT_ENUM_IDX_OR(DT_DRV_INST(inst), prop, default_idx_value)DT_INST_ENUM_IDX(inst,prop)DT_ENUM_IDX(DT_DRV_INST(inst), prop)DT_INST_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(inst,fn,sep,__VA_ARGS__...)DT_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(DT_DRV_INST(inst), fn, sep, __VA_ARGS__)DT_INST_FOREACH_CHILD_STATUS_OKAY_VARGS(inst,fn,__VA_ARGS__...)DT_FOREACH_CHILD_STATUS_OKAY_VARGS(DT_DRV_INST(inst), fn, __VA_ARGS__)DT_INST_FOREACH_CHILD_STATUS_OKAY_SEP(inst,fn,sep)DT_FOREACH_CHILD_STATUS_OKAY_SEP(DT_DRV_INST(inst), fn, sep)DT_INST_FOREACH_CHILD_STATUS_OKAY(inst,fn)DT_FOREACH_CHILD_STATUS_OKAY(DT_DRV_INST(inst), fn)DT_INST_FOREACH_CHILD_SEP_VARGS(inst,fn,sep,__VA_ARGS__...)DT_FOREACH_CHILD_SEP_VARGS(DT_DRV_INST(inst), fn, sep, __VA_ARGS__)DT_INST_FOREACH_CHILD_VARGS(inst,fn,__VA_ARGS__...)DT_FOREACH_CHILD_VARGS(DT_DRV_INST(inst), fn, __VA_ARGS__)DT_INST_FOREACH_CHILD_SEP(inst,fn,sep)DT_FOREACH_CHILD_SEP(DT_DRV_INST(inst), fn, sep)DT_INST_FOREACH_CHILD(inst,fn)DT_FOREACH_CHILD(DT_DRV_INST(inst), fn)DT_INST_CHILD(inst,child)DT_CHILD(DT_DRV_INST(inst), child)DT_INST_GPARENT(inst)DT_GPARENT(DT_DRV_INST(inst))DT_INST_PARENT(inst)DT_PARENT(DT_DRV_INST(inst))DT_DRV_INST(inst)DT_INST(inst, DT_DRV_COMPAT)DT_ON_BUS(node_id,bus)IS_ENABLED(DT_CAT3(node_id, _BUS_, bus))DT_BUS_LABEL(node_id)DT_PROP(DT_BUS(node_id), label) __DEPRECATED_MACRODT_BUS(node_id)DT_CAT(node_id, _BUS)DT_PHA_HAS_CELL(node_id,pha,cell)DT_PHA_HAS_CELL_AT_IDX(node_id, pha, 0, cell)DT_PHA_HAS_CELL_AT_IDX(node_id,pha,idx,cell)IS_ENABLED(DT_CAT8(node_id, _P_, pha, _IDX_, idx, _VAL_, cell, _EXISTS))DT_NODE_HAS_PROP(node_id,prop)IS_ENABLED(DT_CAT4(node_id, _P_, prop, _EXISTS))DT_NODE_HAS_COMPAT_STATUS(node_id,compat,status)DT_NODE_HAS_COMPAT(node_id, compat) && DT_NODE_HAS_STATUS(node_id, status)DT_NODE_HAS_COMPAT(node_id,compat)IS_ENABLED(DT_CAT3(node_id, _COMPAT_MATCHES_, compat))DT_NUM_INST_STATUS_OKAY(compat)UTIL_AND(DT_HAS_COMPAT_STATUS_OKAY(compat), UTIL_CAT(DT_N_INST, DT_DASH(compat, NUM_OKAY)))DT_HAS_COMPAT_STATUS_OKAY(compat)IS_ENABLED(DT_CAT(DT_COMPAT_HAS_OKAY_, compat))DT_NODE_HAS_STATUS(node_id,status)DT_NODE_HAS_STATUS_INTERNAL(node_id, status)DT_NODE_EXISTS(node_id)IS_ENABLED(DT_CAT(node_id, _EXISTS))DT_FOREACH_STATUS_OKAY_VARGS(compat,fn,__VA_ARGS__...)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(compat), (UTIL_CAT(DT_FOREACH_OKAY_VARGS_, compat)(fn, __VA_ARGS__)), ())DT_FOREACH_STATUS_OKAY(compat,fn)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(compat), (UTIL_CAT(DT_FOREACH_OKAY_, compat)(fn)), ())DT_FOREACH_PROP_ELEM_SEP_VARGS(node_id,prop,fn,sep,__VA_ARGS__...)DT_CAT4(node_id, _P_, prop, _FOREACH_PROP_ELEM_SEP_VARGS)( fn, sep, __VA_ARGS__)DT_FOREACH_PROP_ELEM_VARGS(node_id,prop,fn,__VA_ARGS__...)DT_CAT4(node_id, _P_, prop, _FOREACH_PROP_ELEM_VARGS)(fn, __VA_ARGS__)DT_FOREACH_PROP_ELEM_SEP(node_id,prop,fn,sep)DT_CAT4(node_id, _P_, prop, _FOREACH_PROP_ELEM_SEP)(fn, sep)DT_FOREACH_PROP_ELEM(node_id,prop,fn)DT_CAT4(node_id, _P_, prop, _FOREACH_PROP_ELEM)(fn)DT_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS(node_id,fn,sep,__VA_ARGS__...)DT_CAT(node_id, _FOREACH_CHILD_STATUS_OKAY_SEP_VARGS)(fn, sep, __VA_ARGS__)DT_FOREACH_CHILD_STATUS_OKAY_VARGS(node_id,fn,__VA_ARGS__...)DT_CAT(node_id, _FOREACH_CHILD_STATUS_OKAY_VARGS)(fn, __VA_ARGS__)DT_FOREACH_CHILD_STATUS_OKAY_SEP(node_id,fn,sep)DT_CAT(node_id, _FOREACH_CHILD_STATUS_OKAY_SEP)(fn, sep)DT_FOREACH_CHILD_STATUS_OKAY(node_id,fn)DT_CAT(node_id, _FOREACH_CHILD_STATUS_OKAY)(fn)DT_FOREACH_CHILD_SEP_VARGS(node_id,fn,sep,__VA_ARGS__...)DT_CAT(node_id, _FOREACH_CHILD_SEP_VARGS)(fn, sep, __VA_ARGS__)DT_FOREACH_CHILD_VARGS(node_id,fn,__VA_ARGS__...)DT_CAT(node_id, _FOREACH_CHILD_VARGS)(fn, __VA_ARGS__)DT_FOREACH_CHILD_SEP(node_id,fn,sep)DT_CAT(node_id, _FOREACH_CHILD_SEP)(fn, sep)DT_FOREACH_CHILD(node_id,fn)DT_CAT(node_id, _FOREACH_CHILD)(fn)DT_FOREACH_STATUS_OKAY_NODE_VARGS(fn,__VA_ARGS__...)DT_FOREACH_OKAY_VARGS_HELPER(fn, __VA_ARGS__)DT_FOREACH_STATUS_OKAY_NODE(fn)DT_FOREACH_NODE_VARGS(fn,__VA_ARGS__...)DT_FOREACH_VARGS_HELPER(fn, __VA_ARGS__)DT_FOREACH_NODE(fn)DT_HAS_CHOSEN(prop)IS_ENABLED(DT_CAT3(DT_CHOSEN_, prop, _EXISTS))DT_CHOSEN(prop)DT_CAT(DT_CHOSEN_, prop)DT_IRQN(node_id)DT_IRQN_BY_IDX(node_id, 0)DT_IRQN_BY_IDX(node_id,idx)COND_CODE_1(IS_ENABLED(CONFIG_MULTI_LEVEL_INTERRUPTS), (DT_MULTI_LEVEL_IRQN_INTERNAL(node_id, idx)), (DT_IRQN_BY_IDX_INTERNAL(node_id, idx)))DT_MULTI_LEVEL_IRQN_INTERNAL(node_id,idx)COND_CODE_1(DT_HAS_GPARENT_INTC_INTERNAL(node_id), (DT_IRQN_L3_INTERNAL(node_id, idx)), (COND_CODE_1(DT_HAS_PARENT_INTC_INTERNAL(node_id), (DT_IRQN_L2_INTERNAL(node_id, idx)), (DT_IRQN_BY_IDX_INTERNAL(node_id, idx)))))DT_IRQN_L3_INTERNAL(node_id,idx)(IRQ_TO_L3(DT_IRQN_BY_IDX_INTERNAL(node_id, idx)) | IRQ_TO_L2(DT_PARENT_INTC_IRQN_INTERNAL(node_id)) | DT_GPARENT_INTC_IRQN_INTERNAL(node_id))DT_IRQN_L2_INTERNAL(node_id,idx)(IRQ_TO_L2(DT_IRQN_BY_IDX_INTERNAL(node_id, idx)) | DT_PARENT_INTC_IRQN_INTERNAL(node_id))DT_GPARENT_INTC_IRQN_INTERNAL(node_id)DT_IRQ(DT_GPARENT_INTC_INTERNAL(node_id), irq)DT_PARENT_INTC_IRQN_INTERNAL(node_id)DT_IRQ(DT_PARENT_INTC_INTERNAL(node_id), irq)DT_IRQN_BY_IDX_INTERNAL(node_id,idx)DT_IRQ_BY_IDX(node_id, idx, irq)DT_HAS_GPARENT_INTC_INTERNAL(node_id)IF_ENABLED(DT_HAS_PARENT_INTC_INTERNAL(node_id), (DT_HAS_PARENT_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(node_id))))DT_HAS_PARENT_INTC_INTERNAL(node_id)IF_ENABLED(DT_NODE_HAS_PROP(node_id, interrupt_parent), (IF_ENABLED(DT_IS_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(node_id)), (COND_CODE_0(DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(node_id)), (0), (1))))))DT_IS_INTC_INTERNAL(node_id)DT_NODE_HAS_PROP(node_id, interrupt_controller)DT_GPARENT_INTC_INTERNAL(node_id)DT_PARENT_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(node_id))DT_PARENT_INTC_INTERNAL(node_id)DT_PROP(node_id, interrupt_parent)DT_IRQ(node_id,cell)DT_IRQ_BY_IDX(node_id, 0, cell)DT_IRQ_BY_NAME(node_id,name,cell)DT_CAT5(node_id, _IRQ_NAME_, name, _VAL_, cell)DT_IRQ_BY_IDX(node_id,idx,cell)DT_CAT5(node_id, _IRQ_IDX_, idx, _VAL_, cell)DT_IRQ_HAS_NAME(node_id,name)IS_ENABLED(DT_CAT4(node_id, _IRQ_NAME_, name, _VAL_irq_EXISTS))DT_IRQ_HAS_CELL(node_id,cell)DT_IRQ_HAS_CELL_AT_IDX(node_id, 0, cell)DT_IRQ_HAS_CELL_AT_IDX(node_id,idx,cell)IS_ENABLED(DT_CAT6(node_id, _IRQ_IDX_, idx, _VAL_, cell, _EXISTS))DT_IRQ_HAS_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _IRQ_IDX_, idx, _EXISTS))DT_NUM_IRQS(node_id)DT_CAT(node_id, _IRQ_NUM)DT_REG_SIZE_BY_NAME(node_id,name)DT_CAT4(node_id, _REG_NAME_, name, _VAL_SIZE)DT_REG_ADDR_BY_NAME_U64(node_id,name)DT_U64_C(DT_REG_ADDR_BY_NAME(node_id, name))DT_REG_ADDR_BY_NAME(node_id,name)DT_CAT4(node_id, _REG_NAME_, name, _VAL_ADDRESS)DT_REG_SIZE(node_id)DT_REG_SIZE_BY_IDX(node_id, 0)DT_REG_ADDR_U64(node_id)DT_U64_C(DT_REG_ADDR(node_id))DT_REG_ADDR(node_id)DT_REG_ADDR_BY_IDX(node_id, 0)DT_REG_SIZE_BY_IDX(node_id,idx)DT_CAT4(node_id, _REG_IDX_, idx, _VAL_SIZE)DT_REG_ADDR_BY_IDX(node_id,idx)DT_CAT4(node_id, _REG_IDX_, idx, _VAL_ADDRESS)DT_REG_HAS_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _REG_IDX_, idx, _EXISTS))DT_NUM_REGS(node_id)DT_CAT(node_id, _REG_NUM)DT_NODE_MODEL_OR(node_id,default_value)DT_NODE_MODEL_BY_IDX_OR(node_id, 0, default_value)DT_NODE_MODEL_BY_IDX_OR(node_id,idx,default_value)COND_CODE_1(DT_NODE_MODEL_HAS_IDX(node_id, idx), (DT_NODE_MODEL_BY_IDX(node_id, idx)), (default_value))DT_NODE_MODEL_HAS_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _COMPAT_MODEL_IDX_, idx, _EXISTS))DT_NODE_MODEL_BY_IDX(node_id,idx)DT_CAT3(node_id, _COMPAT_MODEL_IDX_, idx)DT_NODE_VENDOR_OR(node_id,default_value)DT_NODE_VENDOR_BY_IDX_OR(node_id, 0, default_value)DT_NODE_VENDOR_BY_IDX_OR(node_id,idx,default_value)COND_CODE_1(DT_NODE_VENDOR_HAS_IDX(node_id, idx), (DT_NODE_VENDOR_BY_IDX(node_id, idx)), (default_value))DT_NODE_VENDOR_HAS_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _COMPAT_VENDOR_IDX_, idx, _EXISTS))DT_NODE_VENDOR_BY_IDX(node_id,idx)DT_CAT3(node_id, _COMPAT_VENDOR_IDX_, idx)DT_FOREACH_RANGE(node_id,fn)DT_CAT(node_id, _FOREACH_RANGE)(fn)DT_RANGES_LENGTH_BY_IDX(node_id,idx)DT_CAT4(node_id, _RANGES_IDX_, idx, _VAL_LENGTH)DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(node_id,idx)DT_CAT4(node_id, _RANGES_IDX_, idx, _VAL_PARENT_BUS_ADDRESS)DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(node_id,idx)DT_CAT4(node_id, _RANGES_IDX_, idx, _VAL_CHILD_BUS_ADDRESS)DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(node_id,idx)DT_CAT4(node_id, _RANGES_IDX_, idx, _VAL_CHILD_BUS_FLAGS)DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _RANGES_IDX_, idx, _VAL_CHILD_BUS_FLAGS_EXISTS))DT_RANGES_HAS_IDX(node_id,idx)IS_ENABLED(DT_CAT4(node_id, _RANGES_IDX_, idx, _EXISTS))DT_NUM_RANGES(node_id)DT_CAT(node_id, _RANGES_NUM)DT_PHANDLE(node_id,prop)DT_PHANDLE_BY_IDX(node_id, prop, 0)DT_PHANDLE_BY_IDX(node_id,prop,idx)DT_CAT6(node_id, _P_, prop, _IDX_, idx, _PH)DT_PHANDLE_BY_NAME(node_id,pha,name)DT_CAT6(node_id, _P_, pha, _NAME_, name, _PH)DT_PHA_BY_NAME_OR(node_id,pha,name,cell,default_value)DT_PROP_OR(node_id, pha ## _NAME_ ## name ## _VAL_ ## cell, default_value)DT_PHA_BY_NAME(node_id,pha,name,cell)DT_CAT7(node_id, _P_, pha, _NAME_, name, _VAL_, cell)DT_PHA_OR(node_id,pha,cell,default_value)DT_PHA_BY_IDX_OR(node_id, pha, 0, cell, default_value)DT_PHA(node_id,pha,cell)DT_PHA_BY_IDX(node_id, pha, 0, cell)DT_PHA_BY_IDX_OR(node_id,pha,idx,cell,default_value)DT_PROP_OR(node_id, pha ## _IDX_ ## idx ## _VAL_ ## cell, default_value)DT_PHA_BY_IDX(node_id,pha,idx,cell)DT_CAT7(node_id, _P_, pha, _IDX_, idx, _VAL_, cell)DT_PROP_BY_PHANDLE(node_id,ph,prop)DT_PROP_BY_PHANDLE_IDX(node_id, ph, 0, prop)DT_PROP_BY_PHANDLE_IDX_OR(node_id,phs,idx,prop,default_value)DT_PROP_OR(DT_PHANDLE_BY_IDX(node_id, phs, idx), prop, default_value)DT_PROP_BY_PHANDLE_IDX(node_id,phs,idx,prop)DT_PROP(DT_PHANDLE_BY_IDX(node_id, phs, idx), prop)DT_STRING_UNQUOTED_BY_IDX(node_id,prop,idx)DT_CAT4(node_id, _P_, prop ## _IDX_ ## idx, _STRING_UNQUOTED)DT_STRING_UPPER_TOKEN_BY_IDX(node_id,prop,idx)DT_CAT6(node_id, _P_, prop, _IDX_, idx, _STRING_UPPER_TOKEN)DT_STRING_TOKEN_BY_IDX(node_id,prop,idx)DT_CAT6(node_id, _P_, prop, _IDX_, idx, _STRING_TOKEN)DT_STRING_UNQUOTED_OR(node_id,prop,default_value)COND_CODE_1(DT_NODE_HAS_PROP(node_id, prop), (DT_STRING_UNQUOTED(node_id, prop)), (default_value))DT_STRING_UNQUOTED(node_id,prop)DT_CAT4(node_id, _P_, prop, _STRING_UNQUOTED)DT_STRING_UPPER_TOKEN_OR(node_id,prop,default_value)COND_CODE_1(DT_NODE_HAS_PROP(node_id, prop), (DT_STRING_UPPER_TOKEN(node_id, prop)), (default_value))DT_STRING_UPPER_TOKEN(node_id,prop)DT_CAT4(node_id, _P_, prop, _STRING_UPPER_TOKEN)DT_STRING_TOKEN_OR(node_id,prop,default_value)COND_CODE_1(DT_NODE_HAS_PROP(node_id, prop), (DT_STRING_TOKEN(node_id, prop)), (default_value))DT_STRING_TOKEN(node_id,prop)DT_CAT4(node_id, _P_, prop, _STRING_TOKEN)DT_ENUM_HAS_VALUE(node_id,prop,value)IS_ENABLED(DT_CAT6(node_id, _P_, prop, _ENUM_VAL_, value, _EXISTS))DT_ENUM_IDX_OR(node_id,prop,default_idx_value)COND_CODE_1(DT_NODE_HAS_PROP(node_id, prop), (DT_ENUM_IDX(node_id, prop)), (default_idx_value))DT_ENUM_IDX(node_id,prop)DT_CAT4(node_id, _P_, prop, _ENUM_IDX)DT_LABEL(node_id)DT_PROP(node_id, label) __DEPRECATED_MACRODT_PROP_OR(node_id,prop,default_value)COND_CODE_1(DT_NODE_HAS_PROP(node_id, prop), (DT_PROP(node_id, prop)), (default_value))DT_PROP_BY_IDX(node_id,prop,idx)DT_CAT5(node_id, _P_, prop, _IDX_, idx)DT_PROP_HAS_NAME(node_id,prop,name)IS_ENABLED(DT_CAT6(node_id, _P_, prop, _NAME_, name, _EXISTS))DT_PROP_HAS_IDX(node_id,prop,idx)IS_ENABLED(DT_CAT6(node_id, _P_, prop, _IDX_, idx, _EXISTS))DT_PROP_LEN_OR(node_id,prop,default_value)COND_CODE_1(DT_NODE_HAS_PROP(node_id, prop), (DT_PROP_LEN(node_id, prop)), (default_value))DT_PROP_LEN(node_id,prop)DT_CAT4(node_id, _P_, prop, _LEN)DT_PROP(node_id,prop)DT_CAT3(node_id, _P_, prop)DT_SAME_NODE(node_id1,node_id2)(DT_DEP_ORD(node_id1) == (DT_DEP_ORD(node_id2)))DT_NODE_CHILD_IDX(node_id)DT_CAT(node_id, _CHILD_IDX)DT_NODE_FULL_NAME(node_id)DT_CAT(node_id, _FULL_NAME)DT_NODE_PATH(node_id)DT_CAT(node_id, _PATH)DT_COMPAT_GET_ANY_STATUS_OKAY(compat)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(compat), (DT_INST(0, compat)), (DT_INVALID_NODE))DT_CHILD(node_id,child)UTIL_CAT(node_id, DT_S_PREFIX(child))DT_GPARENT(node_id)DT_PARENT(DT_PARENT(node_id))DT_PARENT(node_id)UTIL_CAT(node_id, _PARENT)DT_INST(inst,compat)UTIL_CAT(DT_N_INST, DT_DASH(inst, compat))DT_ALIAS(alias)DT_CAT(DT_N_ALIAS_, alias)DT_NODELABEL(label)DT_CAT(DT_N_NODELABEL_, label)DT_PATH(__VA_ARGS__...)DT_PATH_INTERNAL(__VA_ARGS__)DT_ROOTDT_INVALID_NODEDEVICETREE_H!defined(_LINKER) && !defined(_ASMLANGUAGE)defined(_LINKER) || defined(_ASMLANGUAGE)/* DEVICETREE_H *//* have these last so they have access to all previously defined macros *//**
 * @def DT_U64_C
 * @brief Macro to add ULL postfix to the devicetree address constants
 *//** @brief Helper macro to OR multiple has property checks in a loop macro *//** @brief Helper for DT_NODE_HAS_STATUS *//** @brief Helper for DT_DASH(): prepends _ to a name *//** @brief Helper for node identifier macros to expand args *//*
 * If you need to define a bigger DT_CATN(), do so here. Don't leave
 * any "holes" of undefined macros, please.
 *//** @brief concatenation helper, 8 arguments *//** @brief concatenation helper, 7 arguments *//** @brief Concatenation helper, 6 arguments *//** @brief Internal concatenation helper, 5 arguments *//** @brief Concatenation helper, 4 arguments *//** @brief Concatenation helper, 3 arguments *//**
 * @brief Concatenation helper, 2 arguments
 *
 * This and the following macros are used to paste things together
 * with "##" *after* forcing expansion on each argument.
 *
 * We could try to use something like UTIL_CAT(), but the compiler
 * error messages from the util macros can be extremely long when they
 * are misused. This unfortunately happens often with devicetree.h,
 * since its macro-based API is fiddly and can be hard to get right.
 *
 * Keeping things brutally simple here hopefully makes some errors
 * easier to read.
 *//** @brief DT_PATH_INTERNAL() helper: prepends _S_ to a node name
 * We don't want to expand 'name' recursively before expansion
 * in this case. The MACRO_MAP_CAT above is giving us the exact
 * tokens it wants prefixed with _S_.
 *//**
 * @brief Does a `DT_DRV_COMPAT` instance have an interrupt value?
 * @param inst instance number
 * @param name lowercase-and-underscores interrupt specifier name
 * @return 1 if @p name is a valid named specifier
 *//**
 * @brief Does a `DT_DRV_COMPAT` instance have an interrupt value?
 * @param inst instance number
 * @param cell named cell value whose existence to check
 * @return 1 if the named @p cell exists in the interrupt specifier at index 0
 *         0 otherwise.
 *//**
 * @brief Does a `DT_DRV_COMPAT` instance have an interrupt named cell specifier?
 * @param inst instance number
 * @param idx index to check
 * @param cell named cell value whose existence to check
 * @return 1 if the named @p cell exists in the interrupt specifier at index
 *         @p idx 0 otherwise.
 *//**
 * @brief is index valid for interrupt property on a `DT_DRV_COMPAT` instance?
 * @param inst instance number
 * @param idx logical index into the interrupt specifier array
 * @return 1 if the @p idx is valid for the interrupt property
 *         0 otherwise.
 *//**
 * @brief Does a phandle array have a named cell specifier at index 0
 *        for a `DT_DRV_COMPAT` instance?
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param cell named cell value whose existence to check
 * @return 1 if the named @p cell exists in the specifier at index 0,
 *         0 otherwise.
 *//**
 * @brief Does a phandle array have a named cell specifier at an index
 *        for a `DT_DRV_COMPAT` instance?
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param idx index to check
 * @param cell named cell value whose existence to check
 * @return 1 if the named @p cell exists in the specifier at index @p idx,
 *         0 otherwise.
 *//**
 * @brief Does a DT_DRV_COMPAT instance have a property?
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return 1 if the instance has the property, 0 otherwise.
 *//**
 * @brief Invokes @p fn for each element of property @p prop for
 *        a `DT_DRV_COMPAT` instance with multiple arguments and a sepatator.
 *
 * Equivalent to
 *      DT_FOREACH_PROP_ELEM_SEP_VARGS(DT_DRV_INST(inst), prop, fn, sep,
 *                                     __VA_ARGS__)
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... variable number of arguments to pass to fn
 *
 * @see DT_INST_FOREACH_PROP_ELEM
 *//**
 * @brief Invokes @p fn for each element of property @p prop for
 *        a `DT_DRV_COMPAT` instance with multiple arguments.
 *
 * Equivalent to
 *      DT_FOREACH_PROP_ELEM_VARGS(DT_DRV_INST(inst), prop, fn, __VA_ARGS__)
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_INST_FOREACH_PROP_ELEM
 *//**
 * @brief Invokes @p fn for each element of property @p prop for
 *        a `DT_DRV_COMPAT` instance with a separator.
 *
 * Equivalent to DT_FOREACH_PROP_ELEM_SEP(DT_DRV_INST(inst), prop, fn, sep).
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *//**
 * @brief Invokes @p fn for each element of property @p prop for
 *        a `DT_DRV_COMPAT` instance.
 *
 * Equivalent to DT_FOREACH_PROP_ELEM(DT_DRV_INST(inst), prop, fn).
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 *//**
 * @brief Call @p fn on all nodes with compatible `DT_DRV_COMPAT`
 *        and status `okay` with multiple arguments
 *
 *
 * @param fn Macro to call for each enabled node. Must accept an
 *           instance number as its only parameter.
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_INST_FOREACH_STATUS_OKAY
 *//**
 * @brief Call @p fn on all nodes with compatible `DT_DRV_COMPAT`
 *        and status `okay`
 *
 * This macro calls `fn(inst)` on each `inst` number that refers to a
 * node with status `okay`. Whitespace is added between invocations.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     a {
 *             compatible = "vnd,device";
 *             status = "okay";
 *             foobar = "DEV_A";
 *     };
 *
 *     b {
 *             compatible = "vnd,device";
 *             status = "okay";
 *             foobar = "DEV_B";
 *     };
 *
 *     c {
 *             compatible = "vnd,device";
 *             status = "disabled";
 *             foobar = "DEV_C";
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define DT_DRV_COMPAT vnd_device
 *     #define MY_FN(inst) DT_INST_PROP(inst, foobar),
 *
 *     DT_INST_FOREACH_STATUS_OKAY(MY_FN)
 * @endcode
 *
 * This expands to:
 *
 * @code{.c}
 *     MY_FN(0) MY_FN(1)
 * @endcode
 *
 * and from there, to either this:
 *
 *     "DEV_A", "DEV_B",
 *
 * or this:
 *
 *     "DEV_B", "DEV_A",
 *
 * No guarantees are made about the order that a and b appear in the
 * expansion.
 *
 * Note that @p fn is responsible for adding commas, semicolons, or
 * other separators or terminators.
 *
 * Device drivers should use this macro whenever possible to
 * instantiate a struct device for each enabled node in the devicetree
 * of the driver's compatible `DT_DRV_COMPAT`.
 *
 * @param fn Macro to call for each enabled node. Must accept an
 *           instance number as its only parameter.
 *//**
 * @brief Check if any `DT_DRV_COMPAT` node with status `okay` has a given
 *        property.
 *
 * @param prop lowercase-and-underscores property name
 *
 * Example devicetree overlay:
 *
 * @code{.dts}
 *     &i2c0 {
 *         sensor0: sensor@0 {
 *             compatible = "vnd,some-sensor";
 *             status = "okay";
 *             reg = <0>;
 *             foo = <1>;
 *             bar = <2>;
 *         };
 *
 *         sensor1: sensor@1 {
 *             compatible = "vnd,some-sensor";
 *             status = "okay";
 *             reg = <1>;
 *             foo = <2>;
 *         };
 *
 *         sensor2: sensor@2 {
 *             compatible = "vnd,some-sensor";
 *             status = "disabled";
 *             reg = <2>;
 *             baz = <1>;
 *         };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define DT_DRV_COMPAT vnd_some_sensor
 *
 *     DT_ANY_INST_HAS_PROP_STATUS_OKAY(foo) // 1
 *     DT_ANY_INST_HAS_PROP_STATUS_OKAY(bar) // 1
 *     DT_ANY_INST_HAS_PROP_STATUS_OKAY(baz) // 0
 * @endcode
 *//**
 * @brief Test if any `DT_DRV_COMPAT` node is on a bus of a given type
 *        and has status okay
 *
 * This is a special-purpose macro which can be useful when writing
 * drivers for devices which can appear on multiple buses. One example
 * is a sensor device which may be wired on an I2C or SPI bus.
 *
 * Example devicetree overlay:
 *
 * @code{.dts}
 *     &i2c0 {
 *            temp: temperature-sensor@76 {
 *                     compatible = "vnd,some-sensor";
 *                     reg = <0x76>;
 *            };
 *     };
 * @endcode
 *
 * Example usage, assuming `i2c0` is an I2C bus controller node, and
 * therefore `temp` is on an I2C bus:
 *
 * @code{.c}
 *     #define DT_DRV_COMPAT vnd_some_sensor
 *
 *     DT_ANY_INST_ON_BUS_STATUS_OKAY(i2c) // 1
 * @endcode
 *
 * @param bus a binding's bus type as a C token, lowercased and without quotes
 * @return 1 if any enabled node with that compatible is on that bus type,
 *         0 otherwise
 *//*
 * @brief Test if any enabled node with the given compatible is on
 *        the given bus type
 *
 * This is like DT_ANY_INST_ON_BUS_STATUS_OKAY(), except it can also
 * be useful for handling multiple compatibles in single source file.
 *
 * Example devicetree overlay:
 *
 * @code{.dts}
 *     &i2c0 {
 *            temp: temperature-sensor@76 {
 *                     compatible = "vnd,some-sensor";
 *                     reg = <0x76>;
 *            };
 *     };
 * @endcode
 *
 * Example usage, assuming `i2c0` is an I2C bus controller node, and
 * therefore `temp` is on an I2C bus:
 *
 * @code{.c}
 *     DT_HAS_COMPAT_ON_BUS_STATUS_OKAY(vnd_some_sensor, i2c) // 1
 * @endcode
 *
 * @param compat lowercase-and-underscores compatible, without quotes
 * @param bus a binding's bus type as a C token, lowercased and without quotes
 * @return 1 if any enabled node with that compatible is on that bus type,
 *         0 otherwise
 *//**
 * @brief Like DT_INST_STRING_UNQUOTED(), but with a fallback to
 *        @p default_value
 * @param inst instance number
 * @param name lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return the property's value as a sequence of tokens, with no quotes, or @p default_value
 *//**
 * @brief Like DT_INST_STRING_UPPER_TOKEN(), but with a fallback to
 *        @p default_value
 * @param inst instance number
 * @param name lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return the property's value as an uppercased token, or @p default_value
 *//**
 * @brief Like DT_INST_STRING_TOKEN(), but with a fallback to @p default_value
 * @param inst instance number
 * @param name lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return if @p prop exists, its value as a token, i.e. without any quotes and
 *         with special characters converted to underscores. Othewise
 *         @p default_value
 *//**
 * @brief Test if a `DT_DRV_COMPAT`'s bus type is a given type
 * @param inst instance number
 * @param bus a binding's bus type as a C token, lowercased and without quotes
 * @return 1 if the given instance is on a bus of the given type,
 *         0 otherwise
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_INST_BUS(inst)).
 *
 * @brief Get a `DT_DRV_COMPAT`'s bus node's label property
 * @param inst instance number
 * @return the label property of the instance's bus controller
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s bus node identifier
 * @param inst instance number
 * @return node identifier for the instance's bus node
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s irq number at index
 * @param inst instance number
 * @param idx logical index into the interrupt specifier array
 * @return the interrupt number for the node's idx-th interrupt
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s (only) irq number
 * @param inst instance number
 * @return the interrupt number for the node's only interrupt
 *//**
 * @brief Get a `DT_DRV_COMPAT` interrupt specifier's value
 * @param inst instance number
 * @param cell cell name specifier
 * @return the named value at that index
 *//**
 * @brief Get a `DT_DRV_COMPAT` interrupt specifier value by name
 * @param inst instance number
 * @param name lowercase-and-underscores interrupt specifier name
 * @param cell cell name specifier
 * @return the named value at the specifier given by the index
 *//**
 * @brief Get a `DT_DRV_COMPAT` interrupt specifier value at an index
 * @param inst instance number
 * @param idx logical index into the interrupt specifier array
 * @param cell cell name specifier
 * @return the named value at the specifier given by the index
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s (only) register block size
 * @param inst instance number
 * @return instance's register block size
 *//**
 * @brief 64-bit version of DT_INST_REG_ADDR()
 *
 * This macro version adds the appropriate suffix for 64-bit unsigned
 * integer literals.
 * Note that this macro is equivalent to DT_INST_REG_ADDR() in
 * linker/ASM context.
 *
 * @param inst instance number
 * @return instance's register block address
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s (only) register block address
 * @param inst instance number
 * @return instance's register block address
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s register block size by name
 * @param inst instance number
 * @param name lowercase-and-underscores register specifier name
 * @return size of the register block with the given @p name
 *//**
 * @brief 64-bit version of DT_INST_REG_ADDR_BY_NAME()
 *
 * This macro version adds the appropriate suffix for 64-bit unsigned
 * integer literals.
 * Note that this macro is equivalent to DT_INST_REG_ADDR_BY_NAME() in
 * linker/ASM context.
 *
 * @param inst instance number
 * @param name lowercase-and-underscores register specifier name
 * @return address of the register block with the given @p name
 *//**
 * @brief Get a `DT_DRV_COMPAT`'s register block address by  name
 * @param inst instance number
 * @param name lowercase-and-underscores register specifier name
 * @return address of the register block with the given @p name
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's idx-th register block's size
 * @param inst instance number
 * @param idx index of the register whose size to return
 * @return size of the instance's idx-th register block
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's idx-th register block's address
 * @param inst instance number
 * @param idx index of the register whose address to return
 * @return address of the instance's idx-th register block
 *//**
 * @brief is @p idx a valid register block index on a `DT_DRV_COMPAT` instance?
 * @param inst instance number
 * @param idx index to check
 * @return 1 if @p idx is a valid register block index,
 *         0 otherwise.
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's node identifier for a phandle
 * property's value
 * @param inst instance number
 * @param prop lowercase-and-underscores property of @p inst
 *             with type `phandle`
 * @return a node identifier for the node pointed to by "ph"
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's node identifier for a phandle in
 * a property.
 * @param inst instance number
 * @param prop lowercase-and-underscores property name in @p inst
 *             with type `phandle`, `phandles` or `phandle-array`
 * @param idx index into @p prop
 * @return a node identifier for the phandle at index @p idx in @p prop
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's phandle node identifier from a
 * phandle array by name
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param name lowercase-and-underscores name of an element in @p pha
 * @return node identifier for the phandle at the element named "name"
 *//**
 * @brief Like DT_INST_PHA_BY_NAME(), but with a fallback to default_value
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param name lowercase-and-underscores name of a specifier in @p pha
 * @param cell binding's cell name for the named specifier
 * @param default_value a fallback value to expand to
 * @return DT_INST_PHA_BY_NAME(inst, pha, name, cell) or default_value
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's value within a phandle-array
 * specifier by name
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param name lowercase-and-underscores name of a specifier in @p pha
 * @param cell binding's cell name for the named specifier
 * @return the cell value
 *//**
 * @brief Like DT_INST_PHA(), but with a fallback to default_value
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param cell binding's cell name for the specifier at @p pha index 0
 * @param default_value a fallback value to expand to
 * @return DT_INST_PHA(inst, pha, cell) or default_value
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's phandle-array specifier value
 * Equivalent to DT_INST_PHA_BY_IDX(inst, pha, 0, cell)
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param cell binding's cell name for the specifier at @p pha index 0
 * @return the cell value
 *//**
 * @brief Like DT_INST_PHA_BY_IDX(), but with a fallback to default_value
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param idx logical index into the property @p pha
 * @param cell binding's cell name within the specifier at index @p idx
 * @param default_value a fallback value to expand to
 * @return DT_INST_PHA_BY_IDX(inst, pha, idx, cell) or default_value
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's phandle-array specifier value at an index
 * @param inst instance number
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param idx logical index into the property @p pha
 * @param cell binding's cell name within the specifier at index @p idx
 * @return the value of the cell inside the specifier at index @p idx
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's property value from a phandle in a
 * property.
 * @param inst instance number
 * @param phs lowercase-and-underscores property with type `phandle`,
 *            `phandles`, or `phandle-array`
 * @param idx logical index into "phs", which must be zero if "phs"
 *            has type `phandle`
 * @param prop lowercase-and-underscores property of the phandle's node
 * @return the value of @p prop as described in the DT_PROP() documentation
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's property value from a phandle's node
 * @param inst instance number
 * @param ph lowercase-and-underscores property of @p inst
 *           with type `phandle`
 * @param prop lowercase-and-underscores property of the phandle's node
 * @return the value of @p prop as described in the DT_PROP() documentation
 *//**
 * @brief Get an element out of string-array property as an unquoted sequence of tokens.
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return the value of @p prop at index @p idx as a sequence of tokens, with no quotes
 *//**
 * @brief Like DT_INST_STRING_TOKEN_BY_IDX(), but uppercased.
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return the element in @p prop at index @p idx as an uppercased token
 *//**
 * @brief Get an element out of string-array property as a token.
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return the element in @p prop at index @p idx as a token
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's string property's value as
 *        an unquoted sequence of tokens.
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return the value of @p prop as a sequence of tokens, with no quotes
 *//**
 * @brief Like DT_INST_STRING_TOKEN(), but uppercased.
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return the value of @p prop as an uppercased token, i.e. without
 *         any quotes and with special characters converted to underscores
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance's string property's value as a
 *        token.
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return the value of @p prop as a token, i.e. without any quotes
 *         and with special characters converted to underscores
 *//**
 * @deprecated Use DT_INST_PROP(inst, label)
 * @brief Get a `DT_DRV_COMPAT` instance's `label` property
 * @param inst instance number
 * @return instance's label property value
 *//**
 * @brief Like DT_INST_PROP_LEN(), but with a fallback to @p default_value
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return DT_INST_PROP_LEN(inst, prop) or @p default_value
 *//**
 * @brief Like DT_INST_PROP(), but with a fallback to @p default_value
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return DT_INST_PROP(inst, prop) or @p default_value
 *//**
 * @brief Get a `DT_DRV_COMPAT` element value in an array property
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return a representation of the idx-th element of the property
 *//**
 * @brief Is name @p name available in a `foo-names` property?
 * @param inst instance number
 * @param prop a lowercase-and-underscores `prop-names` type property
 * @param name a lowercase-and-underscores name to check
 * @return An expression which evaluates to 1 if @p name is an available
 *         name into the given property, and 0 otherwise.
 *//**
 * @brief Is index @p idx valid for an array type property
 *        on a `DT_DRV_COMPAT` instance?
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param idx index to check
 * @return 1 if @p idx is a valid index into the given property,
 *         0 otherwise.
 *//**
 * @brief Get a `DT_DRV_COMPAT` property length
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return logical length of the property
 *//**
 * @brief Get a `DT_DRV_COMPAT` instance property
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return a representation of the property's value
 *//**
 * @brief Does a `DT_DRV_COMPAT` enumeration property have a given value?
 *
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param value lowercase-and-underscores enumeration value
 * @return 1 if the node property has the value @a value, 0 otherwise.
 *//**
 * @brief Like DT_INST_ENUM_IDX(), but with a fallback to a default enum index
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @param default_idx_value a fallback index value to expand to
 * @return zero-based index of the property's value in its enum if present,
 *         default_idx_value otherwise
 *//**
 * @brief Get a `DT_DRV_COMPAT` value's index into its enumeration values
 * @param inst instance number
 * @param prop lowercase-and-underscores property name
 * @return zero-based index of the property's value in its enum: list
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst) with status `okay`
 * and with separator and multiple arguments.
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD_STATUS_OKAY_SEP_VARGS
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst) with status `okay`
 * and multiple arguments.
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD_STATUS_OKAY_VARGS
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst) with status `okay`
 * and with separator.
 *
 * The macro @p fn should take one argument, which is the node
 * identifier for the child node.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *
 * @see DT_FOREACH_CHILD_STATUS_OKAY_SEP
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst) with status `okay`.
 *
 * The macro @p fn should take one argument, which is the node
 * identifier for the child node.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 *
 * @see DT_FOREACH_CHILD_STATUS_OKAY
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst) with separator.
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD_SEP_VARGS
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst).
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * The children will be iterated over in the same order as they
 * appear in the final devicetree.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst) with a separator
 *
 * The macro @p fn should take one argument, which is the node
 * identifier for the child node.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *
 * @see DT_FOREACH_CHILD_SEP
 *//**
 * @brief Call @p fn on all child nodes of DT_DRV_INST(inst).
 *
 * The macro @p fn should take one argument, which is the node
 * identifier for the child node.
 *
 * The children will be iterated over in the same order as they
 * appear in the final devicetree.
 *
 * @param inst instance number
 * @param fn macro to invoke on each child node identifier
 *
 * @see DT_FOREACH_CHILD
 *//**
 * @brief Get a node identifier for a child node of DT_DRV_INST(inst)
 *
 * @param inst instance number
 * @param child lowercase-and-underscores child node name
 * @return node identifier for the node with the name referred to by 'child'
 *
 * @see DT_CHILD
 *//**
 * @brief Get a `DT_DRV_COMPAT` grandparent's node identifier
 * @param inst instance number
 * @return a node identifier for the instance's grandparent
 *
 * @see DT_GPARENT
 *//**
 * @brief Get a `DT_DRV_COMPAT` parent's node identifier
 * @param inst instance number
 * @return a node identifier for the instance's parent
 *
 * @see DT_PARENT
 *//**
 * @brief Node identifier for an instance of a `DT_DRV_COMPAT` compatible
 * @param inst instance number
 * @return a node identifier for the node with `DT_DRV_COMPAT` compatible and
 *         instance number @p inst
 *//**
 * @defgroup devicetree-inst Instance-based devicetree APIs
 * @ingroup devicetree
 * @{
 *//**
 * @brief Is a node on a bus of a given type?
 *
 * Example devicetree overlay:
 *
 * @code{.dts}
 *     &i2c0 {
 *            temp: temperature-sensor@76 {
 *                     compatible = "vnd,some-sensor";
 *                     reg = <0x76>;
 *            };
 *     };
 * @endcode
 *
 * Example usage, assuming `i2c0` is an I2C bus controller node, and
 * therefore `temp` is on an I2C bus:
 *
 * @code{.c}
 *     DT_ON_BUS(DT_NODELABEL(temp), i2c) // 1
 *     DT_ON_BUS(DT_NODELABEL(temp), spi) // 0
 * @endcode
 *
 * @param node_id node identifier
 * @param bus lowercase-and-underscores bus type as a C token (i.e.
 *            without quotes)
 * @return 1 if the node is on a bus of the given type,
 *         0 otherwise
 *//**
 * @deprecated If used to obtain a device instance with device_get_binding,
 * consider using @c DEVICE_DT_GET(DT_BUS(node)).
 *
 * @brief Node's bus controller's `label` property
 * @param node_id node identifier
 * @return the label property of the node's bus controller DT_BUS(node)
 *//**
 * @brief Node's bus controller
 *
 * Get the node identifier of the node's bus controller. This can be
 * used with DT_PROP() to get properties of the bus controller.
 *
 * It is an error to use this with nodes which do not have bus
 * controllers.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     i2c@deadbeef {
 *             status = "okay";
 *             clock-frequency = < 100000 >;
 *
 *             i2c_device: accelerometer@12 {
 *                     ...
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_PROP(DT_BUS(DT_NODELABEL(i2c_device)), clock_frequency) // 100000
 * @endcode
 *
 * @param node_id node identifier
 * @return a node identifier for the node's bus controller
 *//**
 * @defgroup devicetree-generic-bus Bus helpers
 * @ingroup devicetree
 * @{
 *//**
 * @brief Equivalent to DT_PHA_HAS_CELL_AT_IDX(node_id, pha, 0, cell)
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param cell lowercase-and-underscores cell name whose existence to check
 *             at index @p idx
 * @return 1 if the named cell exists in the specifier at index 0,
 *         0 otherwise.
 *//**
 * @brief Does a phandle array have a named cell specifier at an index?
 *
 * If this returns 1, then the phandle-array property @p pha has a cell
 * named @p cell at index @p idx, and therefore DT_PHA_BY_IDX(node_id,
 * pha, idx, cell) is valid. If it returns 0, it's an error to use
 * DT_PHA_BY_IDX() with the same arguments.
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param idx index to check within @p pha
 * @param cell lowercase-and-underscores cell name whose existence to check
 *             at index @p idx
 * @return 1 if the named cell exists in the specifier at index idx,
 *         0 otherwise.
 *//**
 * @brief Does a devicetree node have a property?
 *
 * Tests whether a devicetree node has a property defined.
 *
 * This tests whether the property is defined at all, not whether a
 * boolean property is true or false. To get a boolean property's
 * truth value, use DT_PROP(node_id, prop) instead.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @return 1 if the node has the property, 0 otherwise.
 *//**
 * @brief Does a devicetree node have a compatible and status?
 *
 * This is equivalent to:
 *
 * @code{.c}
 *     (DT_NODE_HAS_COMPAT(node_id, compat) &&
 *      DT_NODE_HAS_STATUS(node_id, status))
 * @endcode
 *
 * @param node_id node identifier
 * @param compat lowercase-and-underscores compatible, without quotes
 * @param status okay or disabled as a token, not a string
 *//**
 * @brief Does a devicetree node match a compatible?
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node {
 *             compatible = "vnd,specific-device", "generic-device";
 *     }
 * @endcode
 *
 * Example usages which evaluate to 1:
 *
 * @code{.c}
 *     DT_NODE_HAS_COMPAT(DT_NODELABEL(n), vnd_specific_device)
 *     DT_NODE_HAS_COMPAT(DT_NODELABEL(n), generic_device)
 * @endcode
 *
 * This macro only uses the value of the compatible property. Whether
 * or not a particular compatible has a matching binding has no effect
 * on its value, nor does the node's status.
 *
 * @param node_id node identifier
 * @param compat lowercase-and-underscores compatible, without quotes
 * @return 1 if the node's compatible property contains @p compat,
 *         0 otherwise.
 *//**
 * @brief Get the number of instances of a given compatible with
 *        status `okay`
 * @param compat lowercase-and-underscores compatible, without quotes
 * @return Number of instances with status `okay`
 *//**
 * @brief Does the devicetree have a status `okay` node with a compatible?
 *
 * Test for whether the devicetree has any nodes with status `okay`
 * and the given compatible. That is, this returns 1 if and only if
 * there is at least one @p node_id for which both of these
 * expressions return 1:
 *
 * @code{.c}
 *     DT_NODE_HAS_STATUS(node_id, okay)
 *     DT_NODE_HAS_COMPAT(node_id, compat)
 * @endcode
 *
 * As usual, both a missing status and an `ok` status are treated as
 * `okay`.
 *
 * @param compat lowercase-and-underscores compatible, without quotes
 * @return 1 if both of the above conditions are met, 0 otherwise
 *//**
 * @brief Does a node identifier refer to a node with a status?
 *
 * Example uses:
 *
 * @code{.c}
 *     DT_NODE_HAS_STATUS(DT_PATH(soc, i2c_12340000), okay)
 *     DT_NODE_HAS_STATUS(DT_PATH(soc, i2c_12340000), disabled)
 * @endcode
 *
 * Tests whether a node identifier refers to a node which:
 *
 * - exists in the devicetree, and
 * - has a status property matching the second argument
 *   (except that either a missing status or an `ok` status
 *   in the devicetree is treated as if it were `okay` instead)
 *
 * @param node_id a node identifier
 * @param status a status as one of the tokens okay or disabled, not a string
 * @return 1 if the node has the given status, 0 otherwise.
 *//**
 * @brief Does a node identifier refer to a node?
 *
 * Tests whether a node identifier refers to a node which exists, i.e.
 * is defined in the devicetree.
 *
 * It doesn't matter whether or not the node has a matching binding,
 * or what the node's status value is. This is purely a check of
 * whether the node exists at all.
 *
 * @param node_id a node identifier
 * @return 1 if the node identifier refers to a node,
 *         0 otherwise.
 *//**
 * @defgroup devicetree-generic-exist Existence checks
 * @ingroup devicetree
 * @{
 *//**
 * @brief Invokes @p fn for each status `okay` node of a compatible
 *        with multiple arguments.
 *
 * This is like DT_FOREACH_STATUS_OKAY() except you can also pass
 * additional arguments to @p fn.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             a {
 *                     compatible = "foo";
 *                     val = <3>;
 *             };
 *             b {
 *                     compatible = "foo";
 *                     val = <4>;
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define MY_FN(node_id, operator) DT_PROP(node_id, val) operator
 *     x = DT_FOREACH_STATUS_OKAY_VARGS(foo, MY_FN, +) 0;
 * @endcode
 *
 * This expands to one of the following:
 *
 * @code{.c}
 *     x = 3 + 4 + 0;
 *     x = 4 + 3 + 0;
 * @endcode
 *
 * i.e. it sets `x` to 7. As with DT_FOREACH_STATUS_OKAY(), there are no
 * guarantees about the order nodes appear in the expansion.
 *
 * @param compat lowercase-and-underscores devicetree compatible
 * @param fn Macro to call for each enabled node. Must accept a
 *           node_id as its only parameter.
 * @param ... Additional arguments to pass to @p fn
 *//**
 * @brief Invokes @p fn for each status `okay` node of a compatible.
 *
 * This macro expands to:
 *
 *     fn(node_id_1) fn(node_id_2) ... fn(node_id_n)
 *
 * where each `node_id_<i>` is a node identifier for some node with
 * compatible @p compat and status `okay`. Whitespace is added between
 * expansions as shown above.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             a {
 *                     compatible = "foo";
 *                     status = "okay";
 *             };
 *             b {
 *                     compatible = "foo";
 *                     status = "disabled";
 *             };
 *             c {
 *                     compatible = "foo";
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_FOREACH_STATUS_OKAY(foo, DT_NODE_PATH)
 * @endcode
 *
 * This expands to one of the following:
 *
 *     "/a" "/c"
 *     "/c" "/a"
 *
 * "One of the following" is because no guarantees are made about the
 * order that node identifiers are passed to @p fn in the expansion.
 *
 * (The `/c` string literal is present because a missing status
 * property is always treated as if the status were set to `okay`.)
 *
 * Note also that @p fn is responsible for adding commas, semicolons,
 * or other terminators as needed.
 *
 * @param compat lowercase-and-underscores devicetree compatible
 * @param fn Macro to call for each enabled node. Must accept a
 *           node_id as its only parameter.
 *//**
 * @brief Invokes @p fn for each element in the value of property @p prop with
 * multiple arguments and a separator.
 *
 * The @p prop parameter has the same restrictions as the same parameter
 * given to DT_FOREACH_PROP_ELEM().
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... variable number of arguments to pass to fn
 *
 * @see DT_FOREACH_PROP_ELEM_VARGS
 *//**
 * @brief Invokes @p fn for each element in the value of property @p prop with
 * multiple arguments.
 *
 * The macro @p fn must take multiple parameters:
 * `fn(node_id, prop, idx, ...)`. @p node_id and @p prop are the same as what
 * is passed to DT_FOREACH_PROP_ELEM(), and @p idx is the current index into
 * the array. The @p idx values are integer literals starting from 0. The
 * remaining arguments are passed-in by the caller.
 *
 * The @p prop parameter has the same restrictions as the same parameter
 * given to DT_FOREACH_PROP_ELEM().
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_PROP_ELEM
 *//**
 * @brief Invokes @p fn for each element in the value of property @p prop with
 *        separator.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node {
 *             my-gpios = <&gpioa 0 GPIO_ACTICE_HIGH>,
 *                        <&gpiob 1 GPIO_ACTIVE_HIGH>;
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     struct gpio_dt_spec specs[] = {
 *             DT_FOREACH_PROP_ELEM_SEP(DT_NODELABEL(n), my_gpios,
 *                                      GPIO_DT_SPEC_GET_BY_IDX, (,))
 *     };
 * @endcode
 *
 * This expands as a first step to:
 *
 * @code{.c}
 *     struct gpio_dt_spec specs[] = {
 *             GPIO_DT_SPEC_GET_BY_IDX(DT_NODELABEL(n), my_gpios, 0),
 *             GPIO_DT_SPEC_GET_BY_IDX(DT_NODELABEL(n), my_gpios, 1)
 *     };
 * @endcode
 *
 * The @p prop parameter has the same restrictions as the same parameter
 * given to DT_FOREACH_PROP_ELEM().
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *
 * @see DT_FOREACH_PROP_ELEM
 *//**
 * @brief Invokes @p fn for each element in the value of property @p prop.
 *
 * The macro @p fn must take three parameters: fn(node_id, prop, idx).
 * @p node_id and @p prop are the same as what is passed to
 * DT_FOREACH_PROP_ELEM(), and @p idx is the current index into the array.
 * The @p idx values are integer literals starting from 0.
 *
 * The @p prop argument must refer to a property that can be passed to
 * DT_PROP_LEN().
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node {
 *             my-ints = <1 2 3>;
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define TIMES_TWO(node_id, prop, idx) \
 *	       (2 * DT_PROP_BY_IDX(node_id, prop, idx)),
 *
 *     int array[] = {
 *             DT_FOREACH_PROP_ELEM(DT_NODELABEL(n), my_ints, TIMES_TWO)
 *     };
 * @endcode
 *
 * This expands to:
 *
 * @code{.c}
 *     int array[] = {
 *             (2 * 1), (2 * 2), (2 * 3),
 *     };
 * @endcode
 *
 * In general, this macro expands to:
 *
 *     fn(node_id, prop, 0) fn(node_id, prop, 1) [...] fn(node_id, prop, n-1)
 *
 * where `n` is the number of elements in @p prop, as it would be
 * returned by `DT_PROP_LEN(node_id, prop)`.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param fn macro to invoke
 * @see DT_PROP_LEN
 *//**
 * @brief Call @p fn on the child nodes with status `okay` with separator and
 * multiple arguments
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * As usual, both a missing status and an `ok` status are
 * treated as `okay`.
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD_SEP_STATUS_OKAY
 *//**
 * @brief Call @p fn on the child nodes with status `okay` with multiple
 * arguments
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * As usual, both a missing status and an `ok` status are
 * treated as `okay`.
 *
 * The children will be iterated over in the same order as they
 * appear in the final devicetree.
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD_STATUS_OKAY
 *//**
 * @brief Call @p fn on the child nodes with status `okay` with separator
 *
 * The macro @p fn should take one argument, which is the node
 * identifier for the child node.
 *
 * As usual, both a missing status and an `ok` status are
 * treated as `okay`.
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *
 * @see DT_FOREACH_CHILD_STATUS_OKAY
 *//**
 * @brief Call @p fn on the child nodes with status `okay`
 *
 * The macro @p fn should take one argument, which is the node
 * identifier for the child node.
 *
 * As usual, both a missing status and an `ok` status are
 * treated as `okay`.
 *
 * The children will be iterated over in the same order as they
 * appear in the final devicetree.
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 *//**
 * @brief Invokes @p fn for each child of @p node_id with separator and multiple
 *        arguments.
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD_VARGS
 *//**
 * @brief Invokes @p fn for each child of @p node_id with multiple arguments
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the child node. The remaining are passed-in by the caller.
 *
 * The children will be iterated over in the same order as they
 * appear in the final devicetree.
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 * @param ... variable number of arguments to pass to @p fn
 *
 * @see DT_FOREACH_CHILD
 *//**
 * @brief Invokes @p fn for each child of @p node_id with a separator
 *
 * The macro @p fn must take one parameter, which will be the node
 * identifier of a child node of @p node_id.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node {
 *             child-1 {
 *                     ...
 *             };
 *             child-2 {
 *                     ...
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     const char *child_names[] = {
 *         DT_FOREACH_CHILD_SEP(DT_NODELABEL(n), DT_NODE_FULL_NAME, (,))
 *     };
 * @endcode
 *
 * This expands to:
 *
 * @code{.c}
 *     const char *child_names[] = {
 *         "child-1", "child-2"
 *     };
 * @endcode
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 * @param sep Separator (e.g. comma or semicolon). Must be in parentheses;
 *            this is required to enable providing a comma as separator.
 *//**
 * @brief Invokes @p fn for each child of @p node_id
 *
 * The macro @p fn must take one parameter, which will be the node
 * identifier of a child node of @p node_id.
 *
 * The children will be iterated over in the same order as they
 * appear in the final devicetree.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node {
 *             child-1 {
 *                     foobar = "foo";
 *             };
 *             child-2 {
 *                     foobar = "bar";
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define FOOBAR_AND_COMMA(node_id) DT_PROP(node_id, foobar),
 *
 *     const char *child_foobars[] = {
 *         DT_FOREACH_CHILD(DT_NODELABEL(n), FOOBAR_AND_COMMA)
 *     };
 * @endcode
 *
 * This expands to:
 *
 * @code{.c}
 *     const char *child_foobars[] = {
 *         "foo", "bar",
 *     };
 * @endcode
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 *//**
 * @brief Invokes @p fn for every status `okay` node in the tree with multiple
 *        arguments.
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the node. The remaining are passed-in by the caller.
 *
 * The macro is expanded once for each node in the tree with status `okay` (as
 * usual, a missing status property is treated as status `okay`). The order
 * that nodes are visited in is not specified.
 *
 * @param fn macro to invoke
 * @param ... variable number of arguments to pass to @p fn
 *//**
 * @brief Invokes @p fn for every status `okay` node in the tree.
 *
 * The macro @p fn must take one parameter, which will be a node
 * identifier. The macro is expanded once for each node in the tree
 * with status `okay` (as usual, a missing status property is treated
 * as status `okay`). The order that nodes are visited in is not
 * specified.
 *
 * @param fn macro to invoke
 *//**
 * @brief Invokes @p fn for every node in the tree with multiple arguments.
 *
 * The macro @p fn takes multiple arguments. The first should be the node
 * identifier for the node. The remaining are passed-in by the caller.
 *
 * The macro is expanded once for each node in the tree. The order that nodes
 * are visited in is not specified.
 *
 * @param fn macro to invoke
 * @param ... variable number of arguments to pass to @p fn
 *//**
 * @brief Invokes @p fn for every node in the tree.
 *
 * The macro @p fn must take one parameter, which will be a node
 * identifier. The macro is expanded once for each node in the tree.
 * The order that nodes are visited in is not specified.
 *
 * @param fn macro to invoke
 *//**
 * @defgroup devicetree-generic-foreach "For-each" macros
 * @ingroup devicetree
 * @{
 *//**
 * @brief Test if the devicetree has a `/chosen` node
 * @param prop lowercase-and-underscores devicetree property
 * @return 1 if the chosen property exists and refers to a node,
 *         0 otherwise
 *//**
 * @brief Get a node identifier for a `/chosen` node property
 *
 * This is only valid to call if `DT_HAS_CHOSEN(prop)` is 1.
 * @param prop lowercase-and-underscores property name for
 *             the /chosen node
 * @return a node identifier for the chosen node property
 *//**
 * @defgroup devicetree-generic-chosen Chosen nodes
 * @ingroup devicetree
 * @{
 *//**
 * @brief Get a node's (only) irq number
 *
 * Equivalent to DT_IRQ(node_id, irq). This is provided as a convenience
 * for the common case where a node generates exactly one interrupt,
 * and the IRQ number is in a cell named `irq`.
 *
 * @param node_id node identifier
 * @return the interrupt number for the node's only interrupt
 *//**
 * @brief Get the node's Zephyr interrupt number at index
 * If @kconfig{CONFIG_MULTI_LEVEL_INTERRUPTS} is enabled, the interrupt number at index will be
 * multi-level encoded
 * @param node_id node identifier
 * @param idx logical index into the interrupt specifier array
 * @return the Zephyr interrupt number
 *//**
 * DT helper macro to encode a node's interrupt number according to the Zephyr's multi-level scheme
 * See doc/kernel/services/interrupts.rst for details
 *//* DT helper macro to encode a node's IRQN to level 3 according to the multi-level scheme *//* DT helper macro to encode a node's IRQN to level 2 according to the multi-level scheme *//* DT helper macro to get the node's grandparent intc's (only) irq number *//* DT helper macro to get the node's parent intc's (only) irq number *//**
 * DT helper macro to get the as-seen interrupt number in devicetree,
 * or ARM GIC IRQ encoded output from `gen_defines.py`
 *//* DT helper macro to check if the node has a grandparent interrupt controller *//* `interrupt-parent` node has interrupt cell(s) ? 1 : 0 *//* `interrupt-parent` node is an interrupt controller? *//* node has `interrupt-parent`? *//* DT helper macro to check if the node has a parent interrupt controller *//* DT helper macro to check if a node is an interrupt controller *//* DT helper macro to get the node's interrupt grandparent node  *//* DT helper macro to get interrupt-parent node  *//**
 * @brief Get an interrupt specifier's value
 * Equivalent to DT_IRQ_BY_IDX(node_id, 0, cell).
 * @param node_id node identifier
 * @param cell cell name specifier
 * @return the named value at that index
 *//**
 * @brief Get a value within an interrupt specifier by name
 *
 * It might help to read the argument order as being similar to
 * `node->interrupts.name.cell`.
 *
 * This can be used to get information about an individual interrupt
 * when a device generates more than one, if the bindings give each
 * interrupt specifier a name.
 *
 * @param node_id node identifier
 * @param name lowercase-and-underscores interrupt specifier name
 * @param cell cell name specifier
 * @return the named value at the specifier given by the index
 *//**
 * @brief Get a value within an interrupt specifier at an index
 *
 * It might help to read the argument order as being similar to
 * "node->interrupts[index].cell".
 *
 * This can be used to get information about an individual interrupt
 * when a device generates more than one.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     my-serial: serial@abcd1234 {
 *             interrupts = < 33 0 >, < 34 1 >;
 *     };
 * @endcode
 *
 * Assuming the node's interrupt domain has "#interrupt-cells = <2>;" and
 * the individual cells in each interrupt specifier are named "irq" and
 * "priority" by the node's binding, here are some examples:
 *
 *     #define SERIAL DT_NODELABEL(my_serial)
 *
 *     Example usage                       Value
 *     -------------                       -----
 *     DT_IRQ_BY_IDX(SERIAL, 0, irq)          33
 *     DT_IRQ_BY_IDX(SERIAL, 0, priority)      0
 *     DT_IRQ_BY_IDX(SERIAL, 1, irq,          34
 *     DT_IRQ_BY_IDX(SERIAL, 1, priority)      1
 *
 * @param node_id node identifier
 * @param idx logical index into the interrupt specifier array
 * @param cell cell name specifier
 * @return the named value at the specifier given by the index
 *//**
 * @brief Does an interrupts property have a named specifier value at an index?
 * If this returns 1, then DT_IRQ_BY_NAME(node_id, name, cell) is valid.
 * If it returns 0, it is an error to use that macro.
 * @param node_id node identifier
 * @param name lowercase-and-underscores interrupt specifier name
 * @return 1 if "name" is a valid named specifier
 *         0 otherwise.
 *//**
 * @brief Equivalent to DT_IRQ_HAS_CELL_AT_IDX(node_id, 0, cell)
 * @param node_id node identifier
 * @param cell named cell value whose existence to check
 * @return 1 if the named cell exists in the interrupt specifier at index 0
 *         0 otherwise.
 *//**
 * @brief Does an interrupts property have a named cell specifier at an index?
 * If this returns 1, then DT_IRQ_BY_IDX(node_id, idx, cell) is valid.
 * If it returns 0, it is an error to use that macro.
 * @param node_id node identifier
 * @param idx index to check
 * @param cell named cell value whose existence to check
 * @return 1 if the named cell exists in the interrupt specifier at index idx
 *         0 otherwise.
 *//**
 * @brief Is @p idx a valid interrupt index?
 *
 * If this returns 1, then DT_IRQ_BY_IDX(node_id, idx) is valid.
 * If it returns 0, it is an error to use that macro with this index.
 * @param node_id node identifier
 * @param idx index to check
 * @return 1 if the idx is valid for the interrupt property
 *         0 otherwise.
 *//**
 * @brief Get the number of interrupt sources for the node
 *
 * Use this instead of DT_PROP_LEN(node_id, interrupts).
 *
 * @param node_id node identifier
 * @return Number of interrupt specifiers in the node's "interrupts" property.
 *//**
 * @defgroup devicetree-interrupts-prop interrupts property
 * @ingroup devicetree
 * @{
 *//**
 * @brief Get a register block's size by name
 * @param node_id node identifier
 * @param name lowercase-and-underscores register specifier name
 * @return size of the register block specified by name
 *//**
 * @brief 64-bit version of DT_REG_ADDR_BY_NAME()
 *
 * This macro version adds the appropriate suffix for 64-bit unsigned
 * integer literals.
 * Note that this macro is equivalent to DT_REG_ADDR_BY_NAME() in
 * linker/ASM context.
 *
 * @param node_id node identifier
 * @param name lowercase-and-underscores register specifier name
 * @return address of the register block specified by name
 *//**
 * @brief Get a register block's base address by name
 * @param node_id node identifier
 * @param name lowercase-and-underscores register specifier name
 * @return address of the register block specified by name
 *//**
 * @brief Get a node's (only) register block size
 *
 * Equivalent to DT_REG_SIZE_BY_IDX(node_id, 0).
 * @param node_id node identifier
 * @return node's only register block's size
 *//**
 * @brief 64-bit version of DT_REG_ADDR()
 *
 * This macro version adds the appropriate suffix for 64-bit unsigned
 * integer literals.
 * Note that this macro is equivalent to DT_REG_ADDR() in linker/ASM context.
 *
 * @param node_id node identifier
 * @return node's register block address
 *//**
 * @brief Get a node's (only) register block address
 *
 * Equivalent to DT_REG_ADDR_BY_IDX(node_id, 0).
 * @param node_id node identifier
 * @return node's register block address
 *//**
 * @brief Get the size of the register block at index @p idx
 *
 * This is the size of an individual register block, not the total
 * number of register blocks in the property; use DT_NUM_REGS() for
 * that.
 *
 * @param node_id node identifier
 * @param idx index of the register whose size to return
 * @return size of the idx-th register block
 *//**
 * @brief Get the base address of the register block at index @p idx
 * @param node_id node identifier
 * @param idx index of the register whose address to return
 * @return address of the idx-th register block
 *//**
 * @brief Is @p idx a valid register block index?
 *
 * If this returns 1, then DT_REG_ADDR_BY_IDX(node_id, idx) or
 * DT_REG_SIZE_BY_IDX(node_id, idx) are valid.
 * If it returns 0, it is an error to use those macros with index @p idx.
 * @param node_id node identifier
 * @param idx index to check
 * @return 1 if @p idx is a valid register block index,
 *         0 otherwise.
 *//**
 * @brief Get the number of register blocks in the reg property
 *
 * Use this instead of DT_PROP_LEN(node_id, reg).
 * @param node_id node identifier
 * @return Number of register blocks in the node's "reg" property.
 *//**
 * @defgroup devicetree-reg-prop reg property
 * @ingroup devicetree
 * @{
 *//**
 * @brief Get the node's (only) model as a string literal
 *
 * Equivalent to DT_NODE_MODEL_BY_IDX_OR(node_id, 0, default_value).
 *
 * @param node_id node identifier
 * @param default_value a fallback value to expand to
 *//**
 * @brief Like DT_NODE_MODEL_BY_IDX(), but with a fallback to default_value.
 *
 * If the value exists, this expands to DT_NODE_MODEL_BY_IDX(node_id, idx).
 * The default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to default_value.
 *
 * @param node_id node identifier
 * @param idx index of the model to return
 * @return string literal of the idx-th model
 * @param default_value a fallback value to expand to
 * @return string literal of the idx-th model or "default_value"
 *//**
 * @brief Does a node's compatible property have a model at an index?
 *
 * If this returns 1, then DT_NODE_MODEL_BY_IDX(node_id, idx) is valid. If it
 * returns 0, it is an error to use DT_NODE_MODEL_BY_IDX(node_id, idx) with
 * index "idx".
 *
 * @param node_id node identifier
 * @param idx index of the model to check
 * @return 1 if "idx" is a valid model index,
 *         0 otherwise.
 *//**
 * @brief Get the model at index "idx" as a string literal
 *
 * The model is a string extracted from the compatible after the vendor prefix.
 *
 * Example vendor-prefixes.txt:
 *
 *	vnd	A stand-in for a real vendor
 *	zephyr	Zephyr-specific binding
 *
 * Example devicetree fragment:
 *
 *	n1: node-1 {
 *		compatible = "vnd,model1", "gpio", "zephyr,model2";
 *	};
 *
 * Example usage:
 *
 *	DT_NODE_MODEL_BY_IDX(DT_NODELABEL(n1), 0) // "model1"
 *	DT_NODE_MODEL_BY_IDX(DT_NODELABEL(n1), 2) // "model2"
 *
 * Notice that the compatible at index 1 doesn't match any entries in the
 * vendor prefix file and therefore index 1 is not a valid model index. Use
 * DT_NODE_MODEL_HAS_IDX(node_id, idx) to determine if an index is valid.
 *
 * @param node_id node identifier
 * @param idx index of the model to return
 * @return string literal of the idx-th model
 *//**
 * @brief Get the node's (only) vendor as a string literal
 *
 * Equivalent to DT_NODE_VENDOR_BY_IDX_OR(node_id, 0, default_value).
 *
 * @param node_id node identifier
 * @param default_value a fallback value to expand to
 *//**
 * @brief Like DT_NODE_VENDOR_BY_IDX(), but with a fallback to default_value.
 *
 * If the value exists, this expands to DT_NODE_VENDOR_BY_IDX(node_id, idx).
 * The default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to default_value.
 *
 * @param node_id node identifier
 * @param idx index of the vendor to return
 * @return string literal of the idx-th vendor
 * @param default_value a fallback value to expand to
 * @return string literal of the idx-th vendor or "default_value"
 *//**
 * @brief Does a node's compatible property have a vendor at an index?
 *
 * If this returns 1, then DT_NODE_VENDOR_BY_IDX(node_id, idx) is valid. If it
 * returns 0, it is an error to use DT_NODE_VENDOR_BY_IDX(node_id, idx) with
 * index @p idx.
 *
 * @param node_id node identifier
 * @param idx index of the vendor to check
 * @return 1 if @p idx is a valid vendor index,
 *         0 otherwise.
 *//**
 * @brief Get the vendor at index @p idx as a string literal
 *
 * The vendor is a string extracted from vendor prefixes if an entry exists
 * that matches the node's compatible prefix. There may be as many as one
 * vendor prefixes file per directory in DTS_ROOT.
 *
 * Example vendor-prefixes.txt:
 *
 *	vnd	A stand-in for a real vendor
 *	zephyr	Zephyr-specific binding
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *	n1: node-1 {
 *		compatible = "vnd,model1", "gpio", "zephyr,model2";
 *	};
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *	DT_NODE_VENDOR_BY_IDX(DT_NODELABEL(n1), 0) // "A stand-in for a real vendor"
 *	DT_NODE_VENDOR_BY_IDX(DT_NODELABEL(n1), 2) // "Zephyr-specific binding"
 * @endcode
 *
 * Notice that the compatible at index 1 doesn't match any entries in the
 * vendor prefix file and therefore index 1 is not a valid vendor index. Use
 * DT_NODE_VENDOR_HAS_IDX(node_id, idx) to determine if an index is valid.
 *
 * @param node_id node identifier
 * @param idx index of the vendor to return
 * @return string literal of the idx-th vendor
 *//**
 * @defgroup devicetree-generic-vendor Vendor and model name helpers
 * @ingroup devicetree
 * @{
 *//**
 * @brief Invokes @p fn for each entry of @p node_id ranges property
 *
 * The macro @p fn must take two parameters, @p node_id which will be the node
 * identifier of the node with the ranges property and @p idx the index of
 * the ranges block.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node@0 {
 *             reg = <0 0 1>;
 *
 *             ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                      <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define RANGE_LENGTH(node_id, idx) DT_RANGES_LENGTH_BY_IDX(node_id, idx),
 *
 *     const uint64_t *ranges_length[] = {
 *             DT_FOREACH_RANGE(DT_NODELABEL(n), RANGE_LENGTH)
 *     };
 * @endcode
 *
 * This expands to:
 *
 * @code{.c}
 *     const char *ranges_length[] = {
 *         0x10000, 0x2eff0000,
 *     };
 * @endcode
 *
 * @param node_id node identifier
 * @param fn macro to invoke
 *//**
 * @brief Get the ranges property length at index
 *
 * Similarly to DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(), this properly accounts
 * for child bus flags cells when the node is a PCIe bus.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     parent {
 *             #address-cells = <2>;
 *
 *             pcie0: pcie@0 {
 *                     compatible = "intel,pcie";
 *                     reg = <0 0 1>;
 *                     #address-cells = <3>;
 *                     #size-cells = <2>;
 *
 *                     ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                              <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                              <0x3000000 0x80 0 0x80 0 0x80 0>;
 *             };
 *
 *             other: other@1 {
 *                     reg = <0 1 1>;
 *
 *                     ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                              <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_RANGES_LENGTH_BY_IDX(DT_NODELABEL(pcie0), 0) // 0x10000
 *     DT_RANGES_LENGTH_BY_IDX(DT_NODELABEL(pcie0), 1) // 0x2eff0000
 *     DT_RANGES_LENGTH_BY_IDX(DT_NODELABEL(pcie0), 2) // 0x8000000000
 *     DT_RANGES_LENGTH_BY_IDX(DT_NODELABEL(other), 0) // 0x10000
 *     DT_RANGES_LENGTH_BY_IDX(DT_NODELABEL(other), 1) // 0x2eff0000
 * @endcode
 *
 * @param node_id node identifier
 * @param idx logical index into the ranges array
 * @returns range length field at idx
 *//**
 * @brief Get the ranges property parent bus address at index
 *
 * Similarly to DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(), this properly accounts
 * for child bus flags cells when the node is a PCIe bus.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     parent {
 *             #address-cells = <2>;
 *
 *             pcie0: pcie@0 {
 *                     compatible = "intel,pcie";
 *                     reg = <0 0 1>;
 *                     #address-cells = <3>;
 *                     #size-cells = <2>;
 *
 *                     ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                              <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                              <0x3000000 0x80 0 0x80 0 0x80 0>;
 *             };
 *
 *             other: other@1 {
 *                     reg = <0 1 1>;
 *
 *                     ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                              <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(DT_NODELABEL(pcie0), 0) // 0x3eff0000
 *     DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(DT_NODELABEL(pcie0), 1) // 0x10000000
 *     DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(DT_NODELABEL(pcie0), 2) // 0x8000000000
 *     DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(DT_NODELABEL(other), 0) // 0x3eff0000
 *     DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(DT_NODELABEL(other), 1) // 0x10000000
 * @endcode
 *
 * @param node_id node identifier
 * @param idx logical index into the ranges array
 * @returns range parent bus address field at idx
 *//**
 * @brief Get the ranges property child bus address at index
 *
 * When the node is a PCIe bus, the Child Bus Address has an extra cell used to store some
 * flags, thus this cell is removed from the Child Bus Address.
 *
 * Example devicetree fragments:
 *
 * @code{.dts}
 *     parent {
 *             #address-cells = <2>;
 *
 *             pcie0: pcie@0 {
 *                     compatible = "intel,pcie";
 *                     reg = <0 0 1>;
 *                     #address-cells = <3>;
 *                     #size-cells = <2>;
 *
 *                     ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                              <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                              <0x3000000 0x80 0 0x80 0 0x80 0>;
 *             };
 *
 *             other: other@1 {
 *                     reg = <0 1 1>;
 *
 *                     ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                              <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(DT_NODELABEL(pcie0), 0) // 0
 *     DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(DT_NODELABEL(pcie0), 1) // 0x10000000
 *     DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(DT_NODELABEL(pcie0), 2) // 0x8000000000
 *     DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(DT_NODELABEL(other), 0) // 0
 *     DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(DT_NODELABEL(other), 1) // 0x10000000
 * @endcode
 *
 * @param node_id node identifier
 * @param idx logical index into the ranges array
 * @returns range child bus address field at idx
 *//**
 * @brief Get the ranges property child bus flags at index
 *
 * When the node is a PCIe bus, the Child Bus Address has an extra cell used to store some
 * flags, thus this cell is extracted from the Child Bus Address as Child Bus Flags field.
 *
 * Example devicetree fragments:
 *
 * @code{.dts}
 *     parent {
 *             #address-cells = <2>;
 *
 *             pcie0: pcie@0 {
 *                     compatible = "intel,pcie";
 *                     reg = <0 0 1>;
 *                     #address-cells = <3>;
 *                     #size-cells = <2>;
 *
 *                     ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                              <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                              <0x3000000 0x80 0 0x80 0 0x80 0>;
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(DT_NODELABEL(pcie0), 0) // 0x1000000
 *     DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(DT_NODELABEL(pcie0), 1) // 0x2000000
 *     DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(DT_NODELABEL(pcie0), 2) // 0x3000000
 * @endcode
 *
 * @param node_id node identifier
 * @param idx logical index into the ranges array
 * @returns range child bus flags field at idx
 *//**
 * @brief Does a ranges property have child bus flags at index?
 *
 * If this returns 1, then DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(node_id, idx) is valid.
 * If it returns 0, it is an error to use this macro with index @p idx.
 * This macro only returns 1 for PCIe buses (i.e. nodes whose bindings specify they
 * are "pcie" bus nodes.)
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     parent {
 *             #address-cells = <2>;
 *
 *             pcie0: pcie@0 {
 *                     compatible = "intel,pcie";
 *                     reg = <0 0 1>;
 *                     #address-cells = <3>;
 *                     #size-cells = <2>;
 *
 *                     ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                              <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                              <0x3000000 0x80 0 0x80 0 0x80 0>;
 *             };
 *
 *             other: other@1 {
 *                     reg = <0 1 1>;
 *
 *                     ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                              <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(pcie0), 0) // 1
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(pcie0), 1) // 1
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(pcie0), 2) // 1
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(pcie0), 3) // 0
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(other), 0) // 0
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(other), 1) // 0
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(other), 2) // 0
 *     DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(DT_NODELABEL(other), 3) // 0
 * @endcode
 *
 * @param node_id node identifier
 * @param idx logical index into the ranges array
 * @return 1 if @p idx is a valid child bus flags index,
 *         0 otherwise.
 *//**
 * @brief Is @p idx a valid range block index?
 *
 * If this returns 1, then DT_RANGES_CHILD_BUS_ADDRESS_BY_IDX(node_id, idx),
 * DT_RANGES_PARENT_BUS_ADDRESS_BY_IDX(node_id, idx) or
 * DT_RANGES_LENGTH_BY_IDX(node_id, idx) are valid.
 * For DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(node_id, idx) the return value
 * of DT_RANGES_HAS_CHILD_BUS_FLAGS_AT_IDX(node_id, idx) will indicate
 * validity.
 * If it returns 0, it is an error to use those macros with index @p idx,
 * including DT_RANGES_CHILD_BUS_FLAGS_BY_IDX(node_id, idx).
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     pcie0: pcie@0 {
 *             compatible = "intel,pcie";
 *             reg = <0 1>;
 *             #address-cells = <3>;
 *             #size-cells = <2>;
 *
 *             ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                      <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                      <0x3000000 0x80 0 0x80 0 0x80 0>;
 *     };
 *
 *     other: other@1 {
 *             reg = <1 1>;
 *
 *             ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                      <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(pcie0), 0) // 1
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(pcie0), 1) // 1
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(pcie0), 2) // 1
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(pcie0), 3) // 0
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(other), 0) // 1
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(other), 1) // 1
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(other), 2) // 0
 *     DT_RANGES_HAS_IDX(DT_NODELABEL(other), 3) // 0
 * @endcode
 *
 * @param node_id node identifier
 * @param idx index to check
 * @return 1 if @p idx is a valid register block index,
 *         0 otherwise.
 *//**
 * @brief Get the number of range blocks in the ranges property
 *
 * Use this instead of DT_PROP_LEN(node_id, ranges).
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     pcie0: pcie@0 {
 *             compatible = "intel,pcie";
 *             reg = <0 1>;
 *             #address-cells = <3>;
 *             #size-cells = <2>;
 *
 *             ranges = <0x1000000 0 0 0 0x3eff0000 0 0x10000>,
 *                      <0x2000000 0 0x10000000 0 0x10000000 0 0x2eff0000>,
 *                      <0x3000000 0x80 0 0x80 0 0x80 0>;
 *     };
 *
 *     other: other@1 {
 *             reg = <1 1>;
 *
 *             ranges = <0x0 0x0 0x0 0x3eff0000 0x10000>,
 *                      <0x0 0x10000000 0x0 0x10000000 0x2eff0000>;
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_NUM_RANGES(DT_NODELABEL(pcie0)) // 3
 *     DT_NUM_RANGES(DT_NODELABEL(other)) // 2
 * @endcode
 *
 * @param node_id node identifier
 *//**
 * @defgroup devicetree-ranges-prop ranges property
 * @ingroup devicetree
 * @{
 *//**
 * @brief Get a node identifier for a phandle property's value
 *
 * This is equivalent to DT_PHANDLE_BY_IDX(node_id, prop, 0). Its primary
 * benefit is readability when @p prop has type `phandle`.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property of @p node_id
 *             with type `phandle`
 * @return a node identifier for the node pointed to by "ph"
 *//**
 * @brief Get a node identifier for a phandle in a property.
 *
 * When a node's value at a logical index contains a phandle, this
 * macro returns a node identifier for the node with that phandle.
 *
 * Therefore, if @p prop has type `phandle`, @p idx must be zero. (A
 * `phandle` type is treated as a `phandles` with a fixed length of
 * 1).
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n1: node-1 {
 *             foo = <&n2 &n3>;
 *     };
 *
 *     n2: node-2 { ... };
 *     n3: node-3 { ... };
 * @endcode
 *
 * Above, `foo` has type phandles and has two elements:
 *
 * - index 0 has phandle `&n2`, which is `node-2`'s phandle
 * - index 1 has phandle `&n3`, which is `node-3`'s phandle
 *
 * Example usage:
 *
 * @code{.c}
 *     #define N1 DT_NODELABEL(n1)
 *
 *     DT_PHANDLE_BY_IDX(N1, foo, 0) // node identifier for node-2
 *     DT_PHANDLE_BY_IDX(N1, foo, 1) // node identifier for node-3
 * @endcode
 *
 * Behavior is analogous for phandle-arrays.
 *
 * @internal
 * Implementation note: using DT_CAT6 above defers concatenation until
 * after expansion of each parameter. This is important when 'idx' is
 * expandable to a number, but it isn't one "yet".
 * @endinternal
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name in @p node_id
 *             with type `phandle`, `phandles` or `phandle-array`
 * @param idx index into @p prop
 * @return node identifier for the node with the phandle at that index
 *//**
 * @brief Get a phandle's node identifier from a phandle array by @p name
 *
 * It might help to read the argument order as being similar to
 * `node->phandle_struct.name.phandle`. That is, the phandle array is
 * treated as a structure with named elements. The return value is
 * the node identifier for a phandle inside the structure.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     adc1: adc@abcd1234 {
 *             foobar = "ADC_1";
 *     };
 *
 *     adc2: adc@1234abcd {
 *             foobar = "ADC_2";
 *     };
 *
 *     n: node {
 *             io-channels = <&adc1 10>, <&adc2 20>;
 *             io-channel-names = "SENSOR", "BANDGAP";
 *     };
 * @endcode
 *
 * Above, "io-channels" has two elements:
 *
 * - the element named `"SENSOR"` has phandle `&adc1`
 * - the element named `"BANDGAP"` has phandle `&adc2`
 *
 * Example usage:
 *
 * @code{.c}
 *     #define NODE DT_NODELABEL(n)
 *
 *     DT_PROP(DT_PHANDLE_BY_NAME(NODE, io_channels, sensor), foobar)  // "ADC_1"
 *     DT_PROP(DT_PHANDLE_BY_NAME(NODE, io_channels, bandgap), foobar) // "ADC_2"
 * @endcode
 *
 * Notice how devicetree properties and names are lowercased, and
 * non-alphanumeric characters are converted to underscores.
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param name lowercase-and-underscores name of an element in @p pha
 * @return a node identifier for the node with that phandle
 *//**
 * @brief Like DT_PHA_BY_NAME(), but with a fallback to @p default_value
 *
 * If the value exists, this expands to DT_PHA_BY_NAME(node_id, pha,
 * name, cell). The @p default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @internal
 * Implementation note: the `_NAME_##name##_VAL_##cell##_EXISTS` macros are
 * defined, so it's safe to use DT_PROP_OR() here, because that uses an
 * IS_ENABLED() on the `_EXISTS` macro.
 * @endinternal
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param name lowercase-and-underscores name of a specifier in @p pha
 * @param cell lowercase-and-underscores cell name in the named specifier
 * @param default_value a fallback value to expand to
 * @return the cell's value or @p default_value
 *//**
 * @brief Get a value within a phandle-array specifier by name
 *
 * This is like DT_PHA_BY_IDX(), except it treats @p pha as a structure
 * where each array element has a name.
 *
 * It might help to read the argument order as being similar to
 * `node->phandle_struct.name.cell`. That is, the cell value is in the
 * @p pha property of @p node_id, treated as a data structure where
 * each array element has a name.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n: node {
 *             io-channels = <&adc1 10>, <&adc2 20>;
 *             io-channel-names = "SENSOR", "BANDGAP";
 *     };
 * @endcode
 *
 * Bindings fragment for the "adc1" and "adc2" nodes:
 *
 * @code{.yaml}
 *     io-channel-cells:
 *       - input
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_PHA_BY_NAME(DT_NODELABEL(n), io_channels, sensor, input)  // 10
 *     DT_PHA_BY_NAME(DT_NODELABEL(n), io_channels, bandgap, input) // 20
 * @endcode
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param name lowercase-and-underscores name of a specifier in @p pha
 * @param cell lowercase-and-underscores cell name in the named specifier
 * @return the cell's value
 *//**
 * @brief Like DT_PHA(), but with a fallback to @p default_value
 *
 * If the value exists, this expands to DT_PHA(node_id, pha, cell).
 * The @p default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param cell lowercase-and-underscores cell name
 * @param default_value a fallback value to expand to
 * @return the cell's value or @p default_value
 *//**
 * @brief Equivalent to DT_PHA_BY_IDX(node_id, pha, 0, cell)
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param cell lowercase-and-underscores cell name
 * @return the cell's value
 *//**
 * @brief Like DT_PHA_BY_IDX(), but with a fallback to @p default_value.
 *
 * If the value exists, this expands to DT_PHA_BY_IDX(node_id, pha,
 * idx, cell). The @p default_value parameter is not expanded in this
 * case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @internal
 * Implementation note: the _IDX_##idx##_VAL_##cell##_EXISTS macros are
 * defined, so it's safe to use DT_PROP_OR() here, because that uses an
 * IS_ENABLED() on the _EXISTS macro.
 * @endinternal
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param idx logical index into @p pha
 * @param cell lowercase-and-underscores cell name within the specifier
 *             at @p pha index @p idx
 * @param default_value a fallback value to expand to
 * @return the cell's value or @p default_value
 *//**
 * @brief Get a phandle-array specifier cell value at an index
 *
 * It might help to read the argument order as being similar to
 * `node->phandle_array[index].cell`. That is, the cell value is in
 * the @p pha property of @p node_id, inside the specifier at index
 * @p idx.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     gpio0: gpio@abcd1234 {
 *             #gpio-cells = <2>;
 *     };
 *
 *     gpio1: gpio@1234abcd {
 *             #gpio-cells = <2>;
 *     };
 *
 *     led: led_0 {
 *             gpios = <&gpio0 17 0x1>, <&gpio1 5 0x3>;
 *     };
 * @endcode
 *
 * Bindings fragment for the `gpio0` and `gpio1` nodes:
 *
 * @code{.yaml}
 *     gpio-cells:
 *       - pin
 *       - flags
 * @endcode
 *
 * Above, `gpios` has two elements:
 *
 * - index 0 has specifier <17 0x1>, so its `pin` cell is 17, and its
 *   `flags` cell is 0x1
 * - index 1 has specifier <5 0x3>, so `pin` is 5 and `flags` is 0x3
 *
 * Example usage:
 *
 * @code{.c}
 *     #define LED DT_NODELABEL(led)
 *
 *     DT_PHA_BY_IDX(LED, gpios, 0, pin)   // 17
 *     DT_PHA_BY_IDX(LED, gpios, 1, flags) // 0x3
 * @endcode
 *
 * @param node_id node identifier
 * @param pha lowercase-and-underscores property with type `phandle-array`
 * @param idx logical index into @p pha
 * @param cell lowercase-and-underscores cell name within the specifier
 *             at @p pha index @p idx
 * @return the cell's value
 *//**
 * @brief Get a property value from a phandle's node
 *
 * This is equivalent to DT_PROP_BY_PHANDLE_IDX(node_id, ph, 0, prop).
 *
 * @param node_id node identifier
 * @param ph lowercase-and-underscores property of @p node_id
 *           with type `phandle`
 * @param prop lowercase-and-underscores property of the phandle's node
 * @return the property's value
 *//**
 * @brief Like DT_PROP_BY_PHANDLE_IDX(), but with a fallback to
 * @p default_value.
 *
 * If the value exists, this expands to DT_PROP_BY_PHANDLE_IDX(node_id, phs,
 * idx, prop). The @p default_value parameter is not expanded in this
 * case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param phs lowercase-and-underscores property with type `phandle`,
 *            `phandles`, or `phandle-array`
 * @param idx logical index into @p phs, which must be zero if @p phs
 *            has type `phandle`
 * @param prop lowercase-and-underscores property of the phandle's node
 * @param default_value a fallback value to expand to
 * @return the property's value
 *//**
 * @brief Get a property value from a phandle in a property.
 *
 * This is a shorthand for:
 *
 * @code{.c}
 *     DT_PROP(DT_PHANDLE_BY_IDX(node_id, phs, idx), prop)
 * @endcode
 *
 * That is, @p prop is a property of the phandle's node, not a
 * property of @p node_id.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n1: node-1 {
 *             foo = <&n2 &n3>;
 *     };
 *
 *     n2: node-2 {
 *             bar = <42>;
 *     };
 *
 *     n3: node-3 {
 *             baz = <43>;
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     #define N1 DT_NODELABEL(n1)
 *
 *     DT_PROP_BY_PHANDLE_IDX(N1, foo, 0, bar) // 42
 *     DT_PROP_BY_PHANDLE_IDX(N1, foo, 1, baz) // 43
 * @endcode
 *
 * @param node_id node identifier
 * @param phs lowercase-and-underscores property with type `phandle`,
 *            `phandles`, or `phandle-array`
 * @param idx logical index into @p phs, which must be zero if @p phs
 *            has type `phandle`
 * @param prop lowercase-and-underscores property of the phandle's node
 * @return the property's value
 *//*
 * phandle properties
 *
 * These are special-cased to manage the impedance mismatch between
 * phandles, which are just uint32_t node properties that only make sense
 * within the tree itself, and C values.
 *//**
 * @brief Get a string array item value as an unquoted sequence of tokens.
 *
 * This removes "the quotes" from string-valued item.
 * That can be useful, for example,
 * when defining floating point values as a string in devicetree
 * that you would like to use to initialize a float or double variable in C.
 *
 * DT_STRING_UNQUOTED_BY_IDX() can only be used for properties with
 * string-array type.
 *
 * It is an error to use DT_STRING_UNQUOTED_BY_IDX() in other circumstances.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             prop = "12.7", "34.1";
 *     };
 *     n2: node-2 {
 *             prop = "A B", "C D";
 *     }
 *
 * Example bindings fragment:
 *
 *     properties:
 *       prop:
 *         type: string-array
 *
 * Example usage:
 *
 *     DT_STRING_UNQUOTED_BY_IDX(DT_NODELABEL(n1), prop, 0) // 12.7
 *     DT_STRING_UNQUOTED_BY_IDX(DT_NODELABEL(n1), prop, 1) // 34.1
 *     DT_STRING_UNQUOTED_BY_IDX(DT_NODELABEL(n2), prop, 0) // A B
 *     DT_STRING_UNQUOTED_BY_IDX(DT_NODELABEL(n2), prop, 1) // C D
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return the property's value as a sequence of tokens, with no quotes
 *//**
 * @brief Like DT_STRING_TOKEN_BY_IDX(), but uppercased.
 *
 * This removes "the quotes" and capitalizes an element in the array, and
 * converts non-alphanumeric characters to underscores. That can be useful, for
 * example, when programmatically using the value to form a C variable or code.
 *
 * DT_STRING_UPPER_TOKEN_BY_IDX() can only be used for properties with
 * string-array type.
 *
 * It is an error to use DT_STRING_UPPER_TOKEN_BY_IDX() in other circumstances.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n1: node-1 {
 *             prop = "f1", "F2";
 *     };
 *     n2: node-2 {
 *             prop = "123 foo", "456 FOO";
 *     };
 * @endcode
 *
 * Example bindings fragment:
 *
 * @code{.yaml}
 *     properties:
 *       prop:
 *         type: string-array
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_STRING_UPPER_TOKEN_BY_IDX(DT_NODELABEL(n1), prop, 0) // F1
 *     DT_STRING_UPPER_TOKEN_BY_IDX(DT_NODELABEL(n1), prop, 1) // F2
 *     DT_STRING_UPPER_TOKEN_BY_IDX(DT_NODELABEL(n2), prop, 0) // 123_FOO
 *     DT_STRING_UPPER_TOKEN_BY_IDX(DT_NODELABEL(n2), prop, 1) // 456_FOO
 * @endcode
 *
 * For more information, see @ref DT_STRING_UPPER_TOKEN.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return the element in @p prop at index @p idx as an uppercased token
 *//**
 * @brief Get an element out of a string-array property as a token.
 *
 * This removes "the quotes" from an element in the array, and converts
 * non-alphanumeric characters to underscores. That can be useful, for example,
 * when programmatically using the value to form a C variable or code.
 *
 * DT_STRING_TOKEN_BY_IDX() can only be used for properties with
 * string-array type.
 *
 * It is an error to use DT_STRING_TOKEN_BY_IDX() in other circumstances.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n1: node-1 {
 *             prop = "f1", "F2";
 *     };
 *     n2: node-2 {
 *             prop = "123 foo", "456 FOO";
 *     };
 * @endcode
 *
 * Example bindings fragment:
 *
 * @code{.yaml}
 *     properties:
 *       prop:
 *         type: string-array
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_STRING_TOKEN_BY_IDX(DT_NODELABEL(n1), prop, 0) // f1
 *     DT_STRING_TOKEN_BY_IDX(DT_NODELABEL(n1), prop, 1) // F2
 *     DT_STRING_TOKEN_BY_IDX(DT_NODELABEL(n2), prop, 0) // 123_foo
 *     DT_STRING_TOKEN_BY_IDX(DT_NODELABEL(n2), prop, 1) // 456_FOO
 * @endcode
 *
 * For more information, see @ref DT_STRING_TOKEN.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return the element in @p prop at index @p idx as a token
 *//**
 * @brief Like DT_STRING_UNQUOTED(), but with a fallback to @p default_value
 *
 * If the value exists, this expands to DT_STRING_UNQUOTED(node_id, prop).
 * The @p default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return the property's value as a sequence of tokens, with no quotes,
 *         or @p default_value
 *//**
 * @brief Get a string property's value as an unquoted sequence of tokens
 *
 * This removes "the quotes" from string-valued properties.
 * That can be useful, for example,
 * when defining floating point values as a string in devicetree
 * that you would like to use to initialize a float or double variable in C.
 *
 * DT_STRING_UNQUOTED() can only be used for properties with string type.
 *
 * It is an error to use DT_STRING_UNQUOTED() in other circumstances.
 *
 * Example devicetree fragment:
 *
 *     n1: node-1 {
 *             prop = "12.7";
 *     };
 *     n2: node-2 {
 *             prop = "0.5";
 *     }
 *     n3: node-3 {
 *             prop = "A B C";
 *     };
 *
 * Example bindings fragment:
 *
 *     properties:
 *       prop:
 *         type: string
 *
 * Example usage:
 *
 *     DT_STRING_UNQUOTED(DT_NODELABEL(n1), prop) // 12.7
 *     DT_STRING_UNQUOTED(DT_NODELABEL(n2), prop) // 0.5
 *     DT_STRING_UNQUOTED(DT_NODELABEL(n3), prop) // A B C
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @return the property's value as a sequence of tokens, with no quotes
 *//**
 * @brief Like DT_STRING_UPPER_TOKEN(), but with a fallback to @p default_value
 *
 * If the value exists, this expands to DT_STRING_UPPER_TOKEN(node_id, prop).
 * The @p default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return the property's value as an uppercased token,
 *         or @p default_value
 *//**
 * @brief Like DT_STRING_TOKEN(), but uppercased.
 *
 * This removes "the quotes" from a string property's value,
 * converting any non-alphanumeric characters to underscores, and
 * capitalizing the result. This can be useful, for example, when
 * programmatically using the value to form a C variable or code.
 *
 * DT_STRING_UPPER_TOKEN() can only be used for properties with string type.
 *
 * It is an error to use DT_STRING_UPPER_TOKEN() in other circumstances.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n1: node-1 {
 *             prop = "foo";
 *     };
 *     n2: node-2 {
 *             prop = "123 foo";
 *     };
 * @endcode
 *
 * Example bindings fragment:
 *
 * @code{.yaml}
 *     properties:
 *       prop:
 *         type: string
 *
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_STRING_UPPER_TOKEN(DT_NODELABEL(n1), prop) // FOO
 *     DT_STRING_UPPER_TOKEN(DT_NODELABEL(n2), prop) // 123_FOO
 * @endcode
 *
 * Notice how:
 *
 * - Unlike C identifiers, the property values may begin with a
 *   number. It's the user's responsibility not to use such values as
 *   the name of a C identifier.
 *
 * - The lowercased `"foo"` in the DTS becomes `FOO` as a token, i.e.
 *   it is uppercased.
 *
 * - The whitespace in the DTS `"123 foo"` string is converted to
 *   `123_FOO` as a token, i.e. it is uppercased and whitespace becomes
 *   an underscore.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @return the value of @p prop as an uppercased token, i.e. without
 *         any quotes and with special characters converted to underscores
 *//**
 * @brief Like DT_STRING_TOKEN(), but with a fallback to @p default_value
 *
 * If the value exists, this expands to DT_STRING_TOKEN(node_id, prop).
 * The @p default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return the property's value as a token, or @p default_value
 *//**
 * @brief Get a string property's value as a token.
 *
 * This removes "the quotes" from a string property's value,
 * converting any non-alphanumeric characters to underscores. This can
 * be useful, for example, when programmatically using the value to
 * form a C variable or code.
 *
 * DT_STRING_TOKEN() can only be used for properties with string type.
 *
 * It is an error to use DT_STRING_TOKEN() in other circumstances.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     n1: node-1 {
 *             prop = "foo";
 *     };
 *     n2: node-2 {
 *             prop = "FOO";
 *     }
 *     n3: node-3 {
 *             prop = "123 foo";
 *     };
 * @endcode
 *
 * Example bindings fragment:
 *
 * @code{.yaml}
 *     properties:
 *       prop:
 *         type: string
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_STRING_TOKEN(DT_NODELABEL(n1), prop) // foo
 *     DT_STRING_TOKEN(DT_NODELABEL(n2), prop) // FOO
 *     DT_STRING_TOKEN(DT_NODELABEL(n3), prop) // 123_foo
 * @endcode
 *
 * Notice how:
 *
 * - Unlike C identifiers, the property values may begin with a
 *   number. It's the user's responsibility not to use such values as
 *   the name of a C identifier.
 *
 * - The uppercased `"FOO"` in the DTS remains `FOO` as a token. It is
 *   *not* converted to `foo`.
 *
 * - The whitespace in the DTS `"123 foo"` string is converted to
 *   `123_foo` as a token.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @return the value of @p prop as a token, i.e. without any quotes
 *         and with special characters converted to underscores
 *//**
 * @brief Does a node enumeration property have a given value?
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param value lowercase-and-underscores enumeration value
 * @return 1 if the node property has the value @a value, 0 otherwise.
 *//**
 * @brief Like DT_ENUM_IDX(), but with a fallback to a default enum index
 *
 * If the value exists, this expands to its zero based index value thanks to
 * DT_ENUM_IDX(node_id, prop).
 *
 * Otherwise, this expands to provided default index enum value.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param default_idx_value a fallback index value to expand to
 * @return zero-based index of the property's value in its enum if present,
 *         default_idx_value otherwise
 *//**
 * @brief Get a property value's index into its enumeration values
 *
 * The return values start at zero.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     usb1: usb@12340000 {
 *             maximum-speed = "full-speed";
 *     };
 *     usb2: usb@12341000 {
 *             maximum-speed = "super-speed";
 *     };
 * @endcode
 *
 * Example bindings fragment:
 *
 * @code{.yaml}
 *     properties:
 *       maximum-speed:
 *         type: string
 *         enum:
 *            - "low-speed"
 *            - "full-speed"
 *            - "high-speed"
 *            - "super-speed"
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_ENUM_IDX(DT_NODELABEL(usb1), maximum_speed) // 1
 *     DT_ENUM_IDX(DT_NODELABEL(usb2), maximum_speed) // 3
 * @endcode
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @return zero-based index of the property's value in its enum: list
 *//**
 * @deprecated Use DT_PROP(node_id, label)
 * @brief Equivalent to DT_PROP(node_id, label)
 *
 * This is a convenience for the Zephyr device API, which uses label
 * properties as device_get_binding() arguments.
 * @param node_id node identifier
 * @return node's label property value
 *//**
 * @brief Like DT_PROP(), but with a fallback to @p default_value
 *
 * If the value exists, this expands to DT_PROP(node_id, prop).
 * The @p default_value parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param default_value a fallback value to expand to
 * @return the property's value or @p default_value
 *//**
 * @brief Get the value at index @p idx in an array type property
 *
 * It might help to read the argument order as being similar to
 * `node->property[index]`.
 *
 * The return value depends on the property's type:
 *
 * - for types array, string-array, uint8-array, and phandles,
 *   this expands to the idx-th array element as an
 *   integer, string literal, integer, and node identifier
 *   respectively
 *
 * - for type phandle, idx must be 0 and the expansion is a node
 *   identifier (this treats phandle like a phandles of length 1)
 *
 * - for type string, idx must be 0 and the expansion is the the
 *   entire string (this treats string like string-array of length 1)
 *
 * These properties are handled as special cases:
 *
 * - `reg`: use DT_REG_ADDR_BY_IDX() or DT_REG_SIZE_BY_IDX() instead
 * - `interrupts`: use DT_IRQ_BY_IDX()
 * - `ranges`: use DT_NUM_RANGES()
 * - `dma-ranges`: it is an error to use this property with
 *   DT_PROP_BY_IDX()
 *
 * For properties of other types, behavior is undefined.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @param idx the index to get
 * @return a representation of the idx-th element of the property
 *//**
 * @brief Is name @p name available in a `foo-names` property?
 *
 * This property is handled as special case:
 *
 * - `interrupts` property: use DT_IRQ_HAS_NAME(node_id, idx) instead
 *
 * It is an error to use this macro with the `interrupts` property.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *	nx: node-x {
 *		foos = <&bar xx yy>, <&baz xx zz>;
 *		foo-names = "event", "error";
 *		status = "okay";
 *	};
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_PROP_HAS_NAME(DT_NODELABEL(nx), foos, event)    // 1
 *     DT_PROP_HAS_NAME(DT_NODELABEL(nx), foos, failure)  // 0
 * @endcode
 *
 * @param node_id node identifier
 * @param prop a lowercase-and-underscores `prop-names` type property
 * @param name a lowercase-and-underscores name to check
 * @return An expression which evaluates to 1 if "name" is an available
 *         name into the given property, and 0 otherwise.
 *//**
 * @brief Is index @p idx valid for an array type property?
 *
 * If this returns 1, then DT_PROP_BY_IDX(node_id, prop, idx) or
 * DT_PHA_BY_IDX(node_id, prop, idx, ...) are valid at index @p idx.
 * If it returns 0, it is an error to use those macros with that index.
 *
 * These properties are handled as special cases:
 *
 * - `reg` property: use DT_REG_HAS_IDX(node_id, idx) instead
 * - `interrupts` property: use DT_IRQ_HAS_IDX(node_id, idx) instead
 *
 * It is an error to use this macro with the `reg` or `interrupts` properties.
 *
 * @param node_id node identifier
 * @param prop a lowercase-and-underscores property with a logical length
 * @param idx index to check
 * @return An expression which evaluates to 1 if @p idx is a valid index
 *         into the given property, and 0 otherwise.
 *//**
 * @brief Like DT_PROP_LEN(), but with a fallback to @p default_value
 *
 * If the property is defined (as determined by DT_NODE_HAS_PROP()),
 * this expands to DT_PROP_LEN(node_id, prop). The @p default_value
 * parameter is not expanded in this case.
 *
 * Otherwise, this expands to @p default_value.
 *
 * @param node_id node identifier
 * @param prop a lowercase-and-underscores property with a logical length
 * @param default_value a fallback value to expand to
 * @return the property's length or the given default value
 *//**
 * @brief Get a property's logical length
 *
 * Here, "length" is a number of elements, which may differ from the
 * property's size in bytes.
 *
 * The return value depends on the property's type:
 *
 * - for types array, string-array, and uint8-array, this expands
 *   to the number of elements in the array
 * - for type phandles, this expands to the number of phandles
 * - for type phandle-array, this expands to the number of
 *   phandle and specifier blocks in the property
 * - for type phandle, this expands to 1 (so that a phandle
 *   can be treated as a degenerate case of phandles with length 1)
 * - for type string, this expands to 1 (so that a string can be
 *   treated as a degenerate case of string-array with length 1)
 *
 * These properties are handled as special cases:
 *
 * - reg property: use `DT_NUM_REGS(node_id)` instead
 * - interrupts property: use `DT_NUM_IRQS(node_id)` instead
 *
 * It is an error to use this macro with the `ranges`, `dma-ranges`, `reg`
 * or `interrupts` properties.
 *
 * For other properties, behavior is undefined.
 *
 * @param node_id node identifier
 * @param prop a lowercase-and-underscores property with a logical length
 * @return the property's length
 *//**
 * @brief Get a devicetree property value
 *
 * For properties whose bindings have the following types, this macro
 * expands to:
 *
 * - string: a string literal
 * - boolean: `0` if the property is false, or `1` if it is true
 * - int: the property's value as an integer literal
 * - array, uint8-array, string-array: an initializer expression in braces,
 *   whose elements are integer or string literals (like `{0, 1, 2}`,
 *   `{"hello", "world"}`, etc.)
 * - phandle: a node identifier for the node with that phandle
 *
 * A property's type is usually defined by its binding. In some
 * special cases, it has an assumed type defined by the devicetree
 * specification even when no binding is available: `compatible` has
 * type string-array, `status` has type string, and
 * `interrupt-controller` has type boolean.
 *
 * For other properties or properties with unknown type due to a
 * missing binding, behavior is undefined.
 *
 * For usage examples, see DT_PATH(), DT_ALIAS(), DT_NODELABEL(),
 * and DT_INST() above.
 *
 * @param node_id node identifier
 * @param prop lowercase-and-underscores property name
 * @return a representation of the property's value
 *//**
 * @defgroup devicetree-generic-prop Property accessors
 * @ingroup devicetree
 * @{
 *//**
 * @brief Do @p node_id1 and @p node_id2 refer to the same node?
 *
 * Both @p node_id1 and @p node_id2 must be node identifiers for nodes
 * that exist in the devicetree (if unsure, you can check with
 * DT_NODE_EXISTS()).
 *
 * The expansion evaluates to 0 or 1, but may not be a literal integer
 * 0 or 1.
 *
 * @internal
 * Implementation note: distinct nodes have distinct node identifiers.
 * See include/zephyr/devicetree/ordinals.h.
 * @endinternal
 *
 * @param node_id1 first node identifier
 * @param node_id2 second node identifier
 * @return an expression that evaluates to 1 if the node identifiers
 *         refer to the same node, and evaluates to 0 otherwise
 *//**
 * @brief Get a devicetree node's index into its parent's list of children
 *
 * Indexes are zero-based.
 *
 * It is an error to use this macro with the root node.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     parent {
 *             c1: child-1 {};
 *             c2: child-2 {};
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_NODE_CHILD_IDX(DT_NODELABEL(c1)) // 0
 *     DT_NODE_CHILD_IDX(DT_NODELABEL(c2)) // 1
 * @endcode
 *
 * @param node_id node identifier
 * @return the node's index in its parent node's list of children
 *//**
 * @brief Get a devicetree node's name with unit-address as a string literal
 *
 * This returns the node name and unit-address from a node identifier.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             soc {
 *                     node: my-node@12345678 { ... };
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *    DT_NODE_FULL_NAME(DT_NODELABEL(node)) // "my-node@12345678"
 * @endcode
 *
 * @param node_id node identifier
 * @return the node's name with unit-address as a string in the devicetree
 *//**
 * @brief Get a devicetree node's full path as a string literal
 *
 * This returns the path to a node from a node identifier. To get a
 * node identifier from path components instead, use DT_PATH().
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             soc {
 *                     node: my-node@12345678 { ... };
 *             };
 *     };
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *    DT_NODE_PATH(DT_NODELABEL(node)) // "/soc/my-node@12345678"
 *    DT_NODE_PATH(DT_PATH(soc))       // "/soc"
 *    DT_NODE_PATH(DT_ROOT)            // "/"
 * @endcode
 *
 * @param node_id node identifier
 * @return the node's full path in the devicetree
 *//**
 * @brief Get a node identifier for a status `okay` node with a compatible
 *
 * Use this if you want to get an arbitrary enabled node with a given
 * compatible, and you do not care which one you get. If any enabled
 * nodes with the given compatible exist, a node identifier for one
 * of them is returned. Otherwise, @ref DT_INVALID_NODE is returned.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *	node-a {
 *		compatible = "vnd,device";
 *		status = "okay";
 *	};
 *
 *	node-b {
 *		compatible = "vnd,device";
 *		status = "okay";
 *	};
 *
 *	node-c {
 *		compatible = "vnd,device";
 *		status = "disabled";
 *	};
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 *     DT_COMPAT_GET_ANY_STATUS_OKAY(vnd_device)
 * @endcode
 *
 * This expands to a node identifier for either `node-a` or `node-b`.
 * It will not expand to a node identifier for `node-c`, because that
 * node does not have status `okay`.
 *
 * @param compat lowercase-and-underscores compatible, without quotes
 * @return node identifier for a node with that compatible, or
 *         @ref DT_INVALID_NODE
 *//**
 * @brief Get a node identifier for a child node
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             soc-label: soc {
 *                     serial1: serial@40001000 {
 *                             status = "okay";
 *                             current-speed = <115200>;
 *                             ...
 *                     };
 *             };
 *     };
 * @endcode
 *
 * Example usage with DT_PROP() to get the status of the
 * `serial@40001000` node:
 *
 * @code{.c}
 *     #define SOC_NODE DT_NODELABEL(soc_label)
 *     DT_PROP(DT_CHILD(SOC_NODE, serial_40001000), status) // "okay"
 * @endcode
 *
 * Node labels like `serial1` cannot be used as the @p child argument
 * to this macro. Use DT_NODELABEL() for that instead.
 *
 * You can also use DT_FOREACH_CHILD() to iterate over node
 * identifiers for all of a node's children.
 *
 * @param node_id node identifier
 * @param child lowercase-and-underscores child node name
 * @return node identifier for the node with the name referred to by 'child'
 *//**
 * @brief Get a node identifier for a grandparent node
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     gparent: grandparent-node {
 *             parent: parent-node {
 *                     child: child-node { ... }
 *             };
 *     };
 * @endcode
 *
 * The following are equivalent ways to get the same node identifier:
 *
 * @code{.c}
 *     DT_GPARENT(DT_NODELABEL(child))
 *     DT_PARENT(DT_PARENT(DT_NODELABEL(child))
 * @endcode
 *
 * @param node_id node identifier
 * @return a node identifier for the node's parent's parent
 *//**
 * @brief Get a node identifier for a parent node
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     parent: parent-node {
 *             child: child-node {
 *                     ...
 *             };
 *     };
 * @endcode
 *
 * The following are equivalent ways to get the same node identifier:
 *
 * @code{.c}
 *     DT_NODELABEL(parent)
 *     DT_PARENT(DT_NODELABEL(child))
 * @endcode
 *
 * @param node_id node identifier
 * @return a node identifier for the node's parent
 *//**
 * @brief Get a node identifier for an instance of a compatible
 *
 * All nodes with a particular compatible property value are assigned
 * instance numbers, which are zero-based indexes specific to that
 * compatible. You can get a node identifier for these nodes by
 * passing DT_INST() an instance number, @p inst, along with the
 * lowercase-and-underscores version of the compatible, @p compat.
 *
 * Instance numbers have the following properties:
 *
 * - for each compatible, instance numbers start at 0 and are contiguous
 * - exactly one instance number is assigned for each node with a compatible,
 *   **including disabled nodes**
 * - enabled nodes (status property is `okay` or missing) are assigned the
 *   instance numbers starting from 0, and disabled nodes have instance
 *   numbers which are greater than those of any enabled node
 *
 * No other guarantees are made. In particular:
 *
 * - instance numbers **in no way reflect** any numbering scheme that
 *   might exist in SoC documentation, node labels or unit addresses,
 *   or properties of the /aliases node (use DT_NODELABEL() or DT_ALIAS()
 *   for those)
 * - there **is no general guarantee** that the same node will have
 *   the same instance number between builds, even if you are building
 *   the same application again in the same build directory
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     serial1: serial@40001000 {
 *             compatible = "vnd,soc-serial";
 *             status = "disabled";
 *             current-speed = <9600>;
 *             ...
 *     };
 *
 *     serial2: serial@40002000 {
 *             compatible = "vnd,soc-serial";
 *             status = "okay";
 *             current-speed = <57600>;
 *             ...
 *     };
 *
 *     serial3: serial@40003000 {
 *             compatible = "vnd,soc-serial";
 *             current-speed = <115200>;
 *             ...
 *     };
 * @endcode
 *
 * Assuming no other nodes in the devicetree have compatible
 * `"vnd,soc-serial"`, that compatible has nodes with instance numbers
 * 0, 1, and 2.
 *
 * The nodes `serial@40002000` and `serial@40003000` are both enabled, so
 * their instance numbers are 0 and 1, but no guarantees are made
 * regarding which node has which instance number.
 *
 * Since `serial@40001000` is the only disabled node, it has instance
 * number 2, since disabled nodes are assigned the largest instance
 * numbers. Therefore:
 *
 * @code{.c}
 *     // Could be 57600 or 115200. There is no way to be sure:
 *     // either serial@40002000 or serial@40003000 could
 *     // have instance number 0, so this could be the current-speed
 *     // property of either of those nodes.
 *     DT_PROP(DT_INST(0, vnd_soc_serial), current_speed)
 *
 *     // Could be 57600 or 115200, for the same reason.
 *     // If the above expression expands to 57600, then
 *     // this expands to 115200, and vice-versa.
 *     DT_PROP(DT_INST(1, vnd_soc_serial), current_speed)
 *
 *     // 9600, because there is only one disabled node, and
 *     // disabled nodes are "at the the end" of the instance
 *     // number "list".
 *     DT_PROP(DT_INST(2, vnd_soc_serial), current_speed)
 * @endcode
 *
 * Notice how `"vnd,soc-serial"` in the devicetree becomes `vnd_soc_serial`
 * (without quotes) in the DT_INST() arguments. (As usual, `current-speed`
 * in the devicetree becomes `current_speed` as well.)
 *
 * Nodes whose `compatible` property has multiple values are assigned
 * independent instance numbers for each compatible.
 *
 * @param inst instance number for compatible @p compat
 * @param compat lowercase-and-underscores compatible, without quotes
 * @return node identifier for the node with that instance number and
 *         compatible
 *//**
 * @brief Get a node identifier from /aliases
 *
 * This macro's argument is a property of the `/aliases` node. It
 * returns a node identifier for the node which is aliased. Convert
 * non-alphanumeric characters in the alias property to underscores to
 * form valid C tokens, and lowercase all letters.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             aliases {
 *                     my-serial = &serial1;
 *             };
 *
 *             soc {
 *                     serial1: serial@40001000 {
 *                             status = "okay";
 *                             current-speed = <115200>;
 *                             ...
 *                     };
 *             };
 *     };
 * @endcode
 *
 * You can use DT_ALIAS(my_serial) to get a node identifier for the
 * `serial@40001000` node. Notice how `my-serial` in the devicetree
 * becomes `my_serial` in the DT_ALIAS() argument. Example usage with
 * DT_PROP() to get the current-speed property:
 *
 * @code{.c}
 *     DT_PROP(DT_ALIAS(my_serial), current_speed) // 115200
 * @endcode
 *
 * @param alias lowercase-and-underscores alias name.
 * @return node identifier for the node with that alias
 *//**
 * @brief Get a node identifier for a node label
 *
 * Convert non-alphanumeric characters in the node label to
 * underscores to form valid C tokens, and lowercase all letters. Note
 * that node labels are not the same thing as label properties.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     serial1: serial@40001000 {
 *             label = "UART_0";
 *             status = "okay";
 *             current-speed = <115200>;
 *             ...
 *     };
 * @endcode
 *
 * The only node label in this example is `serial1`.
 *
 * The string `UART_0` is *not* a node label; it's the value of a
 * property named label.
 *
 * You can use `DT_NODELABEL(serial1)` to get a node identifier for the
 * `serial@40001000` node. Example usage with DT_PROP() to get the
 * current-speed property:
 *
 * @code{.c}
 *     DT_PROP(DT_NODELABEL(serial1), current_speed) // 115200
 * @endcode
 *
 * Another example devicetree fragment:
 *
 * @code{.dts}
 *     cpu@0 {
 *            L2_0: l2-cache {
 *                    cache-level = <2>;
 *                    ...
 *            };
 *     };
 * @endcode
 *
 * Example usage to get the cache-level property:
 *
 * @code{.c}
 *     DT_PROP(DT_NODELABEL(l2_0), cache_level) // 2
 * @endcode
 *
 * Notice how `L2_0` in the devicetree is lowercased to `l2_0` in the
 * DT_NODELABEL() argument.
 *
 * @param label lowercase-and-underscores node label name
 * @return node identifier for the node with that label
 *//**
 * @brief Get a node identifier for a devicetree path
 *
 * @note This macro returns a node identifier from path components. To get
 *       a path string from a node identifier, use DT_NODE_PATH() instead.
 *
 * The arguments to this macro are the names of non-root nodes in the
 * tree required to reach the desired node, starting from the root.
 * Non-alphanumeric characters in each name must be converted to
 * underscores to form valid C tokens, and letters must be lowercased.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *     / {
 *             soc {
 *                     serial1: serial@40001000 {
 *                             status = "okay";
 *                             current-speed = <115200>;
 *                             ...
 *                     };
 *             };
 *     };
 * @endcode
 *
 * You can use `DT_PATH(soc, serial_40001000)` to get a node identifier
 * for the `serial@40001000` node. Node labels like `serial1` cannot be
 * used as DT_PATH() arguments; use DT_NODELABEL() for those instead.
 *
 * Example usage with DT_PROP() to get the `current-speed` property:
 *
 * @code{.c}
 *     DT_PROP(DT_PATH(soc, serial_40001000), current_speed) // 115200
 * @endcode
 *
 * (The `current-speed` property is also in `lowercase-and-underscores`
 * form when used with this API.)
 *
 * When determining arguments to DT_PATH():
 *
 * - the first argument corresponds to a child node of the root (`soc` above)
 * - a second argument corresponds to a child of the first argument
 *   (`serial_40001000` above, from the node name `serial@40001000`
 *   after lowercasing and changing `@` to `_`)
 * - and so on for deeper nodes in the desired node's path
 *
 * @param ... lowercase-and-underscores node names along the node's path,
 *            with each name given as a separate argument
 * @return node identifier for the node with that path
 *//**
 * @brief Node identifier for the root node in the devicetree
 *//**
 * @brief Name for an invalid node identifier
 *
 * This supports cases where factored macros can be invoked from paths where
 * devicetree data may or may not be available. It is a preprocessor identifier
 * that does not match any valid devicetree node identifier.
 *//**
 * @defgroup devicetree-generic-id Node identifiers and helpers
 * @ingroup devicetree
 * @{
 *//*
 * Property suffixes
 * -----------------
 *
 * These are the optional parts that come after the _P_<property>
 * part in DT_N_<path-id>_P_<property-id> macros, or the "prop-suf"
 * nonterminal in the DT guide's macros.bnf file.
 *
 * Before adding new ones, check this list to avoid conflicts. If any
 * are missing from this list, please add them. It should be complete.
 *
 * _ENUM_IDX: property's value as an index into bindings enum
 * _ENUM_VAL_<val>_EXISTS property's value as a token exists
 * _ENUM_TOKEN: property's value as a token into bindings enum (string
 *              enum values are identifiers) [deprecated, use _STRING_TOKEN]
 * _ENUM_UPPER_TOKEN: like _ENUM_TOKEN, but uppercased [deprecated, use
 *		      _STRING_UPPER_TOKEN]
 * _EXISTS: property is defined
 * _FOREACH_PROP_ELEM: helper for "iterating" over values in the property
 * _FOREACH_PROP_ELEM_VARGS: foreach functions with variable number of arguments
 * _IDX_<i>: logical index into property
 * _IDX_<i>_EXISTS: logical index into property is defined
 * _IDX_<i>_PH: phandle array's phandle by index (or phandle, phandles)
 * _IDX_<i>_STRING_TOKEN: string array element value as a token
 * _IDX_<i>_STRING_UPPER_TOKEN: string array element value as a uppercased token
 * _IDX <i>_STRING_UNQUOTED: string array element value as a sequence of tokens, with no quotes
 * _IDX_<i>_VAL_<val>: phandle array's specifier value by index
 * _IDX_<i>_VAL_<val>_EXISTS: cell value exists, by index
 * _LEN: property logical length
 * _NAME_<name>_PH: phandle array's phandle by name
 * _NAME_<name>_VAL_<val>: phandle array's property specifier by name
 * _NAME_<name>_VAL_<val>_EXISTS: cell value exists, by name
 * _STRING_TOKEN: string property's value as a token
 * _STRING_UPPER_TOKEN: like _STRING_TOKEN, but uppercased
 * _STRING_UNQUOTED: string property's value as a sequence of tokens, with no quotes
 *//**
 * @brief devicetree.h API
 * @defgroup devicetree Devicetree
 * @{
 * @}
 *//**
 * @file
 * @brief Devicetree main header
 *
 * API for accessing the current application's devicetree macros.
 *//*
 * SPDX-License-Identifier: Apache-2.0
 * Copyright (c) 2020 Nordic Semiconductor
 * Copyright (c) 2020, Linaro Ltd.
 *
 * Not a generated file. Feel free to modify.
 */mem_addr_tmm_reg_tio_port_tZEPHYR_INCLUDE_SYS_SYS_IO_H_/* ZEPHYR_INCLUDE_SYS_SYS_IO_H_ *//**
 * @fn static inline int sys_bitfield_test_and_clear_bit(mem_addr_t addr, unsigned int bit)
 * @brief Test the bit and clear it
 *
 * This functions takes the designated bit starting from addr, test its
 * current setting and clears it. It will return the previous setting.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to test and clear (arbitrary)
 *
 * @return 0 if it was clear, 1 otherwise
 *//**
 * @fn static inline int sys_bitfield_test_and_set_bit(mem_addr_t addr, unsigned int bit)
 * @brief Test the bit and set it
 *
 * This functions takes the designated bit starting from addr, tests its
 * current setting and sets it. It will return the previous setting.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to test and set (arbitrary)
 *
 * @return 1 if it was set, 0 otherwise
 *//**
 * @fn static inline int sys_bitfield_test_bit(mem_addr_t addr, unsigned int bit)
 * @brief Test the bit if it is set or not
 *
 * This functions takes the designated bit starting from addr and tests its
 * current setting. It will return the current setting.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to test (arbitrary
 *
 * @return 1 if it is set, 0 otherwise
 *//**
 * @fn static inline void sys_bitfield_clear_bit(mem_addr_t addr, unsigned int bit)
 * @brief Clear the designated bit from addr to 0
 *
 * This functions takes the designated bit starting from addr and sets it to 0.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to clear (arbitrary)
 *//**
 * @fn static inline void sys_bitfield_set_bit(mem_addr_t addr, unsigned int bit)
 * @brief Set the designated bit from addr to 1
 *
 * This functions takes the designated bit starting from addr and sets it to 1.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to set (arbitrary)
 *//**
 * @fn static inline int sys_test_and_clear_bit(mem_addr_t addr, unsigned int bit)
 * @brief Test the bit and clear it
 *
 * This functions takes the designated bit starting from addr, test its
 * current setting and clears it. It will return the previous setting.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to test and clear (from 0 to 31)
 *
 * @return 0 if it was clear, 1 otherwise
 *//**
 * @fn static inline int sys_test_and_set_bit(mem_addr_t addr, unsigned int bit)
 * @brief Test the bit and set it
 *
 * This functions takes the designated bit starting from addr, tests its
 * current setting and sets it. It will return the previous setting.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to test and set (from 0 to 31)
 *
 * @return 1 if it was set, 0 otherwise
 *//**
 * @fn static inline int sys_test_bit(mem_addr_t addr, unsigned int bit)
 * @brief Test the bit if it is set or not
 *
 * This functions takes the designated bit starting from addr and tests its
 * current setting. It will return the current setting.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to test (from 0 to 31)
 *
 * @return 1 if it is set, 0 otherwise
 *//**
 * @fn static inline void sys_clear_bit(mem_addr_t addr, unsigned int bit)
 * @brief Clear the designated bit from addr to 0
 *
 * This functions takes the designated bit starting from addr and sets it to 0.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to clear (from 0 to 31)
 *//**
 * @fn static inline void sys_clear_bits(mem_addr_t addr, unsigned int mask)
 * @brief Masking the designated bits from addr to 0
 *
 * This functions masking designated bits from addr to 0.
 *
 * @param addr the memory address from where to look for the bits
 * @param mask the bit mask of a 32 bits data to set
 *//**
 * @fn static inline void sys_set_bits(mem_addr_t addr, unsigned int mask)
 * @brief Masking the designated bits from addr to 1
 *
 * This functions masking designated bits from addr to 1.
 *
 * @param addr the memory address from where to look for the bits
 * @param mask the bit mask of a 32 bits data to set
 *//**
 * @fn static inline void sys_set_bit(mem_addr_t addr, unsigned int bit)
 * @brief Set the designated bit from addr to 1
 *
 * This functions takes the designated bit starting from addr and sets it to 1.
 *
 * @param addr the memory address from where to look for the bit
 * @param bit the designated bit to set (from 0 to 31)
 *//* Memory bits manipulation functions *//**
 * @fn static inline uint64_t sys_read64(mm_reg_t addr);
 * @brief Read 64 bits from a memory mapped register
 *
 * This function reads 64 bits from the given memory mapped register.
 *
 * @param addr the memory mapped register address from where to read
 *        the 64 bits
 *
 * @return the 64 bits read
 *//**
 * @fn static inline void sys_write64(uint64_t data, mm_reg_t addr);
 * @brief Write 64 bits to a memory mapped register
 *
 * This function writes 64 bits to the given memory mapped register.
 *
 * @param data the 64 bits to write
 * @param addr the memory mapped register address where to write the 64 bits
 *//**
 * @fn static inline uint32_t sys_read32(mm_reg_t addr);
 * @brief Read 32 bits from a memory mapped register
 *
 * This function reads 32 bits from the given memory mapped register.
 *
 * @param addr the memory mapped register address from where to read
 *        the 32 bits
 *
 * @return the 32 bits read
 *//**
 * @fn static inline void sys_write32(uint32_t data, mm_reg_t addr);
 * @brief Write 32 bits to a memory mapped register
 *
 * This function writes 32 bits to the given memory mapped register.
 *
 * @param data the 32 bits to write
 * @param addr the memory mapped register address where to write the 32 bits
 *//**
 * @fn static inline uint16_t sys_read16(mm_reg_t addr);
 * @brief Read 16 bits from a memory mapped register
 *
 * This function reads 16 bits from the given memory mapped register.
 *
 * @param addr the memory mapped register address from where to read
 *        the 16 bits
 *
 * @return the 16 bits read
 *//**
 * @fn static inline void sys_write16(uint16_t data, mm_reg_t addr);
 * @brief Write 16 bits to a memory mapped register
 *
 * This function writes 16 bits to the given memory mapped register.
 *
 * @param data the 16 bits to write
 * @param addr the memory mapped register address where to write the 16 bits
 *//**
 * @fn static inline uint8_t sys_read8(mm_reg_t addr);
 * @brief Read a byte from a memory mapped register
 *
 * This function reads a byte from the given memory mapped register.
 *
 * @param addr the memory mapped register address from where to read the byte
 *
 * @return the byte read
 *//**
 * @fn static inline void sys_write8(uint8_t data, mm_reg_t addr);
 * @brief Write a byte to a memory mapped register
 *
 * This function writes a byte to the given memory mapped register.
 *
 * @param data the byte to write
 * @param addr the memory mapped register address where to write the byte
 *//* Memory mapped registers I/O functions *//**
 * @fn static inline int sys_io_test_and_clear_bit(io_port_t port, unsigned int bit)
 * @brief Test the bit from port and clear it
 *
 * This functions takes the designated bit starting from port, tests its
 * current setting and clears it. It will return the previous setting.
 *
 * @param port the port address from where to look for the bit
 * @param bit the designated bit to test and clear (from 0 to n)
 *
 * @return 0 if it was clear, 1 otherwise
 *//**
 * @fn static inline int sys_io_test_and_set_bit(io_port_t port, unsigned int bit)
 * @brief Test the bit from port and set it
 *
 * This functions takes the designated bit starting from port, tests its
 * current setting and sets it. It will return the previous setting.
 *
 * @param port the port address from where to look for the bit
 * @param bit the designated bit to test and set (from 0 to n)
 *
 * @return 1 if it was set, 0 otherwise
 *//**
 * @fn static inline int sys_io_test_bit(io_port_t port, unsigned int bit)
 * @brief Test the bit from port if it is set or not
 *
 * This functions takes the designated bit starting from port and tests its
 * current setting. It will return the current setting.
 *
 * @param port the port address from where to look for the bit
 * @param bit the designated bit to test (from 0 to n)
 *
 * @return 1 if it is set, 0 otherwise
 *//**
 * @fn static inline void sys_io_clear_bit(io_port_t port, unsigned int bit)
 * @brief Clear the designated bit from port to 0
 *
 * This functions takes the designated bit starting from port and sets it to 0.
 *
 * @param port the port address from where to look for the bit
 * @param bit the designated bit to clear (from 0 to n)
 *//**
 * @fn static inline void sys_io_set_bit(io_port_t port, unsigned int bit)
 * @brief Set the designated bit from port to 1
 *
 * This functions takes the designated bit starting from port and sets it to 1.
 *
 * @param port the port address from where to look for the bit
 * @param bit the designated bit to set (from 0 to n)
 *//**
 * @fn static inline uint32_t sys_in32(io_port_t port);
 * @brief Input 32 bits from an I/O port
 *
 * This function reads 32 bits from the port.
 *
 * @param port the port address from where to read the 32 bits
 *
 * @return the 32 bits read
 *//**
 * @fn static inline void sys_out32(uint32_t data, io_port_t port);
 * @brief Output 32 bits to an I/O port
 *
 * This function writes 32 bits to the given port.
 *
 * @param data the 32 bits to write
 * @param port the port address where to write the 32 bits
 *//**
 * @fn static inline uint16_t sys_in16(io_port_t port);
 * @brief Input 16 bits from an I/O port
 *
 * This function reads 16 bits from the port.
 *
 * @param port the port address from where to read the 16 bits
 *
 * @return the 16 bits read
 *//**
 * @fn static inline void sys_out16(uint16_t data, io_port_t port);
 * @brief Output a 16 bits to an I/O port
 *
 * This function writes a 16 bits to the given port.
 *
 * @param data the 16 bits to write
 * @param port the port address where to write the 16 bits
 *//**
 * @fn static inline uint8_t sys_in8(io_port_t port);
 * @brief Input a byte from an I/O port
 *
 * This function reads a byte from the port.
 *
 * @param port the port address from where to read the byte
 *
 * @return the byte read
 *//**
 * @fn static inline void sys_out8(uint8_t data, io_port_t port);
 * @brief Output a byte to an I/O port
 *
 * This function writes a byte to the given port.
 *
 * @param data the byte to write
 * @param port the port address where to write the byte
 *//* Port I/O functions *//*
 * Copyright (c) 2015 Intel Corporation.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* Port and memory mapped registers I/O operations */irq_disconnect_dynamicirq_connect_dynamicirq_is_enabled(irq)arch_irq_is_enabled(irq)irq_disable(irq)arch_irq_disable(irq)irq_enable(irq)arch_irq_enable(irq)irq_unlock(key)arch_irq_unlock(key)irq_lock()arch_irq_lock()ISR_DIRECT_DECLARE(name)ARCH_ISR_DIRECT_DECLARE(name)ISR_DIRECT_PM()ARCH_ISR_DIRECT_PM()ISR_DIRECT_FOOTER(check_reschedule)ARCH_ISR_DIRECT_FOOTER(check_reschedule)ISR_DIRECT_HEADER()ARCH_ISR_DIRECT_HEADER()IRQ_DIRECT_CONNECT(irq_p,priority_p,isr_p,flags_p)ARCH_IRQ_DIRECT_CONNECT(irq_p, priority_p, isr_p, flags_p)IRQ_CONNECT(irq_p,priority_p,isr_p,isr_param_p,flags_p)ARCH_IRQ_CONNECT(irq_p, priority_p, isr_p, isr_param_p, flags_p)ZEPHYR_INCLUDE_IRQ_H_/* ZEPHYR_INCLUDE_IRQ_H_ *//* ASMLANGUAGE *//**
 * @brief Get IRQ enable state.
 *
 * This routine indicates if interrupts from source @a irq are enabled.
 *
 * @param irq IRQ line.
 *
 * @return interrupt enable state, true or false
 *//**
 * @brief Disable an IRQ.
 *
 * This routine disables interrupts from source @a irq.
 *
 * @param irq IRQ line.
 *//**
 * @brief Enable an IRQ.
 *
 * This routine enables interrupts from source @a irq.
 *
 * @param irq IRQ line.
 *//**
 * @brief Unlock interrupts.
 * @def irq_unlock()
 *
 * This routine reverses the effect of a previous call to irq_lock() using
 * the associated lock-out key. The caller must call the routine once for
 * each time it called irq_lock(), supplying the keys in the reverse order
 * they were acquired, before interrupts are enabled.
 *
 * @note
 * This routine must also serve as a memory barrier to ensure the uniprocessor
 * implementation of `k_spinlock_t` is correct.
 *
 * This routine can only be invoked from supervisor mode. Some architectures
 * (for example, ARM) will fail silently if invoked from user mode instead
 * of generating an exception.
 *
 * @note Can be called by ISRs.
 *
 * @param key Lock-out key generated by irq_lock().
 *//**
 * @brief Lock interrupts.
 * @def irq_lock()
 *
 * This routine disables all interrupts on the CPU. It returns an unsigned
 * integer "lock-out key", which is an architecture-dependent indicator of
 * whether interrupts were locked prior to the call. The lock-out key must be
 * passed to irq_unlock() to re-enable interrupts.
 *
 * @note
 * This routine must also serve as a memory barrier to ensure the uniprocessor
 * implementation of `k_spinlock_t` is correct.
 *
 * This routine can be called recursively, as long as the caller keeps track
 * of each lock-out key that is generated. Interrupts are re-enabled by
 * passing each of the keys to irq_unlock() in the reverse order they were
 * acquired. (That is, each call to irq_lock() must be balanced by
 * a corresponding call to irq_unlock().)
 *
 * This routine can only be invoked from supervisor mode. Some architectures
 * (for example, ARM) will fail silently if invoked from user mode instead
 * of generating an exception.
 *
 * @note
 * This routine can be called by ISRs or by threads. If it is called by a
 * thread, the interrupt lock is thread-specific; this means that interrupts
 * remain disabled only while the thread is running. If the thread performs an
 * operation that allows another thread to run (for example, giving a semaphore
 * or sleeping for N milliseconds), the interrupt lock no longer applies and
 * interrupts may be re-enabled while other processing occurs. When the thread
 * once again becomes the current thread, the kernel re-establishes its
 * interrupt lock; this ensures the thread won't be interrupted until it has
 * explicitly released the interrupt lock it established.
 *
 * @warning
 * The lock-out key should never be used to manually re-enable interrupts
 * or to inspect or manipulate the contents of the CPU's interrupt bits.
 *
 * @return An architecture-dependent lock-out key representing the
 *         "interrupt disable state" prior to the call.
 *//**
 * @brief Helper macro to declare a direct interrupt service routine.
 *
 * This will declare the function in a proper way and automatically include
 * the ISR_DIRECT_FOOTER() and ISR_DIRECT_HEADER() macros. The function should
 * return nonzero status if a scheduling decision should potentially be made.
 * See ISR_DIRECT_FOOTER() for more details on the scheduling decision.
 *
 * For architectures that support 'regular' and 'fast' interrupt types, where
 * these interrupt types require different assembly language handling of
 * registers by the ISR, this will always generate code for the 'fast'
 * interrupt type.
 *
 * Example usage:
 *
 *     ISR_DIRECT_DECLARE(my_isr)
 *     {
 *             bool done = do_stuff();
 *             ISR_DIRECT_PM(); // done after do_stuff() due to latency concerns
 *             if (!done) {
 *                 return 0; // don't bother checking if we have to z_swap()
 *             }
 *
 *             k_sem_give(some_sem);
 *             return 1;
 *      }
 *
 * @param name symbol name of the ISR
 *//**
 * @brief Perform power management idle exit logic
 *
 * This macro may optionally be invoked somewhere in between IRQ_DIRECT_HEADER()
 * and IRQ_DIRECT_FOOTER() invocations. It performs tasks necessary to
 * exit power management idle state. It takes no parameters and returns no
 * arguments. It may be omitted, but be careful!
 *//**
 * @brief Common tasks before exiting the body of an ISR
 *
 * This macro must be at the end of all direct interrupts and performs
 * minimal architecture-specific tasks like EOI. It has no return value.
 *
 * In a normal interrupt, a check is done at end of interrupt to invoke
 * z_swap() logic if the current thread is preemptible and there is another
 * thread ready to run in the kernel's ready queue cache. This is now optional
 * and controlled by the check_reschedule argument. If unsure, set to nonzero.
 * On systems that do stack switching and nested interrupt tracking in software,
 * z_swap() should only be called if this was a non-nested interrupt.
 *
 * @param check_reschedule If nonzero, additionally invoke scheduling logic
 *//**
 * @brief Common tasks before executing the body of an ISR
 *
 * This macro must be at the beginning of all direct interrupts and performs
 * minimal architecture-specific tasks before the ISR itself can run. It takes
 * no arguments and has no return value.
 *//**
 * @brief Initialize a 'direct' interrupt handler.
 *
 * This routine initializes an interrupt handler for an IRQ. The IRQ must be
 * subsequently enabled via irq_enable() before the interrupt handler begins
 * servicing interrupts.
 *
 * These ISRs are designed for performance-critical interrupt handling and do
 * not go through common interrupt handling code. They must be implemented in
 * such a way that it is safe to put them directly in the vector table.  For
 * ISRs written in C, The ISR_DIRECT_DECLARE() macro will do this
 * automatically. For ISRs written in assembly it is entirely up to the
 * developer to ensure that the right steps are taken.
 *
 * This type of interrupt currently has a few limitations compared to normal
 * Zephyr interrupts:
 * - No parameters are passed to the ISR.
 * - No stack switch is done, the ISR will run on the interrupted context's
 *   stack, unless the architecture automatically does the stack switch in HW.
 * - Interrupt locking state is unchanged from how the HW sets it when the ISR
 *   runs. On arches that enter ISRs with interrupts locked, they will remain
 *   locked.
 * - Scheduling decisions are now optional, controlled by the return value of
 *   ISRs implemented with the ISR_DIRECT_DECLARE() macro
 * - The call into the OS to exit power management idle state is now optional.
 *   Normal interrupts always do this before the ISR is run, but when it runs
 *   is now controlled by the placement of a ISR_DIRECT_PM() macro, or omitted
 *   entirely.
 *
 * @warning
 * Although this routine is invoked at run-time, all of its arguments must be
 * computable by the compiler at build time.
 *
 * @param irq_p IRQ line number.
 * @param priority_p Interrupt priority.
 * @param isr_p Address of interrupt service routine.
 * @param flags_p Architecture-specific IRQ configuration flags.
 *//**
 * Disconnect a dynamic interrupt.
 *
 * Use this in conjunction with shared interrupts to remove a routine/parameter
 * pair from the list of clients using the same interrupt line. If the interrupt
 * is not being shared then the associated _sw_isr_table entry will be replaced
 * by (NULL, z_irq_spurious) (default entry).
 *
 * @param irq IRQ line number
 * @param priority Interrupt priority
 * @param routine Interrupt service routine
 * @param parameter ISR parameter
 * @param flags Arch-specific IRQ configuration flags
 *
 * @return 0 in case of success, negative value otherwise
 *//**
 * Configure a dynamic interrupt.
 *
 * Use this instead of IRQ_CONNECT() if arguments cannot be known at build time.
 *
 * @param irq IRQ line number
 * @param priority Interrupt priority
 * @param routine Interrupt service routine
 * @param parameter ISR parameter
 * @param flags Arch-specific IRQ configuration flags
 *
 * @return The vector assigned to this interrupt
 *//**
 * @brief Initialize an interrupt handler.
 *
 * This routine initializes an interrupt handler for an IRQ. The IRQ must be
 * subsequently enabled before the interrupt handler begins servicing
 * interrupts.
 *
 * @warning
 * Although this routine is invoked at run-time, all of its arguments must be
 * computable by the compiler at build time.
 *
 * @param irq_p IRQ line number.
 * @param priority_p Interrupt priority.
 * @param isr_p Address of interrupt service routine.
 * @param isr_param_p Parameter passed to interrupt service routine.
 * @param flags_p Architecture-specific IRQ configuration flags..
 *//**
 * @defgroup isr_apis Interrupt Service Routine APIs
 * @ingroup kernel_apis
 * @{
 *//* Pull in the arch-specific implementations *//**
 * @file
 * @brief Public interface for configuring interrupts
 */arch_mem_domaink_mem_partition_attr_tpentry_tpentry_t *unsigned long long *ptablespentry_t[4]unsigned long long[4]pdptK_MEM_PARTITION_PERM_MASK(Z_X86_MMU_RW | Z_X86_MMU_US | Z_X86_MMU_XD)K_MEM_PARTITION_P_RX_U_NAK_MEM_PARTITION_P_RX_U_RXZ_X86_MMU_USK_MEM_PARTITION_P_RWX_U_NAZ_X86_MMU_RWK_MEM_PARTITION_P_RWX_U_RWX(Z_X86_MMU_RW | Z_X86_MMU_US)K_MEM_PARTITION_P_RO_U_NAZ_X86_MMU_XDK_MEM_PARTITION_P_RO_U_RO(Z_X86_MMU_US | Z_X86_MMU_XD)K_MEM_PARTITION_P_RW_U_NA(Z_X86_MMU_RW | Z_X86_MMU_XD)K_MEM_PARTITION_P_RW_U_RWK_MEM_PARTITION_IS_WRITABLE(attr)(((attr) & Z_X86_MMU_RW) != 0)K_MEM_PARTITION_IS_EXECUTABLE(attr)(((attr) & Z_X86_MMU_XD) == 0)ARCH_DATA_PAGE_NOT_MAPPED((uintptr_t)BIT(7))ARCH_DATA_PAGE_ACCESSED((uintptr_t)BIT(5))ARCH_DATA_PAGE_LOADED((uintptr_t)BIT(0))ARCH_DATA_PAGE_DIRTY((uintptr_t)BIT(6))BIT64(63)BIT64(2)BIT64(1)ZEPHYR_INCLUDE_ARCH_X86_MMU_Hdefined(CONFIG_X86_PAE) || defined(CONFIG_X86_64)defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)/* ZEPHYR_INCLUDE_ARCH_X86_MMU_H *//* CONFIG_X86_PAE *//* Linked list of all active memory domains *//* Pointer to top-level structure, either a PML4, PDPT, PD *//* 4-entry, 32-byte top-level PDPT *//* Page table entry data type at all levels. Defined here due to
 * k_mem_partition_attr_t, eventually move to private x86_mmu.h
 *//* memory partition access permission mask *//* Execution-allowed attributes *//* memory partition arch/soc independent attribute *//* Always true with 32-bit page tables, don't enable
 * CONFIG_EXECUTE_XOR_WRITE and expect it to work for you
 *//* Use an PAT bit for this one since it's never set in a mapped PTE *//* For these we'll just use the same bits in the PTE *//** Execute Disable *//** User-Supervisor *//** Read-Write *//*
 * K_MEM_PARTITION_* defines
 *
 * Slated for removal when virtual memory is implemented, memory
 * mapping APIs will replace memory domains.
 *//*
 * Copyright (c) 2011-2014 Wind River Systems, Inc.
 * Copyright (c) 2020 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */alignedz_x86_thread_stack_headerZ_X86_STACK_BASE_ALIGN4ULARCH_KERNEL_STACK_OBJ_ALIGNARCH_STACK_PTR_ALIGNARCH_KERNEL_STACK_RESERVEDARCH_THREAD_STACK_RESERVEDsizeof(struct z_x86_thread_stack_header)ARCH_THREAD_STACK_SIZE_ADJUST(size)ROUND_UP((size), Z_X86_STACK_SIZE_ALIGN)ARCH_THREAD_STACK_OBJ_ALIGN(size)Z_X86_STACK_SIZE_ALIGNZEPHYR_INCLUDE_ARCH_X86_THREAD_STACK_Hdefined(CONFIG_HW_STACK_PROTECTION) || defined(CONFIG_USERSPACE)CONFIG_HW_STACK_PROTECTION/* ZEPHYR_INCLUDE_ARCH_X86_THREAD_STACK_H *//* With both hardware stack protection and userspace enabled, stacks are
 * arranged as follows:
 *
 * High memory addresses
 * +-----------------------------------------+
 * | Thread stack (varies)                   |
 * +-----------------------------------------+
 * | Privilege elevation stack               |
 * |      (4096 bytes)                       |
 * +-----------------------------------------+
 * | Guard page (4096 bytes)                 |
 * +-----------------------------------------+
 * Low Memory addresses
 *
 * Privilege elevation stacks are fixed-size. All the pages containing the
 * thread stack are marked as user-accessible. The guard page is marked
 * read-only to catch stack overflows in supervisor mode.
 *
 * If a thread starts in supervisor mode, the page containing the
 * privilege elevation stack is also marked read-only.
 *
 * If a thread starts in, or drops down to user mode, the privilege stack page
 * will be marked as present, supervisor-only.
 *
 * If KPTI is not enabled, the _main_tss.esp0 field will always be updated
 * updated to point to the top of the privilege elevation stack. Otherwise
 * _main_tss.esp0 always points to the trampoline stack, which handles the
 * page table switch to the kernel PDPT and transplants context to the
 * privileged mode stack.
 *//* If user mode enabled, expand any stack size to fill a page since that is
 * the access control granularity and we don't want other kernel data to
 * unintentionally fall in the latter part of the page
 */z_x86_msr_readz_x86_msr_writehighlowX86_KERNEL_GS_BASE0xC0000102UX86_GS_BASE0xC0000101UX86_FS_BASE0xC0000100UX86_FMASK_MSR0xC0000084UX86_LSTAR_MSR0xC0000082UX86_STAR_MSR0xC0000081UX86_EFER_MSR_NXEBIT(11)X86_EFER_MSR_LMEBIT(8)X86_EFER_MSR_SCEX86_EFER_MSR0xC0000080UX86_X2APIC_BASE_MSR0x00000800X86_MTRR_DEF_TYPE_MSR_ENABLEX86_MTRR_DEF_TYPE_MSR0x000002ffX86_APIC_BASE_MSR_X2APICBIT(10)X86_APIC_BASE_MSR0x0000001bX86_SPEC_CTRL_MSR_SSBDX86_SPEC_CTRL_MSR_IBRSX86_SPEC_CTRL_MSR0x00000048X86_TIME_STAMP_COUNTER_MSR0x00000010ZEPHYR_INCLUDE_ARCH_X86_MSR_H_/* ZEPHYR_INCLUDE_ARCH_X86_MSR_H_ *//*
 * z_x86_msr_write() is shared between 32- and 64-bit implementations, but
 * due to ABI differences with long return values, z_x86_msr_read() is not.
 *//* Low 32 bits in this MSR are the SYSCALL mask applied to EFLAGS *//* Location for system call entry point *//* STAR 31:0   Unused in long mode
 *      47:32  Kernel CS (SS = CS+8)
 *      63:48  User CS (SS = CS+8)
 *//* .. thru 0x00000BFF *//*
 * Model specific registers (MSR).  Access with z_x86_msr_read/write().
 *//*
 * Copyright (c) 2019 Intel Corp.
 * SPDX-License-Identifier: Apache-2.0
 */msrz_impl_k_mem_paging_histogram_backing_store_page_out_getz_impl_k_mem_paging_histogram_backing_store_page_in_getz_impl_k_mem_paging_histogram_eviction_getz_impl_k_mem_paging_thread_stats_getz_impl_k_mem_paging_stats_getZ_INCLUDE_SYSCALLS_MEM_MANAGE_H<zephyr/sys/sys_io.h>device_mapmm_reg_t *z_device_mmio_romDEVICE_MMIO_TOPLEVEL_GET(name)((mm_reg_t)Z_TOPLEVEL_RAM_NAME(name))DEVICE_MMIO_TOPLEVEL_MAP(name,flags)device_map(&Z_TOPLEVEL_RAM_NAME(name), Z_TOPLEVEL_ROM_NAME(name).phys_addr, Z_TOPLEVEL_ROM_NAME(name).size, flags)DEVICE_MMIO_TOPLEVEL_ROM_PTR(name)&Z_TOPLEVEL_ROM_NAME(name)DEVICE_MMIO_TOPLEVEL_RAM_PTR(name)&Z_TOPLEVEL_RAM_NAME(name)DEVICE_MMIO_TOPLEVEL_STATIC(name,node_id)__pinned_bss static mm_reg_t Z_TOPLEVEL_RAM_NAME(name); __pinned_rodata static const struct z_device_mmio_rom Z_TOPLEVEL_ROM_NAME(name) = Z_DEVICE_MMIO_ROM_INITIALIZER(node_id)DEVICE_MMIO_TOPLEVEL_DECLARE(name)extern mm_reg_t Z_TOPLEVEL_RAM_NAME(name); extern const struct z_device_mmio_rom Z_TOPLEVEL_ROM_NAME(name)DEVICE_MMIO_TOPLEVEL(name,node_id)__pinned_bss mm_reg_t Z_TOPLEVEL_RAM_NAME(name); __pinned_rodata const struct z_device_mmio_rom Z_TOPLEVEL_ROM_NAME(name) = Z_DEVICE_MMIO_ROM_INITIALIZER(node_id)Z_TOPLEVEL_RAM_NAME(name)_CONCAT(z_mmio_ram__, name)Z_TOPLEVEL_ROM_NAME(name)_CONCAT(z_mmio_rom__, name)DEVICE_MMIO_NAMED_GET(dev,name)(*DEVICE_MMIO_NAMED_RAM_PTR((dev), name))DEVICE_MMIO_NAMED_MAP(dev,name,flags)device_map(DEVICE_MMIO_NAMED_RAM_PTR((dev), name), (DEVICE_MMIO_NAMED_ROM_PTR((dev), name)->phys_addr), (DEVICE_MMIO_NAMED_ROM_PTR((dev), name)->size), (flags))DEVICE_MMIO_NAMED_ROM_INIT_BY_NAME(name,node_id).name = Z_DEVICE_MMIO_NAMED_ROM_INITIALIZER(name, node_id)DEVICE_MMIO_NAMED_ROM_INIT(name,node_id).name = Z_DEVICE_MMIO_ROM_INITIALIZER(node_id)DEVICE_MMIO_NAMED_ROM_PTR(dev,name)(&(DEV_CFG(dev)->name))DEVICE_MMIO_NAMED_ROM(name)struct z_device_mmio_rom nameDEVICE_MMIO_NAMED_RAM_PTR(dev,name)(&(DEV_DATA(dev)->name))DEVICE_MMIO_NAMED_RAM(name)mm_reg_t nameDEVICE_MMIO_GET(dev)(*DEVICE_MMIO_RAM_PTR(dev))DEVICE_MMIO_MAP(dev,flags)device_map(DEVICE_MMIO_RAM_PTR(dev), DEVICE_MMIO_ROM_PTR(dev)->phys_addr, DEVICE_MMIO_ROM_PTR(dev)->size, (flags))DEVICE_MMIO_ROM_INIT(node_id)._mmio = Z_DEVICE_MMIO_ROM_INITIALIZER(node_id)DEVICE_MMIO_ROM_PTR(dev)((struct z_device_mmio_rom *)((dev)->config))DEVICE_MMIO_ROMstruct z_device_mmio_rom _mmioDEVICE_MMIO_RAM_PTR(device)(mm_reg_t *)((device)->data)DEVICE_MMIO_RAMmm_reg_t _mmioZ_DEVICE_MMIO_NAMED_ROM_INITIALIZER(name,node_id){ .phys_addr = DT_REG_ADDR_BY_NAME(node_id, name), .size = DT_REG_SIZE_BY_NAME(node_id, name) }Z_DEVICE_MMIO_ROM_INITIALIZER(node_id){ .phys_addr = DT_REG_ADDR(node_id), .size = DT_REG_SIZE(node_id) }ZEPHYR_INCLUDE_SYS_DEVICE_MMIO_Hdefined(CONFIG_MMU) || defined(CONFIG_PCIE) || defined(CONFIG_EXTERNAL_ADDRESS_TRANSLATION)defined(CONFIG_EXTERNAL_ADDRESS_TRANSLATION)CONFIG_EXTERNAL_ADDRESS_TRANSLATION/* ZEPHYR_INCLUDE_SYS_DEVICE_MMIO_H *//**
 * @def DEVICE_MMIO_TOPLEVEL_GET(name)
 *
 * @brief Obtain the MMIO address for a device declared top-level
 *
 * @see DEVICE_MMIO_GET
 *
 * @param name Name of the top-level MMIO region
 * @return mm_reg_t  linear address of the MMIO region
 *//**
 * @def DEVICE_MMIO_TOPLEVEL_MAP(name, flags)
 *
 * @brief Set up memory for a driver'sMMIO region
 *
 * This performs the necessary MMU virtual memory mapping
 * such that DEVICE_MMIO_GET() returns a suitable linear memory address
 * for the MMIO region.
 *
 * If such operations are not required by the target hardware, this expands
 * to nothing.
 *
 * This should be called once from the driver's init function.
 *
 * The flags argument is currently used for caching mode, which should be
 * one of the DEVICE_CACHE_* macros. Unused bits are reserved for future
 * expansion.
 *
 * @param name Name of the top-level MMIO region
 * @param flags One of the DEVICE_CACHE_* caching modes
 *//**
 * Return a pointer to the ROM-based storage area for a toplevel MMIO region.
 *
 * @param name MMIO region name
 * @retval struct device_mmio_rom * pointer to storage location
 *//**
 * @brief Return a pointer to the RAM storage for a device's toplevel MMIO
 * address.
 *
 * @param name Name of toplevel MMIO region
 * @retval mm_reg_t  pointer to storage location
 *//**
 * @def  DEVICE_MMIO_TOPLEVEL_STATIC(name, node_id)
 *
 * @brief Declare top-level storage for MMIO information, static scope
 *
 * This is intended for drivers which do not use Zephyr's driver model
 * of config/dev_data linked to a struct device.
 *
 * Instead, this is a top-level declaration for the driver's C file.
 * The scope of this declaration is static.
 *
 * @param name Name of the top-level MMIO region
 * @param node_id Device-tree node identifier for this region
 *//**
 * @def DEVICE_MMIO_TOPLEVEL_DECLARE(name)
 *
 * Provide an extern reference to a top-level MMIO region
 *
 * If a top-level MMIO region defined with DEVICE_MMIO_DEFINE needs to be
 * referenced from other C files, this macro provides the necessary extern
 * definitions.
 *
 * @see DEVICE_MMIO_TOPLEVEL
 *
 * @param name Name of the top-level MMIO region
 *//**
 * @def DEVICE_MMIO_TOPLEVEL(name, node_id)
 *
 * @brief Declare top-level storage for MMIO information, global scope
 *
 * This is intended for drivers which do not use Zephyr's driver model
 * of config/dev_data linked to a struct device.
 *
 * Instead, this is a top-level declaration for the driver's C file.
 * The scope of this declaration is global and may be referenced by
 * other C files, using DEVICE_MMIO_TOPLEVEL_DECLARE.
 *
 * @param name Base symbol name
 * @param node_id Device-tree node identifier for this region
 *//**
 * @defgroup device-mmio-toplevel Top-level MMIO region macros
 * @ingroup device-mmio
 *
 * For drivers which do not use Zephyr's driver model and do not
 * associate struct device with a driver instance. Top-level storage
 * is used instead, with either global or static scope.
 *
 * This is often useful for interrupt controller and timer drivers.
 *
 * Currently PCIe devices are not well-supported with this set of macros.
 * Either use Zephyr's driver model for these kinds of devices, or
 * manage memory manually with calls to device_map().
 *
 * @{
 *//**
 * @def DEVICE_MMIO_NAMED_GET(dev, name)
 *
 * @brief Obtain a named MMIO address for a device
 *
 * This macro returns the MMIO base address for a named region from the
 * appropriate place within the device object's linked  data structures.
 *
 * This is for drivers which have multiple MMIO regions.
 *
 * This macro requires that the macros DEV_DATA and DEV_CFG are locally
 * defined and return properly typed pointers to the particular dev_data
 * and config structs for this driver.
 *
 * @see DEVICE_MMIO_GET
 *
 * @param dev Device object
 * @param name Member name for MMIO information, as declared with
 *             DEVICE_MMIO_NAMED_RAM/DEVICE_MMIO_NAMED_ROM
 * @return mm_reg_t  linear address of the MMIO region
 *//**
 * @brief Set up memory for a named MMIO region
 *
 * This performs the necessary PCI probing and/or MMU virtual memory mapping
 * such that DEVICE_MMIO_GET(name) returns a suitable linear memory address
 * for the MMIO region.
 *
 * If such operations are not required by the target hardware, this expands
 * to nothing.
 *
 * This should be called from the driver's init function, once for each
 * MMIO region that needs to be mapped.
 *
 * This macro requires that the macros DEV_DATA and DEV_CFG are locally
 * defined and return properly typed pointers to the particular dev_data
 * and config structs for this driver.
 *
 * The flags argument is currently used for caching mode, which should be
 * one of the DEVICE_CACHE_* macros. Unused bits are reserved for future
 * expansion.
 *
 * @param dev Device object
 * @param name Member name for MMIO information, as declared with
 *             DEVICE_MMIO_NAMED_RAM/DEVICE_MMIO_NAMED_ROM
 * @param flags One of the DEVICE_CACHE_* caching modes
 *//**
 * @brief Initialize a named DEVICE_MMIO_NAMED_ROM member using a named DT
 *        reg property.
 *
 * Same as @ref DEVICE_MMIO_NAMED_ROM_INIT but the size and address are taken
 * from a named DT reg property.
 *
 * Example for an instance of a driver belonging to the "foo" subsystem
 * that will have two DT-defined regions named 'chip' and 'dale':
 *
 * @code{.dts}
 *
 *    foo@E5000000 {
 *         reg = <0xE5000000 0x1000>, <0xE6000000 0x1000>;
 *         reg-names = "chip", "dale";
 *         ...
 *    };
 *
 * @endcode
 *
 * @code{.c}
 *
 * struct foo_config my_config = {
 *	bar = 7;
 *	DEVICE_MMIO_NAMED_ROM_INIT_BY_NAME(chip, DT_DRV_INST(...));
 *	DEVICE_MMIO_NAMED_ROM_INIT_BY_NAME(dale, DT_DRV_INST(...));
 *	baz = 2;
 *	...
 * }
 *
 * @endcode
 *
 * @see DEVICE_MMIO_NAMED_ROM_INIT()
 *
 * @param name Member name within config for the MMIO region and name of the
 *             reg property in the DT
 * @param node_id DTS node identifier
 *//**
 * @brief Initialize a named DEVICE_MMIO_NAMED_ROM member
 *
 * Initialize MMIO-related information within a specific instance of
 * a device config struct, using information from DTS.
 *
 * Example for an instance of a driver belonging to the "foo" subsystem
 * that will have two regions named 'corge' and 'grault':
 *
 * @code{.c}
 *
 * struct foo_config my_config = {
 *	bar = 7;
 *	DEVICE_MMIO_NAMED_ROM_INIT(corge, DT_DRV_INST(...));
 *	DEVICE_MMIO_NAMED_ROM_INIT(grault, DT_DRV_INST(...));
 *	baz = 2;
 *	...
 * }
 *
 * @endcode
 *
 * @see DEVICE_MMIO_NAMED_ROM()
 *
 * @param name Member name within config for the MMIO region
 * @param node_id DTS node identifier
 *//**
 * Return a pointer to the ROM-based storage area for a device's MMIO
 * information.
 *
 * This macro requires that the macro DEV_CFG is locally defined and returns
 * a properly typed pointer to the particular config struct for this
 * driver.
 *
 * @param dev device instance object
 * @param name Member name within config
 * @retval struct device_mmio_rom * pointer to storage location
 *//**
 * @brief Declare storage for MMIO data within a device's config struct.
 *
 * This gets accessed by DEVICE_MMIO_NAMED_MAP() and
 * DEVICE_MMIO_NAMED_GET() macros.
 *
 * What gets stored here varies considerably by configuration. Multiple named
 * regions may be declared. There must be corresponding entries in the dev_data
 * struct.
 *
 * This storage is not used if the device is PCIe and may be omitted.
 *
 * If used, this must be initialized at build time with information from DTS
 * using DEVICE_MMIO_NAMED_ROM_INIT()
 *
 * A pointer to this memory may be obtained with DEVICE_MMIO_NAMED_ROM_PTR().
 *
 * Example for a driver named "foo":
 *
 * @code{.c}
 *
 * struct foo_config {
 *      int bar;
 *      DEVICE_MMIO_NAMED_ROM(corge);
 *      DEVICE_MMIO_NAMED_ROM(grault);
 *      int baz;
 *      ...
 * }
 *
 * @endcode
 *
 * @see DEVICE_MMIO_NAMED_ROM_INIT()
 *
 * @param name Member name to store within config
 *//**
 * @brief Return a pointer to the RAM storage for a device's named MMIO address
 *
 * This macro requires that the macro DEV_DATA is locally defined and returns
 * a properly typed pointer to the particular dev_data struct for this driver.
 *
 * @param dev device instance object
 * @param name Member name within dev_data
 * @retval mm_reg_t  pointer to storage location
 *//**
 * @def DEVICE_MMIO_NAMED_RAM(name)
 *
 * @brief Declare storage for MMIO data within a device's dev_data struct
 *
 * This gets accessed by the DEVICE_MMIO_NAMED_MAP() and
 * DEVICE_MMIO_NAMED_GET() macros.
 *
 * Depending on configuration, no memory may be reserved at all.
 * Multiple named regions may be declared.
 *
 * There must be a corresponding DEVICE_MMIO_ROM in config if the
 * physical address is known at build time, but may be omitted if not (such
 * as with PCIe.
 *
 * Example for a driver named "foo":
 *
 * @code{.c}
 *
 * struct foo_driver_data {
 *      int blarg;
 *      DEVICE_MMIO_NAMED_RAM(corge);
 *      DEVICE_MMIO_NAMED_RAM(grault);
 *      int wibble;
 *      ...
 * }
 *
 * @endcode
 *
 * No build-time initialization of this memory is necessary; it
 * will be set up in the init function by DEVICE_MMIO_NAMED_MAP().
 *
 * @param name Member name to use to store within dev_data.
 *//**
 * @defgroup device-mmio-named Named MMIO region macros
 * @ingroup device-mmio
 *
 * For drivers which need to manage multiple MMIO regions, which will
 * be referenced by name.
 *
 * @{
 *//**
 * @def DEVICE_MMIO_GET(dev)
 *
 * @brief Obtain the MMIO address for a device
 *
 * For most microcontrollers MMIO addresses can be fixed values known at
 * build time, and we can store this in device->config, residing in ROM.
 *
 * However, some devices can only know their MMIO addresses at runtime,
 * because they need to be memory-mapped into the address space, enumerated
 * from PCI, or both.
 *
 * This macro returns the linear address of the driver's MMIO region.
 * This is for drivers which have exactly one MMIO region.
 * A call must have been made to device_map() in the driver init function.
 *
 * @param dev Device object
 * @return mm_reg_t  linear address of the MMIO region
 *//**
 * @def DEVICE_MMIO_MAP(device, flags)
 *
 * @brief Map MMIO memory into the address space
 *
 * This is not intended for PCIe devices; these must be probed at runtime
 * and you will want to make a device_map() call directly, using
 * DEVICE_MMIO_RAM_PTR() as the target virtual address location.
 *
 * The flags argument is currently used for caching mode, which should be
 * one of the DEVICE_CACHE_* macros. Unused bits are reserved for future
 * expansion.
 *
 * @param dev Device object instance
 * @param flags cache mode flags
 *//**
 * @brief Initialize a DEVICE_MMIO_ROM member
 *
 * Initialize MMIO-related information within a specific instance of
 * a device config struct, using information from DTS.
 *
 * Example for a driver belonging to the "foo" subsystem:
 *
 * @code{.c}
 *
 * struct foo_config my_config = {
 *	DEVICE_MMIO_ROM_INIT(DT_DRV_INST(...)),
 *	.baz = 2;
 *	...
 * }
 *
 * @endcode
 *
 * @see DEVICE_MMIO_ROM()
 *
 * @param node_id DTS node_id
 *//**
 * Return a pointer to the ROM-based storage area for a device's MMIO
 * information. This macro will not work properly if the ROM storage
 * was omitted from the config struct declaration, and should not
 * be used in this case.
 *
 * @param dev device instance object
 * @retval struct device_mmio_rom * pointer to storage location
 *//**
 * @brief Declare storage for MMIO data within a device's config struct
 *
 * This gets accessed by DEVICE_MMIO_MAP() and DEVICE_MMIO_GET() macros.
 *
 * What gets stored here varies considerably by configuration.
 * This must be the first member of the config struct. There must be
 * a corresponding DEVICE_MMIO_RAM in data.
 *
 * This storage is not used if the device is PCIe and may be omitted.
 *
 * This should be initialized at build time with information from DTS
 * using DEVICE_MMIO_ROM_INIT().
 *
 * A pointer to this memory may be obtained with DEVICE_MMIO_ROM_PTR().
 *
 * Example for a driver named "foo":
 *
 * @code{.c}
 *
 * struct foo_config {
 *	DEVICE_MMIO_ROM;
 *	int baz;
 *	...
 * }
 *
 * @endcode
 *
 * @see DEVICE_MMIO_ROM_INIT()
 *//**
 * Return a pointer to the RAM-based storage area for a device's MMIO
 * address.
 *
 * This is useful for the target MMIO address location when using
 * device_map() directly.
 *
 * @param device device node_id object
 * @retval mm_reg_t  pointer to storage location
 *//**
 * @def DEVICE_MMIO_RAM
 *
 * Declare storage for MMIO information within a device's dev_data struct.
 *
 * This gets accessed by the DEVICE_MMIO_MAP() and DEVICE_MMIO_GET() macros.
 *
 * Depending on configuration, no memory may be reserved at all.
 * This must be the first member of the data struct.
 *
 * There must be a corresponding DEVICE_MMIO_ROM in config_info if the
 * physical address is known at build time, but may be omitted if not (such
 * as with PCIe)
 *
 * Example for a driver named "foo":
 *
 * @code{.c}
 *
 * struct foo_driver_data {
 *	DEVICE_MMIO_RAM;
 *	int wibble;
 *	...
 * }
 *
 * @endcode
 *
 * No build-time initialization of this memory is necessary; it
 * will be set up in the init function by DEVICE_MMIO_MAP().
 *
 * A pointer to this memory may be obtained with DEVICE_MMIO_RAM_PTR().
 *//**
 * @defgroup device-mmio-single Single MMIO region macros
 * @ingroup device-mmio
 *
 * For drivers which need to manage just one MMIO region, the most common
 * case.
 *
 * @{
 *//** MMIO linear address *//* No MMU or PCIe. Just store the address from DTS and treat as a linear
 * address
 *//* CONFIG_EXTERNAL_ADDRESS_TRANSLATION *//* Pass along flags and add that we want supervisor mode
	 * read-write access.
	 *//**
 * Set linear address for device MMIO access
 *
 * This function sets the `virt_addr` parameter to the correct linear
 * address for the MMIO region.
 *
 * If the MMU is enabled, mappings may be created in the page tables.
 *
 * Normally, only a caching mode needs to be set for the 'flags' parameter.
 * The mapped linear address will have read-write access to supervisor mode.
 *
 * @see k_map()
 *
 * @param[out] virt_addr Output linear address storage location, most
 *		         users will want some DEVICE_MMIO_RAM_PTR() value
 * @param[in] phys_addr Physical address base of the MMIO region
 * @param[in] size Size of the MMIO region
 * @param[in] flags Caching mode and access flags, see K_MEM_CACHE_* and
 *                  K_MEM_PERM_* macros
 *//** MMIO region size *//** MMIO physical address *//* Store the physical address and size from DTS, we'll memory
 * map into the virtual address space at runtime. This is not applicable
 * to PCIe devices, which must query the bus for BAR information.
 *//* Storing MMIO addresses in RAM is a system-wide decision based on
 * configuration. This is just used to simplify some other definitions.
 *
 * If we have an MMU enabled, all physical MMIO regions must be mapped into
 * the kernel's virtual address space at runtime, this is a hard requirement.
 *
 * If we have PCIE enabled, this does mean that non-PCIE drivers may waste
 * a bit of RAM, but systems with PCI express are not RAM constrained.
 *//**
 * @defgroup device-mmio Device memory-mapped IO management
 * @ingroup device_model
 *
 * Definitions and helper macros for managing driver memory-mapped
 * input/output (MMIO) regions appropriately in either RAM or ROM.
 *
 * In most cases drivers will just want to include device.h, but
 * including this separately may be needed for arch-level driver code
 * which uses the DEVICE_MMIO_TOPLEVEL variants and including the
 * main device.h would introduce header dependency loops due to that
 * header's reliance on kernel.h.
 *
 * @{
 */virt_addr<zephyr/arch/x86/msr.h>z_loapic_ipiLOAPIC_ICRLOLOAPIC_ICR_BUSYLOAPIC_ICRHIx86_write_loapicx86_write_xapicLOAPIC_REGS_STRloapic_regsz_mmio_ram__x86_write_x2apicx86_read_loapicx86_read_xapicx86_read_x2apicz_loapic_irq_disablez_loapic_irq_enablez_loapic_int_vec_setz_loapic_enablez_loapic_irq_baseconst z_device_mmio_romz_mmio_rom__loapic_regsz_mmio_rom__z_mmio_ram__loapic_regsLOAPIC_LVT_MASKED0x00010000LOAPIC_ICR_IPI_STARTUP0x00004600ULOAPIC_ICR_IPI_INIT0x00004500ULOAPIC_ICR_IPI_OTHERS0x000C4000U0x00001000LOAPIC_SELF_IPI0x3f0LOAPIC_TIMER_CONFIG0x3e0LOAPIC_TIMER_CCR0x390LOAPIC_TIMER_ICR0x380LOAPIC_ERROR0x370LOAPIC_LINT10x360LOAPIC_LINT00x350LOAPIC_PMC0x340LOAPIC_THERMAL0x330LOAPIC_TIMER0x3200x3100x300LOAPIC_ESR0x280LOAPIC_IRR0x200LOAPIC_TMR0x180LOAPIC_ISR0x100LOAPIC_SVR0x0f0LOAPIC_DFR0x0e0LOAPIC_LDR0x0d0LOAPIC_EOI0x0b0LOAPIC_PPR0x0a0LOAPIC_APR0x090LOAPIC_TPR0x080LOAPIC_VER0x030LOAPIC_ID0x020ZEPHYR_INCLUDE_DRIVERS_LOAPIC_H_/* ZEPHYR_INCLUDE_DRIVERS_LOAPIC_H_ *//*
	 * x2APIC mode is greatly simplified: one write, no delivery status.
	 *//*
	 * Legacy xAPIC mode: first wait for any previous IPI to be delivered.
	 *//**
 * @brief Send an IPI.
 *
 * @param apic_id If applicable, the target CPU APIC ID (0 otherwise).
 * @param ipi Type of IPI: one of the LOAPIC_ICR_IPI_* constants.
 * @param vector If applicable, the target vector (0 otherwise).
 *//**
 * @brief Write 32-bit value to the local APIC using the default mode.
 *
 * Write a 32-bit value to the local APIC, using the access method
 * determined by CONFIG_X2APIC (either xAPIC or x2APIC). Note that
 * 64-bit writes are only available in x2APIC mode and can only be
 * done by calling x86_write_x2apic() directly. (This is intentional.)
 *
 * @param reg the LOAPIC register number to write (one of LOAPIC_*)
 * @param val 32-bit value to write
 *//**
 * @brief Write 32-bit value to the local APIC in xAPIC (MMIO) mode.
 *
 * @param reg the LOAPIC register number to write (one of LOAPIC_*)
 * @param val 32-bit value to write
 *//**
 * @brief Write 64-bit value to the local APIC in x2APIC mode.
 *
 * @param reg the LOAPIC register number to write (one of LOAPIC_*)
 * @param val 64-bit value to write
 *//**
 * @brief Read value from the local APIC using the default mode.
 *
 * Returns a 32-bit value read from the local APIC, using the access
 * method determined by CONFIG_X2APIC (either xAPIC or x2APIC). Note
 * that 64-bit reads are only allowed in x2APIC mode and can only be
 * done by calling x86_read_x2apic() directly. (This is intentional.)
 *
 * @param reg the LOAPIC register number to read (LOAPIC_*)
 *//**
 * @brief Read 32-bit value from the local APIC in xAPIC (MMIO) mode.
 *
 * @param reg the LOAPIC register number to read (LOAPIC_*)
 *//**
 * @brief Read 64-bit value from the local APIC in x2APIC mode.
 *
 * @param reg the LOAPIC register number to read (LOAPIC_*)
 *//* mmio device name *//* Defined in intc_loapic.c *//* mask *//* normal IPI to other CPUs *//* delivery status: 1 = busy *//* Self IPI Reg, only support in X2APIC mode *//* Timer Divide Config Reg *//* Timer Current Count Reg *//* Timer Initial Count Reg *//* LVT (ERROR) *//* LVT (LINT1) *//* LVT (LINT0) *//* LVT (PMC) *//* LVT (Thermal) *//* LVT (Timer) *//* Interrupt Command Reg *//* Error Status Reg *//* Interrupt Request Reg *//* Trigger Mode Reg *//* In-service Reg *//* Spurious Interrupt Reg *//* Destination Format Reg *//* Logical Destination Reg *//* EOI Reg *//* Processor Priority Reg *//* Arbitration Priority Reg *//* Task Priority Reg *//* Local APIC Version Reg *//* Local APIC ID Reg *//* Local APIC Register Offset *//* loapic.h - public LOAPIC APIs *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/interrupt_controllerapic_idipicpu_number<zephyr/drivers/interrupt_controller/loapic.h>z_irq_controller_eoiz_irq_controller_isr_vector_getz_irq_controller_irq_configLOAPIC_IRQ_COUNTIRQ_POLARITY_LOWIOAPIC_LOWIRQ_POLARITY_HIGHIOAPIC_HIGHIRQ_TRIGGER_LEVELIOAPIC_LEVELIRQ_TRIGGER_EDGEIOAPIC_EDGEZEPHYR_INCLUDE_DRIVERS_SYSAPIC_H_/* ZEPHYR_INCLUDE_DRIVERS_SYSAPIC_H_ *//* Default to LOAPIC_TIMER to LOAPIC_ERROR */sys_io_test_and_clear_bitsys_io_test_and_set_bitsys_io_test_bitsys_io_clear_bitsys_io_set_bitZEPHYR_INCLUDE_ARCH_X86_IA32_SYS_IO_H_/* ZEPHYR_INCLUDE_ARCH_X86_IA32_SYS_IO_H_ *//* Implementation of sys_io.h's documented functions *//*
 * Copyright (c) 2015, Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */portfind_lsb_set__builtin_ffsfind_msb_set__builtin_clzZEPHYR_INCLUDE_ARCH_COMMON_FFS_H_/* ZEPHYR_INCLUDE_ARCH_COMMON_FFS_H_ *//* CONFIG_TOOLCHAIN_HAS_BUILTIN_FFS *//*
	 * This should never happen but we need to keep
	 * compiler happy.
	 *//*
	 * Toolchain does not have __builtin_ffs().
	 * Need to do this manually.
	 *//**
 *
 * @brief find least significant bit set in a 32-bit word
 *
 * This routine finds the first bit set starting from the least significant bit
 * in the argument passed in and returns the index of that bit.  Bits are
 * numbered starting at 1 from the least significant bit.  A return value of
 * zero indicates that the value passed is zero.
 *
 * @return least significant bit set, 0 if @a op is 0
 *//**
 *
 * @brief find most significant bit set in a 32-bit word
 *
 * This routine finds the first bit set starting from the most significant bit
 * in the argument passed in and returns the index of that bit.  Bits are
 * numbered starting at 1 from the least significant bit.  A return value of
 * zero indicates that the value passed is zero.
 *
 * @return most significant bit set, 0 if @a op is 0
 *//*
 * Copyright (c) 2015, Wind River Systems, Inc.
 * Copyright (c) 2017, Oticon A/S
 *
 * SPDX-License-Identifier: Apache-2.0
 */opgdb_ctxGDB_REGISTERGDB_EAXGDB_ECXGDB_EDXGDB_EBXGDB_ESPGDB_EBPGDB_ESIGDB_EDIGDB_PCGDB_EFLAGSGDB_CSGDB_SSGDB_DSGDB_ESGDB_FSGDB_GSGDB_ORIG_EAXgdb_interrupt_ctxunsigned int[16]GDB_STUB_NUM_REGISTERSregistersexceptioncseiperror_codeespdsesfsgsssZEPHYR_INCLUDE_ARCH_X86_GDBSTUB_SYS_H_/* ZEPHYR_INCLUDE_ARCH_X86_GDBSTUB_SYS_H_ *//**
 * @brief IA-32 register used in gdbstub
 *//**
 * @brief GDB interruption context
 *
 * The exception stack frame contents used by gdbstub. The contents
 * of this struct are used to display information about the current
 * cpu state.
 *//**
 * @brief Number of register used by gdbstub in IA-32
 *//**
 * @file
 * @brief IA-32 specific gdbstub interface header
 */_thread_arch_t_callee_saved_t_thread_archtPreempFloatRegs_preempFloatRegtFpRegSetExs_FpRegSetExtFpRegSets_FpRegSet_callee_savedpreempFloatRegfloatRegsUnionfpRegsExfpRegsX86_THREAD_FLAG_ALL(X86_THREAD_FLAG_INT | X86_THREAD_FLAG_EXC)X86_THREAD_FLAG_EXCX86_THREAD_FLAG_INTFP_REG_SET_ALIGNZEPHYR_INCLUDE_ARCH_X86_IA32_THREAD_H_defined(CONFIG_EAGER_FPU_SHARING) || defined(CONFIG_LAZY_FPU_SHARING)CONFIG_X86_SSECONFIG_X86_COMMON_PAGE_TABLE/* ZEPHYR_INCLUDE_ARCH_X86_IA32_THREAD_H_ *//* volatile float register storage *//* nested exception count *//*
	 * Nested exception count to maintain setting of EXC_ACTIVE flag across
	 * outermost exception.  EXC_ACTIVE is used by z_swap() lazy FP
	 * save/restore and by debug tools.
	 *//* Initial privilege mode stack pointer when doing a system call.
	 * Un-set for supervisor threads.
	 *//* CONFIG_X86_COMMON_PAGE_TABLE *//* Physical address of the page tables used by this thread *//*
 * The thread control structure definition.  It contains the
 * various fields to manage a _single_ thread. The TCS will be aligned
 * to the appropriate architecture specific boundary via the
 * arch_new_thread() call.
 *//* threads with K_SSE_REGS utilize this format *//* threads with K_FP_REGS utilize this format *//*
 * The following structure defines the set of 'volatile' x87 FPU/MMX/SSE
 * registers.  These registers need not be preserved by a called C function.
 * Given that they are not preserved across function calls, they must be
 * save/restored (along with s_coopFloatReg) when a preemptive context
 * switch occurs.
 *//* CONFIG_LAZY_FPU_SHARING || CONFIG_EAGER_FPU_SHARING *//* empty floating point register definition *//* !CONFIG_LAZY_FPU_SHARING && !CONFIG_EAGER_FPU_SHARING *//* CONFIG_X86_SSE == 0 *//* 176 : reserved *//* 128 : XMM registers *//* 128 : x87 FPU/MMX registers *//* 4  : MXCSR register mask *//* 4  : MXCSR register state *//* 2  : reserved *//* 2  : x87 FPU instr operand ptr selector *//* 4  : x87 FPU instr operand ptr offset *//* 2  : x87 FPU instruction pointer selector *//* 4  : x87 FPU instruction pointer offset *//* 2  : x87 FPU opcode *//* 1  : reserved *//* 1  : x87 FPU abridged tag word *//* 2  : x87 FPU status word *//* 2  : x87 FPU control word *//* # of bytes: name of register *//*
 * The following is the "extended" floating point register save area, or
 * more accurately the save area required by the 'fxsave' and 'fxrstor'
 * instructions.  The structure matches the layout described in the
 * "Intel 64 and IA-32 Architectures Software Developer's Manual
 * Volume 2A: Instruction Set Reference, A-M", except for the bytes from offset
 * 464 to 511 since these "are available to software use. The processor does
 * not write to bytes 464:511 of an FXSAVE area".
 *
 * This structure must be aligned on a 16 byte boundary when the instructions
 * fxsave/fxrstor are used to write/read the data to/from the structure.
 *//* 128 bits: XMM[0-7] *//* definition of a single XMM register *//* 48 bits: reserved *//* 80 bits: ST[0-7] or MM[0-7] *//* definition of a single x87 (floating point / MMX) register *//* 80 : ST0 -> ST7 *//* 2  : N/A *//*    : 5 bits = 00000 *//* 2  : x87 FPU tag word *//*
 * The following is the "normal" floating point register save area, or
 * more accurately the save area required by the 'fnsave' and 'frstor'
 * instructions.  The structure matches the layout described in the
 * "Intel(r) 64 and IA-32 Architectures Software Developer's Manual
 * Volume 1: Basic Architecture": Protected Mode x87 FPU State Image in
 * Memory, 32-Bit Format.
 *//* 80 bits: ST[0-7] *//*
 * The macros CONFIG_{LAZY|EAGER}_FPU_SHARING shall be set to indicate that the
 * saving/restoring of the traditional x87 floating point (and MMX) registers
 * are supported by the kernel's context swapping code. The macro
 * CONFIG_X86_SSE shall _also_ be set if saving/restoring of the XMM
 * registers is also supported in the kernel's context swapping code.
 *//*
	 * The following registers are considered non-volatile, i.e.
	 * callee-save,
	 * but their values are pushed onto the stack rather than stored in the
	 * TCS
	 * structure:
	 *
	 *  unsigned long ebp;
	 *  unsigned long ebx;
	 *  unsigned long esi;
	 *  unsigned long edi;
	 *//*
 * The following structure defines the set of 'non-volatile' integer registers.
 * These registers must be preserved by a called C function.  These are the
 * only registers that need to be saved/restored when a cooperative context
 * switch occurs.
 *//*
 * Bits for _thread_arch.flags, see their use in intstub.S et al.
 *//* CONFIG_*_FP_SHARING *//* Unused, no special alignment requirements, use default alignment for
 * char buffers on this arch
 *//**
 * Floating point register set alignment.
 *
 * If support for SSEx extensions is enabled a 16 byte boundary is required,
 * since the 'fxsave' and 'fxrstor' instructions require this. In all other
 * cases a 4 byte boundary is sufficient.
 *//**
 * @file
 * @brief Per-arch thread definition
 *
 * This file contains definitions for
 *
 *  struct _thread_arch
 *  struct _callee_saved
 *
 * necessary to instantiate instances of struct k_thread.
 *//*
 * Copyright (c) 2017 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */vaddr_tpaddr_tZEPHYR_INCLUDE_ARCH_X86_ADDR_TYPES_H_/* ZEPHYR_INCLUDE_ARCH_X86_ADDR_TYPES_H_ *//* x86 address types (virtual, physical, etc) definitions */_get_ds_get_csz_set_idtconst pseudo_descriptorconst pseudo_descriptor *pseudo_descriptor *_set_gdt_set_ldt_get_ldt_get_idt_get_gdt_get_tsssel_set_tssz_init_irq_gateDT_TYPE_SYSTEMSEG_TYPE_IRQ_GATEz_sd_set_seg_offsetfar_ptrpseudo_descriptorsegment_descriptortask_state_segmententriesreserved_task_gate_2offset_hibase_higranularitydbflags_lavllimit_hiuse_other_unionpresentdpldescriptor_typeexecutablecdrwaccessedreserved_task_gate_1base_midalways_0_0reserved_or_parambase_lowsegment_selectoroffset_lowreserved_task_gate_0limit_lowiomapreserved_12reserved_11ldt_ssreserved_10reserved_9reserved_8reserved_7reserved_6reserved_5cr3reserved_4ss2esp2reserved_3ss1esp1reserved_2ss0esp0reserved_1backlinkz_idt_gdtDT_INIT(entries){ sizeof(entries) - 1, &entries[0] }DTE_OFFSET(dt_entry)((dt_entry)->offset_low | ((dt_entry)->offset_hi << 16))DTE_LIMIT(dt_entry)((dt_entry)->limit_low | ((dt_entry)->limit_hi << 16))DTE_BASE(dt_entry)((dt_entry)->base_low | ((dt_entry)->base_mid << 16) | ((dt_entry)->base_hi << 24))DT_CALL_GATE_ENTRY(segment_p,offset_p,dpl_p,param_count_p){ _DESC_COMMON(dpl_p), _SEGMENT_AND_OFFSET(segment_p, offset_p), _SYS_DESC(SEG_TYPE_TRAP_GATE), .reserved_or_param = (param_count_p), .always_0_0 = 0 }DT_TRAP_GATE_ENTRY(segment_p,offset_p,dpl_p){ _DESC_COMMON(dpl_p), _SEGMENT_AND_OFFSET(segment_p, offset_p), _SYS_DESC(SEG_TYPE_TRAP_GATE), .always_0_0 = 0 }DT_IRQ_GATE_ENTRY(segment_p,offset_p,dpl_p){ _DESC_COMMON(dpl_p), _SEGMENT_AND_OFFSET(segment_p, offset_p), _SYS_DESC(SEG_TYPE_IRQ_GATE), .always_0_0 = 0 }DT_TASK_GATE_ENTRY(segment_p,dpl_p){ _DESC_COMMON(dpl_p), _SYS_DESC(SEG_TYPE_TASK_GATE), .segment_selector = (segment_p) }DT_TSS_STD_ENTRY(base_p,dpl_p)DT_TSS_ENTRY(base_p, sizeof(struct task_state_segment), DT_GRAN_BYTE, dpl_p)DT_TSS_ENTRY(base_p,limit_p,granularity_p,dpl_p){ _DESC_COMMON(dpl_p), _LIMIT_AND_BASE(base_p, limit_p, granularity_p), _SYS_DESC(SEG_TYPE_TSS) }DT_LDT_ENTRY(base_p,limit_p,granularity_p,dpl_p){ _DESC_COMMON(dpl_p), _LIMIT_AND_BASE(base_p, limit_p, granularity_p), _SYS_DESC(SEG_TYPE_LDT) }DT_DATA_SEG_ENTRY(base_p,limit_p,granularity_p,dpl_p,writable_p,direction_p){ _DESC_COMMON(dpl_p), _LIMIT_AND_BASE(base_p, limit_p, granularity_p), .accessed = 0, .rw = (writable_p), .cd = (direction_p), .executable = 0, .descriptor_type = 1 }DT_CODE_SEG_ENTRY(base_p,limit_p,granularity_p,dpl_p,readable_p,conforming_p){ _DESC_COMMON(dpl_p), _LIMIT_AND_BASE(base_p, limit_p, granularity_p), .accessed = 0, .rw = (readable_p), .cd = (conforming_p), .executable = 1, .descriptor_type = 1 }_SYS_DESC(type_p).type = type_p, .descriptor_type = 0_DESC_COMMON(dpl_p).dpl = (dpl_p), .present = 1_SEGMENT_AND_OFFSET(segment_p,offset_p).segment_selector = (segment_p), .offset_low = ((offset_p) & 0xFFFF), .offset_hi = ((offset_p) >> 16)_LIMIT_AND_BASE(base_p,limit_p,granularity_p).base_low = (((uint32_t)base_p) & 0xFFFF), .base_mid = (((base_p) >> 16) & 0xFF), .base_hi = (((base_p) >> 24) & 0xFF), .limit_low = ((limit_p) & 0xFFFF), .limit_hi = (((limit_p) >> 16) & 0xF), .granularity = (granularity_p), .flags_l = 0, .db = 1, .avl = 0DT_ZERO_ENTRY{ { 0 } }SEG_SELECTOR(index,table,dpl)(index << 3 | table << 2 | dpl)DT_TYPE_CODEDATADT_NONCONFORMDT_CONFORMDT_EXPAND_UPDT_EXPAND_DOWNDT_NON_WRITABLEDT_WRITABLEDT_NON_READABLEDT_READABLEDT_GRAN_PAGEDT_GRAN_BYTESEG_TYPE_TRAP_GATE0xF0xESEG_TYPE_CALL_GATE0xCSEG_TYPE_TSS_BUSY0xBSEG_TYPE_TSS0x9SEG_TYPE_TASK_GATE0x5SEG_TYPE_LDT0x2ZEPHYR_INCLUDE_ARCH_X86_IA32_SEGMENTATION_H_/* ZEPHYR_INCLUDE_ARCH_X86_IA32_SEGMENTATION_H_ *//**
 * Get the segment selector for the current data segment
 *
 * @return Segment selector
 *//**
 * Get the segment selector for the current code segment
 *
 * @return Segment selector
 *//**
 * Set the interrupt descriptor table
 *
 * @param idt Pointer to IDT pseudo descriptor.
 *//**
 * Set the global descriptor table
 *
 * You will most likely need to update all the data segment registers
 * and do a far call to the code segment.
 *
 * @param gdt Pointer to GDT pseudo descriptor.
 *//**
 * Set the local descriptor table for the current IA Task
 *
 * @param ldt Segment selector in the GDT for an LDT
 *//**
 * Get the current local descriptor table (LDT)
 *
 * @return Segment selector in the GDT for the current LDT
 *//**
 * Get the current interrupt descriptor table
 *
 * @param idt Pointer to memory to receive IDT pseudo descriptor information
 *//**
 * Get the current global descriptor table
 *
 * @param gdt Pointer to memory to receive GDT pseudo descriptor information
 *//**
 * Get the TSS segment selector in the GDT for the current IA task
 *
 * @return Segment selector for current IA task
 *//**
 * Set current IA task TSS
 *
 * @param sel Segment selector in GDT for desired TSS
 *//**
 * Initialize an segment descriptor to be a 32-bit IRQ gate
 *
 * @param sd Segment descriptor memory
 * @param seg_selector Segment selector of handler
 * @param offset offset of handler
 * @param dpl descriptor privilege level
 *//**
 * Properly set the segment descriptor segment and offset
 *
 * Used for call/interrupt/trap gates
 *
 * @param sd Segment descriptor
 * @param offset Offset within segment
 * @param segment_selector Segment selector
 *//* This is either the ROM-based GDT in crt0.S or generated by gen_gdt.py,
 * depending on CONFIG_GDT_DYNAMIC
 *//* "standard" TSS segments that don't stuff extra data past the end of the
 * TSS struct
 *//* NOTE: the below macros only work for fixed addresses provided at build time.
 * Base addresses or offsets cannot be &some_variable, as pointer values are not
 * known until link time and the compiler has to split the address into various
 * fields in the segment selector well before that.
 *
 * If you really need to put &some_variable as the base address in some
 * segment descriptor, you will either need to do the assignment at runtime
 * or implement some tool to populate values post-link like gen_idt does.
 *//** Far pointer segment/gate selector. *//** Far pointer offset, unused when invoking a task. *//*
 * Full linear address (segment selector+offset), for far jumps/calls
 *//* Address of this passed to lidt/lgdt.
 * IA manual calls this a 'pseudo descriptor'.
 *//* Bits 24-31 *//* D/B field 1=32-bit 0=16-bit*//* L field *//* 1=Indicates 64-bit code segment in IA-32e mode *//* CPU ignores this *//* flags *//* segment/LDT/TSS *//* Task Gates *//* Call/IRQ/trap gates *//* Second DWORD: 16-31 *//* Alas, C doesn't let you do a union of the first
			 * 4 bits of a bitfield and put the rest outside of it,
			 * it ends up getting padded.
			 *//* One of the SEG_TYPE_* macros above *//* System types *//* 1=code or data, 0=system type *//* Next 3 fields actually common to all *//* 1=code 0=data *//* executable ? conforming : direction *//* executable ? readable : writable *//* Set by the processor, init to 0 *//* Code or data Segments *//* Second DWORD: 8-15 *//* Bits 5-7 0 0 0 per CPU manual *//* Reserved except in case of call gates *//* IRQ/Trap/Call Gates *//* Task gates *//* Bits 16-23 *//* TSS/LDT/Segments *//* Second DWORD: 0-7 *//* Bits 0-15 *//* Call/Task/Interrupt/Trap gates *//* First DWORD: 16-31 *//* Everything else *//* IRQ, call, trap gates *//* First DWORD: 0-15 *//* References
 *
 * Section 5.8.3 (Call gates)
 * Section 7.2.2 (TSS Descriptor)
 * Section 3.4.5 (Segment descriptors)
 * Section 6.11 (IDT Descriptors)
 *
 * IA architecture SW developer manual, Vol 3.
 *//* Trap bit *//* Section 7.2.1 of IA architecture SW developer manual, Vol 3. *//* NOTE: We currently do not have definitions for 16-bit segment, currently
 * assume everything we are working with is 32-bit
 *//* Host gen_idt uses this header as well, don't depend on toolchain.h */idtgdtldtseg_selectorpm_state_cpu_get_allconst pm_state_infoconst pm_state_info *pm_state_info *const pm_state_info **pm_state_info **cpupm_state_infopm_statePM_STATE_ACTIVEPM_STATE_RUNTIME_IDLEPM_STATE_SUSPEND_TO_IDLEPM_STATE_STANDBYPM_STATE_SUSPEND_TO_RAMPM_STATE_SUSPEND_TO_DISKPM_STATE_SOFT_OFFPM_STATE_COUNTexit_latency_usmin_residency_ussubstate_idPM_STATE_LIST_FROM_DT_CPU(node_id){ LISTIFY(DT_PROP_LEN_OR(node_id, cpu_power_states, 0), Z_PM_STATE_FROM_DT_CPU, (), node_id) }PM_STATE_INFO_LIST_FROM_DT_CPU(node_id){ LISTIFY(DT_PROP_LEN_OR(node_id, cpu_power_states, 0), Z_PM_STATE_INFO_FROM_DT_CPU, (), node_id) }DT_NUM_CPU_POWER_STATES(node_id)COND_CODE_1(DT_NODE_HAS_PROP(node_id, cpu_power_states), (DT_FOREACH_PROP_ELEM_SEP(node_id, cpu_power_states, Z_DT_PHANDLE_01, (+))), (0))PM_STATE_DT_INIT(node_id)DT_ENUM_IDX(node_id, power_state_name)PM_STATE_INFO_DT_INIT(node_id){ .state = PM_STATE_DT_INIT(node_id), .substate_id = DT_PROP_OR(node_id, substate_id, 0), .min_residency_us = DT_PROP_OR(node_id, min_residency_us, 0), .exit_latency_us = DT_PROP_OR(node_id, exit_latency_us, 0), }Z_PM_STATE_FROM_DT_CPU(i,node_id)COND_CODE_1(DT_NODE_HAS_STATUS(DT_PHANDLE_BY_IDX(node_id, cpu_power_states, i), okay), (PM_STATE_DT_INIT(DT_PHANDLE_BY_IDX(node_id, cpu_power_states, i)),), ())Z_PM_STATE_INFO_FROM_DT_CPU(i,node_id)COND_CODE_1(DT_NODE_HAS_STATUS(DT_PHANDLE_BY_IDX(node_id, cpu_power_states, i), okay), (PM_STATE_INFO_DT_INIT(DT_PHANDLE_BY_IDX(node_id, cpu_power_states, i)),), ())Z_DT_PHANDLE_01(node_id,prop,idx)COND_CODE_1(DT_NODE_HAS_STATUS(DT_PHANDLE_BY_IDX(node_id, prop, idx), okay), (1), (0))ZEPHYR_INCLUDE_PM_STATE_H_defined(CONFIG_PM) || defined(__DOXYGEN__)/* CONFIG_PM *//**
 * Obtain information about all supported states by a CPU.
 *
 * @param cpu CPU index.
 * @param states Where to store the list of supported states.
 *
 * @return Number of supported states.
 *//**
 * @brief Initialize an array of struct pm_state with information from all the
 * states present and enabled in the given CPU node identifier.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *	cpus {
 *		...
 *		cpu0: cpu@0 {
 *			device_type = "cpu";
 *			...
 *			cpu-power-states = <&state0 &state1>;
 *		};
 *
 *		power-states {
 *			state0: state0 {
 *				compatible = "zephyr,power-state";
 *				power-state-name = "suspend-to-idle";
 *				min-residency-us = <10000>;
 *				exit-latency-us = <100>;
 *			};
 *
 *			state1: state1 {
 *				compatible = "zephyr,power-state";
 *				power-state-name = "suspend-to-ram";
 *				min-residency-us = <50000>;
 *				exit-latency-us = <500>;
 *			};
 *		};
 *	};
 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 * const enum pm_state states[] = PM_STATE_LIST_FROM_DT_CPU(DT_NODELABEL(cpu0));
 * @endcode
 *
 * @param node_id A CPU node identifier.
 *//**
 * @brief Initialize an array of struct pm_state_info with information from all
 * the states present and enabled in the given CPU node identifier.
 *
 * Example devicetree fragment:
 *
 * @code{.dts}
 *	cpus {
 *		...
 *		cpu0: cpu@0 {
 *			device_type = "cpu";
 *			...
 *			cpu-power-states = <&state0 &state1>;
 *		};
 *
 *		power-states {
 *			state0: state0 {
 *				compatible = "zephyr,power-state";
 *				power-state-name = "suspend-to-idle";
 *				min-residency-us = <10000>;
 *				exit-latency-us = <100>;
 *			};
 *
 *			state1: state1 {
 *				compatible = "zephyr,power-state";
 *				power-state-name = "suspend-to-ram";
 *				min-residency-us = <50000>;
 *				exit-latency-us = <500>;
 *			};
 *		};
 *	};

 * @endcode
 *
 * Example usage:
 *
 * @code{.c}
 * const struct pm_state_info states[] =
 *	PM_STATE_INFO_LIST_FROM_DT_CPU(DT_NODELABEL(cpu0));
 * @endcode
 *
 * @param node_id A CPU node identifier.
 *//**
 * @brief Obtain number of CPU power states supported and enabled by the given
 * CPU node identifier.
 *
 * @param node_id A CPU node identifier.
 * @return Number of supported and enabled CPU power states.
 *//**
 * @brief Initializer for enum pm_state given a DT node identifier with
 * zephyr,power-state compatible.
 *
 * @param node_id A node identifier with compatible zephyr,power-state
 *//**
 * @brief Initializer for struct pm_state_info given a DT node identifier with
 * zephyr,power-state compatible.
 *
 * @param node_id A node identifier with compatible zephyr,power-state
 *//**
 * @brief Helper macro to initialize an entry of a struct pm_state array when
 * using UTIL_LISTIFY in PM_STATE_LIST_FROM_DT_CPU.
 *
 * @note Only enabled states are initialized.
 *
 * @param i UTIL_LISTIFY entry index.
 * @param node_id A node identifier with compatible zephyr,power-state
 *//**
 * @brief Helper macro to initialize an entry of a struct pm_state_info array
 * when using UTIL_LISTIFY in PM_STATE_INFO_LIST_FROM_DT_CPU.
 *
 * @note Only enabled states are initialized.
 *
 * @param i UTIL_LISTIFY entry index.
 * @param node_id A node identifier with compatible zephyr,power-state
 *//**
 * @brief Helper macro that expands to 1 if a phandle node is enabled, 0 otherwise.
 *
 * @param node_id Node identifier.
 * @param prop Property holding phandle-array.
 * @param idx Index within the array.
 *//**
	 * Worst case latency in microseconds required to exit the idle state.
	 *
	 * @note 0 means that this property is not available for this state.
	 *//**
	 * Minimum residency duration in microseconds. It is the minimum
	 * time for a given idle state to be worthwhile energywise.
	 *
	 * @note 0 means that this property is not available for this state.
	 *//**
	 * Some platforms have multiple states that map to
	 * one Zephyr power state. This property allows the platform
	 * distinguish them. e.g:
	 *
	 * @code{.dts}
	 *	power-states {
	 *		state0: state0 {
	 *			compatible = "zephyr,power-state";
	 *			power-state-name = "suspend-to-idle";
	 *			substate-id = <1>;
	 *			min-residency-us = <10000>;
	 *			exit-latency-us = <100>;
	 *		};
	 *		state1: state1 {
	 *			compatible = "zephyr,power-state";
	 *			power-state-name = "suspend-to-idle";
	 *			substate-id = <2>;
	 *			min-residency-us = <20000>;
	 *			exit-latency-us = <200>;
	 *		};
	 *	};
	 * @endcode
	 *//**
 * Information about a power management state
 *//** Number of power management states (internal use) *//**
	 * @brief Soft off state
	 *
	 * This state consumes a minimal amount of power and requires a large
	 * latency in order to return to runtime active state. The contents of
	 * system(CPU and memory) will not be preserved, so the system will be
	 * restarted as if from initial power-up and kernel boot.
	 *
	 * @note This state is correlated with ACPI G2/S5 state
	 *//**
	 * @brief Suspend to disk state
	 *
	 * This state offers significant energy savings by powering off as much
	 * of the system as possible, including the memory. The contents of
	 * memory are written to disk or other non-volatile storage, and on
	 * resume it's read back into memory with the help of boot-strapping
	 * code, restores the system to the same point of execution where it
	 * went to suspend to disk.
	 *
	 * @note This state is correlated with ACPI S4 state
	 *//**
	 * @brief Suspend to ram state
	 *
	 * This state offers significant energy savings by powering off as much
	 * of the system as possible, where memory should be placed into the
	 * self-refresh mode to retain its contents. The state of devices and
	 * CPUs is saved and held in memory, and it may require some boot-
	 * strapping code in ROM to resume the system from it.
	 *
	 * @note This state is correlated with ACPI S3 state
	 *//**
	 * @brief Standby state
	 *
	 * In addition to putting peripherals into low-power states all
	 * non-boot CPUs are powered off. It should allow more energy to be
	 * saved relative to suspend to idle, but the resume latency will
	 * generally be greater than for that state. But it should be the same
	 * state with suspend to idle state on uniprocessor system.
	 *
	 * @note This state is correlated with ACPI S2 state
	 *//**
	 * @brief Suspend to idle state
	 *
	 * The system goes through a normal platform suspend where it puts
	 * all of the cores in deepest possible idle state and *may* puts
	 * peripherals into low-power states. No operating state is lost (ie.
	 * the cpu core does not lose execution context), so the system can go
	 * back to where it left off easily enough.
	 *
	 * @note This state is correlated with ACPI S1 state
	 *//**
	 * @brief Runtime idle state
	 *
	 * Runtime idle is a system sleep state in which all of the cores
	 * enter deepest possible idle state and wait for interrupts, no
	 * requirements for the devices, leaving them at the states where
	 * they are.
	 *
	 * @note This state is correlated with ACPI S0ix state
	 *//**
	 * @brief Runtime active state
	 *
	 * The system is fully powered and active.
	 *
	 * @note This state is correlated with ACPI G0/S0 state
	 *//**
 * @enum pm_state Power management state
 *//**
 * @brief System Power Management States
 * @defgroup subsys_pm_states States
 * @ingroup subsys_pm
 * @{
 *//*
 * Copyright (c) 2020 Intel corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/pmerrno_sys_nerrconst char *constconst char *const[]char *[]_sys_errlist__ELASTERROREWOULDBLOCKEAGAINESTRPIPEEOWNERDEADENOTRECOVERABLEECANCELEDEOVERFLOWEILSEQENOMEDIUMENOTSUPESTALEEDQUOTEUSERSEPROCLIMETOOMANYREFSENOTCONNEISCONNENETRESETEADDRNOTAVAILESOCKTNOSUPPORTEPROTONOSUPPORTEMSGSIZEEDESTADDRREQEALREADYEINPROGRESSEHOSTUNREACHEHOSTDOWNETIMEDOUTENETDOWNENETUNREACHECONNABORTEDEADDRINUSEECONNREFUSEDESHUTDOWNENOPROTOOPTENOTSOCKEPROTOTYPEEAFNOSUPPORTENOBUFSECONNRESETEPFNOSUPPORTEOPNOTSUPPELOOPENAMETOOLONGENOTEMPTYENOSYSELIBEXECELIBMAXELIBSCNELIBBADELIBACCEREMCHGEBADFDENOTUNIQEFTYPEEBADMSGEDOTDOTELBINEMULTIHOPEPROTOECOMMESRMNTEADVENOLINKEREMOTEENOPKGENONETENOSRETIMEENODATAENOSTREBFONTEDEADLOCKEBADSLTEBADRQCENOANOEXFULLEBADREBADEENOLCKEDEADLKEL2HLTENOCSIEUNATCHELNRNGEL3RSTEL3HLTEL2NSYNCECHRNGEIDRMENOMSGERANGEEDOMEPIPEEMLINKEROFSESPIPEENOSPCEFBIGETXTBSYENOTTYEMFILEENFILEEINVALEISDIRENOTDIRENODEVEXDEVEEXISTEBUSYENOTBLKEFAULTEACCESENOMEMECHILDEBADFENOEXECE2BIGENXIOEIOEINTRESRCHENOENTEPERM_REENT_ERRNO(r)(errno)__errno_r(ptr)NEWLIB_THREAD_LOCAL_ERRNO_SYS_ERRNO_H___PICOLIBC_ERRNO_FUNCTION__LINUX_ERRNO_EXTENSIONS__/* _SYS_ERRNO_H *//* Users can add values starting here *//* Operation would block *//* Streams pipe error *//* Previous owner died *//* State not recoverable *//* Operation canceled *//* Value too large for defined data type *//* Illegal byte sequence *//* Filename exists with different case *//* No such host or network path *//* No medium (in tape drive) *//* Not supported *//* Socket is not connected *//* Socket is already connected *//* Connection aborted by network *//* Address not available *//* Socket type not supported *//* Unknown protocol *//* Message too long *//* Destination address required *//* Socket already connected *//* Connection already in progress *//* Host is unreachable *//* Host is down *//* Connection timed out *//* Network interface is not configured *//* Network is unreachable *//* Software caused connection abort *//* Address already in use *//* Connection refused *//* Can't send after socket shutdown *//* Protocol not available *//* Socket operation on non-socket *//* Protocol wrong type for socket *//* Address family not supported by protocol family *//* No buffer space available *//* Connection reset by peer *//* Protocol family not supported *//* Operation not supported on socket *//* Too many symbolic links *//* File or path name too long *//* Directory not empty *//* No more files *//* Function not implemented *//* Attempting to exec a shared library *//* Attempting to link in too many libs *//* .lib section in a.out corrupted *//* Accessing a corrupted shared lib *//* Can't access a needed shared lib *//* Remote address changed *//* f.d. invalid for this operation *//* Given log. name not unique *//* Inappropriate file type or format *//* Bad message *//* Cross mount point (not really error) *//* Inode is remote (not really error) *//* Multihop attempted *//* Protocol error *//* Communication error on send *//* Srmount error *//* Advertise error *//* Virtual circuit is gone *//* The object is remote *//* Package not installed *//* Machine is not on the network *//* No stream resources *//* Stream ioctl timeout *//* No data (for no delay io) *//* Not a stream *//* Bad font file fmt *//* File locking deadlock error *//* Invalid slot *//* Invalid request code *//* No anode *//* Exchange full *//* Invalid request descriptor *//* Invalid exchange *//* No lock *//* Deadlock *//* Level 2 halted *//* No CSI structure available *//* Protocol driver not attached *//* Link number out of range *//* Level 3 reset *//* Level 3 halted *//* Level 2 not synchronized *//* Channel number out of range *//* Identifier removed *//* No message of desired type *//* Result too large *//* Mathematics argument out of domain of function *//* Broken pipe *//* Too many links *//* Read-only file system *//* Illegal seek *//* No space left on device *//* File too large *//* Text file busy *//* Not a character device *//* File descriptor value too large *//* Too many open files in system *//* Invalid argument *//* Is a directory *//* Not a directory *//* No such device *//* Cross-device link *//* File exists *//* Device or resource busy *//* Block device required *//* Bad address *//* Permission denied *//* Not enough space *//* No more processes *//* No children *//* Bad file number *//* Exec format error *//* Arg list too long *//* No such device or address *//* I/O error *//* Interrupted system call *//* No such process *//* No such file or directory *//* Not owner *//* Please don't use these variables directly.
   Use strerror instead. *//* errno is not a global variable, because that would make using it
   non-reentrant.  Instead, its address is returned by the function
   __errno.  */<sys/errno.h>error_t__error_t_defined__ERRNO_H__/* !__ERRNO_H__ */<errno.h><zephyr/pm/state.h>z_pm_save_idle_exitpm_state_next_getpm_notifier_unregisterpm_notifier *notifier-88-ENOSYSpm_notifier_registerpm_notifierstate_exitstate_entry_nodeZEPHYR_INCLUDE_PM_PM_H_/* ZEPHYR_INCLUDE_PM_PM_H_ *//**
 * @brief Do any SoC or architecture specific post ops after sleep state exits.
 *
 * This function is a place holder to do any operations that may
 * be needed to be done after sleep state exits. Currently it enables
 * interrupts after resuming from sleep state. In future, the enabling
 * of interrupts may be moved into the kernel.
 *
 * @param state Power state.
 * @param substate_id Power substate id.
 *//**
 * @brief Put processor into a power state.
 *
 * This function implements the SoC specific details necessary
 * to put the processor into available power states.
 *
 * @param state Power state.
 * @param substate_id Power substate id.
 *//**
 * @brief System Power Management Hooks
 * @defgroup subsys_pm_sys_hooks Hooks
 * @ingroup subsys_pm_sys
 * @{
 *//**
 * @brief Gets the next power state that will be used.
 *
 * This function returns the next power state that will be used by the
 * SoC.
 *
 * @param cpu CPU index.
 * @return next pm_state_info that will be used
 *//**
 * @brief Unregister a power management notifier
 *
 * Remove the given notifier from the power management notification
 * list. After that this object callbacks will not be called.
 *
 * @param notifier pm_notifier object to be unregistered.
 *
 * @return 0 if the notifier was successfully removed, a negative value
 * otherwise.
 *//**
 * @brief Register a power management notifier
 *
 * Register the given notifier from the power management notification
 * list.
 *
 * @param notifier pm_notifier object to be registered.
 *//**
 * @brief Force usage of given power state.
 *
 * This function overrides decision made by PM policy forcing
 * usage of given power state upon next entry of the idle thread.
 *
 * @note This function can only run in thread context
 *
 * @param cpu CPU index.
 * @param info Power state which should be used in the ongoing
 *	suspend operation.
 *//**
	 * Application defined function for doing any target specific operations
	 * for power state exit.
	 *//**
	 * Application defined function for doing any target specific operations
	 * for power state entry.
	 *//**
 * Power management notifier struct
 *
 * This struct contains callbacks that are called when the target enters and
 * exits power states.
 *
 * As currently implemented the entry callback is invoked when
 * transitioning from PM_STATE_ACTIVE to another state, and the exit
 * callback is invoked when transitioning from a non-active state to
 * PM_STATE_ACTIVE. This behavior may change in the future.
 *
 * @note These callbacks can be called from the ISR of the event
 *       that caused the kernel exit from idling.
 *
 * @note It is not allowed to call @ref pm_notifier_unregister or
 *       @ref pm_notifier_register from these callbacks because they are called
 *       with the spin locked in those functions.
 *//**
 * @brief System Power Management API
 * @defgroup subsys_pm_sys System
 * @ingroup subsys_pm
 * @{
 *//**
 * @brief System and device power management
 * @defgroup subsys_pm Power Management (PM)
 * @ingroup os_services
 * @{
 * @}
 *//*
 * Copyright (c) 2012-2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/pm/pm.h><zephyr/arch/common/addr_types.h><zephyr/arch/x86/ia32/thread.h><zephyr/arch/x86/ia32/gdbstub.h><zephyr/arch/common/ffs.h>"sys_io.h"arch_isr_direct_footerarch_isr_direct_header_x86_syscall_stack_framez_arch_esf_tnanoEsfISR_LISTs_isrListerrorCodetssvecfncz_x86_exception_vectorARCH_DYNAMIC_OBJ_K_THREAD_ALIGNMENT(sizeof(void *))ARCH_EXCEPT(reason_p)do { __asm__ volatile( "push %[reason]\n\t" "int %[vector]\n\t" : : [vector] "i" (Z_X86_OOPS_VECTOR), [reason] "i" (reason_p)); CODE_UNREACHABLE; } while (false)static inline int name ## _body(void); __attribute__ ((interrupt)) void name(void *stack_frame) { ARG_UNUSED(stack_frame); int check_reschedule; ISR_DIRECT_HEADER(); check_reschedule = name ## _body(); ISR_DIRECT_FOOTER(check_reschedule); } static inline int name ## _body(void)ARCH_ISR_DIRECT_FOOTER(swap)arch_isr_direct_footer(swap)arch_isr_direct_header()do { } while (false)ARCH_IRQ_DIRECT_CONNECT(irq_p,priority_p,isr_p,flags_p){ NANO_CPU_INT_REGISTER(isr_p, irq_p, priority_p, -1, 0); z_irq_controller_irq_config(Z_IRQ_TO_INTERRUPT_VECTOR(irq_p), (irq_p), (flags_p)); }ARCH_IRQ_CONNECT(irq_p,priority_p,isr_p,isr_param_p,flags_p){ __asm__ __volatile__( ".pushsection .intList\n\t" ".long %c[isr]_irq%c[irq]_stub\n\t" ".long %c[irq]\n\t" ".long %c[priority]\n\t" ".long %c[vector]\n\t" ".long 0\n\t" ".long 0\n\t" ".popsection\n\t" ".pushsection " IRQSTUBS_TEXT_SECTION "\n\t" ".global %c[isr]_irq%c[irq]_stub\n\t" "%c[isr]_irq%c[irq]_stub:\n\t" "pushl %[isr_param]\n\t" "pushl %[isr]\n\t" "jmp _interrupt_enter\n\t" ".popsection\n\t" : : [isr] "i" (isr_p), [isr_param] "i" (isr_param_p), [priority] "i" (priority_p), [vector] "i" _VECTOR_ARG(irq_p), [irq] "i" (irq_p)); z_irq_controller_irq_config(Z_IRQ_TO_INTERRUPT_VECTOR(irq_p), (irq_p), (flags_p)); }IRQSTUBS_TEXT_SECTION".text.irqstubs"_VECTOR_ARG(irq_p)_X86_IDT_TSS_REGISTER(tss_p,irq_p,priority_p,vec_p,dpl_p)static ISR_LIST __attribute__((section(".intList"))) __attribute__((used)) MK_ISR_NAME(vec_p) = { .fnc = NULL, .irq = (irq_p), .priority = (priority_p), .vec = (vec_p), .dpl = (dpl_p), .tss = (tss_p) }NANO_CPU_INT_REGISTER(r,n,p,v,d)static ISR_LIST __attribute__((section(".intList"))) __attribute__((used)) MK_ISR_NAME(r) = { .fnc = &(r), .irq = (n), .priority = (p), .vec = (v), .dpl = (d), .tss = 0 }Z_DYN_STUB_PER_BLOCKZ_DYN_STUB_LONG_JMP_EXTRA_SIZEZ_DYN_STUB_OFFSETZ_DYN_STUB_SIZEMK_ISR_NAME(x)__isr__ ## x(0x18 | 0x03)DF_TSS0x20MAIN_TSS0x18DATA_SEG0x10CODE_SEG0x08ZEPHYR_INCLUDE_ARCH_X86_IA32_ARCH_H_defined(CONFIG_HW_STACK_PROTECTION)defined(CONFIG_TRACING)CONFIG_SSE/* ZEPHYR_INCLUDE_ARCH_X86_IA32_ARCH_H_ *//* No special alignment requirements, simply align on pointer size. *//*
 * Dynamic thread object memory alignment.
 *
 * If support for SSEx extensions is enabled a 16 byte boundary is required,
 * since the 'fxsave' and 'fxrstor' instructions require this. In all other
 * cases a 4 byte boundary is sufficient.
 *//* LCOV_EXCL_LINE *//**
 * @defgroup float_apis Floating Point APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * The NANO_SOFT_IRQ macro must be used as the value for the @a irq parameter
 * to NANO_CPU_INT_REGISTER when connecting to an interrupt that does not
 * correspond to any IRQ line (such as spurious vector or SW IRQ)
 *//* These are only present if cs = USER_CODE_SEG *//**
 * @brief Exception Stack Frame
 *
 * A pointer to an "exception stack frame" (ESF) is passed as an argument
 * to exception handlers registered via nanoCpuExcConnect().  As the system
 * always operates at ring 0, only the EIP, CS and EFLAGS registers are pushed
 * onto the stack when an exception occurs.
 *
 * The exception stack frame includes the volatile registers (EAX, ECX, and
 * EDX) as well as the 5 non-volatile registers (EDI, ESI, EBX, EBP and ESP).
 * Those registers are pushed onto the stack by _ExcEnt().
 *//* !CONFIG_X86_KPTI *//* Fetch EFLAGS argument to z_swap() *//* Call swap if all the following is true:
	 *
	 * 1) swap argument was enabled to this function
	 * 2) We are not in a nested interrupt
	 * 3) Next thread to run in the ready queue is not this thread
	 *//*
 * FIXME: z_swap_irqlock is an inline function declared in a private header and
 *	  cannot be referenced from a public header, so we move it to an
 *	  external function.
 *//* We're not going to unlock IRQs, but we still need to increment this
	 * so that arch_is_in_isr() works
	 *//* FIXME:
 * tracing/tracing.h cannot be included here due to circular dependency
 *//* Direct interrupts won't work as expected with KPTI turned on, because
 * all non-user accessible pages in the page table are marked non-present.
 * It's likely possible to add logic to ARCH_ISR_DIRECT_HEADER/FOOTER to do
 * the necessary trampolining to switch page tables / stacks, but this
 * probably loses all the latency benefits that direct interrupts provide
 * and one might as well use a regular interrupt anyway.
 *//* ISR_LIST.tss *//* ISR_LIST.dpl *//* ISR_LIST.vec *//* ISR_LIST.priority *//* ISR_LIST.irq *//* ISR_LIST.fnc *//* Internally this function does a few things:
 *
 * 1. There is a declaration of the interrupt parameters in the .intList
 * section, used by gen_idt to create the IDT. This does the same thing
 * as the NANO_CPU_INT_REGISTER() macro, but is done in assembly as we
 * need to populate the .fnc member with the address of the assembly
 * IRQ stub that we generate immediately afterwards.
 *
 * 2. The IRQ stub itself is declared. The code will go in its own named
 * section .text.irqstubs section (which eventually gets linked into 'text')
 * and the stub shall be named (isr_name)_irq(irq_line)_stub
 *
 * 3. The IRQ stub pushes the ISR routine and its argument onto the stack
 * and then jumps to the common interrupt handling code in _interrupt_enter().
 *
 * 4. z_irq_controller_irq_config() is called at runtime to set the mapping
 * between the vector and the IRQ line as well as triggering flags
 *//**
 * Code snippets for populating the vector ID and priority into the intList
 *
 * The 'magic' of static interrupts is accomplished by building up an array
 * 'intList' at compile time, and the gen_idt tool uses this to create the
 * actual IDT data structure.
 *
 * For controllers like APIC, the vectors in the IDT are not normally assigned
 * at build time; instead the sentinel value -1 is saved, and gen_idt figures
 * out the right vector to use based on our priority scheme. Groups of 16
 * vectors starting at 32 correspond to each priority level.
 *
 * These macros are only intended to be used by IRQ_CONNECT() macro.
 *//**
 * @brief Connect an IA hardware task to an interrupt vector
 *
 * This is very similar to NANO_CPU_INT_REGISTER but instead of connecting
 * a handler function, the interrupt will induce an IA hardware task
 * switch to another hardware task instead.
 *
 * @param tss_p GDT/LDT segment selector for the TSS representing the task
 * @param irq_p IRQ number
 * @param priority_p IRQ priority
 * @param vec_p Interrupt vector
 * @param dpl_p Descriptor privilege level
 *//**
 * @brief Connect a routine to an interrupt vector
 *
 * This macro "connects" the specified routine, @a r, to the specified interrupt
 * vector, @a v using the descriptor privilege level @a d. On the IA-32
 * architecture, an interrupt vector is a value from 0 to 255. This macro
 * populates the special intList section with the address of the routine, the
 * vector number and the descriptor privilege level. The genIdt tool then picks
 * up this information and generates an actual IDT entry with this information
 * properly encoded.
 *
 * The @a d argument specifies the privilege level for the interrupt-gate
 * descriptor; (hardware) interrupts and exceptions should specify a level of 0,
 * whereas handlers for user-mode software generated interrupts should specify 3.
 * @param r Routine to be connected
 * @param n IRQ number
 * @param p IRQ priority
 * @param v Interrupt Vector
 * @param d Descriptor Privilege Level
 *//** If nonzero, specifies a TSS segment selector. Will configure
	 * a task gate instead of an interrupt gate. fnc parameter will be
	 * ignored
	 *//** Privilege level associated with ISR/stub *//** Vector number associated with ISR/stub, or -1 to assign based
	 * on priority
	 *//** Priority associated with the IRQ. Ignored if vec is not -1 *//** IRQ associated with the ISR/stub, or -1 if this is not
	 * associated with a real interrupt; in this case vec must
	 * not be -1
	 *//** Address of ISR/stub *//* interrupt/exception/error related definitions *//**
 * Macro used internally by NANO_CPU_INT_REGISTER and NANO_CPU_INT_REGISTER_ASM.
 * Not meant to be used explicitly by platform, driver or application code.
 *//*
 * Use for thread local storage.
 * Match these to gen_gdt.py.
 * The 0x03 is added to limit privilege.
 *//* GDT layout *//* for size_t *//**
 * @file
 * @brief IA-32 specific kernel interface header
 * This header contains the IA-32 specific kernel interface.  It is included
 * by the generic kernel interface header (include/arch/cpu.h)
 */swap<zephyr/arch/x86/thread_stack.h>arch_nopz_tsc_readrvz_do_read_cpu_timestamp32sys_clock_cycle_get_64sys_clock_cycle_get_32sys_test_and_clear_bitsys_test_and_set_bitsys_test_bitsys_clear_bitsys_set_bitsys_read32volatile uint32_tvolatile uint32_t *sys_write32sys_read16volatile uint16_tvolatile uint16_t *unsigned short *sys_write16sys_read8sys_write8sys_in32sys_out32sys_in16sys_out16sys_in8sys_out80x00000200Uhilo_irq_to_interrupt_vectorZ_IRQ_TO_INTERRUPT_VECTOR(irq)((unsigned int) _irq_to_interrupt_vector[irq])sys_bitfield_test_and_clear_bitsys_bitfield_test_and_set_bitsys_bitfield_test_bitsys_bitfield_clear_bitsys_bitfield_set_bitZEPHYR_INCLUDE_ARCH_X86_ARCH_H_CONFIG_PCIE_MSICONFIG_INTEL_VTD_ICTL/* ZEPHYR_INCLUDE_ARCH_X86_ARCH_H_ *//* "=A" means that value is in eax:edx pair. *//*
	 * We cannot use "=A", since this would use %rax on x86_64 and
	 * return only the lower 32bits of the TSC
	 *//* serialize *//* rdtsc & cpuid clobbers eax, ebx, ecx and edx registers *//*
	 * According to Intel 64 and IA-32 Architectures Software
	 * Developers Manual, volume 3, chapter 8.2.5, LFENCE provides
	 * a more efficient method of controlling memory ordering than
	 * the CPUID instruction. So use LFENCE here, as all 64-bit
	 * CPUs have LFENCE.
	 *//**
 *  @brief read timestamp register ensuring serialization
 *//**
 * @brief read timestamp register, 32-bits only, unserialized
 *//*
 * Map of IRQ numbers to their assigned vectors. On IA32, this is generated
 * at build time and defined via the linker script. On Intel64, it's an array.
 *//* 'IF' bit *//* CONFIG_PCIE_MSI *//* Changing this value will require manual changes to exception and IDT setup
 * in locore.S for intel64
 */<zephyr/arch/x86/arch.h><zephyr/sys/arch_interface.h>sys_timepoint_expiredsys_timepoint_timeout(timepoint)Z_TIMEOUT_NO_WAIT((k_timeout_t) {0})sys_timepoint_cmpsys_clock_timeout_end_calctpsys_timepoint_timeoutsys_timepoint_calcsys_clock_tick_getsys_clock_tick_get_32k_timepoint_tk_timeout_tk_ticks_ttickSYS_CLOCK_HW_CYCLES_TO_NS_AVG(X,NCYCLES)(uint32_t)(k_cyc_to_ns_floor64(X) / NCYCLES)_NEED_PRECISE_TICK_MS_CONVERSION_TICK_ALIGNZ_TICK_ABS(t)(K_TICKS_FOREVER - 1 - (t))Z_TIMEOUT_MS_TICKS(t)((k_ticks_t)k_ms_to_ticks_ceil64(MAX(t, 0)))Z_TIMEOUT_CYC(t)Z_TIMEOUT_TICKS((k_ticks_t)k_cyc_to_ticks_ceil64(MAX(t, 0)))Z_TIMEOUT_NS(t)Z_TIMEOUT_TICKS((k_ticks_t)k_ns_to_ticks_ceil64(MAX(t, 0)))Z_TIMEOUT_US(t)Z_TIMEOUT_TICKS((k_ticks_t)k_us_to_ticks_ceil64(MAX(t, 0)))Z_TIMEOUT_MS(t)Z_TIMEOUT_TICKS((k_ticks_t)k_ms_to_ticks_ceil64(MAX(t, 0)))Z_FOREVERZ_TIMEOUT_TICKS(K_TICKS_FOREVER)Z_TIMEOUT_TICKS(t)((k_timeout_t) { .ticks = (t) })NSEC_PER_SEC((NSEC_PER_USEC) * (USEC_PER_MSEC) * (MSEC_PER_SEC))USEC_PER_SEC((USEC_PER_MSEC) * (MSEC_PER_SEC))HOUR_PER_DAY24UMIN_PER_HOUR60USEC_PER_MINMSEC_PER_SEC1000UUSEC_PER_MSECNSEC_PER_MSEC1000000UNSEC_PER_USECK_TIMEOUT_EQ(a,b)((a).ticks == (b).ticks)K_TICKS_FOREVER((k_ticks_t) -1)ZEPHYR_INCLUDE_SYS_CLOCK_H_defined(__cplusplus) && ((__cplusplus - 0) < 202002L)defined(CONFIG_SYS_CLOCK_EXISTS) && \defined(CONFIG_TIMER_READS_ITS_FREQUENCY_AT_RUNTIME) || \/* ZEPHYR_INCLUDE_SYS_CLOCK_H_ *//**
 * @brief Indicates if timepoint is expired
 *
 * @param timepoint Timepoint to evaluate
 * @retval true if the timepoint is in the past, false otherwise
 *
 * @see sys_timepoint_calc()
 *//*
 * When timers are configured out, timepoints can't relate to anything.
 * The best we can do is to preserve whether or not they are derived from
 * K_NO_WAIT. Anything else will translate back to K_FOREVER.
 *//**
 * @brief Compare two timepoint values.
 *
 * This function is used to compare two timepoint values.
 *
 * @param a Timepoint to compare
 * @param b Timepoint to compare against.
 * @return zero if both timepoints are the same. Negative value if timepoint @a a is before
 * timepoint @a b, positive otherwise.
 *//**
 * @brief Provided for backward compatibility.
 *
 * This is deprecated. Consider `sys_timepoint_calc()` instead.
 *
 * @see sys_timepoint_calc()
 *//**
 * @brief Remaining time to given timepoint
 *
 * Returns the timeout interval between current time and provided timepoint.
 * If the timepoint is now in the past or if it was created with `K_NO_WAIT`
 * then `K_NO_WAIT` is returned. If it was created with `K_FOREVER` then
 * `K_FOREVER` is returned.
 *
 * @param timepoint Timepoint for which a timeout value is wanted.
 * @retval Corresponding timeout value.
 *
 * @see sys_timepoint_calc()
 *//**
 * @brief Calculate a timepoint value
 *
 * Returns a timepoint corresponding to the expiration (relative to an
 * unlocked "now"!) of a timeout object.  When used correctly, this should
 * be called once, synchronously with the user passing a new timeout value.
 * It should not be used iteratively to adjust a timeout (see
 * `sys_timepoint_timeout()` for that purpose).
 *
 * @param timeout Timeout value relative to current time (may also be
 *                `K_FOREVER` or `K_NO_WAIT`).
 * @retval Timepoint value corresponding to given timeout
 *
 * @see sys_timepoint_timeout()
 * @see sys_timepoint_expired()
 *//**
 * @brief Kernel timepoint type
 *
 * Absolute timepoints are stored in this opaque type.
 * It is best not to inspect its content directly.
 *
 * @see sys_timepoint_calc()
 * @see sys_timepoint_timeout()
 * @see sys_timepoint_expired()
 *//**
 *
 * @brief Return the current system tick count
 *
 * @return the current system tick count
 *
 *//**
 *
 * @brief Return the lower part of the current system tick count
 *
 * @return the current system tick count
 *
 *//**
 * SYS_CLOCK_HW_CYCLES_TO_NS_AVG converts CPU clock cycles to nanoseconds
 * and calculates the average cycle time
 *//**
 * @addtogroup clock_apis
 * @{
 *//*
 * We default to using 64-bit intermediates in timescale conversions,
 * but if the HW timer cycles/sec, ticks/sec and ms/sec are all known
 * to be nicely related, then we can cheat with 32 bits instead.
 *//* kernel clocks *//* added tick needed to account for tick in progress *//* Converts between absolute timeout expiration values (packed into
 * the negative space below K_TICKS_FOREVER) and (non-negative) delta
 * timeout values.  If the result of Z_TICK_ABS(t) is >= 0, then the
 * value was an absolute timeout with the returned expiration time.
 * Note that this macro is bidirectional: Z_TICK_ABS(Z_TICK_ABS(t)) ==
 * t for all inputs, and that the representation of K_TICKS_FOREVER is
 * the same value in both spaces!  Clever, huh?
 *//** number of nanoseconds per second *//** number of microseconds per second *//** number of hours per day *//** number of minutes per hour *//** number of seconds per minute *//** number of milliseconds per second *//** number of microseconds per millisecond *//** number of nanoseconds per millisecond *//** number of nanoseconds per micorsecond *//**
 * @brief Compare timeouts for equality
 *
 * The k_timeout_t object is an opaque struct that should not be
 * inspected by application code.  This macro exists so that users can
 * test timeout objects for equality with known constants
 * (e.g. K_NO_WAIT and K_FOREVER) when implementing their own APIs in
 * terms of Zephyr timeout constants.
 *
 * @return True if the timeout objects are identical
 *//**
 * @brief Kernel timeout type
 *
 * Timeout arguments presented to kernel APIs are stored in this
 * opaque type, which is capable of representing times in various
 * formats and units.  It should be constructed from application data
 * using one of the macros defined for this purpose (e.g. `K_MSEC()`,
 * `K_TIMEOUT_ABS_TICKS()`, etc...), or be one of the two constants
 * K_NO_WAIT or K_FOREVER.  Applications should not inspect the
 * internal data once constructed.  Timeout values may be compared for
 * equality with the `K_TIMEOUT_EQ()` macro.
 *//**
 * @brief Tick precision used in timeout APIs
 *
 * This type defines the word size of the timeout values used in
 * k_timeout_t objects, and thus defines an upper bound on maximum
 * timeout length (or equivalently minimum tick duration).  Note that
 * this does not affect the size of the system uptime counter, which
 * is always a 64 bit count of ticks.
 *//**
 * @file
 * @brief Variables needed for system clock
 *
 *
 * Declare variables used by both system timer device driver and kernel
 * components that use timer functionality.
 *//*
 * Copyright (c) 2014-2015 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */timepointk_spin_releaselk_spin_unlockk_spin_trylockk_spinlock_key_t *z_spinlock_key *k_spin_lockkz_spinlock_validate_postz_spinlock_validate_prek_spinlock_key_tz_spinlock_keyk_spinlockK_SPINLOCK(lck)for (k_spinlock_key_t __i K_SPINLOCK_ONEXIT = {}, __key = k_spin_lock(lck); !__i.key; k_spin_unlock(lck, __key), __i.key = 1)K_SPINLOCK_BREAKcontinueK_SPINLOCK_ONEXITZEPHYR_INCLUDE_SPINLOCK_H_CONFIG_TICKET_SPINLOCKSCONFIG_SPIN_LOCK_TIME_LIMITdefined(CONFIG_CPP) && !defined(CONFIG_SMP) && \defined(CONFIG_SPIN_LOCK_TIME_LIMIT) && (CONFIG_SPIN_LOCK_TIME_LIMIT != 0)defined(CONFIG_SMP) && defined(CONFIG_TEST)defined(CONFIG_SPIN_VALIDATE) && defined(__GNUC__)/* ZEPHYR_INCLUDE_SPINLOCK_H_ *//**
 * @brief Guards a code block with the given spinlock, automatically acquiring
 * the lock before executing the code block. The lock will be released either
 * when reaching the end of the code block or when leaving the block with
 * @ref K_SPINLOCK_BREAK.
 *
 * @details Example usage:
 *
 * @code{.c}
 * K_SPINLOCK(&mylock) {
 *
 *   ...execute statements with the lock held...
 *
 *   if (some_condition) {
 *     ...release the lock and leave the guarded section prematurely:
 *     K_SPINLOCK_BREAK;
 *   }
 *
 *   ...execute statements with the lock held...
 *
 * }
 * @endcode
 *
 * Behind the scenes this pattern expands to a for-loop whose body is executed
 * exactly once:
 *
 * @code{.c}
 * for (k_spinlock_key_t key = k_spin_lock(&mylock); ...; k_spin_unlock(&mylock, key)) {
 *     ...
 * }
 * @endcode
 *
 * @warning The code block must execute to its end or be left by calling
 * @ref K_SPINLOCK_BREAK. Otherwise, e.g. if exiting the block with a break,
 * goto or return statement, the spinlock will not be released on exit.
 *
 * @note In user mode the spinlock must be placed in memory accessible to the
 * application, see @ref K_APP_DMEM and @ref K_APP_BMEM macros for details.
 *
 * @param lck Spinlock used to guard the enclosed code block.
 *//**
 * @brief Leaves a code block guarded with @ref K_SPINLOCK after releasing the
 * lock.
 *
 * See @ref K_SPINLOCK for details.
 *//* CONFIG_TICKET_SPINLOCKS *//* Internal function: releases the lock, but leaves local interrupts disabled *//* defined(CONFIG_SMP) && defined(CONFIG_TEST) *//*
 * @brief Checks if spinlock is held by some CPU, including the local CPU.
 *		This API shouldn't be used outside the tests for spinlock
 *
 * @param l A pointer to the spinlock
 * @retval true - if spinlock is held by some CPU; false - otherwise
 *//* Strictly we don't need atomic_clear() here (which is an
	 * exchange operation that returns the old value).  We are always
	 * setting a zero and (because we hold the lock) know the existing
	 * state won't change due to a race.  But some architectures need
	 * a memory barrier when used like this, and we don't have a
	 * Zephyr framework for that.
	 *//* Give the spinlock to the next CPU in a FIFO *//* CONFIG_SPIN_VALIDATE *//* CONFIG_SPIN_LOCK_TIME_LIMIT *//**
 * @brief Unlock a spin lock
 *
 * This releases a lock acquired by k_spin_lock().  After this
 * function is called, any CPU will be able to acquire the lock.  If
 * other CPUs are currently spinning inside k_spin_lock() waiting for
 * this lock, exactly one of them will return synchronously with the
 * lock held.
 *
 * Spin locks must be properly nested.  A call to k_spin_unlock() must
 * be made on the lock object most recently locked using
 * k_spin_lock(), using the key value that it returned.  Attempts to
 * unlock mis-nested locks, or to unlock locks that are not held, or
 * to passing a key parameter other than the one returned from
 * k_spin_lock(), are illegal.  When CONFIG_SPIN_VALIDATE is set, some
 * of these errors can be detected by the framework.
 *
 * @param l A pointer to the spinlock to release
 * @param key The value returned from k_spin_lock() when this lock was
 *        acquired
 *//*
	 * atomic_get and atomic_cas operations below are not executed
	 * simultaneously.
	 * So in theory k_spin_trylock can lock an already locked spinlock.
	 * To reproduce this the following conditions should be met after we
	 * executed atomic_get and before we executed atomic_cas:
	 *
	 * - spinlock needs to be taken 0xffff_..._ffff + 1 times
	 * (which requires 0xffff_..._ffff number of CPUs, as k_spin_lock call
	 * is blocking) or
	 * - spinlock needs to be taken and released 0xffff_..._ffff times and
	 * then taken again
	 *
	 * In real-life systems this is considered non-reproducible given that
	 * required actions need to be done during this tiny window of several
	 * CPU instructions (which execute with interrupt locked,
	 * so no preemption can happen here)
	 *//**
 * @brief Attempt to lock a spinlock
 *
 * This routine makes one attempt to lock @p l. If it is successful, then
 * it will store the key into @p k.
 *
 * @param[in] l A pointer to the spinlock to lock
 * @param[out] k A pointer to the spinlock key
 * @retval 0 on success
 * @retval -EBUSY if another thread holds the lock
 *
 * @see k_spin_lock
 * @see k_spin_unlock
 *//* Spin until our ticket is served *//*
	 * Enqueue ourselves to the end of a spinlock waiters queue
	 * receiving a ticket
	 *//* Note that we need to use the underlying arch-specific lock
	 * implementation.  The "irq_lock()" API in SMP context is
	 * actually a wrapper for a global spinlock!
	 *//**
 * @brief Lock a spinlock
 *
 * This routine locks the specified spinlock, returning a key handle
 * representing interrupt state needed at unlock time.  Upon
 * returning, the calling thread is guaranteed not to be suspended or
 * interrupted on its current CPU until it calls k_spin_unlock().  The
 * implementation guarantees mutual exclusion: exactly one thread on
 * one CPU will return from k_spin_lock() at a time.  Other CPUs
 * trying to acquire a lock already held by another CPU will enter an
 * implementation-defined busy loop ("spinning") until the lock is
 * released.
 *
 * Separate spin locks may be nested. It is legal to lock an
 * (unlocked) spin lock while holding a different lock.  Spin locks
 * are not recursive, however: an attempt to acquire a spin lock that
 * the CPU already holds will deadlock.
 *
 * In circumstances where only one CPU exists, the behavior of
 * k_spin_lock() remains as specified above, though obviously no
 * spinning will take place.  Implementations may be free to optimize
 * in uniprocessor contexts such that the locking reduces to an
 * interrupt mask operation.
 *
 * @param l A pointer to the spinlock to lock
 * @return A key value that must be passed to k_spin_unlock() when the
 *         lock is released.
 *//**
 * @brief Spinlock key type
 *
 * This type defines a "key" value used by a spinlock implementation
 * to store the system interrupt state at the time of a call to
 * k_spin_lock().  It is expected to be passed to a matching
 * k_spin_unlock().
 *
 * This type is opaque and should not be inspected by application
 * code.
 *//* There's a spinlock validation framework available when asserts are
 * enabled.  It adds a relatively hefty overhead (about 3k or so) to
 * kernel code size, don't use on platforms known to be small.
 *//* If CONFIG_SMP and CONFIG_SPIN_VALIDATE are both not defined
	 * the k_spinlock struct will have no members. The result
	 * is that in C sizeof(k_spinlock) is 0 and in C++ it is 1.
	 *
	 * This size difference causes problems when the k_spinlock
	 * is embedded into another struct like k_msgq, because C and
	 * C++ will have different ideas on the offsets of the members
	 * that come after the k_spinlock member.
	 *
	 * To prevent this we add a 1 byte dummy member to k_spinlock
	 * when the user selects C++ support and k_spinlock would
	 * otherwise be empty.
	 *//* Stores the time (in cycles) when a lock was taken
	 *//* Stores the thread that holds the lock with the locking CPU
	 * ID in the bottom two bits.
	 *//*
	 * Ticket spinlocks are conceptually two atomic variables,
	 * one indicating the current FIFO head (spinlock owner),
	 * and the other indicating the current FIFO tail.
	 * Spinlock is acquired in the following manner:
	 * - current FIFO tail value is atomically incremented while it's
	 *   original value is saved as a "ticket"
	 * - we spin until the FIFO head becomes equal to the ticket value
	 *
	 * Spinlock is released by atomic increment of the FIFO head
	 *//**
 * @brief Kernel Spin Lock
 *
 * This struct defines a spin lock record on which CPUs can wait with
 * k_spin_lock().  Any number of spinlocks may be defined in
 * application code.
 *//**
 * @brief Spinlock APIs
 * @defgroup spinlock_apis Spinlock APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @file
 * @brief Public interface for spinlocks
 */k_fatal_error_reasonK_ERR_STACK_CHK_FAILK_ERR_KERNEL_PANICK_ERR_ARCH_STARTZEPHYR_INCLUDE_FATAL_TYPES_H/* ZEPHYR_INCLUDE_FATAL_TYPES_H *//** Arch specific fatal errors *//** High severity software error *//** Moderate severity software error *//** Faulting context overflowed its stack buffer *//** Unhandled hardware interrupt *//** Generic CPU exception, not covered by other codes *//**
 * @defgroup fatal_types Fatal error base types
 * @ingroup fatal_apis
 * @{
 *//** @file
 *  @brief Fatal base type definitions
 *//*
 * Copyright (c) 2023 CSIRO.
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/fatal_types.h>z_fatal_errork_sys_fatal_error_handlerk_fatal_haltZEPHYR_INCLUDE_FATAL_H/* ZEPHYR_INCLUDE_FATAL_H *//**
 * Called by architecture code upon a fatal error.
 *
 * This function dumps out architecture-agnostic information about the error
 * and then makes a policy decision on what to do by invoking
 * k_sys_fatal_error_handler().
 *
 * On architectures where k_thread_abort() never returns, this function
 * never returns either.
 *
 * @param reason The reason for the fatal error
 * @param esf Exception context, with details and partial or full register
 *            state when the error occurred. May in some cases be NULL.
 *//**
 * @brief Fatal error policy handler
 *
 * This function is not invoked by application code, but is declared as a
 * weak symbol so that applications may introduce their own policy.
 *
 * The default implementation of this function halts the system
 * unconditionally. Depending on architecture support, this may be
 * a simple infinite loop, power off the hardware, or exit an emulator.
 *
 * If this function returns, then the currently executing thread will be
 * aborted.
 *
 * A few notes for custom implementations:
 *
 * - If the error is determined to be unrecoverable, LOG_PANIC() should be
 *   invoked to flush any pending logging buffers.
 * - K_ERR_KERNEL_PANIC indicates a severe unrecoverable error in the kernel
 *   itself, and should not be considered recoverable. There is an assertion
 *   in z_fatal_error() to enforce this.
 * - Even outside of a kernel panic, unless the fault occurred in user mode,
 *   the kernel itself may be in an inconsistent state, with API calls to
 *   kernel objects possibly exhibiting undefined behavior or triggering
 *   another exception.
 *
 * @param reason The reason for the fatal error
 * @param esf Exception context, with details and partial or full register
 *            state when the error occurred. May in some cases be NULL.
 *//**
 * @brief Halt the system on a fatal error
 *
 * Invokes architecture-specific code to power off or halt the system in
 * a low power state. Lacking that, lock interrupts and sit in an idle loop.
 *
 * @param reason Fatal exception reason code
 *//**
 * @defgroup fatal_apis Fatal error APIs
 * @ingroup kernel_apis
 * @{
 *//** @file
 *  @brief Fatal error functions
 */Z_KERNEL_STACK_BUFFERK_KERNEL_STACK_RESERVEDz_stack_ptr_alignK_THREAD_PINNED_STACK_ARRAY_DEFINEK_KERNEL_PINNED_STACK_ARRAY_DEFINEK_THREAD_PINNED_STACK_DEFINEK_KERNEL_PINNED_STACK_DEFINEK_THREAD_STACK_ARRAY_DECLAREK_KERNEL_STACK_ARRAY_DECLAREK_THREAD_STACK_DECLAREK_KERNEL_STACK_DECLAREZ_THREAD_STACK_BUFFERK_THREAD_STACK_MEMBERK_KERNEL_STACK_MEMBERK_THREAD_STACK_ARRAY_DEFINEK_KERNEL_STACK_ARRAY_DEFINEK_THREAD_STACK_DEFINEK_KERNEL_STACK_DEFINEK_THREAD_STACK_LENZ_KERNEL_STACK_LENK_THREAD_STACK_SIZEOFK_KERNEL_STACK_SIZEOFK_THREAD_STACK_RESERVEDK_KERNEL_STACK_SIZEOF(sym)(sizeof(sym) - K_KERNEL_STACK_RESERVED)K_KERNEL_STACK_MEMBER(sym,size)Z_KERNEL_STACK_DEFINE_IN(sym, size,)K_KERNEL_PINNED_STACK_ARRAY_DEFINE(sym,nmemb,size)Z_KERNEL_STACK_ARRAY_DEFINE_IN(sym, nmemb, size, __kstackmem)K_KERNEL_STACK_ARRAY_DEFINE(sym,nmemb,size)K_KERNEL_PINNED_STACK_DEFINE(sym,size)Z_KERNEL_STACK_DEFINE_IN(sym, size, __kstackmem)K_KERNEL_STACK_DEFINE(sym,size)Z_KERNEL_STACK_ARRAY_DEFINE_IN(sym,nmemb,size,lsect)struct z_thread_stack_element lsect __aligned(Z_KERNEL_STACK_OBJ_ALIGN) sym[nmemb][Z_KERNEL_STACK_LEN(size)]Z_KERNEL_STACK_DEFINE_IN(sym,size,lsect)struct z_thread_stack_element lsect __aligned(Z_KERNEL_STACK_OBJ_ALIGN) sym[Z_KERNEL_STACK_SIZE_ADJUST(size)]K_KERNEL_PINNED_STACK_ARRAY_DECLARE(sym,nmemb,size)extern struct z_thread_stack_element sym[nmemb][Z_KERNEL_STACK_LEN(size)]K_KERNEL_STACK_ARRAY_DECLARE(sym,nmemb,size)K_KERNEL_STACK_DECLARE(sym,size)extern struct z_thread_stack_element sym[Z_KERNEL_STACK_SIZE_ADJUST(size)]Z_KERNEL_STACK_LEN(size)ROUND_UP(Z_KERNEL_STACK_SIZE_ADJUST(size), Z_KERNEL_STACK_OBJ_ALIGN)Z_KERNEL_STACK_OBJ_ALIGNZ_KERNEL_STACK_SIZE_ADJUST(size)(ROUND_UP(size, ARCH_STACK_PTR_ALIGN) + K_KERNEL_STACK_RESERVED)((size_t)ARCH_KERNEL_STACK_RESERVED)Z_STACK_PTR_TO_FRAME(type,ptr)(type *)((ptr) - sizeof(type))Z_STACK_PTR_ALIGN(ptr)((uintptr_t)z_stack_ptr_align((char *)(ptr)))ZEPHYR_INCLUDE_SYS_THREAD_STACK_Hdefined(ARCH_THREAD_STACK_OBJ_ALIGN)defined(ARCH_THREAD_STACK_SIZE_ADJUST)/* ZEPHYR_INCLUDE_SYS_THREAD_STACK_H *//**
 * @brief Get a pointer to the physical stack buffer
 *
 * Obtain a pointer to the non-reserved area of a stack object.
 * This is not guaranteed to be the beginning of the thread-writable region;
 * this does not account for any memory carved-out for MPU stack overflow
 * guards.
 *
 * Use with care. The true bounds of the stack buffer are available in the
 * stack_info member of its associated thread.
 *
 * @param sym defined stack symbol name
 * @return The buffer itself, a char *
 *//**
 * @brief Define an embedded stack memory region
 *
 * Used for stacks embedded within other data structures. Use is highly
 * discouraged but in some cases necessary. For memory protection scenarios,
 * it is very important that any RAM preceding this member not be writable
 * by threads else a stack overflow will lead to silent corruption. In other
 * words, the containing data structure should live in RAM owned by the kernel.
 *
 * A user thread can only be started with a stack defined in this way if
 * the thread starting it is in supervisor mode.
 *
 * @deprecated This is now deprecated, as stacks defined in this way are not
 *             usable from user mode. Use K_KERNEL_STACK_MEMBER.
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel array of thread stack memory regions in pinned section
 *
 * Create an array of equally sized stacks. See K_THREAD_STACK_DEFINE
 * definition for additional details and constraints.
 *
 * This is the generic, historical definition. Align to Z_THREAD_STACK_OBJ_ALIGN
 * and put in 'noinit' section so that it isn't zeroed at boot
 *
 * This puts the stack into the pinned noinit linker section if
 * CONFIG_LINKER_USE_PINNED_SECTION is enabled, or else it would
 * put the stack into the same section as K_THREAD_STACK_DEFINE().
 *
 * @param sym Thread stack symbol name
 * @param nmemb Number of stacks to define
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel array of thread stack memory regions
 *
 * Create an array of equally sized stacks. See K_THREAD_STACK_DEFINE
 * definition for additional details and constraints.
 *
 * This is the generic, historical definition. Align to Z_THREAD_STACK_OBJ_ALIGN
 * and put in 'noinit' section so that it isn't zeroed at boot
 *
 * @param sym Thread stack symbol name
 * @param nmemb Number of stacks to define
 * @param size Size of the stack memory region
 *//**
 * @brief Calculate size of stacks to be allocated in a stack array
 *
 * This macro calculates the size to be allocated for the stacks
 * inside a stack array. It accepts the indicated "size" as a parameter
 * and if required, pads some extra bytes (e.g. for MPU scenarios). Refer
 * K_THREAD_STACK_ARRAY_DEFINE definition to see how this is used.
 * The returned size ensures each array member will be aligned to the
 * required stack base alignment.
 *
 * @param size Size of the stack memory region
 * @return Appropriate size for an array member
 *//**
 * @brief Define a toplevel thread stack memory region in pinned section
 *
 * This defines a region of memory suitable for use as a thread's stack.
 *
 * This is the generic, historical definition. Align to Z_THREAD_STACK_OBJ_ALIGN
 * and put in 'noinit' section so that it isn't zeroed at boot
 *
 * The defined symbol will always be a k_thread_stack_t which can be passed to
 * k_thread_create(), but should otherwise not be manipulated. If the buffer
 * inside needs to be examined, examine thread->stack_info for the associated
 * thread object to obtain the boundaries.
 *
 * It is legal to precede this definition with the 'static' keyword.
 *
 * It is NOT legal to take the sizeof(sym) and pass that to the stackSize
 * parameter of k_thread_create(), it may not be the same as the
 * 'size' parameter. Use K_THREAD_STACK_SIZEOF() instead.
 *
 * Some arches may round the size of the usable stack region up to satisfy
 * alignment constraints. K_THREAD_STACK_SIZEOF() will return the aligned
 * size.
 *
 * This puts the stack into the pinned noinit linker section if
 * CONFIG_LINKER_USE_PINNED_SECTION is enabled, or else it would
 * put the stack into the same section as K_THREAD_STACK_DEFINE().
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel thread stack memory region
 *
 * This defines a region of memory suitable for use as a thread's stack.
 *
 * This is the generic, historical definition. Align to Z_THREAD_STACK_OBJ_ALIGN
 * and put in 'noinit' section so that it isn't zeroed at boot
 *
 * The defined symbol will always be a k_thread_stack_t which can be passed to
 * k_thread_create(), but should otherwise not be manipulated. If the buffer
 * inside needs to be examined, examine thread->stack_info for the associated
 * thread object to obtain the boundaries.
 *
 * It is legal to precede this definition with the 'static' keyword.
 *
 * It is NOT legal to take the sizeof(sym) and pass that to the stackSize
 * parameter of k_thread_create(), it may not be the same as the
 * 'size' parameter. Use K_THREAD_STACK_SIZEOF() instead.
 *
 * Some arches may round the size of the usable stack region up to satisfy
 * alignment constraints. K_THREAD_STACK_SIZEOF() will return the aligned
 * size.
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel array of thread stack memory regions in specified region
 *
 * Create an array of equally sized stacks. See Z_THREAD_STACK_DEFINE_IN
 * definition for additional details and constraints.
 *
 * This is the generic, historical definition. Align to Z_THREAD_STACK_OBJ_ALIGN
 * and put in specified section so that it isn't zeroed at boot
 *
 * @param sym Thread stack symbol name
 * @param nmemb Number of stacks to define
 * @param size Size of the stack memory region
 * @param lsect Linker section for this stack
 *//**
 * @brief Define a toplevel thread stack memory region in specified region
 *
 * This defines a region of memory suitable for use as a thread's stack
 * in specified region.
 *
 * This is the generic, historical definition. Align to Z_THREAD_STACK_OBJ_ALIGN
 * and put in 'noinit' section so that it isn't zeroed at boot
 *
 * The defined symbol will always be a k_thread_stack_t which can be passed to
 * k_thread_create(), but should otherwise not be manipulated. If the buffer
 * inside needs to be examined, examine thread->stack_info for the associated
 * thread object to obtain the boundaries.
 *
 * It is legal to precede this definition with the 'static' keyword.
 *
 * It is NOT legal to take the sizeof(sym) and pass that to the stackSize
 * parameter of k_thread_create(), it may not be the same as the
 * 'size' parameter. Use K_THREAD_STACK_SIZEOF() instead.
 *
 * Some arches may round the size of the usable stack region up to satisfy
 * alignment constraints. K_THREAD_STACK_SIZEOF() will return the aligned
 * size.
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 * @param lsect Linker section for this stack
 *//**
 * @brief Return the size in bytes of a stack memory region
 *
 * Convenience macro for passing the desired stack size to k_thread_create()
 * since the underlying implementation may actually create something larger
 * (for instance a guard area).
 *
 * The value returned here is not guaranteed to match the 'size' parameter
 * passed to K_THREAD_STACK_DEFINE and may be larger, but is always safe to
 * pass to k_thread_create() for the associated stack object.
 *
 * @param sym Stack memory symbol
 * @return Size of the stack buffer
 *//**
 * @brief Declare a reference to a thread stack array
 *
 * This macro declares the symbol of a thread stack array defined elsewhere in
 * the current scope.
 *
 * @param sym Thread stack symbol name
 * @param nmemb Number of stacks defined
 * @param size Size of the stack memory region
 *//**
 * @brief Declare a reference to a thread stack
 *
 * This macro declares the symbol of a thread stack defined elsewhere in the
 * current scope.
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @addtogroup thread_stack_api
 * @{
 *//* ARCH_THREAD_STACK_SIZE_ADJUST *//**
 * @brief Round up a requested stack size to satisfy constraints
 *
 * Given a requested stack buffer size, return an adjusted size value for
 * the entire stack object which takes into consideration:
 *
 * - Reserved memory for platform data
 * - Alignment of stack buffer bounds to CPU/ABI constraints
 * - Alignment of stack buffer bounds to satisfy memory management hardware
 *   constraints such that a protection region can cover the stack buffer area
 *
 * If CONFIG_USERSPACE is enabled, this determines the size of stack objects
 * which  may be used by user mode threads, or threads running in supervisor
 * mode which may later drop privileges to user mode.
 *
 * Arches define this with ARCH_THREAD_STACK_SIZE_ADJUST().
 *
 * If ARCH_THREAD_STACK_SIZE_ADJUST is not defined, assume rounding up to
 * ARCH_STACK_PTR_ALIGN is appropriate.
 *
 * Any memory reserved for platform data is also included in the total
 * returned.
 *
 * @param size Requested size of the stack buffer
 * @return Adjusted size of the stack object
 *//* ARCH_THREAD_STACK_OBJ_ALIGN *//**
 * @brief Properly align the lowest address of a stack object
 *
 * Return an alignment value for the lowest address of a stack object, taking
 * into consideration all alignment constraints imposed by the CPU, ABI, and
 * any memory management policies, including any alignment required by
 * reserved platform data within the stack object. This will always be at least
 * ARCH_STACK_PTR_ALIGN or an even multiple thereof.
 *
 * Depending on hardware, this is either a fixed value or a function of the
 * provided size. The requested size is significant only if
 * CONFIG_MPU_REQUIRES_POWER_OF_TWO_ALIGNMENT is enabled.
 *
 * If CONFIG_USERSPACE is enabled, this determines the alignment of stacks
 * which may be used by user mode threads, or threads running in supervisor
 * mode which may later drop privileges to user mode.
 *
 * Arches define this with ARCH_THREAD_STACK_OBJ_ALIGN().
 *
 * If ARCH_THREAD_STACK_OBJ_ALIGN is not defined assume ARCH_STACK_PTR_ALIGN
 * is appropriate.
 *
 * @param size Requested size of the stack buffer (which could be ignored)
 * @return Alignment of the stack object
 *//**
 * @brief Indicate how much additional memory is reserved for stack objects
 *
 * Any given stack declaration may have additional memory in it for guard
 * areas, supervisor mode stacks, or platform-specific data.  This macro
 * indicates how much space is reserved for this.
 *
 * This value only indicates memory that is permanently reserved in the stack
 * object. Memory that is "borrowed" from the thread's stack buffer is never
 * accounted for here.
 *
 * Reserved memory is at the beginning of the stack object. The reserved area
 * must be appropriately sized such that the stack buffer immediately following
 * it is correctly aligned.
 *//**
 * @brief Define an embedded stack memory region
 *
 * Used for kernel stacks embedded within other data structures.
 *
 * Stacks defined with this macro may not host user mode threads.
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel array of kernel stack memory regions in pinned section
 *
 * See K_KERNEL_STACK_ARRAY_DEFINE() for more information and constraints.
 *
 * This puts the stack into the pinned noinit linker section if
 * CONFIG_LINKER_USE_PINNED_SECTION is enabled, or else it would
 * put the stack into the same section as K_KERNEL_STACK_ARRAY_DEFINE().
 *
 * @param sym Kernel stack array symbol name
 * @param nmemb Number of stacks to define
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel array of kernel stack memory regions
 *
 * Stacks defined with this macro may not host user mode threads.
 *
 * @param sym Kernel stack array symbol name
 * @param nmemb Number of stacks to define
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel kernel stack memory region in pinned section
 *
 * See K_KERNEL_STACK_DEFINE() for more information and constraints.
 *
 * This puts the stack into the pinned noinit linker section if
 * CONFIG_LINKER_USE_PINNED_SECTION is enabled, or else it would
 * put the stack into the same section as K_KERNEL_STACK_DEFINE().
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel kernel stack memory region
 *
 * This defines a region of memory for use as a thread stack, for threads
 * that exclusively run in supervisor mode. This is also suitable for
 * declaring special stacks for interrupt or exception handling.
 *
 * Stacks defined with this macro may not host user mode threads.
 *
 * It is legal to precede this definition with the 'static' keyword.
 *
 * It is NOT legal to take the sizeof(sym) and pass that to the stackSize
 * parameter of k_thread_create(), it may not be the same as the
 * 'size' parameter. Use K_KERNEL_STACK_SIZEOF() instead.
 *
 * The total amount of memory allocated may be increased to accommodate
 * fixed-size stack overflow guards.
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 *//**
 * @brief Define a toplevel array of kernel stack memory regions in specified section
 *
 * @param sym Kernel stack array symbol name
 * @param nmemb Number of stacks to define
 * @param size Size of the stack memory region
 * @param lsect Linker section for this array of stacks
 *//**
 * @brief Define a toplevel kernel stack memory region in specified section
 *
 * This defines a region of memory for use as a thread stack in
 * the specified linker section.
 *
 * It is legal to precede this definition with the 'static' keyword.
 *
 * It is NOT legal to take the sizeof(sym) and pass that to the stackSize
 * parameter of k_thread_create(), it may not be the same as the
 * 'size' parameter. Use K_KERNEL_STACK_SIZEOF() instead.
 *
 * The total amount of memory allocated may be increased to accommodate
 * fixed-size stack overflow guards.
 *
 * @param sym Thread stack symbol name
 * @param size Size of the stack memory region
 * @param lsect Linker section for this stack
 *//**
 * @brief Declare a reference to a pinned thread stack array
 *
 * This macro declares the symbol of a pinned thread stack array defined
 * elsewhere in the current scope.
 *
 * @param sym Thread stack symbol name
 * @param nmemb Number of stacks defined
 * @param size Size of the stack memory region
 *//**
 * @brief Helper macro for getting a stack frame struct
 *
 * It is very common for architectures to define a struct which contains
 * all the data members that are pre-populated in arch_new_thread().
 *
 * Given a type and an initial stack pointer, return a properly cast
 * pointer to the frame struct.
 *
 * @param type Type of the initial stack frame struct
 * @param ptr Initial aligned stack pointer value
 * @return Pointer to stack frame struct within the stack buffer
 *//**
 * @brief Properly align a CPU stack pointer value
 *
 * Take the provided value and round it down such that the value is aligned
 * to the CPU and ABI requirements. This is not used for any memory protection
 * hardware requirements.
 *
 * @param ptr Proposed stack pointer address
 * @return Properly aligned stack pointer address
 *//**
 * @typedef k_thread_stack_t
 * @brief Typedef of struct z_thread_stack_element
 *
 * @see z_thread_stack_element
 *//* Using typedef deliberately here, this is quite intended to be an opaque
 * type.
 *
 * The purpose of this data type is to clearly distinguish between the
 * declared symbol for a stack (of type k_thread_stack_t) and the underlying
 * buffer which composes the stack data actually used by the underlying
 * thread; they cannot be used interchangeably as some arches precede the
 * stack buffer region with guard areas that trigger a MPU or MMU fault
 * if written to.
 *
 * APIs that want to work with the buffer inside should continue to use
 * char *.
 *
 * Stacks should always be created with K_THREAD_STACK_DEFINE().
 *//**
 * @brief Thread Stack APIs
 * @ingroup kernel_apis
 * @defgroup thread_stack_api Thread Stack APIs
 * @{
 * @}
 *//**
 * @file
 *
 * @brief Macros for declaring thread stacks
 */symk_tid_t_thread_tz_pollerk_thread_runtime_stats_tk_thread_runtime_stats_thread_base_t_pipe_desc_thread_baseis_pollingbytes_to_xferbuffertlsresource_pooljoin_queueinit_datacallee_savedorder_keypreemptsched_lockedthread_stateuser_optionspended_onqnode_rbqnode_dlistZEPHYR_INCLUDE_KERNEL_THREAD_H_CONFIG_DEMAND_PAGING_THREAD_STATSCONFIG_THREAD_MONITORCONFIG_SCHED_DEADLINECONFIG_MP_MAX_NUM_CPUS <= 8defined(CONFIG_THREAD_STACK_INFO)CONFIG_THREAD_USERSPACE_LOCAL_DATAdefined(CONFIG_ERRNO) && !defined(CONFIG_ERRNO_IN_TLS) && !defined(CONFIG_LIBC_ERRNO)CONFIG_SCHED_THREAD_USAGE_ANALYSISdefined(__cplusplus) && !defined(CONFIG_SCHED_THREAD_USAGE) &&                                 \defined(CONFIG_POLL)defined(CONFIG_EVENTS)defined(CONFIG_THREAD_NAME)CONFIG_THREAD_CUSTOM_DATAdefined(CONFIG_USE_SWITCH)defined(CONFIG_THREAD_LOCAL_STORAGE)CONFIG_PIPESCONFIG_OBJ_CORE_THREADk_heap/** arch-specifics: must always be at the end *//** threads waiting in k_thread_suspend() *//** Pipe descriptor used with blocking k_pipe operations *//** Paging statistics *//* Pointer to arch-specific TLS area *//** resource pool *//** Context handle returned via arch_switch() *//** z_swap() return value *//* When using __switch() a few previously arch-specific items
	 * become part of the core OS
	 *//** current syscall frame pointer *//** Base address of thread stack *//** memory domain info of the thread *//* CONFIG_THREAD_STACK_INFO *//** Stack Info *//** per-thread errno variable *//** crude thread-local storage *//** Thread name *//** next item in list of all threads *//** thread entry and parameters description *//** true if timeout should not wake the thread *//** threads waiting in k_thread_join() *//** static thread init data *//** defined by the architecture, but all archs need these *//**
 * @ingroup thread_apis
 * Thread Structure
 *//* If none of the above Kconfig values are defined, this struct will have a size 0 in C
	 * which is not allowed in C++ (it'll have a size 1). To prevent this, we add a 1 byte dummy
	 * variable when the struct would otherwise be empty.
	 *//*
	 * This field is always zero for individual threads. It only comes
	 * into play when gathering statistics for the CPU. In that case it
	 * represents the total number of cycles spent idling.
	 *//* average # of non-idle cycles *//* peak # of non-idle cycles *//* current # of non-idle cycles *//*
	 * For threads, the following fields refer to the time spent executing
	 * as bounded by when the thread was scheduled in and scheduled out.
	 * For CPUs, the same fields refer to the time spent executing
	 * non-idle threads as bounded by the idle thread(s).
	 *//*
	 * In the context of thread statistics, [execution_cycles] is the same
	 * as the total # of non-idle cycles. In the context of CPU statistics,
	 * it refers to the sum of non-idle + idle cycles.
	 *//* total # of non-idle cycles *//** memory domain of the thread *//** memory domain queue node *//* Adjustment value to the size member, removing any storage
	 * used for TLS or random stack base offsets. (start + size - delta)
	 * is the initial stack pointer for a thread. May be 0.
	 *//* Thread writable stack buffer size. Represents the size of the actual
	 * buffer, starting from the 'start' member, that should be writable by
	 * the thread. This comprises of the thread stack area, any area reserved
	 * for local thread data storage, as well as any area left-out due to
	 * random adjustments applied to the initial thread stack pointer during
	 * thread initialization.
	 *//* Stack start - Represents the start address of the thread-writable
	 * stack area.
	 *//* Contains the stack information of a thread *//* Track thread usage statistics *//* this thread's entry in a timeout queue *//* data returned by APIs *//* CONFIG_SCHED_CPU_MASK *//* "May run on" bits for each CPU *//* Recursive count of irq_lock() calls *//* CPU index on which thread was last run *//* True for the per-CPU idle threads *//* Little Endian *//*
	 * scheduler lock count and thread priority
	 *
	 * These two fields control the preemptibility of a thread.
	 *
	 * When the scheduler is locked, sched_locked is decremented, which
	 * means that the scheduler is locked for values from 0xff to 0x01. A
	 * thread is coop if its prio is negative, thus 0x80 to 0xff when
	 * looked at the value as unsigned.
	 *
	 * By putting them end-to-end, this means that a thread is
	 * non-preemptible if the bundled value is greater than or equal to
	 * 0x0080.
	 *//* thread state *//* user facing 'thread options'; values defined in include/kernel.h *//* wait queue on which the thread is pended (needed only for
	 * trees, not dumb lists)
	 *//* this thread's entry in a ready/wait queue *//* can be used for creating 'dummy' threads, e.g. for pending on objects *//* Back pointer to pended thread *//* # bytes left to transfer *//* Position in src/dest buffer *//*
 * This _pipe_desc structure is used by the pipes kernel module when
 * CONFIG_PIPES has been selected.
 *//**
 * @typedef k_thread_entry_t
 * @brief Thread entry point function type.
 *
 * A thread's entry point function is invoked when the thread starts executing.
 * Up to 3 argument values can be passed to the function.
 *
 * The thread terminates execution permanently if the entry point function
 * returns. The thread is responsible for releasing any shared resources
 * it may own (such as mutexes and dynamically allocated memory), prior to
 * returning.
 *
 * @param p1 First argument.
 * @param p2 Second argument.
 * @param p3 Third argument.
 *//*
 * Copyright (c) 2016, Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/kernel/thread.h>k_mem_domain_add_threadk_mem_domain *k_mem_domain_remove_partitionk_mem_partition *k_mem_domain_add_partitionk_mem_domain_initk_mem_partition *[]k_mem_partitionINCLUDE_APP_MEMORY_MEM_DOMAIN_H_ARCH_MEM_PARTITION_ALIGN_CHECK/* INCLUDE_APP_MEMORY_MEM_DOMAIN_H *//**
 * @brief Add a thread into a memory domain.
 *
 * Add a thread into a memory domain. It will be removed from whatever
 * memory domain it previously belonged to.
 *
 * @param domain The memory domain that the thread is going to be added into.
 * @param thread ID of thread going to be added into the memory domain.
 *
 * @return 0 if successful, fails otherwise.
 *//**
 * @brief Remove a memory partition from a memory domain.
 *
 * Remove a memory partition from a memory domain.
 *
 * @param domain The memory domain to be removed a memory partition.
 * @param part The memory partition to be removed
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 * @retval -ENOENT if no matching partition found
 *//**
 * @brief Add a memory partition into a memory domain.
 *
 * Add a memory partition into a memory domain. Partitions must conform to
 * the following constraints:
 *
 * - Partitions in the same memory domain may not overlap each other.
 * - Partitions must not be defined which expose private kernel
 *   data structures or kernel objects.
 * - The starting address alignment, and the partition size must conform to
 *   the constraints of the underlying memory management hardware, which
 *   varies per architecture.
 * - Memory domain partitions are only intended to control access to memory
 *   from user mode threads.
 * - If CONFIG_EXECUTE_XOR_WRITE is enabled, the partition must not allow
 *   both writes and execution.
 *
 * Violating these constraints may lead to CPU exceptions or undefined
 * behavior.
 *
 * @param domain The memory domain to be added a memory partition.
 * @param part The memory partition to be added
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 * @retval -ENOSPC if no free partition slots available
 *//**
 * @brief Initialize a memory domain.
 *
 * Initialize a memory domain with given name and memory partitions.
 *
 * See documentation for k_mem_domain_add_partition() for details about
 * partition constraints.
 *
 * Do not call k_mem_domain_init() on the same memory domain more than once,
 * doing so is undefined behavior.
 *
 * @param domain The memory domain to be initialized.
 * @param num_parts The number of array items of "parts" parameter.
 * @param parts An array of pointers to the memory partitions. Can be NULL
 *              if num_parts is zero.
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters supplied
 * @retval -ENOMEM if insufficient memory
 *//* To support use of IS_ENABLED for the APIs below *//**
 * Default memory domain
 *
 * All threads are a member of some memory domain, even if running in
 * supervisor mode. Threads belong to this default memory domain if they
 * haven't been added to or inherited membership from some other domain.
 *
 * This memory domain has the z_libc_partition partition for the C library
 * added to it if exists.
 *//** number of active partitions in the domain *//** Doubly linked list of member threads *//** partitions in the domain *//**
 * @brief Memory Domain
 *
 * A memory domain is a collection of memory partitions, used to represent
 * a user thread's access policy for the linear address space. A thread
 * may be a member of only one memory domain, but any memory domain may
 * have multiple threads that are members.
 *
 * Supervisor threads may also be a member of a memory domain; this has
 * no implications on their memory access but can be useful as any child
 * threads inherit the memory domain membership of the parent.
 *
 * A user thread belonging to a memory domain with no active partitions
 * will have guaranteed access to its own stack buffer, program text,
 * and read-only data.
 *//** attribute of memory partition *//** size of memory partition *//** start address of memory partition *//**
 * @brief Memory Partition
 *
 * A memory partition is a region of memory in the linear address space
 * with a specific access policy.
 *
 * The alignment of the starting address, and the alignment of the size
 * value may have varying requirements based on the capabilities of the
 * underlying memory management hardware; arbitrary values are unlikely
 * to work.
 *//* _ARCH_MEM_PARTITION_ALIGN_CHECK *//**
 * @def K_MEM_PARTITION_DEFINE
 *
 * @brief Statically declare a memory partition
 *//**
 * @defgroup mem_domain_apis Memory domain APIs
 * @ingroup kernel_apis
 * @{
 *//*
 * Copyright (c) 2017 Linaro Limited
 * Copyright (c) 2018-2020 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/app_memorydomainpartnum_partspartsSTRUCT_SECTION_COUNT(struct_type,dst)TYPE_SECTION_COUNT(struct struct_type, struct_type, dst);STRUCT_SECTION_GET(struct_type,i,dst)TYPE_SECTION_GET(struct struct_type, struct_type, i, dst)STRUCT_SECTION_FOREACH(struct_type,iterator)STRUCT_SECTION_FOREACH_ALTERNATE(struct_type, struct_type, iterator)STRUCT_SECTION_FOREACH_ALTERNATE(secname,struct_type,iterator)TYPE_SECTION_FOREACH(struct struct_type, secname, iterator)STRUCT_SECTION_ITERABLE_NAMED(struct_type,name,varname)TYPE_SECTION_ITERABLE(struct struct_type, varname, struct_type, name)STRUCT_SECTION_ITERABLE_ARRAY(struct_type,varname,size)STRUCT_SECTION_ITERABLE_ARRAY_ALTERNATE(struct_type, struct_type, varname, size)STRUCT_SECTION_ITERABLE(struct_type,varname)STRUCT_SECTION_ITERABLE_ALTERNATE(struct_type, struct_type, varname)STRUCT_SECTION_ITERABLE_ARRAY_ALTERNATE(secname,struct_type,varname,size)TYPE_SECTION_ITERABLE(struct struct_type, varname[size], secname, varname)STRUCT_SECTION_ITERABLE_ALTERNATE(secname,struct_type,varname)TYPE_SECTION_ITERABLE(struct struct_type, varname, secname, varname)STRUCT_SECTION_END_EXTERN(struct_type)TYPE_SECTION_END_EXTERN(struct struct_type, struct_type)STRUCT_SECTION_END(struct_type)TYPE_SECTION_END(struct_type)STRUCT_SECTION_START_EXTERN(struct_type)TYPE_SECTION_START_EXTERN(struct struct_type, struct_type)STRUCT_SECTION_START(struct_type)TYPE_SECTION_START(struct_type)TYPE_SECTION_COUNT(type,secname,dst)do { TYPE_SECTION_START_EXTERN(type, secname); TYPE_SECTION_END_EXTERN(type, secname); *(dst) = ((uintptr_t)TYPE_SECTION_END(secname) - (uintptr_t)TYPE_SECTION_START(secname)) / sizeof(type); } while (0)TYPE_SECTION_GET(type,secname,i,dst)do { TYPE_SECTION_START_EXTERN(type, secname); *(dst) = &TYPE_SECTION_START(secname)[i]; } while (0)TYPE_SECTION_FOREACH(type,secname,iterator)TYPE_SECTION_START_EXTERN(type, secname); TYPE_SECTION_END_EXTERN(type, secname); for (type * iterator = TYPE_SECTION_START(secname); ({ __ASSERT(iterator <= TYPE_SECTION_END(secname), "unexpected list end location"); iterator < TYPE_SECTION_END(secname); }); iterator++)TYPE_SECTION_END_EXTERN(type,secname)extern type TYPE_SECTION_END(secname)[]TYPE_SECTION_START_EXTERN(type,secname)extern type TYPE_SECTION_START(secname)[]TYPE_SECTION_END(secname)_CONCAT(_ ## secname, _list_end)TYPE_SECTION_START(secname)_CONCAT(_ ## secname, _list_start)TYPE_SECTION_ITERABLE(type,varname,secname,section_postfix)Z_DECL_ALIGN(type) varname __in_section(_ ## secname, static, _CONCAT(section_postfix, _)) __used __noasanINCLUDE_ZEPHYR_SYS_ITERABLE_SECTIONS_H_/* INCLUDE_ZEPHYR_SYS_ITERABLE_SECTIONS_H_ *//* end of struct_section_apis *//**
 * @brief Count elements in a section.
 *
 * @param[in]  struct_type Struct type
 * @param[out] dst Pointer to location where result is written.
 *//**
 * @brief Get element from section.
 *
 * @note There is no protection against reading beyond the section.
 *
 * @param[in]  struct_type Struct type.
 * @param[in]  i Index.
 * @param[out] dst Pointer to location where pointer to element is written.
 *//**
 * @brief Iterate over a specified iterable section.
 *
 * @details
 * Iterator for structure instances gathered by STRUCT_SECTION_ITERABLE().
 * The linker must provide a _<struct_type>_list_start symbol and a
 * _<struct_type>_list_end symbol to mark the start and the end of the
 * list of struct objects to iterate over. This is normally done using
 * ITERABLE_SECTION_ROM() or ITERABLE_SECTION_RAM() in the linker script.
 *//**
 * @brief Iterate over a specified iterable section (alternate).
 *
 * @details
 * Iterator for structure instances gathered by STRUCT_SECTION_ITERABLE().
 * The linker must provide a _<SECNAME>_list_start symbol and a
 * _<SECNAME>_list_end symbol to mark the start and the end of the
 * list of struct objects to iterate over. This is normally done using
 * ITERABLE_SECTION_ROM() or ITERABLE_SECTION_RAM() in the linker script.
 *//**
 * @brief Defines a new element for an iterable section with a custom name.
 *
 * The name can be used to customize how iterable section entries are sorted.
 * @see STRUCT_SECTION_ITERABLE()
 *//**
 * @brief Defines an array of elements for an iterable section.
 *
 * @see STRUCT_SECTION_ITERABLE
 *//**
 * @brief Defines a new element for an iterable section.
 *
 * @details
 * Convenience helper combining __in_section() and Z_DECL_ALIGN().
 * The section name is the struct type prepended with an underscore.
 * The subsection is "static" and the subsubsection is the variable name.
 *
 * In the linker script, create output sections for these using
 * ITERABLE_SECTION_ROM() or ITERABLE_SECTION_RAM().
 *
 * @note In order to store the element in ROM, a const specifier has to
 * be added to the declaration: const STRUCT_SECTION_ITERABLE(...);
 *//**
 * @brief Defines an array of elements of alternate data type for an iterable
 * section.
 *
 * @see STRUCT_SECTION_ITERABLE_ALTERNATE
 *//**
 * @brief Defines a new element of alternate data type for an iterable section.
 *
 * @details
 * Special variant of STRUCT_SECTION_ITERABLE(), for placing alternate
 * data types within the iterable section of a specific data type. The
 * data type sizes and semantics must be equivalent!
 *//**
 * @brief iterable section extern for end symbol for a struct
 *
 * Helper macro to give extern for end of iterable section.
 *
 * @param[in]  struct_type data type of section
 *//**
 * @brief iterable section end symbol for a struct type
 *
 * @param[in]  struct_type data type of section
 *//**
 * @brief iterable section extern for start symbol for a struct
 *
 * Helper macro to give extern for start of iterable section.
 *
 * @param[in]  struct_type data type of section
 *//**
 * @brief iterable section start symbol for a struct type
 *
 * @param[in]  struct_type data type of section
 *//**
 * @brief Count elements in a section for a generic type.
 *
 * @param[in]  type type of element
 * @param[in]  secname name of output section
 * @param[out] dst Pointer to location where result is written.
 *//**
 * @brief Get element from section for a generic type.
 *
 * @note There is no protection against reading beyond the section.
 *
 * @param[in]  type type of element
 * @param[in]  secname name of output section
 * @param[in]  i Index.
 * @param[out] dst Pointer to location where pointer to element is written.
 *//**
 * @brief Iterate over a specified iterable section for a generic type
 *
 * @details
 * Iterator for structure instances gathered by TYPE_SECTION_ITERABLE().
 * The linker must provide a _<SECNAME>_list_start symbol and a
 * _<SECNAME>_list_end symbol to mark the start and the end of the
 * list of struct objects to iterate over. This is normally done using
 * ITERABLE_SECTION_ROM() or ITERABLE_SECTION_RAM() in the linker script.
 *//**
 * @brief iterable section extern for end symbol for a generic type
 *
 * Helper macro to give extern for end of iterable section.  The macro
 * typically will be called TYPE_SECTION_END_EXTERN(struct foobar, foobar).
 * This allows the macro to hand different types as well as cases where the
 * type and section name may differ.
 *
 * @param[in]  type data type of section
 * @param[in]  secname name of output section
 *//**
 * @brief iterable section extern for start symbol for a generic type
 *
 * Helper macro to give extern for start of iterable section.  The macro
 * typically will be called TYPE_SECTION_START_EXTERN(struct foobar, foobar).
 * This allows the macro to hand different types as well as cases where the
 * type and section name may differ.
 *
 * @param[in]  type data type of section
 * @param[in]  secname name of output section
 *//**
 * @brief iterable section end symbol for a generic type
 *
 * will return '_<SECNAME>_list_end'.
 *
 * @param[in]  secname type name of iterable section.  For 'struct foobar' this
 * would be TYPE_SECTION_START(foobar)
 *//**
 * @brief iterable section start symbol for a generic type
 *
 * will return '_[OUT_TYPE]_list_start'.
 *
 * @param[in]  secname type name of iterable section.  For 'struct foobar' this
 * would be TYPE_SECTION_START(foobar)
 *
 *//**
 * @brief Defines a new element for an iterable section for a generic type.
 *
 * @details
 * Convenience helper combining __in_section() and Z_DECL_ALIGN().
 * The section name will be '.[SECNAME].static.[SECTION_POSTFIX]'
 *
 * In the linker script, create output sections for these using
 * ITERABLE_SECTION_ROM() or ITERABLE_SECTION_RAM().
 *
 * @note In order to store the element in ROM, a const specifier has to
 * be added to the declaration: const TYPE_SECTION_ITERABLE(...);
 *
 * @param[in]  type data type of variable
 * @param[in]  varname name of variable to place in section
 * @param[in]  secname type name of iterable section.
 * @param[in]  section_postfix postfix to use in section name
 *//**
 * @brief Iterable Sections APIs
 * @defgroup iterable_section_apis Iterable Sections APIs
 * @ingroup os_services
 * @{
 *//*
 * Copyright (C) 2020, Intel Corporation
 * Copyright (C) 2023, Nordic Semiconductor ASA
 * SPDX-License-Identifier: Apache-2.0
 */k_object *k_object_create_dynamick_object_create_dynamic_alignedk_object_initobjk_objectZEPHYR_INCLUDE_SYS_INTERNAL_KOBJECT_INTERNAL_Hdefined(CONFIG_USERSPACE) || defined(__DOXYGEN__)defined(CONFIG_GEN_PRIV_STACKS) || defined(__DOXYGEN__)CONFIG_DYNAMIC_OBJECTS/* CONFIG_DYNAMIC_OBJECTS *//* LCOV_EXCL_STOP *//* LCOV_EXCL_START *//**
 * Allocate memory and install as a generic kernel object
 *
 * This is a low-level function to allocate some memory, and register that
 * allocated memory in the kernel object lookup tables with type K_OBJ_ANY.
 * Initialization state and thread permissions will be cleared. The
 * returned k_object's data value will be uninitialized.
 *
 * Most users will want to use k_object_alloc() instead.
 *
 * Memory allocated will be drawn from the calling thread's reasource pool
 * and may be freed later by passing the actual object pointer (found
 * in the returned k_object's 'name' member) to k_object_free().
 *
 * @param size Size of the allocated object
 * @return NULL on insufficient memory
 * @return A pointer to the associated k_object that is installed in the
 *	kernel object tables
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * Allocate memory and install as a generic kernel object
 *
 * This is a low-level function to allocate some memory, and register that
 * allocated memory in the kernel object lookup tables with type K_OBJ_ANY.
 * Initialization state and thread permissions will be cleared. The
 * returned k_object's data value will be uninitialized.
 *
 * Most users will want to use k_object_alloc() instead.
 *
 * Memory allocated will be drawn from the calling thread's reasource pool
 * and may be freed later by passing the actual object pointer (found
 * in the returned k_object's 'name' member) to k_object_free().
 *
 * @param align Required memory alignment for the allocated object
 * @param size Size of the allocated object
 * @return NULL on insufficient memory
 * @return A pointer to the associated k_object that is installed in the
 *	kernel object tables
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//* !CONFIG_USERSPACE *//**
 * Lookup a kernel object and init its metadata if it exists
 *
 * Calling this on an object will make it usable from userspace.
 * Intended to be called as the last statement in kernel object init
 * functions.
 *
 * @param obj Address of the kernel object
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Table generated by gperf, these objects are retrieved via
 * k_object_find().
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//* All other objects *//* Futex wait queue and spinlock for K_OBJ_FUTEX *//* CONFIG_GEN_PRIV_STACKS *//* Stack buffer size for K_OBJ_THREAD_STACK_ELEMENT *//* Metadata for K_OBJ_THREAD_STACK_ELEMENT *//* Numerical thread ID for K_OBJ_THREAD *//* Backing mutex for K_OBJ_SYS_MUTEX *//* Object extra data. Only some objects use this, determined by object type *//* Stack buffer for privilege mode elevations *//* Size of the entire stack object, including reserved areas *//* Metadata struct for K_OBJ_THREAD_STACK_ELEMENT *//**
 * @defgroup usermode_internal_apis User Mode Internal APIs
 * @ingroup internal_api
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/sys/internalCONFIG_EVENTSCONFIG_ZTESTCONFIG_RTIOCONFIG_SENSOR_ASYNC_API/* Driver subsystems *//* Core kernel objects */k_object_alloc_sizek_object_allock_object_releasek_object_access_grantZ_INCLUDE_SYSCALLS_KOBJECT_Hz_impl_k_object_alloc_sizez_impl_k_object_allocz_impl_k_object_releasez_impl_k_object_access_grantotypeobject<syscalls/kobject.h><kobj-types-enum.h><zephyr/sys/internal/kobject_internal.h>k_object_freek_object_is_validk_object_access_all_grantk_object_access_revokek_objectsK_OBJ_ANYK_OBJ_MEM_SLABK_OBJ_MSGQK_OBJ_MUTEXK_OBJ_PIPEK_OBJ_QUEUEK_OBJ_POLL_SIGNALK_OBJ_SEMK_OBJ_STACKK_OBJ_THREADK_OBJ_TIMERK_OBJ_THREAD_STACK_ELEMENTK_OBJ_NET_SOCKETK_OBJ_NET_IFK_OBJ_SYS_MUTEXK_OBJ_FUTEXK_OBJ_CONDVARK_OBJ_DRIVER_UARTK_OBJ_DRIVER_CRYPTOK_OBJ_DRIVER_ADCK_OBJ_DRIVER_AUXDISPLAYK_OBJ_DRIVER_BBRAMK_OBJ_DRIVER_CANK_OBJ_DRIVER_CHARGERK_OBJ_DRIVER_COREDUMPK_OBJ_DRIVER_COUNTERK_OBJ_DRIVER_DACK_OBJ_DRIVER_DAIK_OBJ_DRIVER_DMAK_OBJ_DRIVER_EDACK_OBJ_DRIVER_EEPROMK_OBJ_DRIVER_FUEL_GAUGE_EMULK_OBJ_DRIVER_EMUL_SENSOR_BACKEND_APIK_OBJ_DRIVER_ENTROPYK_OBJ_DRIVER_ESPIK_OBJ_DRIVER_ESPI_SAFK_OBJ_DRIVER_FLASHK_OBJ_DRIVER_FPGAK_OBJ_DRIVER_FUEL_GAUGEK_OBJ_DRIVER_GNSSK_OBJ_DRIVER_GPIOK_OBJ_DRIVER_HWSPINLOCKK_OBJ_DRIVER_I2CK_OBJ_DRIVER_I2SK_OBJ_DRIVER_I3CK_OBJ_DRIVER_IPMK_OBJ_DRIVER_KSCANK_OBJ_DRIVER_LEDK_OBJ_DRIVER_MBOXK_OBJ_DRIVER_MDIOK_OBJ_DRIVER_MIPI_DSIK_OBJ_DRIVER_PECIK_OBJ_DRIVER_PS2K_OBJ_DRIVER_PTP_CLOCKK_OBJ_DRIVER_PWMK_OBJ_DRIVER_REGULATOR_PARENTK_OBJ_DRIVER_REGULATORK_OBJ_DRIVER_RESETK_OBJ_DRIVER_RETAINED_MEMK_OBJ_DRIVER_RTCK_OBJ_DRIVER_SDHCK_OBJ_DRIVER_SENSORK_OBJ_DRIVER_SMBUSK_OBJ_DRIVER_SPIK_OBJ_DRIVER_SYSCONK_OBJ_DRIVER_W1K_OBJ_DRIVER_WDTK_OBJ_DRIVER_CAN_TRANSCEIVERK_OBJ_DRIVER_UART_MUXK_OBJ_DRIVER_ITSK_OBJ_DRIVER_TGPIOK_OBJ_DRIVER_PCIE_CTRLK_OBJ_DRIVER_SVCK_OBJ_DRIVER_BC12_EMULK_OBJ_DRIVER_BC12K_OBJ_DRIVER_TCPCK_OBJ_DRIVER_IVSHMEMK_OBJ_DRIVER_EC_HOST_CMD_BACKEND_APIK_OBJ_DRIVER_ETHPHYK_OBJ_LASTz_futex_dataK_THREAD_ACCESS_GRANT(thread,__VA_ARGS__...)ZEPHYR_INCLUDE_SYS_KOBJECT_Hk_mutex/**
 * @brief Free an object
 *
 * @param obj
 *//**
 * Free a kernel object previously allocated with k_object_alloc()
 *
 * This will return memory for a kernel object back to resource pool it was
 * allocated from.  Care must be exercised that the object will not be used
 * during or after when this call is made.
 *
 * @param obj Pointer to the kernel object memory address.
 *//**
 * Allocate a kernel object of a designated type and a given size
 *
 * This will instantiate at runtime a kernel object of the specified type,
 * returning a pointer to it. The object will be returned in an uninitialized
 * state, with the calling thread being granted permission on it. The memory
 * for the object will be allocated out of the calling thread's resource pool.
 *
 * This function is specially helpful for thread stack objects because
 * their sizes can vary. Other objects should probably look k_object_alloc().
 *
 * @param otype Requested kernel object type
 * @param size Requested kernel object size
 * @return A pointer to the allocated kernel object, or NULL if memory wasn't
 * available
 *//**
 * Allocate a kernel object of a designated type
 *
 * This will instantiate at runtime a kernel object of the specified type,
 * returning a pointer to it. The object will be returned in an uninitialized
 * state, with the calling thread being granted permission on it. The memory
 * for the object will be allocated out of the calling thread's resource pool.
 *
 * @note Thread stack object has to use k_object_alloc_size() since stacks may
 * have different sizes.
 *
 * @param otype Requested kernel object type
 * @return A pointer to the allocated kernel object, or NULL if memory wasn't
 * available
 *//**
 * @internal
 *//**
 * Check if a kernel object is of certain type and is valid.
 *
 * This checks if the kernel object exists, of certain type,
 * and has been initialized.
 *
 * @param obj Address of the kernel object
 * @param otype Object type (use K_OBJ_ANY for ignoring type checking)
 * @return True if kernel object (@a obj) exists, of certain type, and
 *         has been initialized. False otherwise.
 *//**
 * Grant all present and future threads access to an object
 *
 * If the caller is from supervisor mode, or the caller is from user mode and
 * have sufficient permissions on the object, then that object will have
 * permissions granted to it for *all* current and future threads running in
 * the system, effectively becoming a public kernel object.
 *
 * Use of this API should be avoided on systems that are running untrusted code
 * as it is possible for such code to derive the addresses of kernel objects
 * and perform unwanted operations on them.
 *
 * It is not possible to revoke permissions on public objects; once public,
 * any thread may use it.
 *
 * @param object Address of kernel object
 *//**
 * @brief Release an object
 *
 * Allows user threads to drop their own permission on an object
 * Their permissions are automatically cleared when a thread terminates.
 *
 * @param object The object to be released
 *
 *//**
 * Revoke a thread's access to a kernel object
 *
 * The thread will lose access to the object if the caller is from
 * supervisor mode, or the caller is from user mode AND has permissions
 * on both the object and the thread whose access is being revoked.
 *
 * @param object Address of kernel object
 * @param thread Thread to remove access to the object
 *//**
 * Grant a thread access to a kernel object
 *
 * The thread will be granted access to the object if the caller is from
 * supervisor mode, or the caller is from user mode AND has permissions
 * on both the object and the thread whose access is being granted.
 *
 * @param object Address of kernel object
 * @param thread Thread to grant access to the object
 *//** Driver Object *//** Object allocated *//** Object is Public *//** Object initialized *//**
 * @brief Grant a static thread access to a list of kernel objects
 *
 * For threads declared with K_THREAD_DEFINE(), grant the thread access to
 * a set of kernel objects. These objects do not need to be in an initialized
 * state. The permissions will be granted when the threads are initialized
 * in the early boot sequence.
 *
 * All arguments beyond the first must be pointers to kernel objects.
 *
 * @param name_ Name of the thread, as passed to K_THREAD_DEFINE()
 *//**
 * @defgroup usermode_apis User Mode APIs
 * @ingroup kernel_apis
 * @{
 *//** @endcond
	 *//** @cond
	 *  Doxygen should ignore this build-time generated include file
	 *  when generating API documentation.  Enumeration values are
	 *  generated during build by gen_kobject_list.py.  It includes
	 *  basic kernel objects (e.g.  pipes and mutexes) and driver types.
	 *//**
 * @brief Kernel Object Types
 *
 * This enumeration needs to be kept in sync with the lists of kernel objects
 * and subsystems in scripts/build/gen_kobject_list.py, as well as the otype_to_str()
 * function in kernel/userspace.c
 */z_smp_start_cpuz_init_cpuZEPHYR_INCLUDE_KERNEL_INTERNAL_SMP_H_CONFIG_SOF/*
 * Copyright (c) 2023 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/kernel/internal/smp.h><zephyr/sys/kobject.h><zephyr/app_memory/mem_domain.h><zephyr/kernel/thread_stack.h><zephyr/fatal.h><zephyr/sys_clock.h><zephyr/sys/printk.h><zephyr/kernel_version.h><zephyr/sys/sflist.h>ZEPHYR_INCLUDE_KERNEL_INCLUDES_H_ZEPHYR_INCLUDE_KERNEL_H_/* ZEPHYR_INCLUDE_KERNEL_INCLUDES_H_ *//* FIXME This needs to be removed. Exposes some private APIs to SOF *//**
 * @file
 *
 * @brief Header files included by kernel.h.
 */SYS_PORT_TRACING_TRACKING_FIELD(type)SYS_PORT_TRACING_OBJ_FUNC_EXIT(obj_type,func,obj,__VA_ARGS__...)SYS_PORT_TRACING_OBJ_FUNC_BLOCKING(obj_type,func,obj,__VA_ARGS__...)SYS_PORT_TRACING_OBJ_FUNC_ENTER(obj_type,func,obj,__VA_ARGS__...)SYS_PORT_TRACING_OBJ_FUNC(obj_type,func,obj,__VA_ARGS__...)SYS_PORT_TRACING_OBJ_INIT(obj_type,obj,__VA_ARGS__...)SYS_PORT_TRACING_FUNC_EXIT(type,func,__VA_ARGS__...)SYS_PORT_TRACING_FUNC_BLOCKING(type,func,__VA_ARGS__...)SYS_PORT_TRACING_FUNC_ENTER(type,func,__VA_ARGS__...)SYS_PORT_TRACING_FUNC(type,func,__VA_ARGS__...)ZEPHYR_INCLUDE_TRACING_TRACING_MACROS_H_!defined(CONFIG_TRACING) && !defined(__DOXYGEN__)defined(CONFIG_TRACING_THREAD)defined(CONFIG_TRACING_WORK)defined(CONFIG_TRACING_SEMAPHORE)defined(CONFIG_TRACING_MUTEX)defined(CONFIG_TRACING_CONDVAR)defined(CONFIG_TRACING_QUEUE)defined(CONFIG_TRACING_FIFO)defined(CONFIG_TRACING_LIFO)defined(CONFIG_TRACING_STACK)defined(CONFIG_TRACING_MESSAGE_QUEUE)defined(CONFIG_TRACING_MAILBOX)defined(CONFIG_TRACING_PIPE)defined(CONFIG_TRACING_HEAP)defined(CONFIG_TRACING_MEMORY_SLAB)defined(CONFIG_TRACING_TIMER)defined(CONFIG_TRACING_EVENT)CONFIG_TRACING_POLLINGCONFIG_TRACING_PM/* ZEPHYR_INCLUDE_TRACING_TRACING_MACROS_H_ *//* CONFIG_TRACING *//* end of subsys_tracing_macros *//**
 * @brief Field added to kernel objects so they are tracked.
 *
 * @param type Type of object being tracked (k_thread, k_sem, etc.)
 *//**
 * @brief Tracing macro for when a function ends its execution. Potential return values
 * can be given as additional arguments.
 *
 * @param obj_type The type of object associated with the call (k_thread, k_sem, k_mutex etc.)
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param obj Object
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for when a function blocks during its execution.
 *
 * @param obj_type The type of object associated with the call (k_thread, k_sem, k_mutex etc.)
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param obj Object
 * @param timeout Timeout
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for the entry into a function that might or might not return
 * a value.
 *
 * @param obj_type The type of object associated with the call (k_thread, k_sem, k_mutex etc.)
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param obj Object
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for simple object function calls often without returns or branching.
 *
 * @param obj_type The type of object associated with the call (k_thread, k_sem, k_mutex etc.)
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param obj Object
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for the initialization of an object.
 *
 * @param obj_type The type of object associated with the call (k_thread, k_sem, k_mutex etc.)
 * @param obj Object
 *//**
 * @brief Tracing macro for when a function ends its execution. Potential return values
 * can be given as additional arguments.
 *
 * @param type Type of tracing event or object type
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for when a function blocks during its execution.
 *
 * @param type Type of tracing event or object type
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for the entry into a function that might or might not return
 * a value.
 *
 * @param type Type of tracing event or object type
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Tracing macro for function calls which are not directly
 * associated with a specific type of object.
 *
 * @param type Type of tracing event or object type
 * @param func Name of the function responsible for the call. This does not need to exactly
 * match the name of the function but should rather match what the user called in case of
 * system calls etc. That is, we can often omit the z_vrfy/z_impl part of the name.
 * @param ... Additional parameters relevant to the tracing call
 *//**
 * @brief Checks if an object type should be traced or not.
 *
 * @param type Tracing event type/object
 * @param trace_call Tracing call
 *//*
 * We cannot positively enumerate all traced APIs, as applications may trace
 * arbitrary custom APIs we know nothing about. Therefore we demand that tracing
 * of an API must be actively disabled.
 *
 * This contrasts with object tracing/tracking as all traceable objects are well
 * known, see the SYS_PORT_TRACING_TYPE_MASK approach below.
 *//*
 * Object trace macros part of the system for checking if certain
 * objects should be traced or not depending on the tracing configuration.
 *//*
 * Helper macros for the object tracking system
 *//*
 * Helper macros used by the extended tracing system
 *//**
 * @brief Tracing utility macros
 * @defgroup subsys_tracing_macros Tracing utility macros
 * @ingroup subsys_tracing
 * @{
 */CONFIG_NUM_COOP_PRIORITIES + CONFIG_NUM_PREEMPT_PRIORITIES == 0CONFIG_POLLCONFIG_ARCdefined(CONFIG_ARC_DSP_SHARING)defined(CONFIG_ARC_AGU_SHARING)defined(CONFIG_FPU_SHARING) && defined(CONFIG_X86_SSE)defined(CONFIG_INIT_STACKS) && defined(CONFIG_THREAD_STACK_INFO)CONFIG_OBJ_CORE_TIMERCONFIG_OBJ_CORE_EVENTCONFIG_OBJ_CORE_FIFOCONFIG_OBJ_CORE_LIFOCONFIG_OBJ_CORE_STACKCONFIG_OBJ_CORE_MUTEXCONFIG_OBJ_CORE_CONDVARCONFIG_OBJ_CORE_SEMCONFIG_OBJ_CORE_MSGQ(CONFIG_NUM_MBOX_ASYNC_MSGS > 0)CONFIG_OBJ_CORE_MAILBOXCONFIG_OBJ_CORE_PIPECONFIG_MEM_SLAB_TRACE_MAX_UTILIZATIONCONFIG_OBJ_CORE_MEM_SLABARCH_EXCEPT!defined(CONFIG_ASSERT_NO_FILE_INFO)/* ZEPHYR_INCLUDE_KERNEL_H_ *//**
 * @brief Disable gathering of system runtime statistics
 *
 * This routine disables the gathering of system runtime statistics. Note that
 * it does not affect the gathering of similar statistics for individual
 * threads.
 *//**
 * @brief Enable gathering of system runtime statistics
 *
 * This routine enables the gathering of system runtime statistics. Note that
 * it does not affect the gathering of similar statistics for individual
 * threads.
 *//**
 * @brief Disable gathering of runtime statistics for specified thread
 *
 * This routine disables the gathering of runtime statistics for the specified
 * thread.
 *
 * @param thread ID of thread
 * @return -EINVAL if invalid thread ID, otherwise 0
 *//**
 * @brief Enable gathering of runtime statistics for specified thread
 *
 * This routine enables the gathering of runtime statistics for the specified
 * thread.
 *
 * @param thread ID of thread
 * @return -EINVAL if invalid thread ID, otherwise 0
 *//**
 * @brief Get the runtime statistics of all threads
 *
 * @param stats Pointer to struct to copy statistics into.
 * @return -EINVAL if null pointers, otherwise 0
 *//**
 * @brief Get the runtime statistics of a thread
 *
 * @param thread ID of thread.
 * @param stats Pointer to struct to copy statistics into.
 * @return -EINVAL if null pointers, otherwise 0
 *//**
 * @brief Enable preservation of floating point context information.
 *
 * This routine informs the kernel that the specified thread
 * will use the floating point registers.

 * Invoking this routine initializes the thread's floating point context info
 * to that of an FPU that has been reset. The next time the thread is scheduled
 * by z_swap() it will either inherit an FPU that is guaranteed to be in a
 * "sane" state (if the most recent user of the FPU was cooperatively swapped
 * out) or the thread's own floating point context will be loaded (if the most
 * recent user of the FPU was preempted, or if this thread is the first user
 * of the FPU). Thereafter, the kernel will protect the thread's FP context
 * so that it is not altered during a preemptive context switch.
 *
 * The @a options parameter indicates which floating point register sets will
 * be used by the specified thread.
 *
 * For x86 options:
 *
 * - K_FP_REGS  indicates x87 FPU and MMX registers only
 * - K_SSE_REGS indicates SSE registers (and also x87 FPU and MMX registers)
 *
 * @warning
 * Some architectures apply restrictions on how the enabling of floating
 * point preservation may be requested, see arch_float_enable.
 *
 * @warning
 * This routine should only be used to enable floating point support for
 * a thread that currently has such support enabled.
 *
 * @param thread  ID of thread.
 * @param options architecture dependent options
 *
 * @retval 0        On success.
 * @retval -ENOTSUP If the floating point enabling is not implemented.
 *         -EINVAL  If the floating point enabling could not be performed.
 *//**
 * @brief Disable preservation of floating point context information.
 *
 * This routine informs the kernel that the specified thread
 * will no longer be using the floating point registers.
 *
 * @warning
 * Some architectures apply restrictions on how the disabling of floating
 * point preservation may be requested, see arch_float_disable.
 *
 * @warning
 * This routine should only be used to disable floating point support for
 * a thread that currently has such support enabled.
 *
 * @param thread ID of thread.
 *
 * @retval 0        On success.
 * @retval -ENOTSUP If the floating point disabling is not implemented.
 *         -EINVAL  If the floating point disabling could not be performed.
 *//**
 * @brief Emit a character buffer to the console device
 *
 * @param c String of characters to print
 * @param n The length of the string
 *
 *//*
 * private APIs that are utilized by one or more public APIs
 *//**
 * @brief Fatally terminate the system
 *
 * This should be called when the Zephyr kernel has encountered an
 * unrecoverable runtime condition and needs to terminate. What this ultimately
 * means is determined by the _fatal_error_handler() implementation, which
 * will be called will reason code K_ERR_KERNEL_PANIC.
 *//**
 * @brief Fatally terminate a thread
 *
 * This should be called when a thread has encountered an unrecoverable
 * runtime condition and needs to terminate. What this ultimately
 * means is determined by the _fatal_error_handler() implementation, which
 * will be called will reason code K_ERR_KERNEL_OOPS.
 *
 * If this is called from ISR context, the default system fatal error handler
 * will treat it as an unrecoverable system error, just like k_panic().
 *//* _ARCH__EXCEPT *//* NOTE: This is the implementation for arches that do not implement
 * ARCH_EXCEPT() to generate a real CPU exception.
 *
 * We won't have a real exception frame to determine the PC value when
 * the oops occurred, so print file and line number before we jump into
 * the fatal error handler.
 *//* This architecture has direct support for triggering a CPU exception *//**
 * @cond INTERNAL_HIDDEN
 * @internal
 *//**
 * @brief Make the CPU idle in an atomic fashion.
 *
 * Similar to k_cpu_idle(), but must be called with interrupts locked.
 *
 * Enabling interrupts and entering a low-power mode will be atomic,
 * i.e. there will be no period of time where interrupts are enabled before
 * the processor enters a low-power mode.
 *
 * After waking up from the low-power mode, the interrupt lockout state will
 * be restored as if by irq_unlock(key).
 *
 * @param key Interrupt locking key obtained from irq_lock().
 *//**
 * @brief Make the CPU idle.
 *
 * This function makes the CPU idle until an event wakes it up.
 *
 * In a regular system, the idle thread should be the only thread responsible
 * for making the CPU idle and triggering any type of power management.
 * However, in some more constrained systems, such as a single-threaded system,
 * the only thread would be responsible for this if needed.
 *
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 *//**
 * @defgroup cpu_idle_apis CPU Idling APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Signal a poll signal object.
 *
 * This routine makes ready a poll signal, which is basically a poll event of
 * type K_POLL_TYPE_SIGNAL. If a thread was polling on that event, it will be
 * made ready to run. A @a result value can be specified.
 *
 * The poll signal contains a 'signaled' field that, when set by
 * k_poll_signal_raise(), stays set until the user sets it back to 0 with
 * k_poll_signal_reset(). It thus has to be reset by the user before being
 * passed again to k_poll() or k_poll() will consider it being signaled, and
 * will return immediately.
 *
 * @note The result is stored and the 'signaled' field is set even if
 * this function returns an error indicating that an expiring poll was
 * not notified.  The next k_poll() will detect the missed raise.
 *
 * @param sig A poll signal.
 * @param result The value to store in the result field of the signal.
 *
 * @retval 0 The signal was delivered successfully.
 * @retval -EAGAIN The polling thread's timeout is in the process of expiring.
 *//**
 * @brief Fetch the signaled state and result value of a poll signal
 *
 * @param sig A poll signal object
 * @param signaled An integer buffer which will be written nonzero if the
 *		   object was signaled
 * @param result An integer destination buffer which will be written with the
 *		   result value if the object was signaled, or an undefined
 *		   value if it was not.
 *//*
 * @brief Reset a poll signal object's state to unsignaled.
 *
 * @param sig A poll signal object
 *//**
 * @brief Initialize a poll signal object.
 *
 * Ready a poll signal object to be signaled via k_poll_signal_raise().
 *
 * @param sig A poll signal.
 *//**
 * @brief Wait for one or many of multiple poll events to occur
 *
 * This routine allows a thread to wait concurrently for one or many of
 * multiple poll events to have occurred. Such events can be a kernel object
 * being available, like a semaphore, or a poll signal event.
 *
 * When an event notifies that a kernel object is available, the kernel object
 * is not "given" to the thread calling k_poll(): it merely signals the fact
 * that the object was available when the k_poll() call was in effect. Also,
 * all threads trying to acquire an object the regular way, i.e. by pending on
 * the object, have precedence over the thread polling on the object. This
 * means that the polling thread will never get the poll event on an object
 * until the object becomes available and its pend queue is empty. For this
 * reason, the k_poll() call is more effective when the objects being polled
 * only have one thread, the polling thread, trying to acquire them.
 *
 * When k_poll() returns 0, the caller should loop on all the events that were
 * passed to k_poll() and check the state field for the values that were
 * expected and take the associated actions.
 *
 * Before being reused for another call to k_poll(), the user has to reset the
 * state field to K_POLL_STATE_NOT_READY.
 *
 * When called from user mode, a temporary memory allocation is required from
 * the caller's resource pool.
 *
 * @param events An array of events to be polled for.
 * @param num_events The number of events in the array.
 * @param timeout Waiting period for an event to be ready,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 One or more events are ready.
 * @retval -EAGAIN Waiting period timed out.
 * @retval -EINTR Polling has been interrupted, e.g. with
 *         k_queue_cancel_wait(). All output events are still set and valid,
 *         cancelled event(s) will be set to K_POLL_STATE_CANCELLED. In other
 *         words, -EINTR status means that at least one of output events is
 *         K_POLL_STATE_CANCELLED.
 * @retval -ENOMEM Thread resource pool insufficient memory (user mode only)
 * @retval -EINVAL Bad parameters (user mode only)
 *//**
 * @brief Initialize one struct k_poll_event instance
 *
 * After this routine is called on a poll event, the event it ready to be
 * placed in an event array to be passed to k_poll().
 *
 * @param event The event to initialize.
 * @param type A bitfield of the types of event, from the K_POLL_TYPE_xxx
 *             values. Only values that apply to the same object being polled
 *             can be used together. Choosing K_POLL_TYPE_IGNORE disables the
 *             event.
 * @param mode Future. Use K_POLL_MODE_NOTIFY_ONLY.
 * @param obj Kernel object or poll signal.
 *//** per-type data *//** unused bits in 32-bit word *//** mode of operation, from enum k_poll_modes *//** bitfield of event states (bitwise-ORed K_POLL_STATE_xxx values) *//** bitfield of event types (bitwise-ORed K_POLL_TYPE_xxx values) *//** optional user-specified tag, opaque, untouched by the API *//** PRIVATE - DO NOT TOUCH *//**
 * @brief Poll Event
 *
 *//** custom result value passed to k_poll_signal_raise() if needed *//**
	 * 1 if the event has been signaled, 0 otherwise. Stays set to 1 until
	 * user resets it to 0.
	 *//* public - poll signal object *//* public - values for k_poll_event.state bitfield *//* polling thread does not take ownership of objects when available *//* public - polling modes *//* public - values for k_poll_event.type bitfield *//* Public polling API *//**
 * @defgroup poll_apis Async polling APIs
 * @ingroup kernel_apis
 * @{
 *//* end of polling API - PRIVATE *//* modes *//* tag *//* data is available to read from a pipe *//* data is available to read on a message queue *//* queue/FIFO/LIFO wait was cancelled *//* data is available to read on queue/FIFO/LIFO *//* semaphore is available *//* signaled by k_poll_signal_raise() *//* default state when creating event *//* private - states bit positions *//* pipe data availability *//* msgq data availability *//* queue/FIFO/LIFO data availability *//* semaphore availability *//* to be signaled by k_poll_signal_raise() *//* can be used to ignore an event *//* private - types bit positions *//* polling API - PRIVATE *//**
 * @brief Allocate memory from heap, array style
 *
 * This routine provides traditional calloc() semantics. Memory is
 * allocated from the heap memory pool and zeroed.
 *
 * @param nmemb Number of elements in the requested array
 * @param size Size of each array element (in bytes).
 *
 * @return Address of the allocated memory if successful; otherwise NULL.
 *//**
 * @brief Free memory allocated from heap.
 *
 * This routine provides traditional free() semantics. The memory being
 * returned must have been allocated from the heap memory pool.
 *
 * If @a ptr is NULL, no operation is performed.
 *
 * @param ptr Pointer to previously allocated memory.
 *//**
 * @brief Allocate memory from the heap.
 *
 * This routine provides traditional malloc() semantics. Memory is
 * allocated from the heap memory pool.
 * Allocated memory is aligned on a multiple of pointer sizes.
 *
 * @param size Amount of memory requested (in bytes).
 *
 * @return Address of the allocated memory if successful; otherwise NULL.
 *//**
 * @brief Allocate memory from the heap with a specified alignment.
 *
 * This routine provides semantics similar to aligned_alloc(); memory is
 * allocated from the heap with a specified alignment. However, one minor
 * difference is that k_aligned_alloc() accepts any non-zero @p size,
 * whereas aligned_alloc() only accepts a @p size that is an integral
 * multiple of @p align.
 *
 * Above, aligned_alloc() refers to:
 * C11 standard (ISO/IEC 9899:2011): 7.22.3.1
 * The aligned_alloc function (p: 347-348)
 *
 * @param align Alignment of memory requested (in bytes).
 * @param size Amount of memory requested (in bytes).
 *
 * @return Address of the allocated memory if successful; otherwise NULL.
 *//**
 * @defgroup heap_apis Heap APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Define a static k_heap in uncached memory
 *
 * This macro defines and initializes a static memory region and
 * k_heap of the requested size in uncached memory.  After kernel
 * start, &name can be used as if k_heap_init() had been called.
 *
 * Note that this macro enforces a minimum size on the memory region
 * to accommodate metadata requirements.  Very small heaps will be
 * padded to fit.
 *
 * @param name Symbol name for the struct k_heap object
 * @param bytes Size of memory region, in bytes
 *//**
 * @brief Define a static k_heap
 *
 * This macro defines and initializes a static memory region and
 * k_heap of the requested size.  After kernel start, &name can be
 * used as if k_heap_init() had been called.
 *
 * Note that this macro enforces a minimum size on the memory region
 * to accommodate metadata requirements.  Very small heaps will be
 * padded to fit.
 *
 * @param name Symbol name for the struct k_heap object
 * @param bytes Size of memory region, in bytes
 *//* CHUNK_UNIT *//**
 * @brief Define a static k_heap in the specified linker section
 *
 * This macro defines and initializes a static memory region and
 * k_heap of the requested size in the specified linker section.
 * After kernel start, &name can be used as if k_heap_init() had
 * been called.
 *
 * Note that this macro enforces a minimum size on the memory region
 * to accommodate metadata requirements.  Very small heaps will be
 * padded to fit.
 *
 * @param name Symbol name for the struct k_heap object
 * @param bytes Size of memory region, in bytes
 * @param in_section __attribute__((section(name))
 *//* Hand-calculated minimum heap sizes needed to return a successful
 * 1-byte allocation.  See details in lib/os/heap.[ch]
 *//**
 * @brief Free memory allocated by k_heap_alloc()
 *
 * Returns the specified memory block, which must have been returned
 * from k_heap_alloc(), to the heap for use by other callers.  Passing
 * a NULL block is legal, and has no effect.
 *
 * @param h Heap to which to return the memory
 * @param mem A valid memory block, or NULL
 *//**
 * @brief Allocate memory from a k_heap
 *
 * Allocates and returns a memory buffer from the memory region owned
 * by the heap.  If no memory is available immediately, the call will
 * block for the specified timeout (constructed via the standard
 * timeout API, or K_NO_WAIT or K_FOREVER) waiting for memory to be
 * freed.  If the allocation cannot be performed by the expiration of
 * the timeout, NULL will be returned.
 * Allocated memory is aligned on a multiple of pointer sizes.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 * @note When CONFIG_MULTITHREADING=n any @a timeout is treated as K_NO_WAIT.
 *
 * @funcprops \isr_ok
 *
 * @param h Heap from which to allocate
 * @param bytes Desired size of block to allocate
 * @param timeout How long to wait, or K_NO_WAIT
 * @return A pointer to valid heap memory, or NULL
 *//** @brief Allocate aligned memory from a k_heap
 *
 * Behaves in all ways like k_heap_alloc(), except that the returned
 * memory (if available) will have a starting address in memory which
 * is a multiple of the specified power-of-two alignment value in
 * bytes.  The resulting memory can be returned to the heap using
 * k_heap_free().
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 * @note When CONFIG_MULTITHREADING=n any @a timeout is treated as K_NO_WAIT.
 *
 * @funcprops \isr_ok
 *
 * @param h Heap from which to allocate
 * @param align Alignment in bytes, must be a power of two
 * @param bytes Number of bytes requested
 * @param timeout How long to wait, or K_NO_WAIT
 * @return Pointer to memory the caller can now use
 *//**
 * @brief Initialize a k_heap
 *
 * This constructs a synchronized k_heap object over a memory region
 * specified by the user.  Note that while any alignment and size can
 * be passed as valid parameters, internal alignment restrictions
 * inside the inner sys_heap mean that not all bytes may be usable as
 * allocated memory.
 *
 * @param h Heap struct to initialize
 * @param mem Pointer to memory.
 * @param bytes Size of memory region, in bytes
 *//* kernel synchronized heap struct *//**
 * @addtogroup heap_apis
 * @{
 *//**
 * @brief Reset the maximum memory usage for a slab
 *
 * This routine resets the maximum memory usage for the slab @a slab to its
 * current usage.
 *
 * @param slab Address of the memory slab
 *
 * @retval 0 Success
 * @retval -EINVAL Memory slab is NULL
 *//**
 * @brief Get the memory stats for a memory slab
 *
 * This routine gets the runtime memory usage stats for the slab @a slab.
 *
 * @param slab Address of the memory slab
 * @param stats Pointer to memory into which to copy memory usage statistics
 *
 * @retval 0 Success
 * @retval -EINVAL Any parameter points to NULL
 *//**
 * @brief Get the number of unused blocks in a memory slab.
 *
 * This routine gets the number of memory blocks that are currently
 * unallocated in @a slab.
 *
 * @param slab Address of the memory slab.
 *
 * @return Number of unallocated memory blocks.
 *//**
 * @brief Get the number of maximum used blocks so far in a memory slab.
 *
 * This routine gets the maximum number of memory blocks that were
 * allocated in @a slab.
 *
 * @param slab Address of the memory slab.
 *
 * @return Maximum number of allocated memory blocks.
 *//**
 * @brief Get the number of used blocks in a memory slab.
 *
 * This routine gets the number of memory blocks that are currently
 * allocated in @a slab.
 *
 * @param slab Address of the memory slab.
 *
 * @return Number of allocated memory blocks.
 *//**
 * @brief Free memory allocated from a memory slab.
 *
 * This routine releases a previously allocated memory block back to its
 * associated memory slab.
 *
 * @param slab Address of the memory slab.
 * @param mem Pointer to the memory block (as returned by k_mem_slab_alloc()).
 *//**
 * @brief Allocate memory from a memory slab.
 *
 * This routine allocates a memory block from a memory slab.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 * @note When CONFIG_MULTITHREADING=n any @a timeout is treated as K_NO_WAIT.
 *
 * @funcprops \isr_ok
 *
 * @param slab Address of the memory slab.
 * @param mem Pointer to block address area.
 * @param timeout Non-negative waiting period to wait for operation to complete.
 *        Use K_NO_WAIT to return without waiting,
 *        or K_FOREVER to wait as long as necessary.
 *
 * @retval 0 Memory allocated. The block address area pointed at by @a mem
 *         is set to the starting address of the memory block.
 * @retval -ENOMEM Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 * @retval -EINVAL Invalid data supplied
 *//**
 * @brief Initialize a memory slab.
 *
 * Initializes a memory slab, prior to its first use.
 *
 * The memory slab's buffer contains @a slab_num_blocks memory blocks
 * that are @a slab_block_size bytes long. The buffer must be aligned to an
 * N-byte boundary matching a word boundary, where N is a power of 2
 * (i.e. 4 on 32-bit systems, 8, 16, ...).
 * To ensure that each memory block is similarly aligned to this boundary,
 * @a slab_block_size must also be a multiple of N.
 *
 * @param slab Address of the memory slab.
 * @param buffer Pointer to buffer used for the memory blocks.
 * @param block_size Size of each memory block (in bytes).
 * @param num_blocks Number of memory blocks.
 *
 * @retval 0 on success
 * @retval -EINVAL invalid data supplied
 *
 *//**
 * @brief Statically define and initialize a memory slab in a private (static) scope.
 *
 * The memory slab's buffer contains @a slab_num_blocks memory blocks
 * that are @a slab_block_size bytes long. The buffer is aligned to a
 * @a slab_align -byte boundary. To ensure that each memory block is similarly
 * aligned to this boundary, @a slab_block_size must also be a multiple of
 * @a slab_align.
 *
 * @param name Name of the memory slab.
 * @param slab_block_size Size of each memory block (in bytes).
 * @param slab_num_blocks Number memory blocks.
 * @param slab_align Alignment of the memory slab's buffer (power of 2).
 *//**
 * @brief Statically define and initialize a memory slab in a public (non-static) scope.
 *
 * The memory slab's buffer contains @a slab_num_blocks memory blocks
 * that are @a slab_block_size bytes long. The buffer is aligned to a
 * @a slab_align -byte boundary. To ensure that each memory block is similarly
 * aligned to this boundary, @a slab_block_size must also be a multiple of
 * @a slab_align.
 *
 * The memory slab can be accessed outside the module where it is defined
 * using:
 *
 * @code extern struct k_mem_slab <name>; @endcode
 *
 * @note This macro cannot be used together with a static keyword.
 *       If such a use-case is desired, use @ref K_MEM_SLAB_DEFINE_STATIC
 *       instead.
 *
 * @param name Name of the memory slab.
 * @param slab_block_size Size of each memory block (in bytes).
 * @param slab_num_blocks Number memory blocks.
 * @param slab_align Alignment of the memory slab's buffer (power of 2).
 *//**
 * @defgroup mem_slab_apis Memory Slab APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Flush the pipe's internal buffer
 *
 * This routine flushes the pipe's internal buffer. This is equivalent to
 * reading up to N bytes from the pipe (where N is the size of the pipe's
 * buffer) into a temporary buffer and then discarding that buffer. If there
 * were writers previously pending, then some may unpend as they try to fill
 * up the pipe's emptied buffer.
 *
 * @param pipe Address of the pipe.
 *//**
 * @brief Flush the pipe of write data
 *
 * This routine flushes the pipe. Flushing the pipe is equivalent to reading
 * both all the data in the pipe's buffer and all the data waiting to go into
 * that pipe into a large temporary buffer and discarding the buffer. Any
 * writers that were previously pended become unpended.
 *
 * @param pipe Address of the pipe.
 *//**
 * @brief Query the number of bytes that may be written to @a pipe
 *
 * @param pipe Address of the pipe.
 *
 * @retval a number n such that 0 <= n <= @ref k_pipe.size; the
 *         result is zero for unbuffered pipes.
 *//**
 * @brief Query the number of bytes that may be read from @a pipe.
 *
 * @param pipe Address of the pipe.
 *
 * @retval a number n such that 0 <= n <= @ref k_pipe.size; the
 *         result is zero for unbuffered pipes.
 *//**
 * @brief Read data from a pipe.
 *
 * This routine reads up to @a bytes_to_read bytes of data from @a pipe.
 *
 * @param pipe Address of the pipe.
 * @param data Address to place the data read from pipe.
 * @param bytes_to_read Maximum number of data bytes to read.
 * @param bytes_read Address of area to hold the number of bytes read.
 * @param min_xfer Minimum number of data bytes to read.
 * @param timeout Waiting period to wait for the data to be read,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 At least @a min_xfer bytes of data were read.
 * @retval -EINVAL invalid parameters supplied
 * @retval -EIO Returned without waiting; zero data bytes were read.
 * @retval -EAGAIN Waiting period timed out; between zero and @a min_xfer
 *                 minus one data bytes were read.
 *//**
 * @brief Write data to a pipe.
 *
 * This routine writes up to @a bytes_to_write bytes of data to @a pipe.
 *
 * @param pipe Address of the pipe.
 * @param data Address of data to write.
 * @param bytes_to_write Size of data (in bytes).
 * @param bytes_written Address of area to hold the number of bytes written.
 * @param min_xfer Minimum number of bytes to write.
 * @param timeout Waiting period to wait for the data to be written,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 At least @a min_xfer bytes of data were written.
 * @retval -EIO Returned without waiting; zero data bytes were written.
 * @retval -EAGAIN Waiting period timed out; between zero and @a min_xfer
 *                 minus one data bytes were written.
 *//**
 * @brief Initialize a pipe and allocate a buffer for it
 *
 * Storage for the buffer region will be allocated from the calling thread's
 * resource pool. This memory will be released if k_pipe_cleanup() is called,
 * or userspace is enabled and the pipe object loses all references to it.
 *
 * This function should only be called on uninitialized pipe objects.
 *
 * @param pipe Address of the pipe.
 * @param size Size of the pipe's ring buffer (in bytes), or zero if no ring
 *             buffer is used.
 * @retval 0 on success
 * @retval -ENOMEM if memory couldn't be allocated
 *//**
 * @brief Release a pipe's allocated buffer
 *
 * If a pipe object was given a dynamically allocated buffer via
 * k_pipe_alloc_init(), this will free it. This function does nothing
 * if the buffer wasn't dynamically allocated.
 *
 * @param pipe Address of the pipe.
 * @retval 0 on success
 * @retval -EAGAIN nothing to cleanup
 *//**
 * @brief Initialize a pipe.
 *
 * This routine initializes a pipe object, prior to its first use.
 *
 * @param pipe Address of the pipe.
 * @param buffer Address of the pipe's ring buffer, or NULL if no ring buffer
 *               is used.
 * @param size Size of the pipe's ring buffer (in bytes), or zero if no ring
 *             buffer is used.
 *//**
 * @brief Statically define and initialize a pipe.
 *
 * The pipe can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_pipe <name>; @endcode
 *
 * @param name Name of the pipe.
 * @param pipe_buffer_size Size of the pipe's ring buffer (in bytes),
 *                         or zero if no ring buffer is used.
 * @param pipe_align Alignment of the pipe's ring buffer (power of 2).
 *
 *//** Buffer was allocated *//**< Flags *//** Wait queue *//**< Writer wait queue *//**< Reader wait queue *//**< Synchronization lock *//**< Where in buffer to write *//**< Where in buffer to read from *//**< # bytes used in buffer *//**< Buffer size *//**< Pipe buffer: may be NULL *//** Pipe Structure *//**
 * @defgroup pipe_apis Pipe APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Retrieve mailbox message data into a buffer.
 *
 * This routine completes the processing of a received message by retrieving
 * its data into a buffer, then disposing of the message.
 *
 * Alternatively, this routine can be used to dispose of a received message
 * without retrieving its data.
 *
 * @param rx_msg Address of the receive message descriptor.
 * @param buffer Address of the buffer to receive data, or NULL to discard
 *               the data.
 *//**
 * @brief Receive a mailbox message.
 *
 * This routine receives a message from @a mbox, then optionally retrieves
 * its data and disposes of the message.
 *
 * @param mbox Address of the mailbox.
 * @param rx_msg Address of the receive message descriptor.
 * @param buffer Address of the buffer to receive data, or NULL to defer data
 *               retrieval and message disposal until later.
 * @param timeout Waiting period for a message to be received,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 Message received.
 * @retval -ENOMSG Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Send a mailbox message in an asynchronous manner.
 *
 * This routine sends a message to @a mbox without waiting for a receiver
 * to process it. The message data may be in a buffer or non-existent
 * (i.e. an empty message). Optionally, the semaphore @a sem will be given
 * when the message has been both received and completely processed by
 * the receiver.
 *
 * @param mbox Address of the mailbox.
 * @param tx_msg Address of the transmit message descriptor.
 * @param sem Address of a semaphore, or NULL if none is needed.
 *//**
 * @brief Send a mailbox message in a synchronous manner.
 *
 * This routine sends a message to @a mbox and waits for a receiver to both
 * receive and process it. The message data may be in a buffer or non-existent
 * (i.e. an empty message).
 *
 * @param mbox Address of the mailbox.
 * @param tx_msg Address of the transmit message descriptor.
 * @param timeout Waiting period for the message to be received,
 *                or one of the special values K_NO_WAIT
 *                and K_FOREVER. Once the message has been received,
 *                this routine waits as long as necessary for the message
 *                to be completely processed.
 *
 * @retval 0 Message sent.
 * @retval -ENOMSG Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Initialize a mailbox.
 *
 * This routine initializes a mailbox object, prior to its first use.
 *
 * @param mbox Address of the mailbox.
 *//**
 * @brief Statically define and initialize a mailbox.
 *
 * The mailbox is to be accessed outside the module where it is defined using:
 *
 * @code extern struct k_mbox <name>; @endcode
 *
 * @param name Name of the mailbox.
 *//** Receive message queue *//** Transmit messages queue *//**
 * @brief Mailbox Structure
 *
 *//** internal use only - semaphore used during asynchronous send *//** internal use only - thread waiting on send (may be a dummy) *//** target thread id *//** source thread id *//** sender's message data buffer *//** application-defined information value *//** size of message (in bytes) *//** internal use only - needed for legacy API support *//**
 * @brief Mailbox Message Structure
 *
 *//**
 * @defgroup mailbox_apis Mailbox APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Get the number of messages in a message queue.
 *
 * This routine returns the number of messages in a message queue's ring buffer.
 *
 * @param msgq Address of the message queue.
 *
 * @return Number of messages.
 *//**
 * @brief Get basic attributes of a message queue.
 *
 * This routine fetches basic attributes of message queue into attr argument.
 *
 * @param msgq Address of the message queue.
 * @param attrs pointer to message queue attribute structure.
 *//**
 * @brief Get the amount of free space in a message queue.
 *
 * This routine returns the number of unused entries in a message queue's
 * ring buffer.
 *
 * @param msgq Address of the message queue.
 *
 * @return Number of unused ring buffer entries.
 *//**
 * @brief Purge a message queue.
 *
 * This routine discards all unreceived messages in a message queue's ring
 * buffer. Any threads that are blocked waiting to send a message to the
 * message queue are unblocked and see an -ENOMSG error code.
 *
 * @param msgq Address of the message queue.
 *//**
 * @brief Peek/read a message from a message queue at the specified index
 *
 * This routine reads a message from message queue at the specified index
 * and leaves the message in the queue.
 * k_msgq_peek_at(msgq, data, 0) is equivalent to k_msgq_peek(msgq, data)
 *
 * @funcprops \isr_ok
 *
 * @param msgq Address of the message queue.
 * @param data Address of area to hold the message read from the queue.
 * @param idx Message queue index at which to peek
 *
 * @retval 0 Message read.
 * @retval -ENOMSG Returned when the queue has no message at index.
 *//**
 * @brief Peek/read a message from a message queue.
 *
 * This routine reads a message from message queue @a q in a "first in,
 * first out" manner and leaves the message in the queue.
 *
 * @funcprops \isr_ok
 *
 * @param msgq Address of the message queue.
 * @param data Address of area to hold the message read from the queue.
 *
 * @retval 0 Message read.
 * @retval -ENOMSG Returned when the queue has no message.
 *//**
 * @brief Receive a message from a message queue.
 *
 * This routine receives a message from message queue @a q in a "first in,
 * first out" manner.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param msgq Address of the message queue.
 * @param data Address of area to hold the received message.
 * @param timeout Waiting period to receive the message,
 *                or one of the special values K_NO_WAIT and
 *                K_FOREVER.
 *
 * @retval 0 Message received.
 * @retval -ENOMSG Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Send a message to a message queue.
 *
 * This routine sends a message to message queue @a q.
 *
 * @note The message content is copied from @a data into @a msgq and the @a data
 * pointer is not retained, so the message content will not be modified
 * by this function.
 *
 * @funcprops \isr_ok
 *
 * @param msgq Address of the message queue.
 * @param data Pointer to the message.
 * @param timeout Non-negative waiting period to add the message,
 *                or one of the special values K_NO_WAIT and
 *                K_FOREVER.
 *
 * @retval 0 Message sent.
 * @retval -ENOMSG Returned without waiting or queue purged.
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Release allocated buffer for a queue
 *
 * Releases memory allocated for the ring buffer.
 *
 * @param msgq message queue to cleanup
 *
 * @retval 0 on success
 * @retval -EBUSY Queue not empty
 *//**
 * @brief Initialize a message queue.
 *
 * This routine initializes a message queue object, prior to its first use,
 * allocating its internal ring buffer from the calling thread's resource
 * pool.
 *
 * Memory allocated for the ring buffer can be released by calling
 * k_msgq_cleanup(), or if userspace is enabled and the msgq object loses
 * all of its references.
 *
 * @param msgq Address of the message queue.
 * @param msg_size Message size (in bytes).
 * @param max_msgs Maximum number of messages that can be queued.
 *
 * @return 0 on success, -ENOMEM if there was insufficient memory in the
 *	thread's resource pool, or -EINVAL if the size parameters cause
 *	an integer overflow.
 *//**
 * @brief Initialize a message queue.
 *
 * This routine initializes a message queue object, prior to its first use.
 *
 * The message queue's ring buffer must contain space for @a max_msgs messages,
 * each of which is @a msg_size bytes long. Alignment of the message queue's
 * ring buffer is not necessary.
 *
 * @param msgq Address of the message queue.
 * @param buffer Pointer to ring buffer that holds queued messages.
 * @param msg_size Message size (in bytes).
 * @param max_msgs Maximum number of messages that can be queued.
 *//**
 * @brief Statically define and initialize a message queue.
 *
 * The message queue's ring buffer contains space for @a q_max_msgs messages,
 * each of which is @a q_msg_size bytes long. Alignment of the message queue's
 * ring buffer is not necessary, setting @a q_align to 1 is sufficient.
 *
 * The message queue can be accessed outside the module where it is defined
 * using:
 *
 * @code extern struct k_msgq <name>; @endcode
 *
 * @param q_name Name of the message queue.
 * @param q_msg_size Message size (in bytes).
 * @param q_max_msgs Maximum number of messages that can be queued.
 * @param q_align Alignment of the message queue's ring buffer (power of 2).
 *
 *//** Used messages *//** Maximal number of messages *//** Message Size *//**
 * @brief Message Queue Attributes
 *//** Message queue *//** Number of used messages *//** Write pointer *//** Read pointer *//** End of message buffer *//** Start of message buffer *//** Message size *//** Lock *//** Message queue wait queue *//**
 * @brief Message Queue Structure
 *//**
 * @defgroup msgq_apis Message Queue APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Cancel a triggered work item.
 *
 * This routine cancels the submission of triggered work item @a work.
 * A triggered work item can only be canceled if no event triggered work
 * submission.
 *
 * @funcprops \isr_ok
 *
 * @param work Address of delayed work item.
 *
 * @retval 0 Work item canceled.
 * @retval -EINVAL Work item is being processed or has completed its work.
 *//**
 * @brief Submit a triggered work item to the system workqueue.
 *
 * This routine schedules work item @a work to be processed by system
 * workqueue when one of the given @a events is signaled. The routine
 * initiates internal poller for the work item and then returns to the caller.
 * Only when one of the watched events happen the work item is actually
 * submitted to the workqueue and becomes pending.
 *
 * Submitting a previously submitted triggered work item that is still
 * waiting for the event cancels the existing submission and reschedules it
 * the using the new event list. Note that this behavior is inherently subject
 * to race conditions with the pre-existing triggered work item and work queue,
 * so care must be taken to synchronize such resubmissions externally.
 *
 * @funcprops \isr_ok
 *
 * @warning
 * Provided array of events as well as a triggered work item must not be
 * modified until the item has been processed by the workqueue.
 *
 * @param work Address of delayed work item.
 * @param events An array of events which trigger the work.
 * @param num_events The number of events in the array.
 * @param timeout Timeout after which the work will be scheduled
 *		  for execution even if not triggered.
 *
 * @retval 0 Work item started watching for events.
 * @retval -EINVAL Work item is being processed or has completed its work.
 * @retval -EADDRINUSE Work item is pending on a different workqueue.
 *//**
 * @brief Submit a triggered work item.
 *
 * This routine schedules work item @a work to be processed by workqueue
 * @a work_q when one of the given @a events is signaled. The routine
 * initiates internal poller for the work item and then returns to the caller.
 * Only when one of the watched events happen the work item is actually
 * submitted to the workqueue and becomes pending.
 *
 * Submitting a previously submitted triggered work item that is still
 * waiting for the event cancels the existing submission and reschedules it
 * the using the new event list. Note that this behavior is inherently subject
 * to race conditions with the pre-existing triggered work item and work queue,
 * so care must be taken to synchronize such resubmissions externally.
 *
 * @funcprops \isr_ok
 *
 * @warning
 * Provided array of events as well as a triggered work item must be placed
 * in persistent memory (valid until work handler execution or work
 * cancellation) and cannot be modified after submission.
 *
 * @param work_q Address of workqueue.
 * @param work Address of delayed work item.
 * @param events An array of events which trigger the work.
 * @param num_events The number of events in the array.
 * @param timeout Timeout after which the work will be scheduled
 *		  for execution even if not triggered.
 *
 *
 * @retval 0 Work item started watching for events.
 * @retval -EINVAL Work item is being processed or has completed its work.
 * @retval -EADDRINUSE Work item is pending on a different workqueue.
 *//**
 * @brief Initialize a triggered work item.
 *
 * This routine initializes a workqueue triggered work item, prior to
 * its first use.
 *
 * @param work Address of triggered work item.
 * @param handler Function to invoke each time work item is processed.
 *//**
 * @brief Initialize a statically-defined work item.
 *
 * This macro can be used to initialize a statically-defined workqueue work
 * item, prior to its first use. For example,
 *
 * @code static K_WORK_DEFINE(<work>, <work_handler>); @endcode
 *
 * @param work Symbol name for work item object
 * @param work_handler Function to invoke each time work item is processed.
 *//**
 * @addtogroup workqueue_apis
 * @{
 *//**
 * @brief Access the user mode thread that animates a work queue.
 *
 * This is necessary to grant a user mode work queue thread access to things
 * the work items it will process are expected to use.
 *
 * @param work_q pointer to the user mode queue structure.
 *
 * @return the user mode thread associated with the work queue.
 *//**
 * @brief Start a workqueue in user mode
 *
 * This works identically to k_work_queue_start() except it is callable from
 * user mode, and the worker thread created will run in user mode.  The caller
 * must have permissions granted on both the work_q parameter's thread and
 * queue objects, and the same restrictions on priority apply as
 * k_thread_create().
 *
 * @param work_q Address of workqueue.
 * @param stack Pointer to work queue thread's stack space, as defined by
 *		K_THREAD_STACK_DEFINE()
 * @param stack_size Size of the work queue thread's stack (in bytes), which
 *		should either be the same constant passed to
 *		K_THREAD_STACK_DEFINE() or the value of K_THREAD_STACK_SIZEOF().
 * @param prio Priority of the work queue's thread.
 * @param name optional thread name.  If not null a copy is made into the
 *		thread's name buffer.
 *//* Couldn't insert into the queue. Clear the pending bit
		 * so the work item can be submitted again
		 *//**
 * @brief Submit a work item to a user mode workqueue
 *
 * Submits a work item to a workqueue that runs in user mode. A temporary
 * memory allocation is made from the caller's resource pool which is freed
 * once the worker thread consumes the k_work item. The workqueue
 * thread must have memory access to the k_work item being submitted. The caller
 * must have permission granted on the work_q parameter's queue object.
 *
 * @funcprops \isr_ok
 *
 * @param work_q Address of workqueue.
 * @param work Address of work item.
 *
 * @retval -EBUSY if the work item was already in some workqueue
 * @retval -ENOMEM if no memory for thread resource pool allocation
 * @retval 0 Success
 *//**
 * @brief Check if a userspace work item is pending.
 *
 * This routine indicates if user work item @a work is pending in a workqueue's
 * queue.
 *
 * @note Checking if the work is pending gives no guarantee that the
 *       work will still be pending when this information is used. It is up to
 *       the caller to make sure that this information is used in a safe manner.
 *
 * @funcprops \isr_ok
 *
 * @param work Address of work item.
 *
 * @return true if work item is pending, or false if it is not pending.
 *//**
 * @brief Initialize a userspace work item.
 *
 * This routine initializes a user workqueue work item, prior to its
 * first use.
 *
 * @param work Address of work item.
 * @param handler Function to invoke each time work item is processed.
 *//**
 * @brief Initialize a statically-defined user work item.
 *
 * This macro can be used to initialize a statically-defined user work
 * item, prior to its first use. For example,
 *
 * @code static K_WORK_USER_DEFINE(<work>, <work_handler>); @endcode
 *
 * @param work Symbol name for work item object
 * @param work_handler Function to invoke each time work item is processed.
 *//* Used by k_queue implementation. *//* Work item pending state *//**
 * @typedef k_work_user_handler_t
 * @brief Work item handler function type for user work queues.
 *
 * A work item's handler function is executed by a user workqueue's thread
 * when the work item is processed by the workqueue.
 *
 * @param work Address of the work item.
 *//* Provide the implementation for inline functions declared above *//* Flags describing queue state. *//* Wait queue for threads waiting for the queue to drain. *//* Wait queue for idle work thread. *//* List of k_work items to be worked. *//* All the following fields must be accessed only while the
	 * work module spinlock is held.
	 *//* The thread that animates the work. *//** @brief A structure used to hold work until it can be processed. *//** Control whether the work queue thread should yield between
	 * items.
	 *
	 * Yielding between items helps guarantee the work queue
	 * thread does not starve other threads, including cooperative
	 * ones released by a work item.  This is the default behavior.
	 *
	 * Set this to @c true to prevent the work queue thread from
	 * yielding between items.  This may be appropriate when a
	 * sequence of items should complete without yielding
	 * control.
	 *//** The name to be given to the work queue thread.
	 *
	 * If left null the thread will not have a name.
	 *//** @brief A structure holding optional configuration items for a work
 * queue.
 *
 * This structure, and values it references, are not retained by
 * k_work_queue_start().
 *//** @brief A structure holding internal state for a pending synchronous
 * operation on a work item or queue.
 *
 * Instances of this type are provided by the caller for invocation of
 * k_work_flush(), k_work_cancel_sync() and sibling flush and cancel APIs.  A
 * referenced object must persist until the call returns, and be accessible
 * from both the caller thread and the work queue thread.
 *
 * @note If CONFIG_KERNEL_COHERENCE is enabled the object must be allocated in
 * coherent memory; see arch_mem_coherent().  The stack on these architectures
 * is generally not coherent.  be stack-allocated.  Violations are detected by
 * runtime assertion.
 *//* Record used to wait for work to complete a cancellation.
 *
 * The work item is inserted into a global queue of pending cancels.
 * When a cancelling work item goes idle any matching waiters are
 * removed from pending_cancels and are woken.
 *//* Record used to wait for work to flush.
 *
 * The work item is inserted into the queue that will process (or is
 * processing) the item, and will be processed as soon as the item
 * completes.  When the flusher is processed the semaphore will be
 * signaled, releasing the thread waiting for the flush.
 *//**
 * @brief Initialize a statically-defined delayable work item.
 *
 * This macro can be used to initialize a statically-defined delayable
 * work item, prior to its first use. For example,
 *
 * @code static K_WORK_DELAYABLE_DEFINE(<dwork>, <work_handler>); @endcode
 *
 * Note that if the runtime dependencies support initialization with
 * k_work_init_delayable() using that will eliminate the initialized
 * object in ROM that is produced by this macro and copied in at
 * system startup.
 *
 * @param work Symbol name for delayable work item object
 * @param work_handler Function to invoke each time work item is processed.
 *//* The queue to which the work should be submitted. *//* Timeout used to submit work after a delay. *//* The work item. *//** @brief A structure used to submit work after a delay. *//* State of the work item.
	 *
	 * The item can be DELAYED, QUEUED, and RUNNING simultaneously.
	 *
	 * It can be RUNNING and CANCELING simultaneously.
	 *//* The queue on which the work item was last submitted. *//* The function to be invoked by the work queue thread. *//* Node to link into k_work_q pending list. *//* All fields are protected by the work module spinlock.  No fields
	 * are to be accessed except through kernel API.
	 *//** @brief A structure used to submit work. *//** @brief Flag indicating a delayed work item that is scheduled for
	 * submission to a queue.
	 *
	 * Accessed via k_work_busy_get().  May co-occur with other flags.
	 *//** @brief Flag indicating a work item that has been submitted to a
	 * queue but has not started running.
	 *
	 * Accessed via k_work_busy_get().  May co-occur with other flags.
	 *//** @brief Flag indicating a work item that is being canceled.
	 *
	 * Accessed via k_work_busy_get().  May co-occur with other flags.
	 *//** @brief Flag indicating a work item that is running under a work
	 * queue thread.
	 *
	 * Accessed via k_work_busy_get().  May co-occur with other flags.
	 *//* Transient work flags *//* Static work queue flags *//* Dynamic work queue flags *//* Static work flags *//* Bits that represent the work item states.  At least nine of the
	 * combinations are distinct valid stable states.
	 *//* The atomic API is used for all work and queue flags fields to
	 * enforce sequential consistency in SMP environments.
	 *//** @brief Cancel delayable work and wait.
 *
 * Like k_work_cancel_delayable() but waits until the work becomes idle.
 *
 * @note Canceling delayable work does not prevent rescheduling it.  It does
 * prevent submitting it until the cancellation completes.
 *
 * @note Be careful of caller and work queue thread relative priority.  If
 * this function sleeps it will not return until the work queue thread
 * completes the tasks that allow this thread to resume.
 *
 * @note Behavior is undefined if this function is invoked on @p dwork from a
 * work queue running @p dwork.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @param sync pointer to an opaque item containing state related to the
 * pending cancellation.  The object must persist until the call returns, and
 * be accessible from both the caller thread and the work queue thread.  The
 * object must not be used for any other flush or cancel operation until this
 * one completes.  On architectures with CONFIG_KERNEL_COHERENCE the object
 * must be allocated in coherent memory.
 *
 * @retval true if work was not idle (call had to wait for cancellation of a
 * running handler to complete, or scheduled or submitted operations were
 * cancelled);
 * @retval false otherwise
 *//** @brief Cancel delayable work.
 *
 * Similar to k_work_cancel() but for delayable work.  If the work is
 * scheduled or submitted it is canceled.  This function does not wait for the
 * cancellation to complete.
 *
 * @note The work may still be running when this returns.  Use
 * k_work_flush_delayable() or k_work_cancel_delayable_sync() to ensure it is
 * not running.
 *
 * @note Canceling delayable work does not prevent rescheduling it.  It does
 * prevent submitting it until the cancellation completes.
 *
 * @funcprops \isr_ok
 *
 * @param dwork pointer to the delayable work item.
 *
 * @return the k_work_delayable_busy_get() status indicating the state of the
 * item after all cancellation steps performed by this call are completed.
 *//** @brief Flush delayable work.
 *
 * If the work is scheduled, it is immediately submitted.  Then the caller
 * blocks until the work completes, as with k_work_flush().
 *
 * @note Be careful of caller and work queue thread relative priority.  If
 * this function sleeps it will not return until the work queue thread
 * completes the tasks that allow this thread to resume.
 *
 * @note Behavior is undefined if this function is invoked on @p dwork from a
 * work queue running @p dwork.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @param sync pointer to an opaque item containing state related to the
 * pending cancellation.  The object must persist until the call returns, and
 * be accessible from both the caller thread and the work queue thread.  The
 * object must not be used for any other flush or cancel operation until this
 * one completes.  On architectures with CONFIG_KERNEL_COHERENCE the object
 * must be allocated in coherent memory.
 *
 * @retval true if call had to wait for completion
 * @retval false if work was already idle
 *//** @brief Reschedule a work item to the system work queue after a
 * delay.
 *
 * This is a thin wrapper around k_work_reschedule_for_queue(), with all the
 * API characteristics of that function.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @param delay the time to wait before submitting the work item.
 *
 * @return as with k_work_reschedule_for_queue().
 *//** @brief Reschedule a work item to a queue after a delay.
 *
 * Unlike k_work_schedule_for_queue() this function can change the deadline of
 * a scheduled work item, and will schedule a work item that is in any state
 * (e.g. is idle, submitted, or running).  This function does not affect
 * ("unsubmit") a work item that has been submitted to a queue.
 *
 * @funcprops \isr_ok
 *
 * @param queue the queue on which the work item should be submitted after the
 * delay.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @param delay the time to wait before submitting the work item.  If @c
 * K_NO_WAIT this is equivalent to k_work_submit_to_queue() after canceling
 * any previous scheduled submission.
 *
 * @note If delay is @c K_NO_WAIT ("no delay") the return values are as with
 * k_work_submit_to_queue().
 *
 * @retval 0 if delay is @c K_NO_WAIT and work was already on a queue
 * @retval 1 if
 * * delay is @c K_NO_WAIT and work was not submitted but has now been queued
 *   to @p queue; or
 * * delay not @c K_NO_WAIT and work has been scheduled
 * @retval 2 if delay is @c K_NO_WAIT and work was running and has been queued
 * to the queue that was running it
 * @retval -EBUSY if @p delay is @c K_NO_WAIT and
 *         k_work_submit_to_queue() fails with this code.
 * @retval -EINVAL if @p delay is @c K_NO_WAIT and
 *         k_work_submit_to_queue() fails with this code.
 * @retval -ENODEV if @p delay is @c K_NO_WAIT and
 *         k_work_submit_to_queue() fails with this code.
 *//** @brief Submit an idle work item to the system work queue after a
 * delay.
 *
 * This is a thin wrapper around k_work_schedule_for_queue(), with all the API
 * characteristics of that function.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @param delay the time to wait before submitting the work item.  If @c
 * K_NO_WAIT this is equivalent to k_work_submit_to_queue().
 *
 * @return as with k_work_schedule_for_queue().
 *//** @brief Submit an idle work item to a queue after a delay.
 *
 * Unlike k_work_reschedule_for_queue() this is a no-op if the work item is
 * already scheduled or submitted, even if @p delay is @c K_NO_WAIT.
 *
 * @funcprops \isr_ok
 *
 * @param queue the queue on which the work item should be submitted after the
 * delay.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @param delay the time to wait before submitting the work item.  If @c
 * K_NO_WAIT and the work is not pending this is equivalent to
 * k_work_submit_to_queue().
 *
 * @retval 0 if work was already scheduled or submitted.
 * @retval 1 if work has been scheduled.
 * @retval -EBUSY if @p delay is @c K_NO_WAIT and
 *         k_work_submit_to_queue() fails with this code.
 * @retval -EINVAL if @p delay is @c K_NO_WAIT and
 *         k_work_submit_to_queue() fails with this code.
 * @retval -ENODEV if @p delay is @c K_NO_WAIT and
 *         k_work_submit_to_queue() fails with this code.
 *//** @brief Get the number of ticks until a scheduled delayable work will be
 * submitted.
 *
 * @note This is a live snapshot of state, which may change before the result
 * can be inspected.  Use locks where appropriate.
 *
 * @funcprops \isr_ok
 *
 * @param dwork pointer to the delayable work item.
 *
 * @return the number of ticks until the timer that will schedule the work
 * item will expire, or zero if the item is not scheduled.
 *//** @brief Get the absolute tick count at which a scheduled delayable work
 * will be submitted.
 *
 * @note This is a live snapshot of state, which may change before the result
 * can be inspected.  Use locks where appropriate.
 *
 * @funcprops \isr_ok
 *
 * @param dwork pointer to the delayable work item.
 *
 * @return the tick count when the timer that will schedule the work item will
 * expire, or the current tick count if the work is not scheduled.
 *//** @brief Test whether a delayed work item is currently pending.
 *
 * Wrapper to determine whether a delayed work item is in a non-idle state.
 *
 * @note This is a live snapshot of state, which may change before the result
 * can be inspected.  Use locks where appropriate.
 *
 * @funcprops \isr_ok
 *
 * @param dwork pointer to the delayable work item.
 *
 * @return true if and only if k_work_delayable_busy_get() returns a non-zero
 * value.
 *//** @brief Busy state flags from the delayable work item.
 *
 * @funcprops \isr_ok
 *
 * @note This is a live snapshot of state, which may change before the result
 * can be inspected.  Use locks where appropriate.
 *
 * @param dwork pointer to the delayable work item.
 *
 * @return a mask of flags K_WORK_DELAYED, K_WORK_QUEUED, K_WORK_RUNNING, and
 * K_WORK_CANCELING.  A zero return value indicates the work item appears to
 * be idle.
 *//**
 * @brief Get the parent delayable work structure from a work pointer.
 *
 * This function is necessary when a @c k_work_handler_t function is passed to
 * k_work_schedule_for_queue() and the handler needs to access data from the
 * container of the containing `k_work_delayable`.
 *
 * @param work Address passed to the work handler
 *
 * @return Address of the containing @c k_work_delayable structure.
 *//** @brief Initialize a delayable work structure.
 *
 * This must be invoked before scheduling a delayable work structure for the
 * first time.  It need not be invoked again on the same work structure.  It
 * can be re-invoked to change the associated handler, but this must be done
 * when the work item is idle.
 *
 * @funcprops \isr_ok
 *
 * @param dwork the delayable work structure to be initialized.
 *
 * @param handler the handler to be invoked by the work item.
 *//** @brief Release a work queue to accept new submissions.
 *
 * This releases the block on new submissions placed when k_work_queue_drain()
 * is invoked with the @p plug option enabled.  If this is invoked before the
 * drain completes new items may be submitted as soon as the drain completes.
 *
 * @funcprops \isr_ok
 *
 * @param queue pointer to the queue structure.
 *
 * @retval 0 if successfully unplugged
 * @retval -EALREADY if the work queue was not plugged.
 *//** @brief Wait until the work queue has drained, optionally plugging it.
 *
 * This blocks submission to the work queue except when coming from queue
 * thread, and blocks the caller until no more work items are available in the
 * queue.
 *
 * If @p plug is true then submission will continue to be blocked after the
 * drain operation completes until k_work_queue_unplug() is invoked.
 *
 * Note that work items that are delayed are not yet associated with their
 * work queue.  They must be cancelled externally if a goal is to ensure the
 * work queue remains empty.  The @p plug feature can be used to prevent
 * delayed items from being submitted after the drain completes.
 *
 * @param queue pointer to the queue structure.
 *
 * @param plug if true the work queue will continue to block new submissions
 * after all items have drained.
 *
 * @retval 1 if call had to wait for the drain to complete
 * @retval 0 if call did not have to wait
 * @retval negative if wait was interrupted or failed
 *//** @brief Access the thread that animates a work queue.
 *
 * This is necessary to grant a work queue thread access to things the work
 * items it will process are expected to use.
 *
 * @param queue pointer to the queue structure.
 *
 * @return the thread associated with the work queue.
 *//** @brief Initialize a work queue.
 *
 * This configures the work queue thread and starts it running.  The function
 * should not be re-invoked on a queue.
 *
 * @param queue pointer to the queue structure. It must be initialized
 *        in zeroed/bss memory or with @ref k_work_queue_init before
 *        use.
 *
 * @param stack pointer to the work thread stack area.
 *
 * @param stack_size size of the the work thread stack area, in bytes.
 *
 * @param prio initial thread priority
 *
 * @param cfg optional additional configuration parameters.  Pass @c
 * NULL if not required, to use the defaults documented in
 * k_work_queue_config.
 *//** @brief Initialize a work queue structure.
 *
 * This must be invoked before starting a work queue structure for the first time.
 * It need not be invoked again on the same work queue structure.
 *
 * @funcprops \isr_ok
 *
 * @param queue the queue structure to be initialized.
 *//** @brief Cancel a work item and wait for it to complete.
 *
 * Same as k_work_cancel() but does not return until cancellation is complete.
 * This can be invoked by a thread after k_work_cancel() to synchronize with a
 * previous cancellation.
 *
 * On return the work structure will be idle unless something submits it after
 * the cancellation was complete.
 *
 * @note Be careful of caller and work queue thread relative priority.  If
 * this function sleeps it will not return until the work queue thread
 * completes the tasks that allow this thread to resume.
 *
 * @note Behavior is undefined if this function is invoked on @p work from a
 * work queue running @p work.
 *
 * @param work pointer to the work item.
 *
 * @param sync pointer to an opaque item containing state related to the
 * pending cancellation.  The object must persist until the call returns, and
 * be accessible from both the caller thread and the work queue thread.  The
 * object must not be used for any other flush or cancel operation until this
 * one completes.  On architectures with CONFIG_KERNEL_COHERENCE the object
 * must be allocated in coherent memory.
 *
 * @retval true if work was pending (call had to wait for cancellation of a
 * running handler to complete, or scheduled or submitted operations were
 * cancelled);
 * @retval false otherwise
 *//** @brief Cancel a work item.
 *
 * This attempts to prevent a pending (non-delayable) work item from being
 * processed by removing it from the work queue.  If the item is being
 * processed, the work item will continue to be processed, but resubmissions
 * are rejected until cancellation completes.
 *
 * If this returns zero cancellation is complete, otherwise something
 * (probably a work queue thread) is still referencing the item.
 *
 * See also k_work_cancel_sync().
 *
 * @funcprops \isr_ok
 *
 * @param work pointer to the work item.
 *
 * @return the k_work_busy_get() status indicating the state of the item after all
 * cancellation steps performed by this call are completed.
 *//** @brief Wait for last-submitted instance to complete.
 *
 * Resubmissions may occur while waiting, including chained submissions (from
 * within the handler).
 *
 * @note Be careful of caller and work queue thread relative priority.  If
 * this function sleeps it will not return until the work queue thread
 * completes the tasks that allow this thread to resume.
 *
 * @note Behavior is undefined if this function is invoked on @p work from a
 * work queue running @p work.
 *
 * @param work pointer to the work item.
 *
 * @param sync pointer to an opaque item containing state related to the
 * pending cancellation.  The object must persist until the call returns, and
 * be accessible from both the caller thread and the work queue thread.  The
 * object must not be used for any other flush or cancel operation until this
 * one completes.  On architectures with CONFIG_KERNEL_COHERENCE the object
 * must be allocated in coherent memory.
 *
 * @retval true if call had to wait for completion
 * @retval false if work was already idle
 *//** @brief Submit a work item to the system queue.
 *
 * @funcprops \isr_ok
 *
 * @param work pointer to the work item.
 *
 * @return as with k_work_submit_to_queue().
 *//** @brief Submit a work item to a queue.
 *
 * @param queue pointer to the work queue on which the item should run.  If
 * NULL the queue from the most recent submission will be used.
 *
 * @funcprops \isr_ok
 *
 * @param work pointer to the work item.
 *
 * @retval 0 if work was already submitted to a queue
 * @retval 1 if work was not submitted and has been queued to @p queue
 * @retval 2 if work was running and has been queued to the queue that was
 * running it
 * @retval -EBUSY
 * * if work submission was rejected because the work item is cancelling; or
 * * @p queue is draining; or
 * * @p queue is plugged.
 * @retval -EINVAL if @p queue is null and the work item has never been run.
 * @retval -ENODEV if @p queue has not been started.
 *//** @brief Test whether a work item is currently pending.
 *
 * Wrapper to determine whether a work item is in a non-idle dstate.
 *
 * @note This is a live snapshot of state, which may change before the result
 * is checked.  Use locks where appropriate.
 *
 * @funcprops \isr_ok
 *
 * @param work pointer to the work item.
 *
 * @return true if and only if k_work_busy_get() returns a non-zero value.
 *//** @brief Busy state flags from the work item.
 *
 * A zero return value indicates the work item appears to be idle.
 *
 * @note This is a live snapshot of state, which may change before the result
 * is checked.  Use locks where appropriate.
 *
 * @funcprops \isr_ok
 *
 * @param work pointer to the work item.
 *
 * @return a mask of flags K_WORK_DELAYED, K_WORK_QUEUED,
 * K_WORK_RUNNING, and K_WORK_CANCELING.
 *//** @brief Initialize a (non-delayable) work structure.
 *
 * This must be invoked before submitting a work structure for the first time.
 * It need not be invoked again on the same work structure.  It can be
 * re-invoked to change the associated handler, but this must be done when the
 * work item is idle.
 *
 * @funcprops \isr_ok
 *
 * @param work the work structure to be initialized.
 *
 * @param handler the handler to be invoked by the work item.
 *//** @brief The signature for a work item handler function.
 *
 * The function will be invoked by the thread animating a work queue.
 *
 * @param work the work item that provided the handler.
 *//**
 * @defgroup workqueue_apis Work Queue APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Statically define and initialize a semaphore.
 *
 * The semaphore can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_sem <name>; @endcode
 *
 * @param name Name of the semaphore.
 * @param initial_count Initial semaphore count.
 * @param count_limit Maximum permitted semaphore count.
 *//**
 * @brief Get a semaphore's count.
 *
 * This routine returns the current count of @a sem.
 *
 * @param sem Address of the semaphore.
 *
 * @return Current semaphore count.
 *//**
 * @brief Resets a semaphore's count to zero.
 *
 * This routine sets the count of @a sem to zero.
 * Any outstanding semaphore takes will be aborted
 * with -EAGAIN.
 *
 * @param sem Address of the semaphore.
 *//**
 * @brief Give a semaphore.
 *
 * This routine gives @a sem, unless the semaphore is already at its maximum
 * permitted count.
 *
 * @funcprops \isr_ok
 *
 * @param sem Address of the semaphore.
 *//**
 * @brief Take a semaphore.
 *
 * This routine takes @a sem.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param sem Address of the semaphore.
 * @param timeout Waiting period to take the semaphore,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 Semaphore taken.
 * @retval -EBUSY Returned without waiting.
 * @retval -EAGAIN Waiting period timed out,
 *			or the semaphore was reset during the waiting period.
 *//**
 * @brief Initialize a semaphore.
 *
 * This routine initializes a semaphore object, prior to its first use.
 *
 * @param sem Address of the semaphore.
 * @param initial_count Initial semaphore count.
 * @param limit Maximum permitted semaphore count.
 *
 * @see K_SEM_MAX_LIMIT
 *
 * @retval 0 Semaphore created successfully
 * @retval -EINVAL Invalid values
 *
 *//**
 * @brief Maximum limit value allowed for a semaphore.
 *
 * This is intended for use when a semaphore does not have
 * an explicit maximum limit, and instead is just used for
 * counting purposes.
 *
 *//**
 * @defgroup semaphore_apis Semaphore APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Statically define and initialize a condition variable.
 *
 * The condition variable can be accessed outside the module where it is
 * defined using:
 *
 * @code extern struct k_condvar <name>; @endcode
 *
 * @param name Name of the condition variable.
 *//**
 * @brief Waits on the condition variable releasing the mutex lock
 *
 * Atomically releases the currently owned mutex, blocks the current thread
 * waiting on the condition variable specified by @a condvar,
 * and finally acquires the mutex again.
 *
 * The waiting thread unblocks only after another thread calls
 * k_condvar_signal, or k_condvar_broadcast with the same condition variable.
 *
 * @param condvar pointer to a @p k_condvar structure
 * @param mutex Address of the mutex.
 * @param timeout Waiting period for the condition variable
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 * @retval 0 On success
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Unblock all threads that are pending on the condition
 * variable
 *
 * @param condvar pointer to a @p k_condvar structure
 * @return An integer with number of woken threads on success
 *//**
 * @brief Signals one thread that is pending on the condition variable
 *
 * @param condvar pointer to a @p k_condvar structure
 * @retval 0 On success
 *//**
 * @brief Initialize a condition variable
 *
 * @param condvar pointer to a @p k_condvar structure
 * @retval 0 Condition variable created successfully
 *//**
 * @defgroup condvar_apis Condition Variables APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Unlock a mutex.
 *
 * This routine unlocks @a mutex. The mutex must already be locked by the
 * calling thread.
 *
 * The mutex cannot be claimed by another thread until it has been unlocked by
 * the calling thread as many times as it was previously locked by that
 * thread.
 *
 * Mutexes may not be unlocked in ISRs, as mutexes must only be manipulated
 * in thread context due to ownership and priority inheritance semantics.
 *
 * @param mutex Address of the mutex.
 *
 * @retval 0 Mutex unlocked.
 * @retval -EPERM The current thread does not own the mutex
 * @retval -EINVAL The mutex is not locked
 *
 *//**
 * @brief Lock a mutex.
 *
 * This routine locks @a mutex. If the mutex is locked by another thread,
 * the calling thread waits until the mutex becomes available or until
 * a timeout occurs.
 *
 * A thread is permitted to lock a mutex it has already locked. The operation
 * completes immediately and the lock count is increased by 1.
 *
 * Mutexes may not be locked in ISRs.
 *
 * @param mutex Address of the mutex.
 * @param timeout Waiting period to lock the mutex,
 *                or one of the special values K_NO_WAIT and
 *                K_FOREVER.
 *
 * @retval 0 Mutex locked.
 * @retval -EBUSY Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Initialize a mutex.
 *
 * This routine initializes a mutex object, prior to its first use.
 *
 * Upon completion, the mutex is available and does not have an owner.
 *
 * @param mutex Address of the mutex.
 *
 * @retval 0 Mutex object created
 *
 *//**
 * @brief Statically define and initialize a mutex.
 *
 * The mutex can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_mutex <name>; @endcode
 *
 * @param name Name of the mutex.
 *//** Original thread priority *//** Current lock count *//** Mutex owner *//** Mutex wait queue *//**
 * Mutex Structure
 * @ingroup mutex_apis
 *//**
 * @defgroup mutex_apis Mutex APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Statically define and initialize a stack
 *
 * The stack can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_stack <name>; @endcode
 *
 * @param name Name of the stack.
 * @param stack_num_entries Maximum number of values that can be stacked.
 *//**
 * @brief Pop an element from a stack.
 *
 * This routine removes a stack_data_t value from @a stack in a "last in,
 * first out" manner and stores the value in @a data.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param stack Address of the stack.
 * @param data Address of area to hold the value popped from the stack.
 * @param timeout Waiting period to obtain a value,
 *                or one of the special values K_NO_WAIT and
 *                K_FOREVER.
 *
 * @retval 0 Element popped from stack.
 * @retval -EBUSY Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 *//**
 * @brief Push an element onto a stack.
 *
 * This routine adds a stack_data_t value @a data to @a stack.
 *
 * @funcprops \isr_ok
 *
 * @param stack Address of the stack.
 * @param data Value to push onto the stack.
 *
 * @retval 0 on success
 * @retval -ENOMEM if stack is full
 *//**
 * @brief Release a stack's allocated buffer
 *
 * If a stack object was given a dynamically allocated buffer via
 * k_stack_alloc_init(), this will free it. This function does nothing
 * if the buffer wasn't dynamically allocated.
 *
 * @param stack Address of the stack.
 * @retval 0 on success
 * @retval -EAGAIN when object is still in use
 *//**
 * @brief Initialize a stack.
 *
 * This routine initializes a stack object, prior to its first use. Internal
 * buffers will be allocated from the calling thread's resource pool.
 * This memory will be released if k_stack_cleanup() is called, or
 * userspace is enabled and the stack object loses all references to it.
 *
 * @param stack Address of the stack.
 * @param num_entries Maximum number of values that can be stacked.
 *
 * @return -ENOMEM if memory couldn't be allocated
 *//**
 * @brief Initialize a stack.
 *
 * This routine initializes a stack object, prior to its first use.
 *
 * @param stack Address of the stack.
 * @param buffer Address of array used to hold stacked values.
 * @param num_entries Maximum number of values that can be stacked.
 *//**
 * @defgroup stack_apis Stack APIs
 * @ingroup kernel_apis
 * @{
 *//* Buffer was allocated *//**
 * @brief Statically define and initialize a LIFO queue.
 *
 * The LIFO queue can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_lifo <name>; @endcode
 *
 * @param name Name of the fifo.
 *//**
 * @brief Get an element from a LIFO queue.
 *
 * This routine removes a data item from @a LIFO in a "last in, first out"
 * manner. The first word of the data item is reserved for the kernel's use.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param lifo Address of the LIFO queue.
 * @param timeout Waiting period to obtain a data item,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @return Address of the data item if successful; NULL if returned
 * without waiting, or waiting period timed out.
 *//**
 * @brief Add an element to a LIFO queue.
 *
 * This routine adds a data item to @a lifo. There is an implicit memory
 * allocation to create an additional temporary bookkeeping data structure from
 * the calling thread's resource pool, which is automatically freed when the
 * item is removed. The data itself is not copied.
 *
 * @funcprops \isr_ok
 *
 * @param lifo Address of the LIFO.
 * @param data Address of the data item.
 *
 * @retval 0 on success
 * @retval -ENOMEM if there isn't sufficient RAM in the caller's resource pool
 *//**
 * @brief Add an element to a LIFO queue.
 *
 * This routine adds a data item to @a lifo. A LIFO queue data item must be
 * aligned on a word boundary, and the first word of the item is
 * reserved for the kernel's use.
 *
 * @funcprops \isr_ok
 *
 * @param lifo Address of the LIFO queue.
 * @param data Address of the data item.
 *//**
 * @brief Initialize a LIFO queue.
 *
 * This routine initializes a LIFO queue object, prior to its first use.
 *
 * @param lifo Address of the LIFO queue.
 *//**
 * @defgroup lifo_apis LIFO APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Statically define and initialize a FIFO queue.
 *
 * The FIFO queue can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_fifo <name>; @endcode
 *
 * @param name Name of the FIFO queue.
 *//**
 * @brief Peek element at the tail of FIFO queue.
 *
 * Return element from the tail of FIFO queue (without removing it). A usecase
 * for this is if elements of the FIFO queue are themselves containers. Then
 * it may be useful to add more data to the last container in a FIFO queue.
 *
 * @param fifo Address of the FIFO queue.
 *
 * @return Tail element, or NULL if a FIFO queue is empty.
 *//**
 * @brief Peek element at the head of a FIFO queue.
 *
 * Return element from the head of FIFO queue without removing it. A usecase
 * for this is if elements of the FIFO object are themselves containers. Then
 * on each iteration of processing, a head container will be peeked,
 * and some data processed out of it, and only if the container is empty,
 * it will be completely remove from the FIFO queue.
 *
 * @param fifo Address of the FIFO queue.
 *
 * @return Head element, or NULL if the FIFO queue is empty.
 *//**
 * @brief FIFO
 *
 *  @a fifo 
 *
 * @note ISR@a timeout  K_NO_WAIT
 *
 * @funcprops \isr_ok
 *
 * @param fifo FIFO
 * @param timeout  K_NO_WAIT  K_FOREVER
 *
 * @return NULL
 *//**
 * @brief Query a FIFO queue to see if it has data available.
 *
 * Note that the data might be already gone by the time this function returns
 * if other threads is also trying to read from the FIFO.
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO queue.
 *
 * @return Non-zero if the FIFO queue is empty.
 * @return 0 if data is available.
 *//**
 * @brief Get an element from a FIFO queue.
 *
 * This routine removes a data item from @a fifo in a "first in, first out"
 * manner. The first word of the data item is reserved for the kernel's use.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO queue.
 * @param timeout Waiting period to obtain a data item,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @return Address of the data item if successful; NULL if returned
 * without waiting, or waiting period timed out.
 *//**
 * @brief Atomically add a list of elements to a FIFO queue.
 *
 * This routine adds a list of data items to @a fifo in one operation.
 * The data items must be in a singly-linked list implemented using a
 * sys_slist_t object. Upon completion, the sys_slist_t object is invalid
 * and must be re-initialized via sys_slist_init().
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO queue.
 * @param list Pointer to sys_slist_t object.
 *//**
 * @brief Atomically add a list of elements to a FIFO.
 *
 * This routine adds a list of data items to @a fifo in one operation.
 * The data items must be in a singly-linked list, with the first word of
 * each data item pointing to the next data item; the list must be
 * NULL-terminated.
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO queue.
 * @param head Pointer to first node in singly-linked list.
 * @param tail Pointer to last node in singly-linked list.
 *//**
 * @brief Add an element to a FIFO queue.
 *
 * This routine adds a data item to @a fifo. There is an implicit memory
 * allocation to create an additional temporary bookkeeping data structure from
 * the calling thread's resource pool, which is automatically freed when the
 * item is removed. The data itself is not copied.
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO.
 * @param data Address of the data item.
 *
 * @retval 0 on success
 * @retval -ENOMEM if there isn't sufficient RAM in the caller's resource pool
 *//**
 * @brief Add an element to a FIFO queue.
 *
 * This routine adds a data item to @a fifo. A FIFO data item must be
 * aligned on a word boundary, and the first word of the item is reserved
 * for the kernel's use.
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO.
 * @param data Address of the data item.
 *//**
 * @brief Cancel waiting on a FIFO queue.
 *
 * This routine causes first thread pending on @a fifo, if any, to
 * return from k_fifo_get() call with NULL value (as if timeout
 * expired).
 *
 * @funcprops \isr_ok
 *
 * @param fifo Address of the FIFO queue.
 *//**
 * @brief Initialize a FIFO queue.
 *
 * This routine initializes a FIFO queue, prior to its first use.
 *
 * @param fifo Address of the FIFO queue.
 *//**
 * @defgroup fifo_apis FIFO APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Statically define and initialize an event object
 *
 * The event can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_event <name>; @endcode
 *
 * @param name Name of the event object.
 *//**
 * @brief Test the events currently tracked in the event object
 *
 * @param event Address of the event object
 * @param events_mask Set of desired events to test
 *
 * @retval Current value of events in @a events_mask
 *//**
 * @brief Wait for all of the specified events
 *
 * This routine waits on event object @a event until all of the specified
 * events have been delivered to the event object, or the maximum wait time
 * @a timeout has expired. A thread may wait on up to 32 distinctly numbered
 * events that are expressed as bits in a single 32-bit word.
 *
 * @note The caller must be careful when resetting if there are multiple threads
 * waiting for the event object @a event.
 *
 * @param event Address of the event object
 * @param events Set of desired events on which to wait
 * @param reset If true, clear the set of events tracked by the event object
 *              before waiting. If false, do not clear the events.
 * @param timeout Waiting period for the desired set of events or one of the
 *                special values K_NO_WAIT and K_FOREVER.
 *
 * @retval set of matching events upon success
 * @retval 0 if matching events were not received within the specified time
 *//**
 * @brief Wait for any of the specified events
 *
 * This routine waits on event object @a event until any of the specified
 * events have been delivered to the event object, or the maximum wait time
 * @a timeout has expired. A thread may wait on up to 32 distinctly numbered
 * events that are expressed as bits in a single 32-bit word.
 *
 * @note The caller must be careful when resetting if there are multiple threads
 * waiting for the event object @a event.
 *
 * @param event Address of the event object
 * @param events Set of desired events on which to wait
 * @param reset If true, clear the set of events tracked by the event object
 *              before waiting. If false, do not clear the events.
 * @param timeout Waiting period for the desired set of events or one of the
 *                special values K_NO_WAIT and K_FOREVER.
 *
 * @retval set of matching events upon success
 * @retval 0 if matching events were not received within the specified time
 *//**
 * @brief Clear the events in an event object
 *
 * This routine clears (resets) the specified events stored in an event object.
 *
 * @param event Address of the event object
 * @param events Set of events to clear in @a event
 *
 * @retval Previous value of the events in @a event
 *//**
 * @brief Set or clear the events in an event object
 *
 * This routine sets the events stored in event object to the specified value.
 * All tasks waiting on the event object @a event whose waiting conditions
 * become met by this immediately unpend. Unlike @ref k_event_set, this routine
 * allows specific event bits to be set and cleared as determined by the mask.
 *
 * @param event Address of the event object
 * @param events Set of events to set/clear in @a event
 * @param events_mask Mask to be applied to @a events
 *
 * @retval Previous value of the events in @a events_mask
 *//**
 * @brief Set the events in an event object
 *
 * This routine sets the events stored in event object to the specified value.
 * All tasks waiting on the event object @a event whose waiting conditions
 * become met by this immediately unpend.
 *
 * Setting differs from posting in that set events replace the current set of
 * events tracked by the event object.
 *
 * @param event Address of the event object
 * @param events Set of events to set in @a event
 *
 * @retval Previous value of the events in @a event
 *//**
 * @brief Post one or more events to an event object
 *
 * This routine posts one or more events to an event object. All tasks waiting
 * on the event object @a event whose waiting conditions become met by this
 * posting immediately unpend.
 *
 * Posting differs from setting in that posted events are merged together with
 * the current set of events tracked by the event object.
 *
 * @param event Address of the event object
 * @param events Set of events to post to @a event
 *
 * @retval Previous value of the events in @a event
 *//**
 * @brief Initialize an event object
 *
 * This routine initializes an event object, prior to its first use.
 *
 * @param event Address of the event object.
 *//**
 * Event Structure
 * @ingroup event_apis
 *//**
 * @defgroup event_apis Event APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Wake one/all threads pending on a futex
 *
 * Wake up the highest priority thread pending on the supplied futex, or
 * wakeup all the threads pending on the supplied futex, and the behavior
 * depends on wake_all.
 *
 * @param futex Futex to wake up pending threads.
 * @param wake_all If true, wake up all pending threads; If false,
 *                 wakeup the highest priority thread.
 * @retval -EACCES Caller does not have access to the futex address.
 * @retval -EINVAL Futex parameter address not recognized by the kernel.
 * @retval Number of threads that were woken up.
 *//**
 * @brief Pend the current thread on a futex
 *
 * Tests that the supplied futex contains the expected value, and if so,
 * goes to sleep until some other thread calls k_futex_wake() on it.
 *
 * @param futex Address of the futex.
 * @param expected Expected value of the futex, if it is different the caller
 *		   will not wait on it.
 * @param timeout Non-negative waiting period on the futex, or
 *		  one of the special values K_NO_WAIT or K_FOREVER.
 * @retval -EACCES Caller does not have read access to futex address.
 * @retval -EAGAIN If the futex value did not match the expected parameter.
 * @retval -EINVAL Futex parameter address not recognized by the kernel.
 * @retval -ETIMEDOUT Thread woke up due to timeout and not a futex wakeup.
 * @retval 0 if the caller went to sleep and was woken up. The caller
 *	     should check the futex's value on wakeup to determine if it needs
 *	     to block again.
 *//**
 * @defgroup futex_apis FUTEX APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief futex kernel data structure
 *
 * z_futex_data are the helper data structure for k_futex to complete
 * futex contended operation on kernel side, structure z_futex_data
 * of every futex object is invisible in user mode.
 *//**
 * @brief futex structure
 *
 * A k_futex is a lightweight mutual exclusion primitive designed
 * to minimize kernel involvement. Uncontended operation relies
 * only on atomic access to shared memory. k_futex are tracked as
 * kernel objects and can live in user memory so that any access
 * bypasses the kernel object permission management mechanism.
 *//**
 * @brief Statically define and initialize a queue.
 *
 * The queue can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_queue <name>; @endcode
 *
 * @param name Name of the queue.
 *//**
 * @brief Peek element at the tail of queue.
 *
 * Return element from the tail of queue without removing it.
 *
 * @param queue Address of the queue.
 *
 * @return Tail element, or NULL if queue is empty.
 *//**
 * @brief Peek element at the head of queue.
 *
 * Return element from the head of queue without removing it.
 *
 * @param queue Address of the queue.
 *
 * @return Head element, or NULL if queue is empty.
 *//**
 * @brief Query a queue to see if it has data available.
 *
 * Note that the data might be already gone by the time this function returns
 * if other threads are also trying to read from the queue.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 *
 * @return Non-zero if the queue is empty.
 * @return 0 if data is available.
 *//**
 * @brief Append an element to a queue only if it's not present already.
 *
 * This routine appends data item to @a queue. The first word of the data
 * item is reserved for the kernel's use. Appending elements to k_queue
 * relies on sys_slist_is_node_in_list which is not a constant time operation.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param data Address of the data item.
 *
 * @return true if data item was added, false if not
 *//**
 * @brief Remove an element from a queue.
 *
 * This routine removes data item from @a queue. The first word of the
 * data item is reserved for the kernel's use. Removing elements from k_queue
 * rely on sys_slist_find_and_remove which is not a constant time operation.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param data Address of the data item.
 *
 * @return true if data item was removed
 *//**
 * @brief Get an element from a queue.
 *
 * This routine removes first data item from @a queue. The first word of the
 * data item is reserved for the kernel's use.
 *
 * @note @a timeout must be set to K_NO_WAIT if called from ISR.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param timeout Non-negative waiting period to obtain a data item
 *                or one of the special values K_NO_WAIT and
 *                K_FOREVER.
 *
 * @return Address of the data item if successful; NULL if returned
 * without waiting, or waiting period timed out.
 *//**
 * @brief Atomically add a list of elements to a queue.
 *
 * This routine adds a list of data items to @a queue in one operation.
 * The data items must be in a singly-linked list implemented using a
 * sys_slist_t object. Upon completion, the original list is empty.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param list Pointer to sys_slist_t object.
 *
 * @retval 0 on success
 * @retval -EINVAL on invalid data
 *//**
 * @brief Atomically append a list of elements to a queue.
 *
 * This routine adds a list of data items to @a queue in one operation.
 * The data items must be in a singly-linked list, with the first word
 * in each data item pointing to the next data item; the list must be
 * NULL-terminated.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param head Pointer to first node in singly-linked list.
 * @param tail Pointer to last node in singly-linked list.
 *
 * @retval 0 on success
 * @retval -EINVAL on invalid supplied data
 *
 *//**
 * @brief Inserts an element to a queue.
 *
 * This routine inserts a data item to @a queue after previous item. A queue
 * data item must be aligned on a word boundary, and the first word of
 * the item is reserved for the kernel's use.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param prev Address of the previous data item.
 * @param data Address of the data item.
 *//**
 * @brief Prepend an element to a queue.
 *
 * This routine prepends a data item to @a queue. There is an implicit memory
 * allocation to create an additional temporary bookkeeping data structure from
 * the calling thread's resource pool, which is automatically freed when the
 * item is removed. The data itself is not copied.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param data Address of the data item.
 *
 * @retval 0 on success
 * @retval -ENOMEM if there isn't sufficient RAM in the caller's resource pool
 *//**
 * @brief Prepend an element to a queue.
 *
 * This routine prepends a data item to @a queue. A queue data item must be
 * aligned on a word boundary, and the first word of the item is reserved
 * for the kernel's use.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param data Address of the data item.
 *//**
 * @brief Append an element to a queue.
 *
 * This routine appends a data item to @a queue. There is an implicit memory
 * allocation to create an additional temporary bookkeeping data structure from
 * the calling thread's resource pool, which is automatically freed when the
 * item is removed. The data itself is not copied.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param data Address of the data item.
 *
 * @retval 0 on success
 * @retval -ENOMEM if there isn't sufficient RAM in the caller's resource pool
 *//**
 * @brief Append an element to the end of a queue.
 *
 * This routine appends a data item to @a queue. A queue data item must be
 * aligned on a word boundary, and the first word of the item is reserved
 * for the kernel's use.
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 * @param data Address of the data item.
 *//**
 * @brief Cancel waiting on a queue.
 *
 * This routine causes first thread pending on @a queue, if any, to
 * return from k_queue_get() call with NULL value (as if timeout expired).
 * If the queue is being waited on by k_poll(), it will return with
 * -EINTR and K_POLL_STATE_CANCELLED state (and per above, subsequent
 * k_queue_get() will return NULL).
 *
 * @funcprops \isr_ok
 *
 * @param queue Address of the queue.
 *//**
 * @brief Initialize a queue.
 *
 * This routine initializes a queue object, prior to its first use.
 *
 * @param queue Address of the queue.
 *//**
 * @defgroup queue_apis Queue APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Read the 64-bit hardware clock.
 *
 * This routine returns the current time in 64-bits, as measured by the
 * system's hardware clock, if available.
 *
 * @see CONFIG_TIMER_HAS_64BIT_CYCLE_COUNTER
 *
 * @return Current hardware clock up-counter (in cycles).
 *//**
 * @brief Read the hardware clock.
 *
 * This routine returns the current time, as measured by the system's hardware
 * clock.
 *
 * @return Current hardware clock up-counter (in cycles).
 *//**
 * @brief Get elapsed time.
 *
 * This routine computes the elapsed time between the current system uptime
 * and an earlier reference time, in milliseconds.
 *
 * @param reftime Pointer to a reference time, which is updated to the current
 *                uptime upon return.
 *
 * @return Elapsed time.
 *//**
 * @brief Get system uptime (32-bit version).
 *
 * This routine returns the lower 32 bits of the system uptime in
 * milliseconds.
 *
 * Because correct conversion requires full precision of the system
 * clock there is no benefit to using this over k_uptime_get() unless
 * you know the application will never run long enough for the system
 * clock to approach 2^32 ticks.  Calls to this function may involve
 * interrupt blocking and 64-bit math.
 *
 * @note
 *    While this function returns time in milliseconds, it does
 *    not mean it has millisecond resolution. The actual resolution depends on
 *    @kconfig{CONFIG_SYS_CLOCK_TICKS_PER_SEC} config option
 *
 * @return The low 32 bits of the current uptime, in milliseconds.
 *//**
 * @brief Get system uptime.
 *
 * This routine returns the elapsed time since the system booted,
 * in milliseconds.
 *
 * @note
 *    While this function returns time in milliseconds, it does
 *    not mean it has millisecond resolution. The actual resolution depends on
 *    @kconfig{CONFIG_SYS_CLOCK_TICKS_PER_SEC} config option.
 *
 * @return Current uptime in milliseconds.
 *//**
 * @brief Get system uptime, in system ticks.
 *
 * This routine returns the elapsed time since the system booted, in
 * ticks (c.f. @kconfig{CONFIG_SYS_CLOCK_TICKS_PER_SEC}), which is the
 * fundamental unit of resolution of kernel timekeeping.
 *
 * @return Current uptime in ticks.
 *//**
 * @addtogroup clock_apis
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Retrieve the user-specific data from a timer.
 *
 * @param timer     Address of timer.
 *
 * @return The user data.
 *//**
 * @brief Associate user-specific data with a timer.
 *
 * This routine records the @a user_data with the @a timer, to be retrieved
 * later.
 *
 * It can be used e.g. in a timer handler shared across multiple subsystems to
 * retrieve data specific to the subsystem this timer is associated with.
 *
 * @param timer     Address of timer.
 * @param user_data User data to associate with the timer.
 *//* CONFIG_SYS_CLOCK_EXISTS *//**
 * @brief Get time remaining before a timer next expires.
 *
 * This routine computes the (approximate) time remaining before a running
 * timer next expires. If the timer is not running, it returns zero.
 *
 * @param timer     Address of timer.
 *
 * @return Remaining time (in milliseconds).
 *//**
 * @brief Get time remaining before a timer next expires, in system ticks
 *
 * This routine computes the time remaining before a running timer
 * next expires, in units of system ticks.  If the timer is not
 * running, it returns zero.
 *//**
 * @brief Get next expiration time of a timer, in system ticks
 *
 * This routine returns the future system uptime reached at the next
 * time of expiration of the timer, in units of system ticks.  If the
 * timer is not running, current system time is returned.
 *
 * @param timer The timer object
 * @return Uptime of expiration, in ticks
 *//**
 * @brief Synchronize thread to timer expiration.
 *
 * This routine blocks the calling thread until the timer's status is non-zero
 * (indicating that it has expired at least once since it was last examined)
 * or the timer is stopped. If the timer status is already non-zero,
 * or the timer is already stopped, the caller continues without waiting.
 *
 * Calling this routine resets the timer's status to zero.
 *
 * This routine must not be used by interrupt handlers, since they are not
 * allowed to block.
 *
 * @param timer     Address of timer.
 *
 * @return Timer status.
 *//**
 * @brief Read timer status.
 *
 * This routine reads the timer's status, which indicates the number of times
 * it has expired since its status was last read.
 *
 * Calling this routine resets the timer's status to zero.
 *
 * @param timer     Address of timer.
 *
 * @return Timer status.
 *//**
 * @brief Stop a timer.
 *
 * This routine stops a running timer prematurely. The timer's stop function,
 * if one exists, is invoked by the caller.
 *
 * Attempting to stop a timer that is not running is permitted, but has no
 * effect on the timer.
 *
 * @note The stop handler has to be callable from ISRs if @a k_timer_stop is to
 * be called from ISRs.
 *
 * @funcprops \isr_ok
 *
 * @param timer     Address of timer.
 *//**
 * @brief Start a timer.
 *
 * This routine starts a timer, and resets its status to zero. The timer
 * begins counting down using the specified duration and period values.
 *
 * Attempting to start a timer that is already running is permitted.
 * The timer's status is reset to zero and the timer begins counting down
 * using the new duration and period values.
 *
 * @param timer     Address of timer.
 * @param duration  Initial timer duration.
 * @param period    Timer period.
 *//**
 * @brief Initialize a timer.
 *
 * This routine initializes a timer, prior to its first use.
 *
 * @param timer     Address of timer.
 * @param expiry_fn Function to invoke each time the timer expires.
 * @param stop_fn   Function to invoke if the timer is stopped while running.
 *//**
 * @brief Statically define and initialize a timer.
 *
 * The timer can be accessed outside the module where it is defined using:
 *
 * @code extern struct k_timer <name>; @endcode
 *
 * @param name Name of the timer variable.
 * @param expiry_fn Function to invoke each time the timer expires.
 * @param stop_fn   Function to invoke if the timer is stopped while running.
 *//**
 * @typedef k_timer_stop_t
 * @brief Timer stop function type.
 *
 * A timer's stop function is executed if the timer is stopped prematurely.
 * The function runs in the context of call that stops the timer.  As
 * k_timer_stop() can be invoked from an ISR, the stop function must be
 * callable from interrupt context (isr-ok).
 *
 * The stop function is optional, and is only invoked if the timer has been
 * initialized with one.
 *
 * @param timer     Address of timer.
 *//**
 * @typedef k_timer_expiry_t
 * @brief Timer expiry function type.
 *
 * A timer's expiry function is executed by the system clock interrupt handler
 * each time the timer expires. The expiry function is optional, and is only
 * invoked if the timer has been initialized with one.
 *
 * @param timer     Address of timer.
 *//**
 * @defgroup timer_apis Timer APIs
 * @ingroup kernel_apis
 * @{
 *//* user-specific data, also used to support legacy features *//* timer status *//* timer period *//* runs in the context of the thread that calls k_timer_stop() *//* runs in ISR context *//* wait queue for the (single) thread waiting on this timer *//*
	 * _timeout structure must be first here if we want to use
	 * dynamic timer allocation. timeout.node is used in the double-linked
	 * list of free timers
	 *//**
 * @brief Generates an absolute/uptime timeout value from system cycles
 *
 * This macro generates a timeout delay that represents an expiration
 * at the absolute uptime value specified, in cycles.  That is, the
 * timeout will expire immediately after the system uptime reaches the
 * specified time.  Note that timer precision is limited by the system
 * tick rate and not the requested timeout value.
 *
 * @param t Cycle uptime value
 * @return Timeout delay value
 *//**
 * @brief Generates an absolute/uptime timeout value from nanoseconds
 *
 * This macro generates a timeout delay that represents an expiration
 * at the absolute uptime value specified, in nanoseconds.  That is,
 * the timeout will expire immediately after the system uptime reaches
 * the specified time.  Note that timer precision is limited by the
 * system tick rate and not the requested timeout value.
 *
 * @param t Nanosecond uptime value
 * @return Timeout delay value
 *//**
 * @brief Generates an absolute/uptime timeout value from microseconds
 *
 * This macro generates a timeout delay that represents an expiration
 * at the absolute uptime value specified, in microseconds.  That is,
 * the timeout will expire immediately after the system uptime reaches
 * the specified time.  Note that timer precision is limited by the
 * system tick rate and not the requested timeout value.
 *
 * @param t Microsecond uptime value
 * @return Timeout delay value
 *//**
 * @brief Generates an absolute/uptime timeout value from milliseconds
 *
 * This macro generates a timeout delay that represents an expiration
 * at the absolute uptime value specified, in milliseconds.  That is,
 * the timeout will expire immediately after the system uptime reaches
 * the specified tick count.
 *
 * @param t Millisecond uptime value
 * @return Timeout delay value
 *//**
 * @brief Generates an absolute/uptime timeout value from system ticks
 *
 * This macro generates a timeout delay that represents an expiration
 * at the absolute uptime value specified, in system ticks.  That is, the
 * timeout will expire immediately after the system uptime reaches the
 * specified tick count.
 *
 * @param t Tick uptime value
 * @return Timeout delay value
 *//**
 * @brief Generate infinite timeout delay.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait as long as necessary to perform the requested operation.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from hours.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a h hours to perform the requested operation.
 *
 * @param h Duration in hours.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from minutes.

 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a m minutes to perform the requested operation.
 *
 * @param m Duration in minutes.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from seconds.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a s seconds to perform the requested operation.
 *
 * @param s Duration in seconds.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from milliseconds.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a ms milliseconds to perform the requested operation.
 *
 * @param ms Duration in milliseconds.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from system ticks.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a t ticks to perform the requested operation.
 *
 * @param t Duration in system ticks.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from cycles.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a t cycles to perform the requested operation.
 *
 * @param t Duration in cycles.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from microseconds.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * to wait up to @a t microseconds to perform the requested operation.
 * Note that timer precision is limited to the tick rate, not the
 * requested value.
 *
 * @param t Duration in microseconds.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate timeout delay from nanoseconds.
 *
 * This macro generates a timeout delay that instructs a kernel API to
 * wait up to @a t nanoseconds to perform the requested operation.
 * Note that timer precision is limited to the tick rate, not the
 * requested value.
 *
 * @param t Duration in nanoseconds.
 *
 * @return Timeout delay value.
 *//**
 * @brief Generate null timeout delay.
 *
 * This macro generates a timeout delay that instructs a kernel API
 * not to wait if the requested operation cannot be performed immediately.
 *
 * @return Timeout delay value.
 *//**
 * @brief Get thread state string
 *
 * This routine generates a human friendly string containing the thread's
 * state, and copies as much of it as possible into @a buf.
 *
 * @param thread_id Thread ID
 * @param buf Buffer into which to copy state strings
 * @param buf_size Size of the buffer
 *
 * @retval Pointer to @a buf if data was copied, else a pointer to "".
 *//**
 * @brief Copy the thread name into a supplied buffer
 *
 * @param thread Thread to obtain name information
 * @param buf Destination buffer
 * @param size Destination buffer size
 * @retval -ENOSPC Destination buffer too small
 * @retval -EFAULT Memory access error
 * @retval -ENOSYS Thread name feature not enabled
 * @retval 0 Success
 *//**
 * @brief Get thread name
 *
 * Get the name of a thread
 *
 * @param thread Thread ID
 * @retval Thread name, or NULL if configuration not enabled
 *//**
 * @brief Set current thread name
 *
 * Set the name of the thread to be used when @kconfig{CONFIG_THREAD_MONITOR}
 * is enabled for tracing and debugging.
 *
 * @param thread Thread to set name, or NULL to set the current thread
 * @param str Name string
 * @retval 0 on success
 * @retval -EFAULT Memory access error with supplied string
 * @retval -ENOSYS Thread name configuration option not enabled
 * @retval -EINVAL Thread name too long
 *//**
 * @brief Get current thread's custom data.
 *
 * This routine returns the custom data for the current thread.
 *
 * @return Current custom data value.
 *//**
 * @brief Set current thread's custom data.
 *
 * This routine sets the custom data for the current thread to @ value.
 *
 * Custom data is not used by the kernel itself, and is freely available
 * for a thread to use as it sees fit. It can be used as a framework
 * upon which to build thread-local storage.
 *
 * @param value New custom data value.
 *
 *//**
 * @brief Unlock the scheduler.
 *
 * This routine reverses the effect of a previous call to k_sched_lock().
 * A thread must call the routine once for each time it called k_sched_lock()
 * before the thread becomes preemptible.
 *//**
 * @brief Lock the scheduler.
 *
 * This routine prevents the current thread from being preempted by another
 * thread by instructing the scheduler to treat it as a cooperative thread.
 * If the thread subsequently performs an operation that makes it unready,
 * it will be context switched out in the normal manner. When the thread
 * again becomes the current thread, its non-preemptible status is maintained.
 *
 * This routine can be called recursively.
 *
 * Owing to clever implementation details, scheduler locks are
 * extremely fast for non-userspace threads (just one byte
 * inc/decrement in the thread struct).
 *
 * @note This works by elevating the thread priority temporarily to a
 * cooperative priority, allowing cheap synchronization vs. other
 * preemptible or cooperative threads running on the current CPU.  It
 * does not prevent preemption or asynchrony of other types.  It does
 * not prevent threads from running on other CPUs when CONFIG_SMP=y.
 * It does not prevent interrupts from happening, nor does it prevent
 * threads with MetaIRQ priorities from preempting the current thread.
 * In general this is a historical API not well-suited to modern
 * applications, use with care.
 *//**
 * @addtogroup thread_apis
 * @{
 *//* in init.c *//**
 * @brief Test whether startup is in the before-main-task phase.
 *
 * This routine allows the caller to customize its actions, depending on
 * whether it being invoked before the kernel is fully active.
 *
 * @funcprops \isr_ok
 *
 * @return true if invoked before post-kernel initialization
 * @return false if invoked during/after post-kernel initialization
 *//**
 * @brief Determine if code is running in a preemptible thread.
 *
 * This routine allows the caller to customize its actions, depending on
 * whether it can be preempted by another thread. The routine returns a 'true'
 * value if all of the following conditions are met:
 *
 * - The code is running in a thread, not at ISR.
 * - The thread's priority is in the preemptible range.
 * - The thread has not locked the scheduler.
 *
 * @funcprops \isr_ok
 *
 * @return 0 if invoked by an ISR or by a cooperative thread.
 * @return Non-zero if invoked by a preemptible thread.
 *//**
 * @brief Determine if code is running at interrupt level.
 *
 * This routine allows the caller to customize its actions, depending on
 * whether it is a thread or an ISR.
 *
 * @funcprops \isr_ok
 *
 * @return false if invoked by a thread.
 * @return true if invoked by an ISR.
 *//**
 * @addtogroup isr_apis
 * @{
 *//**
 * @brief Set thread time slice
 *
 * As for k_sched_time_slice_set, but (when
 * CONFIG_TIMESLICE_PER_THREAD=y) sets the timeslice for a specific
 * thread.  When non-zero, this timeslice will take precedence over
 * the global value.
 *
 * When such a thread's timeslice expires, the configured callback
 * will be called before the thread is removed/re-added to the run
 * queue.  This callback will occur in interrupt context, and the
 * specified thread is guaranteed to have been preempted by the
 * currently-executing ISR.  Such a callback is free to, for example,
 * modify the thread priority or slice time for future execution,
 * suspend the thread, etc...
 *
 * @note Unlike the older API, the time slice parameter here is
 * specified in ticks, not milliseconds.  Ticks have always been the
 * internal unit, and not all platforms have integer conversions
 * between the two.
 *
 * @note Threads with a non-zero slice time set will be timesliced
 * always, even if they are higher priority than the maximum timeslice
 * priority set via k_sched_time_slice_set().
 *
 * @note The callback notification for slice expiration happens, as it
 * must, while the thread is still "current", and thus it happens
 * before any registered timeouts at this tick.  This has the somewhat
 * confusing side effect that the tick time (c.f. k_uptime_get()) does
 * not yet reflect the expired ticks.  Applications wishing to make
 * fine-grained timing decisions within this callback should use the
 * cycle API, or derived facilities like k_thread_runtime_stats_get().
 *
 * @param th A valid, initialized thread
 * @param slice_ticks Maximum timeslice, in ticks
 * @param expired Callback function called on slice expiration
 * @param data Parameter for the expiration handler
 *//**
 * @brief Set time-slicing period and scope.
 *
 * This routine specifies how the scheduler will perform time slicing of
 * preemptible threads.
 *
 * To enable time slicing, @a slice must be non-zero. The scheduler
 * ensures that no thread runs for more than the specified time limit
 * before other threads of that priority are given a chance to execute.
 * Any thread whose priority is higher than @a prio is exempted, and may
 * execute as long as desired without being preempted due to time slicing.
 *
 * Time slicing only limits the maximum amount of time a thread may continuously
 * execute. Once the scheduler selects a thread for execution, there is no
 * minimum guaranteed time the thread will execute before threads of greater or
 * equal priority are scheduled.
 *
 * When the current thread is the only one of that priority eligible
 * for execution, this routine has no effect; the thread is immediately
 * rescheduled after the slice period expires.
 *
 * To disable timeslicing, set both @a slice and @a prio to zero.
 *
 * @param slice Maximum time slice length (in milliseconds).
 * @param prio Highest thread priority level eligible for time slicing.
 *//**
 * @brief Resume a suspended thread.
 *
 * This routine allows the kernel scheduler to make @a thread the current
 * thread, when it is next eligible for that role.
 *
 * If @a thread is not currently suspended, the routine has no effect.
 *
 * @param thread ID of thread to resume.
 *//**
 * @brief Suspend a thread.
 *
 * This routine prevents the kernel scheduler from making @a thread
 * the current thread. All other internal operations on @a thread are
 * still performed; for example, kernel objects it is waiting on are
 * still handed to it.  Note that any existing timeouts
 * (e.g. k_sleep(), or a timeout argument to k_sem_take() et. al.)
 * will be canceled.  On resume, the thread will begin running
 * immediately and return from the blocked call.
 *
 * When the target thread is active on another CPU, the caller will block until
 * the target thread is halted (suspended or aborted).  But if the caller is in
 * an interrupt context, it will spin waiting for that target thread active on
 * another CPU to halt.
 *
 * If @a thread is already suspended, the routine has no effect.
 *
 * @param thread ID of thread to suspend.
 *//**
 * @brief Pin a thread to a CPU
 *
 * Pin a thread to a CPU by first clearing the cpu mask and then enabling the
 * thread on the selected CPU.
 *
 * @param thread Thread to operate upon
 * @param cpu CPU index
 * @return Zero on success, otherwise error code
 *//**
 * @brief Prevent thread to run on specified CPU
 *
 * The thread must not be currently runnable.
 *
 * @note You should enable @kconfig{CONFIG_SCHED_CPU_MASK} in your project
 * configuration.
 *
 * @param thread Thread to operate upon
 * @param cpu CPU index
 * @return Zero on success, otherwise error code
 *//**
 * @brief Enable thread to run on specified CPU
 *
 * The thread must not be currently runnable.
 *
 * @note You should enable @kconfig{CONFIG_SCHED_CPU_MASK} in your project
 * configuration.
 *
 * @param thread Thread to operate upon
 * @param cpu CPU index
 * @return Zero on success, otherwise error code
 *//**
 * @brief Sets all CPU enable masks to one
 *
 * After this returns, the thread will be schedulable on any CPU.  The
 * thread must not be currently runnable.
 *
 * @note You should enable @kconfig{CONFIG_SCHED_CPU_MASK} in your project
 * configuration.
 *
 * @param thread Thread to operate upon
 * @return Zero on success, otherwise error code
 *//**
 * @brief Sets all CPU enable masks to zero
 *
 * After this returns, the thread will no longer be schedulable on any
 * CPUs.  The thread must not be currently runnable.
 *
 * @note You should enable @kconfig{CONFIG_SCHED_CPU_MASK} in your project
 * configuration.
 *
 * @param thread Thread to operate upon
 * @return Zero on success, otherwise error code
 *//**
 * @brief Set deadline expiration time for scheduler
 *
 * This sets the "deadline" expiration as a time delta from the
 * current time, in the same units used by k_cycle_get_32().  The
 * scheduler (when deadline scheduling is enabled) will choose the
 * next expiring thread when selecting between threads at the same
 * static priority.  Threads at different priorities will be scheduled
 * according to their static priority.
 *
 * @note Deadlines are stored internally using 32 bit unsigned
 * integers.  The number of cycles between the "first" deadline in the
 * scheduler queue and the "last" deadline must be less than 2^31 (i.e
 * a signed non-negative quantity).  Failure to adhere to this rule
 * may result in scheduled threads running in an incorrect deadline
 * order.
 *
 * @note Despite the API naming, the scheduler makes no guarantees
 * the thread WILL be scheduled within that deadline, nor does it take
 * extra metadata (like e.g. the "runtime" and "period" parameters in
 * Linux sched_setattr()) that allows the kernel to validate the
 * scheduling for achievability.  Such features could be implemented
 * above this call, which is simply input to the priority selection
 * logic.
 *
 * @note You should enable @kconfig{CONFIG_SCHED_DEADLINE} in your project
 * configuration.
 *
 * @param thread A thread on which to set the deadline
 * @param deadline A time delta, in cycle units
 *
 *//**
 * @brief Set a thread's priority.
 *
 * This routine immediately changes the priority of @a thread.
 *
 * Rescheduling can occur immediately depending on the priority @a thread is
 * set to:
 *
 * - If its priority is raised above the priority of the caller of this
 * function, and the caller is preemptible, @a thread will be scheduled in.
 *
 * - If the caller operates on itself, it lowers its priority below that of
 * other threads in the system, and the caller is preemptible, the thread of
 * highest priority will be scheduled in.
 *
 * Priority can be assigned in the range of -CONFIG_NUM_COOP_PRIORITIES to
 * CONFIG_NUM_PREEMPT_PRIORITIES-1, where -CONFIG_NUM_COOP_PRIORITIES is the
 * highest priority.
 *
 * @param thread ID of thread whose priority is to be set.
 * @param prio New priority.
 *
 * @warning Changing the priority of a thread currently involved in mutex
 * priority inheritance may result in undefined behavior.
 *//**
 * @brief Get a thread's priority.
 *
 * This routine gets the priority of @a thread.
 *
 * @param thread ID of thread whose priority is needed.
 *
 * @return Priority of @a thread.
 *//**
 * @brief Statically define and initialize a thread intended to run only in kernel mode.
 *
 * The thread may be scheduled for immediate execution or a delayed start.
 *
 * Thread options are architecture-specific, and can include K_ESSENTIAL,
 * K_FP_REGS, and K_SSE_REGS. Multiple options may be specified by separating
 * them using "|" (the logical OR operator).
 *
 * The ID of the thread can be accessed using:
 *
 * @code extern const k_tid_t <name>; @endcode
 *
 * @note Threads defined by this can only run in kernel mode, and cannot be
 *       transformed into user thread via k_thread_user_mode_enter().
 *
 * @warning Depending on the architecture, the stack size (@p stack_size)
 *          may need to be multiples of CONFIG_MMU_PAGE_SIZE (if MMU)
 *          or in power-of-two size (if MPU).
 *
 * @param name Name of the thread.
 * @param stack_size Stack size in bytes.
 * @param entry Thread entry function.
 * @param p1 1st entry point parameter.
 * @param p2 2nd entry point parameter.
 * @param p3 3rd entry point parameter.
 * @param prio Thread priority.
 * @param options Thread options.
 * @param delay Scheduling delay (in milliseconds), zero for no delay.
 *//**
 * @brief Statically define and initialize a thread.
 *
 * The thread may be scheduled for immediate execution or a delayed start.
 *
 * Thread options are architecture-specific, and can include K_ESSENTIAL,
 * K_FP_REGS, and K_SSE_REGS. Multiple options may be specified by separating
 * them using "|" (the logical OR operator).
 *
 * The ID of the thread can be accessed using:
 *
 * @code extern const k_tid_t <name>; @endcode
 *
 * @param name Name of the thread.
 * @param stack_size Stack size in bytes.
 * @param entry Thread entry function.
 * @param p1 1st entry point parameter.
 * @param p2 2nd entry point parameter.
 * @param p3 3rd entry point parameter.
 * @param prio Thread priority.
 * @param options Thread options.
 * @param delay Scheduling delay (in milliseconds), zero for no delay.
 *
 * @note Static threads with zero delay should not normally have
 * MetaIRQ priority levels.  This can preempt the system
 * initialization handling (depending on the priority of the main
 * thread) and cause surprising ordering side effects.  It will not
 * affect anything in the OS per se, but consider it bad practice.
 * Use a SYS_INIT() callback if you need to run code before entrance
 * to the application main().
 *//*
 * Refer to K_THREAD_DEFINE() and K_KERNEL_THREAD_DEFINE() for
 * information on arguments.
 *//**
 * @brief Get time remaining before a thread wakes up, in system ticks
 *
 * This routine computes the time remaining before a waiting thread
 * next executes, in units of system ticks.  If the thread is not
 * waiting, it returns zero.
 *//**
 * @brief Get time when a thread wakes up, in system ticks
 *
 * This routine computes the system uptime when a waiting thread next
 * executes, in units of system ticks.  If the thread is not waiting,
 * it returns current system time.
 *//**
 * @brief Start an inactive thread
 *
 * If a thread was created with K_FOREVER in the delay parameter, it will
 * not be added to the scheduling queue until this function is called
 * on it.
 *
 * @param thread thread to start
 *//**
 * @brief Abort a thread.
 *
 * This routine permanently stops execution of @a thread. The thread is taken
 * off all kernel queues it is part of (i.e. the ready queue, the timeout
 * queue, or a kernel object wait queue). However, any kernel resources the
 * thread might currently own (such as mutexes or memory blocks) are not
 * released. It is the responsibility of the caller of this routine to ensure
 * all necessary cleanup is performed.
 *
 * After k_thread_abort() returns, the thread is guaranteed not to be
 * running or to become runnable anywhere on the system.  Normally
 * this is done via blocking the caller (in the same manner as
 * k_thread_join()), but in interrupt context on SMP systems the
 * implementation is required to spin for threads that are running on
 * other CPUs.
 *
 * @param thread ID of thread to abort.
 *//* Thread-local cache of current thread ID, set in z_thread_entry() *//**
 * @brief Get thread ID of the current thread.
 *
 * @return ID of current thread.
 *
 *//**
 * @brief Query thread ID of the current thread.
 *
 * This unconditionally queries the kernel via a system call.
 *
 * @note Use k_current_get() unless absolutely sure this is necessary.
 *       This should only be used directly where the thread local
 *       variable cannot be used or may contain invalid values
 *       if thread local storage (TLS) is enabled. If TLS is not
 *       enabled, this is the same as k_current_get().
 *
 * @return ID of current thread.
 *//**
 * @brief Wake up a sleeping thread.
 *
 * This routine prematurely wakes up @a thread from sleeping.
 *
 * If @a thread is not currently sleeping, the routine has no effect.
 *
 * @param thread ID of thread to wake.
 *//**
 * @brief Yield the current thread.
 *
 * This routine causes the current thread to yield execution to another
 * thread of the same or higher priority. If there are no other ready threads
 * of the same or higher priority, the routine returns immediately.
 *//**
 * @brief Check whether it is possible to yield in the current context.
 *
 * This routine checks whether the kernel is in a state where it is possible to
 * yield or call blocking API's. It should be used by code that needs to yield
 * to perform correctly, but can feasibly be called from contexts where that
 * is not possible. For example in the PRE_KERNEL initialization step, or when
 * being run from the idle thread.
 *
 * @return True if it is possible to yield in the current context, false otherwise.
 *//**
 * @brief Cause the current thread to busy wait.
 *
 * This routine causes the current thread to execute a "do nothing" loop for
 * @a usec_to_wait microseconds.
 *
 * @note The clock used for the microsecond-resolution delay here may
 * be skewed relative to the clock used for system timeouts like
 * k_sleep().  For example k_busy_wait(1000) may take slightly more or
 * less time than k_sleep(K_MSEC(1)), with the offset dependent on
 * clock tolerances.
 *
 * @note In case when @kconfig{CONFIG_SYSTEM_CLOCK_SLOPPY_IDLE} and
 * @kconfig{CONFIG_PM} options are enabled, this function may not work.
 * The timer/clock used for delay processing may be disabled/inactive.
 *//**
 * @brief Put the current thread to sleep with microsecond resolution.
 *
 * This function is unlikely to work as expected without kernel tuning.
 * In particular, because the lower bound on the duration of a sleep is
 * the duration of a tick, @kconfig{CONFIG_SYS_CLOCK_TICKS_PER_SEC} must be
 * adjusted to achieve the resolution desired. The implications of doing
 * this must be understood before attempting to use k_usleep(). Use with
 * caution.
 *
 * @param us Number of microseconds to sleep.
 *
 * @return Zero if the requested time has elapsed or the number of microseconds
 * left to sleep, if thread was woken up by \ref k_wakeup call.
 *//**
 * @brief Put the current thread to sleep.
 *
 * This routine puts the current thread to sleep for @a duration milliseconds.
 *
 * @param ms Number of milliseconds to sleep.
 *
 * @return Zero if the requested time has elapsed or the number of milliseconds
 * left to sleep, if thread was woken up by \ref k_wakeup call.
 *//**
 * @brief Put the current thread to sleep.
 *
 * This routine puts the current thread to sleep for @a duration,
 * specified as a k_timeout_t object.
 *
 * @note if @a timeout is set to K_FOREVER then the thread is suspended.
 *
 * @param timeout Desired duration of sleep.
 *
 * @return Zero if the requested time has elapsed or the number of milliseconds
 * left to sleep, if thread was woken up by \ref k_wakeup call.
 *//**
 * @brief Sleep until a thread exits
 *
 * The caller will be put to sleep until the target thread exits, either due
 * to being aborted, self-exiting, or taking a fatal error. This API returns
 * immediately if the thread isn't running.
 *
 * This API may only be called from ISRs with a K_NO_WAIT timeout,
 * where it can be useful as a predicate to detect when a thread has
 * aborted.
 *
 * @param thread Thread to wait to exit
 * @param timeout upper bound time to wait for the thread to exit.
 * @retval 0 success, target thread has exited or wasn't running
 * @retval -EBUSY returned without waiting
 * @retval -EAGAIN waiting period timed out
 * @retval -EDEADLK target thread is joining on the caller, or target thread
 *                  is the caller
 *//* (CONFIG_HEAP_MEM_POOL_SIZE > 0) *//**
 * @brief Assign the system heap as a thread's resource pool
 *
 * Similar to k_thread_heap_assign(), but the thread will use
 * the kernel heap to draw memory.
 *
 * Use with caution, as a malicious thread could perform DoS attacks on the
 * kernel heap.
 *
 * @param thread Target thread to assign the system heap for resource requests
 *
 *//**
 * @brief Obtain stack usage information for the specified thread
 *
 * User threads will need to have permission on the target thread object.
 *
 * Some hardware may prevent inspection of a stack buffer currently in use.
 * If this API is called from supervisor mode, on the currently running thread,
 * on a platform which selects @kconfig{CONFIG_NO_UNUSED_STACK_INSPECTION}, an
 * error will be generated.
 *
 * @param thread Thread to inspect stack information
 * @param unused_ptr Output parameter, filled in with the unused stack space
 *	of the target thread in bytes.
 * @return 0 on success
 * @return -EBADF Bad thread object (user mode only)
 * @return -EPERM No permissions on thread object (user mode only)
 * #return -ENOTSUP Forbidden by hardware policy
 * @return -EINVAL Thread is uninitialized or exited (user mode only)
 * @return -EFAULT Bad memory address for unused_ptr (user mode only)
 *//**
 * @brief Assign a resource memory pool to a thread
 *
 * By default, threads have no resource pool assigned unless their parent
 * thread has a resource pool, in which case it is inherited. Multiple
 * threads may be assigned to the same memory pool.
 *
 * Changing a thread's resource pool will not migrate allocations from the
 * previous pool.
 *
 * @param thread Target thread to assign a memory pool for resource requests.
 * @param heap Heap object to use for resources,
 *             or NULL if the thread should no longer have a memory pool.
 *//**
 * @brief Grant a thread access to a set of kernel objects
 *
 * This is a convenience function. For the provided thread, grant access to
 * the remaining arguments, which must be pointers to kernel objects.
 *
 * The thread object must be initialized (i.e. running). The objects don't
 * need to be.
 * Note that NULL shouldn't be passed as an argument.
 *
 * @param thread Thread to grant access to objects
 * @param ... list of kernel object pointers
 *//**
 * @brief Drop a thread's privileges permanently to user mode
 *
 * This allows a supervisor thread to be re-used as a user thread.
 * This function does not return, but control will transfer to the provided
 * entry point as if this was a new user thread.
 *
 * The implementation ensures that the stack buffer contents are erased.
 * Any thread-local storage will be reverted to a pristine state.
 *
 * Memory domain membership, resource pool assignment, kernel object
 * permissions, priority, and thread options are preserved.
 *
 * A common use of this function is to re-use the main thread as a user thread
 * once all supervisor mode-only tasks have been completed.
 *
 * @param entry Function to start executing from
 * @param p1 1st entry point parameter
 * @param p2 2nd entry point parameter
 * @param p3 3rd entry point parameter
 *//**
 * @brief Create a thread.
 *
 * This routine initializes a thread, then schedules it for execution.
 *
 * The new thread may be scheduled for immediate execution or a delayed start.
 * If the newly spawned thread does not have a delayed start the kernel
 * scheduler may preempt the current thread to allow the new thread to
 * execute.
 *
 * Thread options are architecture-specific, and can include K_ESSENTIAL,
 * K_FP_REGS, and K_SSE_REGS. Multiple options may be specified by separating
 * them using "|" (the logical OR operator).
 *
 * Stack objects passed to this function must be originally defined with
 * either of these macros in order to be portable:
 *
 * - K_THREAD_STACK_DEFINE() - For stacks that may support either user or
 *   supervisor threads.
 * - K_KERNEL_STACK_DEFINE() - For stacks that may support supervisor
 *   threads only. These stacks use less memory if CONFIG_USERSPACE is
 *   enabled.
 *
 * The stack_size parameter has constraints. It must either be:
 *
 * - The original size value passed to K_THREAD_STACK_DEFINE() or
 *   K_KERNEL_STACK_DEFINE()
 * - The return value of K_THREAD_STACK_SIZEOF(stack) if the stack was
 *   defined with K_THREAD_STACK_DEFINE()
 * - The return value of K_KERNEL_STACK_SIZEOF(stack) if the stack was
 *   defined with K_KERNEL_STACK_DEFINE().
 *
 * Using other values, or sizeof(stack) may produce undefined behavior.
 *
 * @param new_thread Pointer to uninitialized struct k_thread
 * @param stack Pointer to the stack space.
 * @param stack_size Stack size in bytes.
 * @param entry Thread entry function.
 * @param p1 1st entry point parameter.
 * @param p2 2nd entry point parameter.
 * @param p3 3rd entry point parameter.
 * @param prio Thread priority.
 * @param options Thread options.
 * @param delay Scheduling delay, or K_NO_WAIT (for no delay).
 *
 * @return ID of new thread.
 *
 *//**
 * @brief Free a dynamically allocated thread stack.
 *
 * @param stack Pointer to the thread stack.
 *
 * @retval 0 on success.
 * @retval -EBUSY if the thread stack is in use.
 * @retval -EINVAL if @p stack is invalid.
 * @retval -ENOSYS if dynamic thread stack allocation is disabled
 *
 * @see CONFIG_DYNAMIC_THREAD
 *//**
 * @brief Dynamically allocate a thread stack.
 *
 * Relevant stack creation flags include:
 * - @ref K_USER allocate a userspace thread (requires `CONFIG_USERSPACE=y`)
 *
 * @param size Stack size in bytes.
 * @param flags Stack creation flags, or 0.
 *
 * @retval the allocated thread stack on success.
 * @retval NULL on failure.
 *
 * @see CONFIG_DYNAMIC_THREAD
 *//* end - thread options *//**
 * @brief FP and SSE registers are managed by context switch on x86
 *
 * @details
 * This option indicates that the thread uses the x86 CPU's floating point
 * and SSE registers. This instructs the kernel to take additional steps to
 * save and restore the contents of these registers when scheduling
 * the thread. No effect if @kconfig{CONFIG_X86_SSE} is not enabled.
 *//* x86 Bitmask definitions for threads user options *//**
 * @brief AGU registers are managed by context switch
 *
 * @details
 * This option indicates that the thread uses the ARC processor's XY
 * memory and DSP feature. Often used with @kconfig{CONFIG_ARC_AGU_SHARING}.
 * No effect if @kconfig{CONFIG_ARC_AGU_SHARING} is not enabled.
 *//**
 * @brief DSP registers are managed by context switch
 *
 * @details
 * This option indicates that the thread uses the CPU's DSP registers.
 * This instructs the kernel to take additional steps to save and
 * restore the contents of these registers when scheduling the thread.
 * No effect if @kconfig{CONFIG_ARC_DSP_SHARING} is not enabled.
 *//* ARC processor Bitmask definitions for threads user options *//**
 * @brief Callback item state
 *
 * @details
 * This is a single bit of state reserved for "callback manager"
 * utilities (p4wq initially) who need to track operations invoked
 * from within a user-provided callback they have been invoked.
 * Effectively it serves as a tiny bit of zero-overhead TLS data.
 *//**
 * @brief Inherit Permissions
 *
 * @details
 * Indicates that the thread being created should inherit all kernel object
 * permissions from the thread that created it. No effect if
 * @kconfig{CONFIG_USERSPACE} is not enabled.
 *//**
 * @brief user mode thread
 *
 * This thread has dropped from supervisor mode to user mode and consequently
 * has additional restrictions
 *//**
 * @brief FPU registers are managed by context switch
 *
 * @details
 * This option indicates that the thread uses the CPU's floating point
 * registers. This instructs the kernel to take additional steps to save
 * and restore the contents of these registers when scheduling the thread.
 * No effect if @kconfig{CONFIG_FPU_SHARING} is not enabled.
 *//**
 * @brief system thread that must not abort
 * *//*
 * Thread user options. May be needed by assembly code. Common part uses low
 * bits, arch-specific use high bits.
 *//**
 * @defgroup thread_apis Thread APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * @brief Iterate over all the threads in the system without locking.
 *
 * This routine works exactly the same like @ref k_thread_foreach
 * but unlocks interrupts when user_cb is executed.
 *
 * @param user_cb Pointer to the user callback function.
 * @param user_data Pointer to user data.
 *
 * @note @kconfig{CONFIG_THREAD_MONITOR} must be set for this function
 * to be effective.
 * @note This API uses @ref k_spin_lock only when accessing the _kernel.threads
 * queue elements. It unlocks it during user callback function processing.
 * If a new task is created when this @c foreach function is in progress,
 * the added new task would not be included in the enumeration.
 * If a task is aborted during this enumeration, there would be a race here
 * and there is a possibility that this aborted task would be included in the
 * enumeration.
 * @note If the task is aborted and the memory occupied by its @c k_thread
 * structure is reused when this @c k_thread_foreach_unlocked is in progress
 * it might even lead to the system behave unstable.
 * This function may never return, as it would follow some @c next task
 * pointers treating given pointer as a pointer to the k_thread structure
 * while it is something different right now.
 * Do not reuse the memory that was occupied by k_thread structure of aborted
 * task if it was aborted after this function was called in any context.
 *//**
 * @brief Iterate over all the threads in the system.
 *
 * This routine iterates over all the threads in the system and
 * calls the user_cb function for each thread.
 *
 * @param user_cb Pointer to the user callback function.
 * @param user_data Pointer to user data.
 *
 * @note @kconfig{CONFIG_THREAD_MONITOR} must be set for this function
 * to be effective.
 * @note This API uses @ref k_spin_lock to protect the _kernel.threads
 * list which means creation of new threads and terminations of existing
 * threads are blocked until this API returns.
 *//* private, used by k_poll and k_work_poll *//**
 * @brief Kernel APIs
 * @defgroup kernel_apis Kernel APIs
 * @{
 * @}
 *//*
 * Zephyr currently assumes the size of a couple standard types to simplify
 * print string formats. Let's make sure this doesn't change without notice.
 *//**
 * @file
 *
 * @brief Public kernel APIs.
 */sys_port_track_k_event_init(event)sys_port_track_k_heap_init(h)sys_port_track_k_heap_free(h)sys_port_track_k_mem_slab_init(slab,rc)sys_port_track_k_mbox_init(mbox)sys_port_track_k_msgq_init(msgq)sys_port_track_k_msgq_peek(msgq,ret)sys_port_track_k_msgq_purge(msgq)sys_port_track_k_sem_init(sem,ret)sys_port_track_k_sem_reset(sem)sys_port_track_k_thread_name_set(thread,ret)sys_port_track_k_stack_init(stack)sys_port_track_k_condvar_init(condvar,ret)sys_port_track_k_pipe_init(pipe)sys_port_track_k_queue_init(queue)sys_port_track_k_queue_cancel_wait(queue)sys_port_track_k_queue_peek_head(queue,ret)sys_port_track_k_queue_peek_tail(queue,ret)sys_port_track_k_timer_init(timer)sys_port_track_k_timer_start(timer,duration,period)sys_port_track_k_timer_stop(timer)sys_port_track_k_mutex_init(mutex,ret)sys_port_track_k_work_init(work)sys_port_track_k_work_queue_init(queue)sys_port_track_k_work_delayable_init(dwork)sys_port_track_k_thread_sched_priority_set(thread,prio)sys_port_track_k_thread_wakeup(thread)sys_port_track_k_thread_sched_ready(thread)sys_port_track_k_thread_create(new_thread)sys_port_track_k_thread_start(thread)ZEPHYR_INCLUDE_TRACING_TRACKING_H_defined(CONFIG_TRACING_OBJECT_TRACKING) || defined(__DOXYGEN__)/* ZEPHYR_INCLUDE_TRACING_TRACKING_H_ *//* end of subsys_tracing_object_tracking *//**
 * @brief Gets node's next element in a object tracking list.
 *
 * @param list Node to get next element from.
 *//**
 * @brief Object tracking
 *
 * Object tracking provides lists to kernel objects, so their
 * existence and current status can be tracked.
 *
 * The following global variables are the heads of available lists:
 * - _track_list_k_timer
 * - _track_list_k_mem_slab
 * - _track_list_k_sem
 * - _track_list_k_mutex
 * - _track_list_k_stack
 * - _track_list_k_msgq
 * - _track_list_k_mbox
 * - _track_list_k_pipe
 * - _track_list_k_queue
 * - _track_list_k_event
 *
 * @defgroup subsys_tracing_object_tracking Object tracking
 * @ingroup subsys_tracing
 * @{
 */"tracking.h"sys_trace_idlesys_trace_isr_exit_to_schedulersys_trace_isr_exitsys_trace_isr_entersys_port_trace_pm_device_runtime_disable_exit(dev,ret)sys_port_trace_pm_device_runtime_disable_enter(dev)sys_port_trace_pm_device_runtime_enable_exit(dev,ret)sys_port_trace_pm_device_runtime_enable_enter(dev)sys_port_trace_pm_device_runtime_put_async_exit(dev,ret)sys_port_trace_pm_device_runtime_put_async_enter(dev)sys_port_trace_pm_device_runtime_put_exit(dev,ret)sys_port_trace_pm_device_runtime_put_enter(dev)sys_port_trace_pm_device_runtime_get_exit(dev,ret)sys_port_trace_pm_device_runtime_get_enter(dev)sys_port_trace_pm_system_suspend_exit(ticks,state)sys_port_trace_pm_system_suspend_enter(ticks)sys_port_trace_k_event_wait_exit(event,events,ret)sys_port_trace_k_event_wait_blocking(event,events,options,timeout)sys_port_trace_k_event_wait_enter(event,events,options,timeout)sys_port_trace_k_event_post_exit(event,events,events_mask)sys_port_trace_k_event_post_enter(event,events,events_mask)sys_port_trace_k_event_init(event)sys_port_trace_k_timer_status_sync_exit(timer,result)sys_port_trace_k_timer_status_sync_blocking(timer,timeout)sys_port_trace_k_timer_status_sync_enter(timer)sys_port_trace_k_timer_stop(timer)sys_port_trace_k_timer_start(timer,duration,period)sys_port_trace_k_timer_init(timer)sys_port_trace_k_mem_slab_free_exit(slab)sys_port_trace_k_mem_slab_free_enter(slab)sys_port_trace_k_mem_slab_alloc_exit(slab,timeout,ret)sys_port_trace_k_mem_slab_alloc_blocking(slab,timeout)sys_port_trace_k_mem_slab_alloc_enter(slab,timeout)sys_port_trace_k_mem_slab_init(slab,rc)sys_port_trace_k_heap_sys_k_calloc_exit(heap,ret)sys_port_trace_k_heap_sys_k_calloc_enter(heap)sys_port_trace_k_heap_sys_k_free_exit(heap,heap_ref)sys_port_trace_k_heap_sys_k_free_enter(heap,heap_ref)sys_port_trace_k_heap_sys_k_malloc_exit(heap,ret)sys_port_trace_k_heap_sys_k_malloc_enter(heap)sys_port_trace_k_heap_sys_k_aligned_alloc_exit(heap,ret)sys_port_trace_k_heap_sys_k_aligned_alloc_enter(heap)sys_port_trace_k_heap_free(h)sys_port_trace_k_heap_alloc_exit(h,timeout,ret)sys_port_trace_k_heap_alloc_enter(h,timeout)sys_port_trace_k_heap_aligned_alloc_exit(h,timeout,ret)sys_port_trace_k_heap_aligned_alloc_blocking(h,timeout)sys_port_trace_k_heap_aligned_alloc_enter(h,timeout)sys_port_trace_k_heap_init(h)sys_port_trace_k_pipe_get_exit(pipe,timeout,ret)sys_port_trace_k_pipe_get_blocking(pipe,timeout)sys_port_trace_k_pipe_get_enter(pipe,timeout)sys_port_trace_k_pipe_put_exit(pipe,timeout,ret)sys_port_trace_k_pipe_put_blocking(pipe,timeout)sys_port_trace_k_pipe_put_enter(pipe,timeout)sys_port_trace_k_pipe_buffer_flush_exit(pipe)sys_port_trace_k_pipe_buffer_flush_enter(pipe)sys_port_trace_k_pipe_flush_exit(pipe)sys_port_trace_k_pipe_flush_enter(pipe)sys_port_trace_k_pipe_alloc_init_exit(pipe,ret)sys_port_trace_k_pipe_alloc_init_enter(pipe)sys_port_trace_k_pipe_cleanup_exit(pipe,ret)sys_port_trace_k_pipe_cleanup_enter(pipe)sys_port_trace_k_pipe_init(pipe)sys_port_trace_k_mbox_data_get(rx_msg)sys_port_trace_k_mbox_get_exit(mbox,timeout,ret)sys_port_trace_k_mbox_get_blocking(mbox,timeout)sys_port_trace_k_mbox_get_enter(mbox,timeout)sys_port_trace_k_mbox_async_put_exit(mbox,sem)sys_port_trace_k_mbox_async_put_enter(mbox,sem)sys_port_trace_k_mbox_put_exit(mbox,timeout,ret)sys_port_trace_k_mbox_put_enter(mbox,timeout)sys_port_trace_k_mbox_message_put_exit(mbox,timeout,ret)sys_port_trace_k_mbox_message_put_blocking(mbox,timeout)sys_port_trace_k_mbox_message_put_enter(mbox,timeout)sys_port_trace_k_mbox_init(mbox)sys_port_trace_k_msgq_purge(msgq)sys_port_trace_k_msgq_peek(msgq,ret)sys_port_trace_k_msgq_get_exit(msgq,timeout,ret)sys_port_trace_k_msgq_get_blocking(msgq,timeout)sys_port_trace_k_msgq_get_enter(msgq,timeout)sys_port_trace_k_msgq_put_exit(msgq,timeout,ret)sys_port_trace_k_msgq_put_blocking(msgq,timeout)sys_port_trace_k_msgq_put_enter(msgq,timeout)sys_port_trace_k_msgq_cleanup_exit(msgq,ret)sys_port_trace_k_msgq_cleanup_enter(msgq)sys_port_trace_k_msgq_alloc_init_exit(msgq,ret)sys_port_trace_k_msgq_alloc_init_enter(msgq)sys_port_trace_k_msgq_init(msgq)sys_port_trace_k_stack_pop_exit(stack,timeout,ret)sys_port_trace_k_stack_pop_blocking(stack,timeout)sys_port_trace_k_stack_pop_enter(stack,timeout)sys_port_trace_k_stack_push_exit(stack,ret)sys_port_trace_k_stack_push_enter(stack)sys_port_trace_k_stack_cleanup_exit(stack,ret)sys_port_trace_k_stack_cleanup_enter(stack)sys_port_trace_k_stack_alloc_init_exit(stack,ret)sys_port_trace_k_stack_alloc_init_enter(stack)sys_port_trace_k_stack_init(stack)sys_port_trace_k_lifo_get_exit(lifo,timeout,ret)sys_port_trace_k_lifo_get_enter(lifo,timeout)sys_port_trace_k_lifo_alloc_put_exit(lifo,data,ret)sys_port_trace_k_lifo_alloc_put_enter(lifo,data)sys_port_trace_k_lifo_put_exit(lifo,data)sys_port_trace_k_lifo_put_enter(lifo,data)sys_port_trace_k_lifo_init_exit(lifo)sys_port_trace_k_lifo_init_enter(lifo)sys_port_trace_k_fifo_peek_tail_exit(fifo,ret)sys_port_trace_k_fifo_peek_tail_enter(fifo)sys_port_trace_k_fifo_peek_head_exit(fifo,ret)sys_port_trace_k_fifo_peek_head_enter(fifo)sys_port_trace_k_fifo_get_exit(fifo,timeout,ret)sys_port_trace_k_fifo_get_enter(fifo,timeout)sys_port_trace_k_fifo_alloc_put_slist_exit(fifo,list)sys_port_trace_k_fifo_alloc_put_slist_enter(fifo,list)sys_port_trace_k_fifo_put_list_exit(fifo,head,tail)sys_port_trace_k_fifo_put_list_enter(fifo,head,tail)sys_port_trace_k_fifo_alloc_put_exit(fifo,data,ret)sys_port_trace_k_fifo_alloc_put_enter(fifo,data)sys_port_trace_k_fifo_put_exit(fifo,data)sys_port_trace_k_fifo_put_enter(fifo,data)sys_port_trace_k_fifo_cancel_wait_exit(fifo)sys_port_trace_k_fifo_cancel_wait_enter(fifo)sys_port_trace_k_fifo_init_exit(fifo)sys_port_trace_k_fifo_init_enter(fifo)sys_port_trace_k_queue_peek_tail(queue,ret)sys_port_trace_k_queue_peek_head(queue,ret)sys_port_trace_k_queue_unique_append_exit(queue,ret)sys_port_trace_k_queue_unique_append_enter(queue)sys_port_trace_k_queue_remove_exit(queue,ret)sys_port_trace_k_queue_remove_enter(queue)sys_port_trace_k_queue_get_exit(queue,timeout,ret)sys_port_trace_k_queue_get_blocking(queue,timeout)sys_port_trace_k_queue_get_enter(queue,timeout)sys_port_trace_k_queue_merge_slist_exit(queue,ret)sys_port_trace_k_queue_merge_slist_enter(queue)sys_port_trace_k_queue_append_list_exit(queue,ret)sys_port_trace_k_queue_append_list_enter(queue)sys_port_trace_k_queue_insert_exit(queue)sys_port_trace_k_queue_insert_blocking(queue,timeout)sys_port_trace_k_queue_insert_enter(queue)sys_port_trace_k_queue_alloc_prepend_exit(queue,ret)sys_port_trace_k_queue_alloc_prepend_enter(queue)sys_port_trace_k_queue_prepend_exit(queue)sys_port_trace_k_queue_prepend_enter(queue)sys_port_trace_k_queue_alloc_append_exit(queue,ret)sys_port_trace_k_queue_alloc_append_enter(queue)sys_port_trace_k_queue_append_exit(queue)sys_port_trace_k_queue_append_enter(queue)sys_port_trace_k_queue_queue_insert_exit(queue,alloc,ret)sys_port_trace_k_queue_queue_insert_blocking(queue,alloc,timeout)sys_port_trace_k_queue_queue_insert_enter(queue,alloc)sys_port_trace_k_queue_cancel_wait(queue)sys_port_trace_k_queue_init(queue)sys_port_trace_k_condvar_wait_exit(condvar,ret)sys_port_trace_k_condvar_wait_enter(condvar)sys_port_trace_k_condvar_broadcast_exit(condvar,ret)sys_port_trace_k_condvar_broadcast_enter(condvar)sys_port_trace_k_condvar_signal_exit(condvar,ret)sys_port_trace_k_condvar_signal_blocking(condvar,timeout)sys_port_trace_k_condvar_signal_enter(condvar)sys_port_trace_k_condvar_init(condvar,ret)sys_port_trace_k_mutex_unlock_exit(mutex,ret)sys_port_trace_k_mutex_unlock_enter(mutex)sys_port_trace_k_mutex_lock_exit(mutex,timeout,ret)sys_port_trace_k_mutex_lock_blocking(mutex,timeout)sys_port_trace_k_mutex_lock_enter(mutex,timeout)sys_port_trace_k_mutex_init(mutex,ret)sys_port_trace_k_sem_reset(sem)sys_port_trace_k_sem_take_exit(sem,timeout,ret)sys_port_trace_k_sem_take_blocking(sem,timeout)sys_port_trace_k_sem_take_enter(sem,timeout)sys_port_trace_k_sem_give_exit(sem)sys_port_trace_k_sem_give_enter(sem)sys_port_trace_k_sem_init(sem,ret)sys_port_trace_k_poll_api_signal_raise(signal,ret)sys_port_trace_k_poll_api_signal_check(signal)sys_port_trace_k_poll_api_signal_reset(signal)sys_port_trace_k_poll_api_signal_init(signal)sys_port_trace_k_poll_api_poll_exit(events,ret)sys_port_trace_k_poll_api_poll_enter(events)sys_port_trace_k_poll_api_event_init(event)sys_port_trace_k_work_poll_cancel_exit(work,ret)sys_port_trace_k_work_poll_cancel_enter(work)sys_port_trace_k_work_poll_submit_exit(work,timeout,ret)sys_port_trace_k_work_poll_submit_enter(work,timeout)sys_port_trace_k_work_poll_submit_to_queue_exit(work_q,work,timeout,ret)sys_port_trace_k_work_poll_submit_to_queue_blocking(work_q,work,timeout)sys_port_trace_k_work_poll_submit_to_queue_enter(work_q,work,timeout)sys_port_trace_k_work_poll_init_exit(work)sys_port_trace_k_work_poll_init_enter(work)sys_port_trace_k_work_cancel_delayable_sync_exit(dwork,sync,ret)sys_port_trace_k_work_cancel_delayable_sync_enter(dwork,sync)sys_port_trace_k_work_cancel_delayable_exit(dwork,ret)sys_port_trace_k_work_cancel_delayable_enter(dwork)sys_port_trace_k_work_flush_delayable_exit(dwork,sync,ret)sys_port_trace_k_work_flush_delayable_enter(dwork,sync)sys_port_trace_k_work_reschedule_exit(dwork,delay,ret)sys_port_trace_k_work_reschedule_enter(dwork,delay)sys_port_trace_k_work_reschedule_for_queue_exit(queue,dwork,delay,ret)sys_port_trace_k_work_reschedule_for_queue_enter(queue,dwork,delay)sys_port_trace_k_work_schedule_exit(dwork,delay,ret)sys_port_trace_k_work_schedule_enter(dwork,delay)sys_port_trace_k_work_schedule_for_queue_exit(queue,dwork,delay,ret)sys_port_trace_k_work_schedule_for_queue_enter(queue,dwork,delay)sys_port_trace_k_work_delayable_init(dwork)sys_port_trace_k_work_queue_unplug_exit(queue,ret)sys_port_trace_k_work_queue_unplug_enter(queue)sys_port_trace_k_work_queue_drain_exit(queue,ret)sys_port_trace_k_work_queue_drain_enter(queue)sys_port_trace_k_work_queue_start_exit(queue)sys_port_trace_k_work_queue_start_enter(queue)sys_port_trace_k_work_queue_init(queue)sys_port_trace_k_work_cancel_sync_exit(work,sync,ret)sys_port_trace_k_work_cancel_sync_blocking(work,sync)sys_port_trace_k_work_cancel_sync_enter(work,sync)sys_port_trace_k_work_cancel_exit(work,ret)sys_port_trace_k_work_cancel_enter(work)sys_port_trace_k_work_flush_exit(work,ret)sys_port_trace_k_work_flush_blocking(work,timeout)sys_port_trace_k_work_flush_enter(work)sys_port_trace_k_work_submit_exit(work,ret)sys_port_trace_k_work_submit_enter(work)sys_port_trace_k_work_submit_to_queue_exit(queue,work,ret)sys_port_trace_k_work_submit_to_queue_enter(queue,work)sys_port_trace_k_work_init(work)sys_port_trace_k_thread_sched_suspend(thread)sys_port_trace_k_thread_sched_resume(thread)sys_port_trace_k_thread_sched_pend(thread)sys_port_trace_k_thread_sched_ready(thread)sys_port_trace_k_thread_sched_priority_set(thread,prio)sys_port_trace_k_thread_sched_abort(thread)sys_port_trace_k_thread_sched_wakeup(thread)sys_port_trace_k_thread_info(thread)sys_port_trace_k_thread_pend(thread)sys_port_trace_k_thread_ready(thread)sys_port_trace_k_thread_switched_in()sys_port_trace_k_thread_switched_out()sys_port_trace_k_thread_name_set(thread,ret)sys_port_trace_k_thread_sched_unlock()sys_port_trace_k_thread_sched_lock()sys_port_trace_k_thread_resume_exit(thread)sys_port_trace_k_thread_resume_enter(thread)sys_port_trace_k_thread_suspend_exit(thread)sys_port_trace_k_thread_suspend_enter(thread)sys_port_trace_k_thread_priority_set(thread)sys_port_trace_k_thread_abort_exit(thread)sys_port_trace_k_thread_abort_enter(thread)sys_port_trace_k_thread_abort(thread)sys_port_trace_k_thread_start(thread)sys_port_trace_k_thread_wakeup(thread)sys_port_trace_k_thread_yield()sys_port_trace_k_thread_busy_wait_exit(usec_to_wait)sys_port_trace_k_thread_busy_wait_enter(usec_to_wait)sys_port_trace_k_thread_usleep_exit(us,ret)sys_port_trace_k_thread_usleep_enter(us)sys_port_trace_k_thread_msleep_exit(ms,ret)sys_port_trace_k_thread_msleep_enter(ms)sys_port_trace_k_thread_sleep_exit(timeout,ret)sys_port_trace_k_thread_sleep_enter(timeout)sys_port_trace_k_thread_join_exit(thread,timeout,ret)sys_port_trace_k_thread_join_blocking(thread,timeout)sys_port_trace_k_thread_join_enter(thread,timeout)sys_port_trace_k_thread_user_mode_enter()sys_port_trace_k_thread_create(new_thread)sys_port_trace_k_thread_foreach_unlocked_exit()sys_port_trace_k_thread_foreach_unlocked_enter()sys_port_trace_k_thread_foreach_exit()sys_port_trace_k_thread_foreach_enter()ZEPHYR_INCLUDE_TRACING_TRACING_H_defined CONFIG_TRACING_CTFdefined CONFIG_TRACING_USERdefined(CONFIG_PERCEPIO_TRACERECORDER)/* ZEPHYR_INCLUDE_TRACING_TRACING_H_ *//* end of subsys_tracing *//* end of subsys_tracing_apis *//* CONFIG_PERCEPIO_TRACERECORDER *//**
 * @brief Called when the cpu enters the idle state
 *//**
 * @brief Called when exiting an ISR and switching to scheduler
 *//**
 * @brief Called when exiting an ISR
 *//**
 * @brief Called when entering an ISR
 *//* end of subsys_tracing_apis_pm_device_runtime *//**
 * @brief Trace disabling device runtime PM call exit.
 * @param dev Device instance.
 * @param ret Return value.
 *//**
 * @brief Trace disabling device runtime PM call entry.
 * @param dev Device instance.
 *//**
 * @brief Trace enabling device runtime PM call exit.
 * @param dev Device instance.
 * @param ret Return value.
 *//**
 * @brief Trace enabling device runtime PM call entry.
 * @param dev Device instance.
 *//**
 * @brief Trace putting a device (asynchronously) call exit.
 * @param dev Device instance.
 * @param ret Return value.
 *//**
 * @brief Trace putting a device (asynchronously) call entry.
 * @param dev Device instance.
 *//**
 * @brief Trace putting a device call exit.
 * @param dev Device instance.
 * @param ret Return value.
 *//**
 * @brief Trace putting a device call entry.
 * @param dev Device instance.
 *//**
 * @brief Trace getting a device call exit.
 * @param dev Device instance.
 * @param ret Return value.
 *//**
 * @brief Trace getting a device call entry.
 * @param dev Device instance.
 *//**
 * @brief PM Device Runtime Tracing APIs
 * @defgroup subsys_tracing_apis_pm_device_runtime PM Device Runtime Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_pm_system *//**
 * @brief Trace system suspend call exit.
 * @param ticks Ticks.
 * @param state PM state.
 *//**
 * @brief Trace system suspend call entry.
 * @param ticks Ticks.
 *//**
 * @brief System PM Tracing APIs
 * @defgroup subsys_tracing_apis_pm_system System PM Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_event *//**
 * @brief Trace waiting of an Event call exit
 * @param event Event object
 * @param events Set of events for which to wait
 * @param ret Set of received events
 *//**
 * @brief Trace waiting of an Event call exit
 * @param event Event object
 * @param events Set of events for which to wait
 * @param options Event wait options
 * @param timeout Timeout period
 *//**
 * @brief Trace waiting of an Event call entry
 * @param event Event object
 * @param events Set of events for which to wait
 * @param options Event wait options
 * @param timeout Timeout period
 *//**
 * @brief Trace posting of an Event call exit
 * @param event Event object
 * @param events Set of posted events
 * @param events_mask Mask to apply against posted events
 *//**
 * @brief Trace posting of an Event call entry
 * @param event Event object
 * @param events Set of posted events
 * @param events_mask Mask to apply against posted events
 *//**
 * @brief Trace initialisation of an Event
 * @param event Event object
 *//**
 * @brief Event Tracing APIs
 * @defgroup subsys_tracing_apis_event Event Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_timer *//**
 * @brief Trace Time Status sync outcome
 * @param timer Timer object
 * @param result Return value
 *//**
 * @brief Trace Timer Status sync blocking
 * @param timer Timer object
 * @param timeout Timeout period
 *//**
 * @brief Trace Timer status sync entry
 * @param timer Timer object
 *//**
 * @brief Trace Timer stop
 * @param timer Timer object
 *//**
 * @brief Trace Timer start
 * @param timer Timer object
 * @param duration Timer duration
 * @param period Timer period
 *//**
 * @brief Trace initialization of Timer
 * @param timer Timer object
 *//**
 * @brief Timer Tracing APIs
 * @defgroup subsys_tracing_apis_timer Timer Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_mslab *//**
 * @brief Trace Memory Slab free exit
 * @param slab Memory Slab object
 *//**
 * @brief Trace Memory Slab free entry
 * @param slab Memory Slab object
 *//**
 * @brief Trace Memory Slab alloc attempt outcome
 * @param slab Memory Slab object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Memory Slab alloc attempt blocking
 * @param slab Memory Slab object
 * @param timeout Timeout period
 *//**
 * @brief Trace Memory Slab alloc attempt entry
 * @param slab Memory Slab object
 * @param timeout Timeout period
 *//**
 * @brief Trace initialization of Memory Slab
 * @param slab Memory Slab object
 * @param rc Return value
 *//**
 * @brief Memory Slab Tracing APIs
 * @defgroup subsys_tracing_apis_mslab Memory Slab Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_heap *//**
 * @brief Trace System heap calloc exit
 * @param heap Heap object
 * @param ret Return value
 *//**
 * @brief Trace System heap calloc enter
 * @param heap
 *//**
 * @brief Trace System Heap free exit
 * @param heap Heap object
 * @param heap_ref Heap reference
 *//**
 * @brief Trace System Heap free entry
 * @param heap Heap object
 * @param heap_ref Heap reference
 *//**
 * @brief Trace System Heap aligned alloc exit
 * @param heap Heap object
 * @param ret Return value
 *//**
 * @brief Trace System Heap aligned alloc enter
 * @param heap Heap object
 *//**
 * @brief Trace Heap free
 * @param h Heap object
 *//**
 * @brief Trace Heap alloc exit
 * @param h Heap object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Heap alloc enter
 * @param h Heap object
 * @param timeout Timeout period
 *//**
 * @brief Trace Heap align alloc attempt outcome
 * @param h Heap object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Heap align alloc attempt blocking
 * @param h Heap object
 * @param timeout Timeout period
 *//**
 * @brief Trace Heap aligned alloc attempt entry
 * @param h Heap object
 * @param timeout Timeout period
 *//**
 * @brief Trace initialization of Heap
 * @param h Heap object
 *//**
 * @brief Heap Tracing APIs
 * @defgroup subsys_tracing_apis_heap Heap Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_pipe *//**
 * @brief Trace Pipe get attempt outcome
 * @param pipe Pipe object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Pipe get attempt blocking
 * @param pipe Pipe object
 * @param timeout Timeout period
 *//**
 * @brief Trace Pipe get attempt entry
 * @param pipe Pipe object
 * @param timeout Timeout period
 *//**
 * @brief Trace Pipe put attempt outcome
 * @param pipe Pipe object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Pipe put attempt blocking
 * @param pipe Pipe object
 * @param timeout Timeout period
 *//**
 * @brief Trace Pipe put attempt entry
 * @param pipe Pipe object
 * @param timeout Timeout period
 *//**
 * @brief Trace Pipe buffer flush exit
 * @param pipe Pipe object
 *//**
 * @brief Trace Pipe buffer flush entry
 * @param pipe Pipe object
 *//**
 * @brief Trace Pipe flush exit
 * @param pipe Pipe object
 *//**
 * @brief Trace Pipe flush entry
 * @param pipe Pipe object
 *//**
 * @brief Trace Pipe alloc init exit
 * @param pipe Pipe object
 * @param ret Return value
 *//**
 * @brief Trace Pipe alloc init entry
 * @param pipe Pipe object
 *//**
 * @brief Trace Pipe cleanup exit
 * @param pipe Pipe object
 * @param ret Return value
 *//**
 * @brief Trace Pipe cleanup entry
 * @param pipe Pipe object
 *//**
 * @brief Trace initialization of Pipe
 * @param pipe Pipe object
 *//**
 * @brief Pipe Tracing APIs
 * @defgroup subsys_tracing_apis_pipe Pipe Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_mbox *//**
 * @brief Trace Mailbox data get
 * @brief rx_msg Receive Message object
 *//**
 * @brief Trace Mailbox get attempt outcome
 * @param mbox Mailbox entry
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Mailbox get attempt blocking
 * @param mbox Mailbox entry
 * @param timeout Timeout period
 *//**
 * @brief Trace Mailbox get attempt entry
 * @param mbox Mailbox entry
 * @param timeout Timeout period
 *//**
 * @brief Trace Mailbox async put exit
 * @param mbox Mailbox object
 * @param sem Semaphore object
 *//**
 * @brief Trace Mailbox async put entry
 * @param mbox Mailbox object
 * @param sem Semaphore object
 *//**
 * @brief Trace Mailbox put attempt blocking
 * @param mbox Mailbox object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Mailbox put attempt entry
 * @param mbox Mailbox object
 * @param timeout Timeout period
 *//**
 * @brief Trace Mailbox message put attempt outcome
 * @param mbox Mailbox object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Mailbox message put attempt blocking
 * @param mbox Mailbox object
 * @param timeout Timeout period
 *//**
 * @brief Trace Mailbox message put attempt entry
 * @param mbox Mailbox object
 * @param timeout Timeout period
 *//**
 * @brief Trace initialization of Mailbox
 * @param mbox Mailbox object
 *//**
 * @brief Mailbox Tracing APIs
 * @defgroup subsys_tracing_apis_mbox Mailbox Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_msgq *//**
 * @brief Trace Message Queue purge
 * @param msgq Message Queue object
 *//**
 * @brief Trace Message Queue peek
 * @param msgq Message Queue object
 * @param ret Return value
 *//**
 * @brief Trace Message Queue get attempt outcome
 * @param msgq Message Queue object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Message Queue get attempt blockings
 * @param msgq Message Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Message Queue get attempt entry
 * @param msgq Message Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Message Queue put attempt outcome
 * @param msgq Message Queue object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Message Queue put attempt blocking
 * @param msgq Message Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Message Queue put attempt entry
 * @param msgq Message Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Message Queue cleanup attempt outcome
 * @param msgq Message Queue object
 * @param ret Return value
 *//**
 * @brief Trace Message Queue cleanup attempt entry
 * @param msgq Message Queue object
 *//**
 * @brief Trace Message Queue alloc init attempt outcome
 * @param msgq Message Queue object
 * @param ret Return value
 *//**
 * @brief Trace Message Queue alloc init attempt entry
 * @param msgq Message Queue object
 *//**
 * @brief Trace initialization of Message Queue
 * @param msgq Message Queue object
 *//**
 * @brief Message Queue Tracing APIs
 * @defgroup subsys_tracing_apis_msgq Message Queue Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_stack *//**
 * @brief Trace Stack pop attempt outcome
 * @param stack Stack object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Stack pop attempt blocking
 * @param stack Stack object
 * @param timeout Timeout period
 *//**
 * @brief Trace Stack pop attempt entry
 * @param stack Stack object
 * @param timeout Timeout period
 *//**
 * @brief Trace Stack push attempt outcome
 * @param stack Stack object
 * @param ret Return value
 *//**
 * @brief Trace Stack push attempt entry
 * @param stack Stack object
 *//**
 * @brief Trace Stack cleanup outcome
 * @param stack Stack object
 * @param ret Return value
 *//**
 * @brief Trace Stack cleanup attempt entry
 * @param stack Stack object
 *//**
 * @brief Trace Stack alloc init outcome
 * @param stack Stack object
 * @param ret Return value
 *//**
 * @brief Trace Stack alloc init attempt entry
 * @param stack Stack object
 *//**
 * @brief Trace initialization of Stack
 * @param stack Stack object
 *//**
 * @brief Stack Tracing APIs
 * @defgroup subsys_tracing_apis_stack Stack Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_lifo *//**
 * @brief Trace LIFO Queue get exit
 * @param lifo LIFO object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace LIFO Queue get entry
 * @param lifo LIFO object
 * @param timeout Timeout period
 *//**
 * @brief Trace LIFO Queue alloc put exit
 * @param lifo LIFO object
 * @param data Data item
 * @param ret Return value
 *//**
 * @brief Trace LIFO Queue alloc put entry
 * @param lifo LIFO object
 * @param data Data item
 *//**
 * @brief Trace LIFO Queue put exit
 * @param lifo LIFO object
 * @param data Data item
 *//**
 * @brief Trace LIFO Queue put entry
 * @param lifo LIFO object
 * @param data Data item
 *//**
 * @brief Trace initialization of LIFO Queue exit
 * @param lifo LIFO object
 *//**
 * @brief Trace initialization of LIFO Queue entry
 * @param lifo LIFO object
 *//**
 * @brief LIFO Tracing APIs
 * @defgroup subsys_tracing_apis_lifo LIFO Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_fifo *//**
 * @brief Trace FIFO Queue peek tail exit
 * @param fifo FIFO object
 * @param ret Return value
 *//**
 * @brief Trace FIFO Queue peek tail entry
 * @param fifo FIFO object
 *//**
 * @brief Trace FIFO Queue peek head exit
 * @param fifo FIFO object
 * @param ret Return value
 *//**
 * @brief Trace FIFO Queue peek head entry
 * @param fifo FIFO object
 *//**
 * @brief Trace FIFO Queue get exit
 * @param fifo FIFO object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace FIFO Queue get entry
 * @param fifo FIFO object
 * @param timeout Timeout period
 *//**
 * @brief Trace FIFO Queue put slist exit
 * @param fifo FIFO object
 * @param list Syslist object
 *//**
 * @brief Trace FIFO Queue put slist entry
 * @param fifo FIFO object
 * @param list Syslist object
 *//**
 * @brief Trace FIFO Queue put list exit
 * @param fifo FIFO object
 * @param head First ll-node
 * @param tail Last ll-node
 *//**
 * @brief Trace FIFO Queue put list entry
 * @param fifo FIFO object
 * @param head First ll-node
 * @param tail Last ll-node
 *//**
 * @brief Trace FIFO Queue alloc put exit
 * @param fifo FIFO object
 * @param data Data item
 * @param ret Return value
 *//**
 * @brief Trace FIFO Queue alloc put entry
 * @param fifo FIFO object
 * @param data Data item
 *//**
 * @brief Trace FIFO Queue put exit
 * @param fifo FIFO object
 * @param data Data item
 *//**
 * @brief Trace FIFO Queue put entry
 * @param fifo FIFO object
 * @param data Data item
 *//**
 * @brief Trace FIFO Queue cancel wait exit
 * @param fifo FIFO object
 *//**
 * @brief Trace FIFO Queue cancel wait entry
 * @param fifo FIFO object
 *//**
 * @brief Trace initialization of FIFO Queue exit
 * @param fifo FIFO object
 *//**
 * @brief Trace initialization of FIFO Queue entry
 * @param fifo FIFO object
 *//**
 * @brief FIFO Tracing APIs
 * @defgroup subsys_tracing_apis_fifo FIFO Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_queue *//**
 * @brief Trace Queue peek tail
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue peek head
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue unique append exit
 * @param queue Queue object
 *
 * @param ret Return value
 *//**
 * @brief Trace Queue unique append enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue remove exit
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue remove enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue get attempt outcome
 * @param queue Queue object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Queue get attempt blockings
 * @param queue Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Queue get attempt enter
 * @param queue Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Queue merge slist exit
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue merge slist enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue append list exit
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue append list enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue insert attempt exit
 * @param queue Queue object
 *//**
 * @brief Trace Queue insert attempt blocking
 * @param queue Queue object
 * @param timeout Timeout period
 *//**
 * @brief Trace Queue insert attempt entry
 * @param queue Queue object
 *//**
 * @brief Trace Queue alloc prepend exit
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue alloc prepend enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue prepend exit
 * @param queue Queue object
 *//**
 * @brief Trace Queue prepend enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue alloc append exit
 * @param queue Queue object
 * @param ret Return value
 *//**
 * @brief Trace Queue alloc append enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue append exit
 * @param queue Queue object
 *//**
 * @brief Trace Queue append enter
 * @param queue Queue object
 *//**
 * @brief Trace Queue insert attempt outcome
 * @param queue Queue object
 * @param alloc Allocation flag
 * @param ret Return value
 *//**
 * @brief Trace Queue insert attempt blocking
 * @param queue Queue object
 * @param alloc Allocation flag
 * @param timeout Timeout period
 *//**
 * @brief Trace Queue insert attempt entry
 * @param queue Queue object
 * @param alloc Allocation flag
 *//**
 * @brief Trace Queue cancel wait
 * @param queue Queue object
 *//**
 * @brief Trace initialization of Queue
 * @param queue Queue object
 *//**
 * @brief Queue Tracing APIs
 * @defgroup subsys_tracing_apis_queue Queue Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_condvar *//**
 * @brief Trace Conditional Variable wait exit
 * @param condvar Conditional Variable object
 * @param ret Return value
 *//**
 * @brief Trace Conditional Variable wait enter
 * @param condvar Conditional Variable object
 *//**
 * @brief Trace Conditional Variable broadcast exit
 * @param condvar Conditional Variable object
 * @param ret Return value
 *//**
 * @brief Trace Conditional Variable broadcast enter
 * @param condvar Conditional Variable object
 *//**
 * @brief Trace Conditional Variable signaling outcome
 * @param condvar Conditional Variable object
 * @param ret Return value
 *//**
 * @brief Trace Conditional Variable signaling blocking
 * @param condvar Conditional Variable object
 * @param timeout Timeout period
 *//**
 * @brief Trace Conditional Variable signaling start
 * @param condvar Conditional Variable object
 *//**
 * @brief Trace initialization of Conditional Variable
 * @param condvar Conditional Variable object
 * @param ret Return value
 *//**
 * @brief Conditional Variable Tracing APIs
 * @defgroup subsys_tracing_apis_condvar Conditional Variable Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_mutex *//**
 * @brief Trace Mutex unlock exit
 *//**
 * @brief Trace Mutex unlock entry
 * @param mutex Mutex object
 *//**
 * @brief Trace Mutex lock attempt outcome
 * @param mutex Mutex object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace Mutex lock attempt blocking
 * @param mutex Mutex object
 * @param timeout Timeout period
 *//**
 * @brief Trace Mutex lock attempt start
 * @param mutex Mutex object
 * @param timeout Timeout period
 *//**
 * @brief Trace initialization of Mutex
 * @param mutex Mutex object
 * @param ret Return value
 *//**
 * @brief Mutex Tracing APIs
 * @defgroup subsys_tracing_apis_mutex Mutex Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_sem *//**
 * @brief Trace resetting a Semaphore
 * @param sem Semaphore object
 *//**
 * @brief Trace taking a Semaphore attempt outcome
 * @param sem Semaphore object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace taking a Semaphore attempt blocking
 * @param sem Semaphore object
 * @param timeout Timeout period
 *//**
 * @brief Trace taking a Semaphore attempt start
 * @param sem Semaphore object
 * @param timeout Timeout period
 *//**
 * @brief Trace giving a Semaphore exit
 * @param sem Semaphore object
 *//**
 * @brief Trace giving a Semaphore entry
 * @param sem Semaphore object
 *//**
 * @brief Trace initialisation of a Semaphore
 * @param sem Semaphore object
 * @param ret Return value
 *//**
 * @brief Semaphore Tracing APIs
 * @defgroup subsys_tracing_apis_sem Semaphore Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_poll *//**
 * @brief Trace raising of Poll Signal
 * @param signal Poll Signal
 * @param ret Return value
 *//**
 * @brief Trace checking of Poll Signal
 * @param signal Poll Signal
 *//**
 * @brief Trace resetting of Poll Signal
 * @param signal Poll Signal
 *//**
 * @brief Trace initialisation of a Poll Signal
 * @param signal Poll Signal
 *//**
 * @brief Trace Polling call outcome
 * @param events Poll Events
 * @param ret Return value
 *//**
 * @brief Trace Polling call start
 * @param events Poll Events
 *//**
 * @brief Trace initialisation of a Poll Event
 * @param event Poll Event
 *//**
 * @brief Poll Tracing APIs
 * @defgroup subsys_tracing_apis_poll Poll Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_work_poll *//**
 * @brief Trace work poll cancel exit
 * @param work Work structure
 * @param ret Return value
 *//**
 * @brief Trace work poll cancel enter
 * @param work Work structure
 *//**
 * @brief Trace work poll submit to system queue exit
 * @param work Work structure
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace work poll submit to system queue enter
 * @param work Work structure
 * @param timeout Timeout period
 *//**
 * @brief Trace work poll submit to queue exit
 * @param work_q Work queue
 * @param work Work structure
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Trace work poll submit to queue blocking
 * @param work_q Work queue
 * @param work Work structure
 * @param timeout Timeout period
 *//**
 * @brief Trace work poll submit to queue enter
 * @param work_q Work queue
 * @param work Work structure
 * @param timeout Timeout period
 *//**
 * @brief Trace initialisation of a Work Poll structure exit
 * @param work Work structure
 *//**
 * @brief Trace initialisation of a Work Poll structure enter
 * @param work Work structure
 *//**
 * @brief Work Poll Tracing APIs
 * @defgroup subsys_tracing_apis_work_poll Work Poll Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_work_delayable *//**
 * @brief Trace delayable work cancel sync enter
 * @param dwork Delayable Work structure
 * @param sync Sync object
 * @param ret Return value
 *//**
 * @brief Trace delayable work cancel sync enter
 * @param dwork Delayable Work structure
 * @param sync Sync object
 *//**
 * @brief Trace delayable work cancel enter
 * @param dwork Delayable Work structure
 * @param ret Return value
 *//**
 * @brief Trace delayable work cancel enter
 * @param dwork Delayable Work structure
 *//**
 * @brief Trace delayable work flush exit
 * @param dwork Delayable Work structure
 * @param sync Sync object
 * @param ret Return value
 *//**
 * @brief Trace delayable work flush enter
 * @param dwork Delayable Work structure
 * @param sync Sync object
 *//**
 * @brief Trace reschedule delayable work for system queue exit
 * @param dwork Delayable Work structure
 * @param delay Delay period
 * @param ret Return value
 *//**
 * @brief Trace reschedule delayable work for system queue enter
 * @param dwork Delayable Work structure
 * @param delay Delay period
 *//**
 * @brief Trace reschedule delayable work for queue exit
 * @param queue Work Queue structure
 * @param dwork Delayable Work structure
 * @param delay Delay period
 * @param ret Return value
 *//**
 * @brief Trace reschedule delayable work for queue enter
 * @param queue Work Queue structure
 * @param dwork Delayable Work structure
 * @param delay Delay period
 *//**
 * @brief Trace schedule delayable work for system work queue exit
 * @param dwork Delayable Work structure
 * @param delay Delay period
 * @param ret Return value
 *//**
 * @brief Trace schedule delayable work for system work queue enter
 * @param dwork Delayable Work structure
 * @param delay Delay period
 *//**
 * @brief Trace schedule delayable work for queue exit
 * @param queue Work Queue structure
 * @param dwork Delayable Work structure
 * @param delay Delay period
 * @param ret Return value
 *//**
 * @brief Trace schedule delayable work for queue enter
 * @param queue Work Queue structure
 * @param dwork Delayable Work structure
 * @param delay Delay period
 *//**
 * @brief Trace initialisation of a Delayable Work structure
 * @param dwork Delayable Work structure
 *//**
 * @brief Work Delayable Tracing APIs
 * @defgroup subsys_tracing_apis_work_delayable Work Delayable Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_work_q *//**
 * @brief Trace Work Queue unplug call exit
 * @param queue Work Queue structure
 * @param ret Return value
 *//**
 * @brief Trace Work Queue unplug call entry
 * @param queue Work Queue structure
 *//**
 * @brief Trace Work Queue drain call exit
 * @param queue Work Queue structure
 * @param ret Return value
 *//**
 * @brief Trace Work Queue drain call entry
 * @param queue Work Queue structure
 *//**
 * @brief Trace start of a Work Queue call exit
 * @param queue Work Queue structure
 *//**
 * @brief Trace start of a Work Queue call entry
 * @param queue Work Queue structure
 *//**
 * @brief Trace initialisation of a Work Queue structure
 * @param queue Work Queue structure
 *//**
 * @brief Work Queue Tracing APIs
 * @defgroup subsys_tracing_apis_work_q Work Queue Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_work *//**
 * @brief Trace cancel sync work call exit
 * @param work Work structure
 * @param sync Sync object
 * @param ret Return value
 *//**
 * @brief Trace cancel sync work call blocking
 * @param work Work structure
 * @param sync Sync object
 *//**
 * @brief Trace cancel sync work call entry
 * @param work Work structure
 * @param sync Sync object
 *//**
 * @brief Trace cancel work call exit
 * @param work Work structure
 * @param ret Return value
 *//**
 * @brief Trace cancel work call entry
 * @param work Work structure
 *//**
 * @brief Trace flush work call exit
 * @param work Work structure
 * @param ret Return value
 *//**
 * @brief Trace flush work call blocking
 * @param work Work structure
 * @param timeout Timeout period
 *//**
 * @brief Trace flush work call entry
 * @param work Work structure
 *//**
 * @brief Trace submit work to system work queue call exit
 * @param work Work structure
 * @param ret Return value
 *//**
 * @brief Trace submit work to system work queue call entry
 * @param work Work structure
 *//**
 * @brief Trace submit work to work queue call exit
 * @param queue Work queue structure
 * @param work Work structure
 * @param ret Return value
 *//**
 * @brief Trace submit work to work queue call entry
 * @param queue Work queue structure
 * @param work Work structure
 *//**
 * @brief Trace initialisation of a Work structure
 * @param work Work structure
 *//**
 * @brief Work Tracing APIs
 * @defgroup subsys_tracing_apis_work Work Tracing APIs
 * @{
 *//* end of subsys_tracing_apis_thread *//** @}c*//**
 * @brief Trace implicit thread suspend invocation by the scheduler
 * @param thread Thread object
 *//**
 * @brief Trace implicit thread resume invocation by the scheduler
 * @param thread Thread object
 *//**
 * @brief Trace implicit thread pend invocation by the scheduler
 * @param thread Thread object
 *//**
 * @brief Trace implicit thread ready invocation by the scheduler
 * @param thread Thread object
 *//**
 * @brief Trace implicit thread set priority invocation by the scheduler
 * @param thread Thread object
 * @param prio Thread priority
 *//**
 * @brief Trace implicit thread abort invocation by the scheduler
 * @param thread Thread object
 *//**
 * @brief Trace implicit thread wakeup invocation by the scheduler
 * @param thread Thread object
 *//**
 * @brief Provide information about specific thread
 * @param thread Thread object
 *//**
 * @brief Called when a thread is pending
 * @param thread Thread object
 *//**
 * @brief Called when a thread is ready to run
 * @param thread Thread object
 *//**
 * @brief Called after a thread has been selected to run
 *//**
 * @brief Called before a thread has been selected to run
 *//**
 * @brief Called when a thread name is set
 * @param thread Thread object
 * @param ret Return value
 *//**
 * @brief Called when the thread scheduler is unlocked
 *//**
 * @brief Called when the thread scheduler is locked
 *//**
 * @brief Called when a thread exits the resumed from suspension
 * function.
 * @param thread Thread object
 *//**
 * @brief Called when a thread enters the resume from suspension
 * function.
 * @param thread Thread object
 *//**
 * @brief Called when a thread exits the k_thread_suspend
 * function.
 * @param thread Thread object
 *//**
 * @brief Called when a thread enters the k_thread_suspend
 * function.
 * @param thread Thread object
 *//**
 * @brief Called when setting priority of a thread
 * @param thread Thread object
 *//**
 * @brief Called when a thread exits the k_thread_abort routine
 * @param thread Thread object
 *//**
 * @brief Called when a thread enters the k_thread_abort routine
 * @param thread Thread object
 *//**
 * @brief Called when a thread is being aborted
 * @param thread Thread object
 *//**
 * @brief Called when a thread is started
 * @param thread Thread object
 *//**
 * @brief Called when a thread wakes up
 * @param thread Thread object
 *//**
 * @brief Called when a thread yields
 *//**
 * @brief Called when exiting k_thread_busy_wait
 * @param usec_to_wait Duration in microseconds
 *//**
 * @brief Called when entering k_thread_busy_wait
 * @param usec_to_wait Duration in microseconds
 *//**
 * @brief Called when exiting k_thread_usleep
 * @param us Duration in microseconds
 * @param ret Return value
 *//**
 * @brief Called when entering k_thread_usleep
 * @param us Duration in microseconds
 *//**
 * @brief Called when exiting k_thread_msleep
 * @param ms Duration in milliseconds
 * @param ret Return value
 *//**
 * @brief Called when entering k_thread_msleep
 * @param ms Duration in milliseconds
 *//**
 * @brief Called when exiting k_thread_sleep
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Called when entering k_thread_sleep
 * @param timeout Timeout period
 *//**
 * @brief Called when exiting k_thread_join
 * @param thread Thread object
 * @param timeout Timeout period
 * @param ret Return value
 *//**
 * @brief Called when k_thread_join blocks
 * @param thread Thread object
 * @param timeout Timeout period
 *//**
 * @brief Called when entering a k_thread_join
 * @param thread Thread object
 * @param timeout Timeout period
 *//**
 * @brief Trace Thread entering user mode
 *//**
 * @brief Trace creating a Thread
 * @param new_thread Thread object
 *//**
 * @brief Called when exiting a k_thread_foreach_unlocked
 *//**
 * @brief Called when entering a k_thread_foreach_unlocked
 *//**
 * @brief Called when exiting a k_thread_foreach call
 *//**
 * @brief Called when entering a k_thread_foreach call
 *//**
 * @brief Thread Tracing APIs
 * @defgroup subsys_tracing_apis_thread Thread Tracing APIs
 * @{
 *//**
 * @brief Tracing APIs
 * @defgroup subsys_tracing_apis Tracing APIs
 * @{
 *//**
 * @brief Tracing
 *
 * The tracing subsystem provides hooks that permits you to collect data from
 * your application and allows tools running on a host to visualize the
 * inner-working of the kernel and various other subsystems.
 *
 * @defgroup subsys_tracing Tracing
 * @ingroup os_services
 * @{
 */k_float_enablez_impl_k_float_enablek_float_disablez_impl_k_float_disablek_str_outz_impl_k_str_outk_poll_signal_raisek_poll_signal *z_impl_k_poll_signal_raisek_poll_signal_checkz_impl_k_poll_signal_checkk_poll_signal_resetz_impl_k_poll_signal_resetk_poll_signal_initz_impl_k_poll_signal_initk_pollk_poll_event *z_impl_k_pollk_pipe_buffer_flushk_pipe *z_impl_k_pipe_buffer_flushk_pipe_flushz_impl_k_pipe_flushk_pipe_write_availz_impl_k_pipe_write_availk_pipe_read_availz_impl_k_pipe_read_availk_pipe_getz_impl_k_pipe_getk_pipe_putz_impl_k_pipe_putk_pipe_alloc_initz_impl_k_pipe_alloc_initk_msgq_num_used_getk_msgq *k_msgq_get_attrsk_msgq_attrs *z_impl_k_msgq_get_attrsk_msgq_num_free_getk_msgq_purgez_impl_k_msgq_purgek_msgq_peek_atz_impl_k_msgq_peek_atk_msgq_peekz_impl_k_msgq_peekk_msgq_getz_impl_k_msgq_getk_msgq_putz_impl_k_msgq_putk_msgq_alloc_initz_impl_k_msgq_alloc_initk_sem_count_getk_sem *k_sem_resetz_impl_k_sem_resetk_sem_givez_impl_k_sem_givek_sem_takez_impl_k_sem_takek_sem_initz_impl_k_sem_initk_condvar_waitk_condvar *k_mutex *z_impl_k_condvar_waitk_condvar_broadcastz_impl_k_condvar_broadcastk_condvar_signalz_impl_k_condvar_signalk_condvar_initz_impl_k_condvar_initk_mutex_unlockz_impl_k_mutex_unlockk_mutex_lockz_impl_k_mutex_lockk_mutex_initz_impl_k_mutex_initk_stack_popk_stack *stack_data_t *z_impl_k_stack_popk_stack_pushz_impl_k_stack_pushk_stack_alloc_initz_impl_k_stack_alloc_initk_event_wait_allk_event *z_impl_k_event_wait_allk_event_waitz_impl_k_event_waitk_event_clearz_impl_k_event_cleark_event_set_maskedz_impl_k_event_set_maskedk_event_setz_impl_k_event_setk_event_postz_impl_k_event_postk_event_initz_impl_k_event_initk_futex_wakek_futex *z_impl_k_futex_wakek_futex_waitz_impl_k_futex_waitk_queue_peek_tailk_queue *z_impl_k_queue_peek_tailk_queue_peek_headz_impl_k_queue_peek_headk_queue_is_emptyk_queue_getz_impl_k_queue_getk_queue_alloc_prependz_impl_k_queue_alloc_prependk_queue_alloc_appendz_impl_k_queue_alloc_appendk_queue_cancel_waitz_impl_k_queue_cancel_waitk_queue_initz_impl_k_queue_initk_uptime_ticksz_impl_k_uptime_ticksk_timer_user_data_getconst k_timerconst k_timer *k_timer *k_timer_user_data_setk_timer_remaining_ticksk_timer_expires_ticksk_timer_status_syncz_impl_k_timer_status_synck_timer_status_getz_impl_k_timer_status_getk_timer_stopz_impl_k_timer_stopk_timer_startz_impl_k_timer_startk_thread_name_copyz_impl_k_thread_name_copyk_thread_name_setz_impl_k_thread_name_setk_thread_custom_data_getz_impl_k_thread_custom_data_getoptionssigsignaledeventsnum_eventspipebytes_to_readbytes_readmin_xferbytes_to_writebytes_writtenmsgqattrsidxmsg_sizemax_msgsseminitial_countlimitcondvarmutexnum_entrieseventevents_maskfutexwake_allexpectedqueuetimeruser_datadurationperiodstrk_thread_custom_data_setz_impl_k_thread_custom_data_setk_is_preempt_threadz_impl_k_is_preempt_threadk_thread_resumez_impl_k_thread_resumek_thread_suspendz_impl_k_thread_suspendk_thread_deadline_setz_impl_k_thread_deadline_setk_thread_priority_setz_impl_k_thread_priority_setk_thread_priority_getz_impl_k_thread_priority_getk_thread_timeout_remaining_ticksconst k_threadconst k_thread *k_thread_timeout_expires_ticksk_thread_startz_impl_k_thread_startk_thread_abortz_impl_k_thread_abortk_sched_current_thread_queryz_impl_k_sched_current_thread_queryk_wakeupz_impl_k_wakeupk_yieldz_impl_k_yieldk_busy_waitz_impl_k_busy_waitk_usleepz_impl_k_usleepk_sleepz_impl_k_sleepk_thread_joinz_impl_k_thread_joink_thread_stack_space_getz_impl_k_thread_stack_space_getk_thread_createz_impl_k_thread_createk_thread_stack_freez_impl_k_thread_stack_freek_thread_stack_allocz_impl_k_thread_stack_allocZ_INCLUDE_SYSCALLS_KERNEL_Hz_impl_k_msgq_num_used_getz_impl_k_msgq_num_free_getz_impl_k_sem_count_getz_impl_k_queue_is_emptyz_impl_k_timer_user_data_getz_impl_k_timer_user_data_setz_impl_k_timer_remaining_ticksz_impl_k_timer_expires_ticksz_impl_k_thread_timeout_remaining_ticksz_impl_k_thread_timeout_expires_ticksdeadlineusec_to_waitusunused_ptrstack_sizedelay<syscalls/kernel.h><zephyr/tracing/tracing_macros.h><zephyr/kernel_includes.h>k_sys_runtime_stats_disablek_sys_runtime_stats_enablek_thread_runtime_stats_disablek_thread_runtime_stats_enablek_thread_runtime_stats_all_getk_thread_runtime_stats_t *k_thread_runtime_stats_getz_timer_expiration_handlerz_init_static_threadsk_cpu_atomic_idlek_cpu_idlek_poll_event_initk_callock_freek_mallock_aligned_allock_heap_freek_heap_allock_heap_aligned_allock_heap_initk_mem_slab_runtime_stats_reset_maxk_mem_slab *k_mem_slab_runtime_stats_getsys_memory_stats *k_mem_slab_num_free_getk_mem_slab_max_used_getslabk_mem_slab_num_used_getk_mem_slab_freek_mem_slab_allock_mem_slab_initk_pipe_cleanupk_pipe_initk_mbox_data_getk_mbox_msg *k_mbox_getk_mbox *k_mbox_async_putk_mbox_putk_mbox_initk_msgq_cleanupk_msgq_initk_work_poll_cancelk_work_poll *k_work_poll_submitk_work_poll_submit_to_queuek_work_q *k_work_poll_initk_work_user_queue_thread_getk_work_user_q *k_work_user_queue_startk_work_user_submit_to_queuek_work_user *-EBUSYK_WORK_USER_STATE_PENDINGk_work_user_is_pendingk_work_user_initk_work_queue_thread_getk_work_delayable_remaining_getconst k_work_delayableconst k_work_delayable *k_work_delayable *k_work_delayable_expires_getk_work_delayable_is_pendingk_work_delayable_from_workk_work *workstruct k_work_delayableSAME_TYPE(*(work), ((struct k_work_delayable *)0)->work) || SAME_TYPE(*(work), void)__builtin_types_compatible_p(__typeof__(*(work)), __typeof__(((struct k_work_delayable *)0)->work)) || __builtin_types_compatible_p(__typeof__(*(work)), __typeof__(void))"pointer type mismatch in CONTAINER_OF"*(work)((struct k_work_delayable *)0)->workvoidpointer type mismatch in CONTAINER_OFk_work_is_pendingconst k_workconst k_work *k_work_cancel_delayable_synck_work_sync *k_work_cancel_delayablek_work_flush_delayablek_work_reschedulek_work_reschedule_for_queuek_work_schedulek_work_schedule_for_queuek_work_delayable_busy_getk_work_init_delayablek_work_queue_unplugk_work_queue_draink_work_queue_startconst k_work_queue_configconst k_work_queue_config *k_work_queue_config *k_work_queue_initk_work_cancel_synck_work_cancelk_work_flushk_work_submitk_work_submit_to_queuek_work_busy_getk_work_initk_stack_cleanupk_stack_initk_event_testk_queue_unique_appendk_queue_removek_queue_merge_slistk_queue_append_listk_queue_insertk_queue_prependk_queue_appendk_cycle_get_64"64-bit cycle counter not enabled on this platform. " "See CONFIG_TIMER_HAS_64BIT_CYCLE_COUNTER"!IS_ENABLED(CONFIG_TIMER_HAS_64BIT_CYCLE_COUNTER)k_cycle_get_32k_uptime_deltaint64_t *uptimedeltak_uptime_get_32k_uptime_getk_uptime_ticks()CONFIG_SYS_CLOCK_MAX_TIMEOUT_DAYS * 24ULL * 3600ULL * 100365 * 24ULL * 3600ULL * 100(0xffffffffUL)876031536000315360000074485672957448567294work_qdworkreftimek_timer_remaining_getk_timer_remaining_ticks(timer)k_timer_initk_thread_state_strk_thread_name_getk_sched_unlockk_sched_lockk_is_pre_kernelk_is_in_isrk_thread_time_slice_setk_sched_time_slice_setz_timeout_expiresk_current_getk_can_yieldk_msleepms(k_ticks_t)k_ms_to_ticks_ceil64(MAX(ms, 0))(k_ticks_t)((1) ? ( ((100) == (1000)) ? (uint64_t) ((((ms) > (0)) ? (ms) : (0))) : ((1000) > (100) && (1000) % (100) == 0U) ? (((uint64_t) ((((ms) > (0)) ? (ms) : (0))) + ((0) ? ((1000) / (100)) / 2 : (1) ? ((1000) / (100)) - 1 : 0)) / ((1000) / (100))) : ((100) > (1000) && (100) % (1000) == 0U) ? (uint64_t) ((((ms) > (0)) ? (ms) : (0)))*((100) / (1000)) : ((((((365 * 24ULL * 3600ULL * 1000) + ((0xffffffffUL)) - 1) / ((0xffffffffUL))) * 100) <= (0xffffffffUL)) ? (((uint64_t) ((((ms) > (0)) ? (ms) : (0)))*(100) + ((0) ? (1000) / 2 : (1) ? (1000) - 1 : 0)) / (1000)) : (((uint64_t) ((((ms) > (0)) ? (ms) : (0))) / (1000))*(100) + (((uint64_t) ((((ms) > (0)) ? (ms) : (0))) % (1000))*(100) + ((0) ? (1000) / 2 : (1) ? (1000) - 1 : 0)) / (1000))) ) : (((uint64_t) ((((ms) > (0)) ? (ms) : (0))) / (1000))*(100) + (((uint64_t) ((((ms) > (0)) ? (ms) : (0))) % (1000))*(100) + ((0) ? (1000) / 2 : (1) ? (1000) - 1 : 0)) / (1000)) )MAX(ms, 0)(((ms) > (0)) ? (ms) : (0))CONFIG_SYS_CLOCK_MAX_TIMEOUT_DAYS * 24ULL * 3600ULL * 1000365 * 24ULL * 3600ULL * 1000315360000003583096729535830967294k_thread_heap_assignk_thread_user_mode_enterk_thread_foreach_unlockedk_thread_foreachk_poll_modesK_POLL_MODE_NOTIFY_ONLYK_POLL_NUM_MODESk_mem_slabk_mem_slab_infok_pipek_mboxk_mbox_msgk_msgq_attrsk_work_pollk_work_user_qk_work_user_handler_tk_work_userk_work_queue_configk_work_syncz_work_cancellerz_work_flusherk_work_delayableK_WORK_RUNNING_BITK_WORK_CANCELING_BITK_WORK_QUEUED_BITK_WORK_DELAYED_BITK_WORK_MASKBIT(K_WORK_DELAYED_BIT)BIT(K_WORK_QUEUED_BIT)BIT(K_WORK_DELAYED_BIT) | BIT(K_WORK_QUEUED_BIT)BIT(K_WORK_RUNNING_BIT)BIT(K_WORK_DELAYED_BIT) | BIT(K_WORK_QUEUED_BIT)
		| BIT(K_WORK_RUNNING_BIT)BIT(K_WORK_CANCELING_BIT)BIT(K_WORK_DELAYED_BIT) | BIT(K_WORK_QUEUED_BIT)
		| BIT(K_WORK_RUNNING_BIT) | BIT(K_WORK_CANCELING_BIT)K_WORK_DELAYABLE_BITK_WORK_DELAYABLEBIT(K_WORK_DELAYABLE_BIT)K_WORK_QUEUE_STARTED_BITK_WORK_QUEUE_STARTEDBIT(K_WORK_QUEUE_STARTED_BIT)K_WORK_QUEUE_BUSY_BITK_WORK_QUEUE_BUSYBIT(K_WORK_QUEUE_BUSY_BIT)K_WORK_QUEUE_DRAIN_BITK_WORK_QUEUE_DRAINBIT(K_WORK_QUEUE_DRAIN_BIT)K_WORK_QUEUE_PLUGGED_BITK_WORK_QUEUE_PLUGGEDBIT(K_WORK_QUEUE_PLUGGED_BIT)K_WORK_QUEUE_NO_YIELD_BITK_WORK_QUEUE_NO_YIELDBIT(K_WORK_QUEUE_NO_YIELD_BIT)K_WORK_RUNNINGK_WORK_CANCELINGK_WORK_QUEUEDK_WORK_DELAYEDk_work_handler_tk_workk_work_qk_condvark_stackstack_data_tk_lifok_eventk_timer_stop_tk_timer_expiry_tk_timer_static_thread_datak_thread_user_cb_t_poller_cb_tk_poll_eventk_msgqk_fifok_queuek_semk_poll_signal_poll_states_bits_POLL_STATE_NOT_READY_POLL_STATE_SIGNALED_POLL_STATE_SEM_AVAILABLE_POLL_STATE_DATA_AVAILABLE_POLL_STATE_CANCELLED_POLL_STATE_MSGQ_DATA_AVAILABLE_POLL_STATE_PIPE_DATA_AVAILABLE_POLL_NUM_STATES_poll_types_bits_POLL_TYPE_IGNORE_POLL_TYPE_SIGNAL_POLL_TYPE_SEM_AVAILABLE_POLL_TYPE_DATA_AVAILABLE_POLL_TYPE_MSGQ_DATA_AVAILABLE_POLL_TYPE_PIPE_DATA_AVAILABLE_POLL_NUM_TYPESexecution_context_typesK_ISRK_COOP_THREADK_PREEMPT_THREADk_futexfree_listnum_usedblock_sizenum_blockswrite_indexread_indexbytes_usedwritersreadersrx_msg_queuetx_msg_queue_async_sem_syncing_threadtx_target_threadrx_source_threadtx_data_mailboxused_msgspoll_resultreal_handlerpollerworkq_reservedno_yieldcancellerflusherdrainqnotifyqpendingowner_orig_priolock_countowner_queuestatusstop_fnexpiry_fninit_delay_msinit_nameinit_optionsinit_prioinit_p3init_p2init_p1init_entryinit_stack_sizeinit_stackinit_threadwrite_ptrread_ptrbuffer_endbuffer_startk_fifo *fifodata_qcountsignalpoll_eventstagz_poller *k_sys_work_qz_sys_post_kernelz_tls_currentsizeof(intptr_t) == sizeof(long)sizeof(int64_t) == sizeof(long long)sizeof(int32_t) == sizeof(int)k_panic()z_except_reason(K_ERR_KERNEL_PANIC)k_oops()z_except_reason(K_ERR_KERNEL_OOPS)z_except_reason(reason)ARCH_EXCEPT(reason)K_POLL_EVENT_STATIC_INITIALIZER(_event_type,_event_mode,_event_obj,event_tag){ .tag = event_tag, .type = _event_type, .state = K_POLL_STATE_NOT_READY, .mode = _event_mode, .unused = 0, { .obj = _event_obj, }, }K_POLL_EVENT_INITIALIZER(_event_type,_event_mode,_event_obj){ .poller = NULL, .type = _event_type, .state = K_POLL_STATE_NOT_READY, .mode = _event_mode, .unused = 0, { .obj = _event_obj, }, }K_POLL_SIGNAL_INITIALIZER(obj){ .poll_events = SYS_DLIST_STATIC_INIT(&obj.poll_events), .signaled = 0, .result = 0, }K_POLL_STATE_CANCELLEDZ_POLL_STATE_BIT(_POLL_STATE_CANCELLED)K_POLL_STATE_PIPE_DATA_AVAILABLEZ_POLL_STATE_BIT(_POLL_STATE_PIPE_DATA_AVAILABLE)K_POLL_STATE_MSGQ_DATA_AVAILABLEZ_POLL_STATE_BIT(_POLL_STATE_MSGQ_DATA_AVAILABLE)K_POLL_STATE_FIFO_DATA_AVAILABLEK_POLL_STATE_DATA_AVAILABLEZ_POLL_STATE_BIT(_POLL_STATE_DATA_AVAILABLE)K_POLL_STATE_SEM_AVAILABLEZ_POLL_STATE_BIT(_POLL_STATE_SEM_AVAILABLE)K_POLL_STATE_SIGNALEDZ_POLL_STATE_BIT(_POLL_STATE_SIGNALED)K_POLL_STATE_NOT_READYK_POLL_TYPE_PIPE_DATA_AVAILABLEZ_POLL_TYPE_BIT(_POLL_TYPE_PIPE_DATA_AVAILABLE)K_POLL_TYPE_MSGQ_DATA_AVAILABLEZ_POLL_TYPE_BIT(_POLL_TYPE_MSGQ_DATA_AVAILABLE)K_POLL_TYPE_FIFO_DATA_AVAILABLEK_POLL_TYPE_DATA_AVAILABLEZ_POLL_TYPE_BIT(_POLL_TYPE_DATA_AVAILABLE)K_POLL_TYPE_SEM_AVAILABLEZ_POLL_TYPE_BIT(_POLL_TYPE_SEM_AVAILABLE)K_POLL_TYPE_SIGNALZ_POLL_TYPE_BIT(_POLL_TYPE_SIGNAL)K_POLL_TYPE_IGNORE_POLL_EVENT_NUM_UNUSED_BITS(32 - (0 + 8 + _POLL_NUM_TYPES + _POLL_NUM_STATES + 1 ))Z_POLL_STATE_BIT(state)(1U << ((state) - 1U))Z_POLL_TYPE_BIT(type)(1U << ((type) - 1U))_INIT_OBJ_POLL_EVENT(obj)K_HEAP_DEFINE_NOCACHE(name,bytes)Z_HEAP_DEFINE_IN_SECT(name, bytes, __nocache)K_HEAP_DEFINE(name,bytes)Z_HEAP_DEFINE_IN_SECT(name, bytes, __noinit_named(kheap_buf_ ## name))Z_HEAP_DEFINE_IN_SECT(name,bytes,in_section)char in_section __aligned(8) kheap_ ## name[MAX(bytes, Z_HEAP_MIN_SIZE)]; STRUCT_SECTION_ITERABLE(k_heap, name) = { .heap = { .init_mem = kheap_ ## name, .init_bytes = MAX(bytes, Z_HEAP_MIN_SIZE), }, }Z_HEAP_MIN_SIZE(sizeof(void *) > 4 ? 56 : 44)K_MEM_SLAB_DEFINE_STATIC(name,slab_block_size,slab_num_blocks,slab_align)static char __noinit_named(k_mem_slab_buf_ ## name) __aligned(WB_UP(slab_align)) _k_mem_slab_buf_ ## name[(slab_num_blocks) * WB_UP(slab_block_size)]; static STRUCT_SECTION_ITERABLE(k_mem_slab, name) = Z_MEM_SLAB_INITIALIZER(name, _k_mem_slab_buf_ ## name, WB_UP(slab_block_size), slab_num_blocks)K_MEM_SLAB_DEFINE(name,slab_block_size,slab_num_blocks,slab_align)char __noinit_named(k_mem_slab_buf_ ## name) __aligned(WB_UP(slab_align)) _k_mem_slab_buf_ ## name[(slab_num_blocks) * WB_UP(slab_block_size)]; STRUCT_SECTION_ITERABLE(k_mem_slab, name) = Z_MEM_SLAB_INITIALIZER(name, _k_mem_slab_buf_ ## name, WB_UP(slab_block_size), slab_num_blocks)Z_MEM_SLAB_INITIALIZER(_slab,_slab_buffer,_slab_block_size,_slab_num_blocks){ .wait_q = Z_WAIT_Q_INIT(&(_slab).wait_q), .lock = {}, .buffer = _slab_buffer, .free_list = NULL, .info = {_slab_num_blocks, _slab_block_size, 0} }K_PIPE_DEFINE(name,pipe_buffer_size,pipe_align)static unsigned char __noinit __aligned(pipe_align) _k_pipe_buf_ ## name[pipe_buffer_size]; STRUCT_SECTION_ITERABLE(k_pipe, name) = Z_PIPE_INITIALIZER(name, _k_pipe_buf_ ## name, pipe_buffer_size)Z_PIPE_INITIALIZER(obj,pipe_buffer,pipe_buffer_size){ .buffer = pipe_buffer, .size = pipe_buffer_size, .bytes_used = 0, .read_index = 0, .write_index = 0, .lock = {}, .wait_q = { .readers = Z_WAIT_Q_INIT(&obj.wait_q.readers), .writers = Z_WAIT_Q_INIT(&obj.wait_q.writers) }, Z_POLL_EVENT_OBJ_INIT(obj) .flags = 0, }K_PIPE_FLAG_ALLOCK_MBOX_DEFINE(name)STRUCT_SECTION_ITERABLE(k_mbox, name) = Z_MBOX_INITIALIZER(name)Z_MBOX_INITIALIZER(obj){ .tx_msg_queue = Z_WAIT_Q_INIT(&obj.tx_msg_queue), .rx_msg_queue = Z_WAIT_Q_INIT(&obj.rx_msg_queue), }K_MSGQ_DEFINE(q_name,q_msg_size,q_max_msgs,q_align)static char __noinit __aligned(q_align) _k_fifo_buf_ ## q_name[(q_max_msgs) * (q_msg_size)]; STRUCT_SECTION_ITERABLE(k_msgq, q_name) = Z_MSGQ_INITIALIZER(q_name, _k_fifo_buf_ ## q_name, (q_msg_size), (q_max_msgs))K_MSGQ_FLAG_ALLOCZ_MSGQ_INITIALIZER(obj,q_buffer,q_msg_size,q_max_msgs){ .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), .msg_size = q_msg_size, .max_msgs = q_max_msgs, .buffer_start = q_buffer, .buffer_end = q_buffer + (q_max_msgs * q_msg_size), .read_ptr = q_buffer, .write_ptr = q_buffer, .used_msgs = 0, Z_POLL_EVENT_OBJ_INIT(obj) }K_WORK_DEFINE(work,work_handler)struct k_work work = Z_WORK_INITIALIZER(work_handler)K_WORK_USER_DEFINE(work,work_handler)struct k_work_user work = Z_WORK_USER_INITIALIZER(work_handler)Z_WORK_USER_INITIALIZER(work_handler){ ._reserved = NULL, .handler = work_handler, .flags = 0 }K_WORK_DELAYABLE_DEFINE(work,work_handler)struct k_work_delayable work = Z_WORK_DELAYABLE_INITIALIZER(work_handler)Z_WORK_DELAYABLE_INITIALIZER(work_handler){ .work = { .handler = work_handler, .flags = K_WORK_DELAYABLE, }, }Z_WORK_INITIALIZER(work_handler){ .handler = work_handler, }K_SEM_DEFINE(name,initial_count,count_limit)STRUCT_SECTION_ITERABLE(k_sem, name) = Z_SEM_INITIALIZER(name, initial_count, count_limit); BUILD_ASSERT(((count_limit) != 0) && ((initial_count) <= (count_limit)) && ((count_limit) <= K_SEM_MAX_LIMIT));K_SEM_MAX_LIMITZ_SEM_INITIALIZER(obj,initial_count,count_limit){ .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), .count = initial_count, .limit = count_limit, Z_POLL_EVENT_OBJ_INIT(obj) }K_CONDVAR_DEFINE(name)STRUCT_SECTION_ITERABLE(k_condvar, name) = Z_CONDVAR_INITIALIZER(name)Z_CONDVAR_INITIALIZER(obj){ .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), }K_MUTEX_DEFINE(name)STRUCT_SECTION_ITERABLE(k_mutex, name) = Z_MUTEX_INITIALIZER(name)Z_MUTEX_INITIALIZER(obj){ .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), .owner = NULL, .lock_count = 0, .owner_orig_prio = K_LOWEST_APPLICATION_THREAD_PRIO, }K_STACK_DEFINE(name,stack_num_entries)stack_data_t __noinit _k_stack_buf_ ## name[stack_num_entries]; STRUCT_SECTION_ITERABLE(k_stack, name) = Z_STACK_INITIALIZER(name, _k_stack_buf_ ## name, stack_num_entries)Z_STACK_INITIALIZER(obj,stack_buffer,stack_num_entries){ .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), .base = stack_buffer, .next = stack_buffer, .top = stack_buffer + stack_num_entries, }K_STACK_FLAG_ALLOC((uint8_t)1)K_LIFO_DEFINE(name)STRUCT_SECTION_ITERABLE(k_lifo, name) = Z_LIFO_INITIALIZER(name)k_lifo_get(lifo,timeout)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_lifo, get, lifo, timeout); void *lg_ret = k_queue_get(&(lifo)->_queue, timeout); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_lifo, get, lifo, timeout, lg_ret); lg_ret; })k_lifo_alloc_put(lifo,data)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_lifo, alloc_put, lifo, data); int lap_ret = k_queue_alloc_prepend(&(lifo)->_queue, data); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_lifo, alloc_put, lifo, data, lap_ret); lap_ret; })k_lifo_put(lifo,data)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_lifo, put, lifo, data); k_queue_prepend(&(lifo)->_queue, data); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_lifo, put, lifo, data); })k_lifo_init(lifo)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_lifo, init, lifo); k_queue_init(&(lifo)->_queue); K_OBJ_CORE_INIT(K_OBJ_CORE(lifo), _obj_type_lifo); K_OBJ_CORE_LINK(K_OBJ_CORE(lifo)); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_lifo, init, lifo); })Z_LIFO_INITIALIZER(obj){ ._queue = Z_QUEUE_INITIALIZER(obj._queue) }K_FIFO_DEFINE(name)STRUCT_SECTION_ITERABLE(k_fifo, name) = Z_FIFO_INITIALIZER(name)k_fifo_peek_tail(fifo)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, peek_tail, fifo); void *fpt_ret = k_queue_peek_tail(&(fifo)->_queue); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, peek_tail, fifo, fpt_ret); fpt_ret; })k_fifo_peek_head(fifo)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, peek_head, fifo); void *fph_ret = k_queue_peek_head(&(fifo)->_queue); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, peek_head, fifo, fph_ret); fph_ret; })k_fifo_get(fifo,timeout)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, get, fifo, timeout); void *fg_ret = k_queue_get(&(fifo)->_queue, timeout); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, get, fifo, timeout, fg_ret); fg_ret; })k_fifo_is_empty(fifo)k_queue_is_empty(&(fifo)->_queue)k_fifo_put_slist(fifo,list)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, put_slist, fifo, list); k_queue_merge_slist(&(fifo)->_queue, list); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, put_slist, fifo, list); })k_fifo_put_list(fifo,head,tail)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, put_list, fifo, head, tail); k_queue_append_list(&(fifo)->_queue, head, tail); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, put_list, fifo, head, tail); })k_fifo_alloc_put(fifo,data)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, alloc_put, fifo, data); int fap_ret = k_queue_alloc_append(&(fifo)->_queue, data); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, alloc_put, fifo, data, fap_ret); fap_ret; })k_fifo_put(fifo,data)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, put, fifo, data); k_queue_append(&(fifo)->_queue, data); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, put, fifo, data); })k_fifo_cancel_wait(fifo)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, cancel_wait, fifo); k_queue_cancel_wait(&(fifo)->_queue); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, cancel_wait, fifo); })k_fifo_init(fifo)({ SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_fifo, init, fifo); k_queue_init(&(fifo)->_queue); K_OBJ_CORE_INIT(K_OBJ_CORE(fifo), _obj_type_fifo); K_OBJ_CORE_LINK(K_OBJ_CORE(fifo)); SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_fifo, init, fifo); })Z_FIFO_INITIALIZER(obj)K_EVENT_DEFINE(name)STRUCT_SECTION_ITERABLE(k_event, name) = Z_EVENT_INITIALIZER(name);Z_EVENT_INITIALIZER(obj){ .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), .events = 0 }K_QUEUE_DEFINE(name)STRUCT_SECTION_ITERABLE(k_queue, name) = Z_QUEUE_INITIALIZER(name)Z_QUEUE_INITIALIZER(obj){ .data_q = SYS_SFLIST_STATIC_INIT(&obj.data_q), .lock = { }, .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), Z_POLL_EVENT_OBJ_INIT(obj) }K_TIMER_DEFINE(name,expiry_fn,stop_fn)STRUCT_SECTION_ITERABLE(k_timer, name) = Z_TIMER_INITIALIZER(name, expiry_fn, stop_fn)Z_TIMER_INITIALIZER(obj,expiry,stop){ .timeout = { .node = {}, .fn = z_timer_expiration_handler, .dticks = 0, }, .wait_q = Z_WAIT_Q_INIT(&obj.wait_q), .expiry_fn = expiry, .stop_fn = stop, .status = 0, .user_data = 0, }K_TIMEOUT_ABS_CYC(t)K_TIMEOUT_ABS_TICKS(k_cyc_to_ticks_ceil64(t))K_TIMEOUT_ABS_NS(t)K_TIMEOUT_ABS_TICKS(k_ns_to_ticks_ceil64(t))K_TIMEOUT_ABS_US(t)K_TIMEOUT_ABS_TICKS(k_us_to_ticks_ceil64(t))K_TIMEOUT_ABS_MS(t)K_TIMEOUT_ABS_TICKS(k_ms_to_ticks_ceil64(t))K_TIMEOUT_ABS_TICKS(t)Z_TIMEOUT_TICKS(Z_TICK_ABS((k_ticks_t)MAX(t, 0)))K_FOREVERK_HOURS(h)K_MINUTES((h) * 60)K_MINUTES(m)K_SECONDS((m) * 60)K_SECONDS(s)K_MSEC((s) * MSEC_PER_SEC)K_MSEC(ms)Z_TIMEOUT_MS(ms)K_TICKS(t)K_CYC(t)K_USEC(t)K_NSEC(t)K_NO_WAITK_KERNEL_THREAD_DEFINE(name,stack_size,entry,p1,p2,p3,prio,options,delay)K_KERNEL_STACK_DEFINE(_k_thread_stack_ ## name, stack_size); Z_THREAD_COMMON_DEFINE(name, stack_size, entry, p1, p2, p3, prio, options, delay)K_THREAD_DEFINE(name,stack_size,entry,p1,p2,p3,prio,options,delay)K_THREAD_STACK_DEFINE(_k_thread_stack_ ## name, stack_size); Z_THREAD_COMMON_DEFINE(name, stack_size, entry, p1, p2, p3, prio, options, delay)Z_THREAD_COMMON_DEFINE(name,stack_size,entry,p1,p2,p3,prio,options,delay)struct k_thread _k_thread_obj_ ## name; STRUCT_SECTION_ITERABLE(_static_thread_data, _k_thread_data_ ## name) = Z_THREAD_INITIALIZER(&_k_thread_obj_ ## name, _k_thread_stack_ ## name, stack_size, entry, p1, p2, p3, prio, options, delay, name); const k_tid_t name = (k_tid_t)&_k_thread_obj_ ## nameZ_THREAD_INITIALIZER(thread,stack,stack_size,entry,p1,p2,p3,prio,options,delay,tname){ .init_thread = (thread), .init_stack = (stack), .init_stack_size = (stack_size), .init_entry = (k_thread_entry_t)entry, .init_p1 = (void *)p1, .init_p2 = (void *)p2, .init_p3 = (void *)p3, .init_prio = (prio), .init_options = (options), .init_name = STRINGIFY(tname), Z_THREAD_INIT_DELAY_INITIALIZER(delay) }Z_THREAD_INIT_DELAY(thread)SYS_TIMEOUT_MS((thread)->init_delay_ms)Z_THREAD_INIT_DELAY_INITIALIZER(ms).init_delay_ms = (ms)k_thread_access_grant(thread,__VA_ARGS__...)FOR_EACH_FIXED_ARG(k_object_access_grant, (;), thread, __VA_ARGS__)K_CALLBACK_STATEK_INHERIT_PERMSK_USERZ_DECL_POLL_EVENTZ_POLL_EVENT_OBJ_INIT(obj)(K_LOWEST_THREAD_PRIO - 1)(K_HIGHEST_THREAD_PRIO)K_IDLE_PRIOK_LOWEST_THREAD_PRIOK_HIGHEST_THREAD_PRIO(-CONFIG_NUM_COOP_PRIORITIES)K_PRIO_PREEMPT(x)(x)K_PRIO_COOP(x)(-(CONFIG_NUM_COOP_PRIORITIES - (x)))K_ANYnmembnonnullh__UINT32_MAX__0xffffffffULrx_msgmboxtx_msgsyncplugcfgthread_idbuf_sizethslice_ticksexpiredsliceuser_cb_EXCEPTION_CONNECT_CODE(handler,vector,dpl)__EXCEPTION_CONNECT(handler, vector, dpl, "")_EXCEPTION_CONNECT_NOCODE(handler,vector,dpl)__EXCEPTION_CONNECT(handler, vector, dpl, "push $0\n\t")__EXCEPTION_CONNECT(handler,vector,dpl,codepush)__asm__ ( _EXCEPTION_INTLIST(vector, dpl) ".pushsection .gnu.linkonce.t.exc_" STRINGIFY(vector) "_stub, \"ax\"\n\t" ".global " STRINGIFY(_EXCEPTION_STUB_NAME(handler, vector)) "\n\t" STRINGIFY(_EXCEPTION_STUB_NAME(handler, vector)) ":\n\t" "1:\n\t" codepush "push $" STRINGIFY(handler) "\n\t" "jmp _exception_enter\n\t" ".popsection\n\t" )_EXCEPTION_STUB_NAME(handler,vec)__EXCEPTION_STUB_NAME(handler, vec)__EXCEPTION_STUB_NAME(handler,vec)_ ## handler ## _vector_ ## vec ## _stub_EXCEPTION_INTLIST(vector,dpl)".pushsection .gnu.linkonce.intList.exc_" #vector "\n\t" ".long 1f\n\t" ".long -1\n\t" ".long -1\n\t" ".long " STRINGIFY(vector) "\n\t" ".long " STRINGIFY(dpl) "\n\t" ".long 0\n\t" ".popsection\n\t"ZEPHYR_ARCH_X86_INCLUDE_IA32_EXCEPTION_H_/* ZEPHYR_ARCH_X86_INCLUDE_IA32_EXCEPTION_H_ *//**
 * @brief Connect an exception handler that does expect error code
 *
 * Assign an exception handler to a particular vector in the IDT.
 * The error code will be accessible in esf->errorCode
 *
 * @param handler A handler function of the prototype
 *                void handler(const z_arch_esf_t *esf)
 * @param vector Vector index in the IDT
 *//**
 * @brief Connect an exception handler that doesn't expect error code
 *
 * Assign an exception handler to a particular vector in the IDT.
 *
 * @param handler A handler function of the prototype
 *                void handler(const z_arch_esf_t *esf)
 * @param vector Vector index in the IDT
 *//* Unfortunately, GCC extended asm doesn't work at toplevel so we need
 * to stringify stuff.
 *
 * What we are doing here is generating entries in the .intList section
 * and also the assembly language stubs for the exception. We use
 * .gnu.linkonce section prefix so that the linker only includes the
 * first one of these it encounters for a particular vector. In this
 * way it's easy for applications or drivers to install custom exception
 * handlers without having to #ifdef out previous instances such as in
 * arch/x86/core/fatal.c
 *//* Extra preprocessor indirection to ensure arguments get expanded before
 * concatenation takes place
 *//home/haojie/zephyrproject/zephyr/arch/x86/include/ia32/home/haojie/zephyrproject/zephyr/arch/x86/includez_x86_thread_entry_wrapperZEPHYR_ARCH_X86_INCLUDE_IA32_KERNEL_ARCH_DATA_H_defined(CONFIG_DEBUG_INFO)defined(CONFIG_LAZY_FPU_SHARING) && defined(CONFIG_X86_SSE)/* ZEPHYR_ARCH_X86_INCLUDE_IA32_KERNEL_ARCH_DATA_H_ *//* Some configurations require that the stack/registers be adjusted before
 * z_thread_entry. See discussion in swap.S for z_x86_thread_entry_wrapper()
 *//* this file is only meant to be included by kernel_structs.h *//**
 * @file
 * @brief Private kernel definitions (IA-32)
 *
 * This file contains private kernel structures definitions and various
 * other definitions for the Intel Architecture 32 bit (IA-32) processor
 * architecture.
 * The header include/kernel.h contains the public kernel interface
 * definitions, with include/arch/x86/ia32/arch.h supplying the
 * IA-32 specific portions of the public kernel interface.
 *
 * This file is also included by assembly language files which must #define
 * _ASMLANGUAGE before including this header file.  Note that kernel
 * assembly source files obtains structure offset values via "absolute symbols"
 * in the offsets.o module.
 */<ia32/kernel_arch_data.h>x86_boot_arg_tx86_boot_argboot_typeCR4_OSFXSRBIT(9)CR4_PAECR4_PSECR0_WPCR0_PGBIT(31)EFLAGS_SYSCALL(EFLAGS_IF | EFLAGS_DF)(EFLAGS_IF)EFLAGS_DFEFLAGS_IFIV_NR_VECTORSIV_IRQSIV_SECURITY_EXCEPTIONIV_VIRT_EXCEPTIONIV_SIMD_FPIV_MACHINE_CHECKIV_ALIGNMENT_CHECKIV_X87_FPU_FP_ERRORIV_RESERVEDIV_GENERAL_PROTECTIONIV_STACK_FAULTIV_SEGMENT_NOT_PRESENTIV_INVALID_TSSIV_COPROC_SEGMENT_OVERRUNIV_DOUBLE_FAULTIV_DEVICE_NOT_AVAILABLEIV_INVALID_OPCODEIV_BOUND_RANGEIV_OVERFLOWIV_BREAKPOINTIV_NON_MASKABLE_INTERRUPTIV_DEBUGIV_DIVIDE_ERRORZEPHYR_ARCH_X86_INCLUDE_KERNEL_ARCH_DATA_H_/* ZEPHYR_ARCH_X86_INCLUDE_KERNEL_ARCH_DATA_H_ *//* _ASMLANGUAGE  *//* x86 boot argument (see prep_c.c) *//* enable SSE (OS FXSAVE/RSTOR) *//* enable PAE *//* Page size extension (4MB pages) *//* honor W bit even when supervisor *//* enable paging *//*
 * Control register definitions.
 *//* Direction flag *//* interrupts enabled *//*
 * EFLAGS/RFLAGS definitions. (RFLAGS is just zero-extended EFLAGS.)
 *//* total number of vectors *//* start of vectors available for IRQs *//*
 * Exception/interrupt vector definitions: vectors 20 to 31 are reserved
 * for Intel; vectors 32 to 255 are user defined interrupt vectors.
 *//home/haojie/zephyrproject/zephyr/kernel/include/gen_offset.hGEN_NAMED_OFFSET_SYM(S,M,N)GEN_ABSOLUTE_SYM(__ ## S ## _ ## N ## _ ## OFFSET, offsetof(S, M))GEN_OFFSET_SYM(S,M)GEN_ABSOLUTE_SYM(__ ## S ## _ ## M ## _ ## OFFSET, offsetof(S, M))ZEPHYR_KERNEL_INCLUDE_GEN_OFFSET_H_/* ZEPHYR_KERNEL_INCLUDE_GEN_OFFSET_H_ *//* definition of the GEN_OFFSET_SYM() macros is toolchain independent  *//**
 * @file
 * @brief Macros to generate structure member offset definitions
 *
 * This header contains macros to allow a kernel implementation to generate
 * absolute symbols whose values represents the member offsets for various
 * kernel structures.  These absolute symbols are typically utilized by
 * assembly source files rather than hardcoding the values in some local header
 * file.
 *
 * WARNING: Absolute symbols can potentially be utilized by external tools --
 * for example, to locate a specific field within a data structure.
 * Consequently, changes made to such symbols may require modifications to the
 * associated tool(s). Typically, relocating a member of a structure merely
 * requires that a tool be rebuilt; however, moving a member to another
 * structure (or to a new sub-structure within an existing structure) may
 * require that the tool itself be modified. Likewise, deleting, renaming, or
 * changing the meaning of an absolute symbol may require modifications to a
 * tool.
 *
 * The macro "GEN_OFFSET_SYM(structure, member)" is used to generate a single
 * absolute symbol.  The absolute symbol will appear in the object module
 * generated from the source file that utilizes the GEN_OFFSET_SYM() macro.
 * Absolute symbols representing a structure member offset have the following
 * form:
 *
 *    __<structure>_<member>_OFFSET
 *
 * The macro "GEN_NAMED_OFFSET_SYM(structure, member, name)" is also provided
 * to create the symbol with the following form:
 *
 *    __<structure>_<name>_OFFSET
 *
 * This header also defines the GEN_ABSOLUTE_SYM macro to simply define an
 * absolute symbol, irrespective of whether the value represents a structure
 * or offset.
 *
 * The following sample file illustrates the usage of the macros available
 * in this file:
 *
 *	<START of sample source file: offsets.c>
 *
 * #include <gen_offset.h>
 * /@ include struct definitions for which offsets symbols are to be
 * generated @/
 *
 * #include <zephyr/kernel_structs.h>
 * GEN_ABS_SYM_BEGIN (_OffsetAbsSyms)	/@ the name parameter is arbitrary @/
 * /@ _kernel_t structure member offsets @/
 *
 * GEN_OFFSET_SYM (_kernel_t, nested);
 * GEN_OFFSET_SYM (_kernel_t, irq_stack);
 * GEN_OFFSET_SYM (_kernel_t, current);
 * GEN_OFFSET_SYM (_kernel_t, idle);
 *
 * GEN_ABSOLUTE_SYM (___kernel_t_SIZEOF, sizeof(_kernel_t));
 *
 * GEN_ABS_SYM_END
 * <END of sample source file: offsets.c>
 *
 * Compiling the sample offsets.c results in the following symbols in offsets.o:
 *
 * $ nm offsets.o
 * 00000000 A ___kernel_t_nested_OFFSET
 * 00000004 A ___kernel_t_irq_stack_OFFSET
 * 00000008 A ___kernel_t_current_OFFSET
 * 0000000c A ___kernel_t_idle_OFFSET
 *//*
 * Copyright (c) 2010, 2012, 2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */init_functionconst deviceconst device *device *init_fnsysSYS_INIT_NAMED(name,init_fn_,level,prio)static const Z_DECL_ALIGN(struct init_entry) Z_INIT_ENTRY_SECTION(level, prio, 0) __used __noasan Z_INIT_ENTRY_NAME(name) = { .init_fn = {.sys = (init_fn_)}, .dev = NULL, }SYS_INIT(init_fn,level,prio)SYS_INIT_NAMED(init_fn, init_fn, level, prio)INIT_LEVEL_ORD(level)COND_CODE_1(Z_INIT_EARLY_ ## level, (Z_INIT_ORD_EARLY), (COND_CODE_1(Z_INIT_PRE_KERNEL_1_ ## level, (Z_INIT_ORD_PRE_KERNEL_1), (COND_CODE_1(Z_INIT_PRE_KERNEL_2_ ## level, (Z_INIT_ORD_PRE_KERNEL_2), (COND_CODE_1(Z_INIT_POST_KERNEL_ ## level, (Z_INIT_ORD_POST_KERNEL), (COND_CODE_1(Z_INIT_APPLICATION_ ## level, (Z_INIT_ORD_APPLICATION), (COND_CODE_1(Z_INIT_SMP_ ## level, (Z_INIT_ORD_SMP), (ZERO_OR_COMPILE_ERROR(0)))))))))))))Z_INIT_ENTRY_SECTION(level,prio,sub_prio)__attribute__((__section__( ".z_init_" #level STRINGIFY(prio)"_" STRINGIFY(sub_prio)"_")))Z_INIT_ENTRY_NAME(init_id)_CONCAT(__init_, init_id)Z_INIT_ORD_SMPZ_INIT_ORD_APPLICATIONZ_INIT_ORD_POST_KERNELZ_INIT_ORD_PRE_KERNEL_2Z_INIT_ORD_PRE_KERNEL_1Z_INIT_ORD_EARLYZ_INIT_SMP_SMPZ_INIT_APPLICATION_APPLICATIONZ_INIT_POST_KERNEL_POST_KERNELZ_INIT_PRE_KERNEL_2_PRE_KERNEL_2Z_INIT_PRE_KERNEL_1_PRE_KERNEL_1Z_INIT_EARLY_EARLYZEPHYR_INCLUDE_INIT_H_device/* ZEPHYR_INCLUDE_INIT_H_ *//**
 * @brief Register an initialization function (named).
 *
 * @note This macro can be used for cases where the multiple init calls use the
 * same init function.
 *
 * @param name Unique name for SYS_INIT entry.
 * @param init_fn_ See SYS_INIT().
 * @param level See SYS_INIT().
 * @param prio See SYS_INIT().
 *
 * @see SYS_INIT()
 *//**
 * @brief Register an initialization function.
 *
 * The function will be called during system initialization according to the
 * given level and priority.
 *
 * @param init_fn Initialization function.
 * @param level Initialization level. Allowed tokens: `EARLY`, `PRE_KERNEL_1`,
 * `PRE_KERNEL_2`, `POST_KERNEL`, `APPLICATION` and `SMP` if
 * @kconfig{CONFIG_SMP} is enabled.
 * @param prio Initialization priority within @p _level. Note that it must be a
 * decimal integer literal without leading zeroes or sign (e.g. `32`), or an
 * equivalent symbolic name (e.g. `#define MY_INIT_PRIO 32`); symbolic
 * expressions are **not** permitted (e.g.
 * `CONFIG_KERNEL_INIT_PRIORITY_DEFAULT + 5`).
 *//**
 * @brief Obtain the ordinal for an init level.
 *
 * @param level Init level (EARLY, PRE_KERNEL_1, PRE_KERNEL_2, POST_KERNEL,
 * APPLICATION, SMP).
 *
 * @return Init level ordinal.
 *//**
 * @brief Init entry section.
 *
 * Each init entry is placed in a section with a name crafted so that it allows
 * linker scripts to sort them according to the specified
 * level/priority/sub-priority.
 *//**
 * @brief Obtain init entry name.
 *
 * @param init_id Init entry unique identifier.
 *//* Init level ordinals *//* Helper definitions to evaluate level equality *//**
	 * If the init entry belongs to a device, this fields stores a
	 * reference to it, otherwise it is set to NULL.
	 *//** Initialization function. *//**
 * @brief Structure to store initialization entry information.
 *
 * @internal
 * Init entries need to be defined following these rules:
 *
 * - Their name must be set using Z_INIT_ENTRY_NAME().
 * - They must be placed in a special init section, given by
 *   Z_INIT_ENTRY_SECTION().
 * - They must be aligned, e.g. using Z_DECL_ALIGN().
 *
 * See SYS_INIT_NAMED() for an example.
 * @endinternal
 *//**
	 * Device initialization function.
	 *
	 * @param dev Device instance.
	 *
	 * @retval 0 On success
	 * @retval -errno If device initialization fails.
	 *//**
	 * System initialization function.
	 *
	 * @retval 0 On success
	 * @retval -errno If init fails.
	 *//**
 * @brief Initialization function for init entries.
 *
 * Init entries support both the system initialization and the device
 * APIs. Each API has its own init function signature; hence, we have a
 * union to cover both.
 *//**
 * @defgroup sys_init System Initialization
 * @ingroup os_services
 *
 * Zephyr offers an infrastructure to call initialization code before `main`.
 * Such initialization calls can be registered using SYS_INIT() or
 * SYS_INIT_NAMED() macros. By using a combination of initialization levels and
 * priorities init sequence can be adjusted as needed. The available
 * initialization levels are described, in order, below:
 *
 * - `EARLY`: Used very early in the boot process, right after entering the C
 *   domain (``z_cstart()``). This can be used in architectures and SoCs that
 *   extend or implement architecture code and use drivers or system services
 *   that have to be initialized before the Kernel calls any architecture
 *   specific initialization code.
 * - `PRE_KERNEL_1`: Executed in Kernel's initialization context, which uses
 *   the interrupt stack. At this point Kernel services are not yet available.
 * - `PRE_KERNEL_2`: Same as `PRE_KERNEL_1`.
 * - `POST_KERNEL`: Executed after Kernel is alive. From this point on, Kernel
 *   primitives can be used.
 * - `APPLICATION`: Executed just before application code (`main`).
 * - `SMP`: Only available if @kconfig{CONFIG_SMP} is enabled, specific for
 *   SMP.
 *
 * Initialization priority can take a value in the range of 0 to 99.
 *
 * @note The same infrastructure is used by devices.
 * @{
 */device_is_readydevice_get_bindingz_impl_device_get_bindingZ_INCLUDE_SYSCALLS_DEVICE_Hz_impl_device_is_ready<syscalls/device.h><zephyr/init.h>z_device_is_readyz_device_get_all_staticconst device **device **device_from_handlestruct device_device_list_startnumdev&numdev_list_enddevice[]device_handle_getDEVICE_HANDLE_NULLdevice_handle_tdevice_statedevice_state *initializedinit_resapiconfig__device_dts_ord_10Z_MAYBE_DEVICE_DECLARE_INTERNALZ_DEVICE_DT_DEV_ID(DT_N_S_ieee802154)dts_ord_10__device___device_dts_ord_3Z_DEVICE_DT_DEV_ID(DT_N_S_eeprom0)dts_ord_3__device_dts_ord_8Z_DEVICE_DT_DEV_ID(DT_N_S_eeprom1)dts_ord_8__device_dts_ord_7Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000)dts_ord_7__device_dts_ord_22Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000)dts_ord_22__device_dts_ord_21Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000)dts_ord_21__device_dts_ord_20Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000)dts_ord_20__device_dts_ord_6Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash_S_flash_sim_0_S_partitions)dts_ord_6__device_dts_ord_5Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash_S_flash_sim_0)dts_ord_5__device_dts_ord_4Z_DEVICE_DT_DEV_ID(DT_N_S_sim_flash)dts_ord_4__device_dts_ord_17Z_DEVICE_DT_DEV_ID(DT_N_S_pcie0_S_eth0)dts_ord_17__device_dts_ord_19DT_N_S_pcie0_S_can0_S_can_transceiverZ_DEVICE_DT_DEV_ID(DT_N_S_pcie0_S_can0_S_can_transceiver)dts_ord_19__device_dts_ord_18Z_DEVICE_DT_DEV_ID(DT_N_S_pcie0_S_can0)dts_ord_18__device_dts_ord_16Z_DEVICE_DT_DEV_ID(DT_N_S_pcie0)dts_ord_16__device_dts_ord_9Z_DEVICE_DT_DEV_ID(DT_N_S_flash_500000)dts_ord_9__device_dts_ord_25Z_DEVICE_DT_DEV_ID(DT_N_S_soc_S_rtc_70)dts_ord_25__device_dts_ord_24Z_DEVICE_DT_DEV_ID(DT_N_S_soc_S_hpet_fed00000)dts_ord_24__device_dts_ord_26Z_DEVICE_DT_DEV_ID(DT_N_S_soc_S_uart_2f8)dts_ord_26__device_dts_ord_27Z_DEVICE_DT_DEV_ID(DT_N_S_soc_S_uart_3f8)dts_ord_27__device_dts_ord_23Z_DEVICE_DT_DEV_ID(DT_N_S_soc)dts_ord_23__device_dts_ord_12Z_DEVICE_DT_DEV_ID(DT_N_S_memory_0)dts_ord_12__device_dts_ord_11Z_DEVICE_DT_DEV_ID(DT_N_S_loapic_fee00000)dts_ord_11__device_dts_ord_15Z_DEVICE_DT_DEV_ID(DT_N_S_ioapic_fec00000)dts_ord_15__device_dts_ord_14Z_DEVICE_DT_DEV_ID(DT_N_S_cpus_S_cpu_0)dts_ord_14__device_dts_ord_13Z_DEVICE_DT_DEV_ID(DT_N_S_cpus)dts_ord_13__device_dts_ord_1DT_N_S_aliasesZ_DEVICE_DT_DEV_ID(DT_N_S_aliases)dts_ord_1__device_dts_ord_2DT_N_S_chosenZ_DEVICE_DT_DEV_ID(DT_N_S_chosen)dts_ord_2__device_dts_ord_0Z_DEVICE_DT_DEV_ID(DT_N)dts_ord_0_device_list_end_device_list_startZ_MAYBE_DEVICE_DECLARE_INTERNAL(node_id)extern const struct device DEVICE_DT_NAME_GET(node_id);Z_DEVICE_DEFINE(node_id,dev_id,name,init_fn,pm,data,config,level,prio,api,state,__VA_ARGS__...)Z_DEVICE_NAME_CHECK(name); IF_ENABLED(CONFIG_DEVICE_DEPS, (Z_DEVICE_DEPS_DEFINE(node_id, dev_id, __VA_ARGS__);)) Z_DEVICE_BASE_DEFINE(node_id, dev_id, name, pm, data, config, level, prio, api, state, Z_DEVICE_DEPS_NAME(dev_id)); Z_DEVICE_INIT_ENTRY_DEFINE(node_id, dev_id, init_fn, level, prio)Z_DEVICE_INIT_ENTRY_DEFINE(node_id,dev_id,init_fn_,level,prio)Z_DEVICE_LEVEL_CHECK_DEPRECATED_LEVEL(level) static const Z_DECL_ALIGN(struct init_entry) __used __noasan Z_INIT_ENTRY_SECTION(level, prio, Z_DEVICE_INIT_SUB_PRIO(node_id)) Z_INIT_ENTRY_NAME(DEVICE_NAME_GET(dev_id)) = { .init_fn = {.dev = (init_fn_)}, .dev = &DEVICE_NAME_GET(dev_id), }Z_DEVICE_LEVEL_CHECK_DEPRECATED_LEVEL(level)Z_DEVICE_LEVEL_DEPRECATED_ ## levelZ_DEVICE_LEVEL_DEPRECATED_SMP__WARN("SMP device driver level is deprecated")Z_DEVICE_LEVEL_DEPRECATED_APPLICATION__WARN("APPLICATION device driver level is deprecated")Z_DEVICE_LEVEL_DEPRECATED_POST_KERNELZ_DEVICE_LEVEL_DEPRECATED_PRE_KERNEL_2Z_DEVICE_LEVEL_DEPRECATED_PRE_KERNEL_1Z_DEVICE_LEVEL_DEPRECATED_EARLY__WARN("EARLY device driver level is deprecated")Z_DEVICE_BASE_DEFINE(node_id,dev_id,name,pm,data,config,level,prio,api,state,deps)COND_CODE_1(DT_NODE_EXISTS(node_id), (), (static)) const STRUCT_SECTION_ITERABLE_NAMED(device, Z_DEVICE_SECTION_NAME(level, prio), DEVICE_NAME_GET(dev_id)) = Z_DEVICE_INIT(name, pm, data, config, api, state, deps)Z_DEVICE_SECTION_NAME(level,prio)_CONCAT(INIT_LEVEL_ORD(level), _ ## prio)Z_DEVICE_INIT(name_,pm_,data_,config_,api_,state_,deps_){ .name = name_, .config = (config_), .api = (api_), .state = (state_), .data = (data_), IF_ENABLED(CONFIG_DEVICE_DEPS, (.deps = (deps_),)) IF_ENABLED(CONFIG_PM_DEVICE, (.pm = (pm_),)) }Z_DEVICE_NAME_CHECK(name)BUILD_ASSERT(sizeof(Z_STRINGIFY(name)) <= Z_DEVICE_MAX_NAME_LEN, Z_STRINGIFY(DEVICE_NAME_GET(name)) " too long")Z_DEVICE_MAX_NAME_LEN48UZ_DEVICE_INIT_SUB_PRIO(node_id)COND_CODE_1(DT_NODE_EXISTS(node_id), (DT_DEP_ORD_STR_SORTABLE(node_id)), (0))Z_DEVICE_STATE_DEFINE(dev_id)static Z_DECL_ALIGN(struct device_state) Z_DEVICE_STATE_NAME(dev_id) __attribute__((__section__(".z_devstate")))Z_DEVICE_STATE_NAME(dev_id)_CONCAT(__devstate_, dev_id)Z_DEVICE_DEPS_CONSTDEVICE_INIT_GET(dev_id)(&Z_INIT_ENTRY_NAME(DEVICE_NAME_GET(dev_id)))DEVICE_INIT_DT_GET(node_id)(&Z_INIT_ENTRY_NAME(DEVICE_DT_NAME_GET(node_id)))DEVICE_DECLARE(dev_id)static const struct device DEVICE_NAME_GET(dev_id)DEVICE_GET(dev_id)(&DEVICE_NAME_GET(dev_id))DEVICE_DT_GET_OR_NULL(node_id)COND_CODE_1(DT_NODE_HAS_STATUS(node_id, okay), (DEVICE_DT_GET(node_id)), (NULL))DEVICE_DT_GET_ONE(compat)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(compat), (DEVICE_DT_GET(DT_COMPAT_GET_ANY_STATUS_OKAY(compat))), (ZERO_OR_COMPILE_ERROR(0)))DEVICE_DT_GET_ANY(compat)COND_CODE_1(DT_HAS_COMPAT_STATUS_OKAY(compat), (DEVICE_DT_GET(DT_COMPAT_GET_ANY_STATUS_OKAY(compat))), (NULL))DEVICE_DT_INST_GET(inst)DEVICE_DT_GET(DT_DRV_INST(inst))DEVICE_DT_GET(node_id)(&DEVICE_DT_NAME_GET(node_id))DEVICE_DT_NAME_GET(node_id)DEVICE_NAME_GET(Z_DEVICE_DT_DEV_ID(node_id))DEVICE_DT_INST_DEFINE(inst,__VA_ARGS__...)DEVICE_DT_DEFINE(DT_DRV_INST(inst), __VA_ARGS__)DEVICE_DT_DEFINE(node_id,init_fn,pm,data,config,level,prio,api,__VA_ARGS__...)Z_DEVICE_STATE_DEFINE(Z_DEVICE_DT_DEV_ID(node_id)); Z_DEVICE_DEFINE(node_id, Z_DEVICE_DT_DEV_ID(node_id), DEVICE_DT_NAME(node_id), init_fn, pm, data, config, level, prio, api, &Z_DEVICE_STATE_NAME(Z_DEVICE_DT_DEV_ID(node_id)), __VA_ARGS__)DEVICE_DT_NAME(node_id)DT_PROP_OR(node_id, label, DT_NODE_FULL_NAME(node_id))DEVICE_DEFINE(dev_id,name,init_fn,pm,data,config,level,prio,api)Z_DEVICE_STATE_DEFINE(dev_id); Z_DEVICE_DEFINE(DT_INVALID_NODE, dev_id, name, init_fn, pm, data, config, level, prio, api, &Z_DEVICE_STATE_NAME(dev_id))Z_DEVICE_DT_DEV_ID(node_id)_CONCAT(dts_ord_, DT_DEP_ORD(node_id))DEVICE_NAME_GET(dev_id)_CONCAT(__device_, dev_id)Z_DEVICE_DEPS_ENDSZ_DEVICE_DEPS_SEPZEPHYR_INCLUDE_DEVICE_H_CONFIG_DEVICE_DEPS_DYNAMICdefined(CONFIG_DEVICE_DEPS) || defined(__DOXYGEN__)defined(CONFIG_PM_DEVICE) || defined(__DOXYGEN__)pm_devicedts_ord_DT_DEP_ORD(DT_N_S_sim_flash_S_flash_sim_0_S_partitions)_ORDDT_DEP_ORD(DT_N_S_sim_flash_S_flash_sim_0)DT_DEP_ORD(DT_N_S_sim_flash)DT_DEP_ORD(DT_N_S_pcie0_S_eth0)DT_DEP_ORD(DT_N_S_pcie0_S_can0_S_can_transceiver)DT_DEP_ORD(DT_N_S_pcie0_S_can0)DT_DEP_ORD(DT_N_S_pcie0)DT_DEP_ORD(DT_N_S_flash_500000)DT_DEP_ORD(DT_N_S_soc_S_rtc_70)DT_DEP_ORD(DT_N_S_soc_S_hpet_fed00000)DT_DEP_ORD(DT_N_S_soc_S_uart_2f8)DT_DEP_ORD(DT_N_S_ieee802154)DT_DEP_ORD(DT_N_S_eeprom0)DT_DEP_ORD(DT_N_S_eeprom1)DT_DEP_ORD(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_31000)DT_DEP_ORD(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_21000)DT_DEP_ORD(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_11000)DT_DEP_ORD(DT_N_S_sim_flash_S_flash_sim_0_S_partitions_S_partition_1000)DT_DEP_ORD(DT_N_S_soc_S_uart_3f8)DT_DEP_ORD(DT_N_S_soc)DT_DEP_ORD(DT_N_S_memory_0)DT_DEP_ORD(DT_N_S_loapic_fee00000)DT_DEP_ORD(DT_N_S_ioapic_fec00000)DT_DEP_ORD(DT_N_S_cpus_S_cpu_0)DT_DEP_ORD(DT_N_S_cpus)DT_DEP_ORD(DT_N_S_aliases)DT_DEP_ORD(DT_N_S_chosen)DT_DEP_ORD(DT_N)/* ZEPHYR_INCLUDE_DEVICE_H_ *//**
 * @brief Declare a device for each status "okay" devicetree node.
 *
 * @note Disabled nodes should not result in devices, so not predeclaring these
 * keeps drivers honest.
 *
 * This is only "maybe" a device because some nodes have status "okay", but
 * don't have a corresponding @ref device allocated. There's no way to figure
 * that out until after we've built the zephyr image, though.
 *//**
 * @brief Define a @ref device and all other required objects.
 *
 * This is the common macro used to define @ref device objects. It can be used
 * to define both Devicetree and software devices.
 *
 * @param node_id Devicetree node id for the device (DT_INVALID_NODE if a
 * software device).
 * @param dev_id Device identifier (used to name the defined @ref device).
 * @param name Name of the device.
 * @param init_fn Device init function.
 * @param pm Reference to @ref pm_device associated with the device.
 * (optional).
 * @param data Reference to device data.
 * @param config Reference to device config.
 * @param level Initialization level.
 * @param prio Initialization priority.
 * @param api Reference to device API.
 * @param state Reference to device state.
 * @param ... Optional dependencies, manually specified.
 *//**
 * @brief Define the init entry for a device.
 *
 * @param node_id Devicetree node id for the device (DT_INVALID_NODE if a
 * software device).
 * @param dev_id Device identifier.
 * @param init_fn_ Device init function.
 * @param level Initialization level.
 * @param prio Initialization priority.
 *//**
 * @brief Issue a warning if the given init level is deprecated.
 *
 * @param level Init level
 *//* deprecated device initialization levels *//**
 * @brief Define a @ref device
 *
 * @param node_id Devicetree node id for the device (DT_INVALID_NODE if a
 * software device).
 * @param dev_id Device identifier (used to name the defined @ref device).
 * @param name Name of the device.
 * @param pm Reference to @ref pm_device associated with the device.
 * (optional).
 * @param data Reference to device data.
 * @param config Reference to device config.
 * @param level Initialization level.
 * @param prio Initialization priority.
 * @param api Reference to device API.
 * @param ... Optional dependencies, manually specified.
 *//**
 * @brief Device section name (used for sorting purposes).
 *
 * @param level Initialization level
 * @param prio Initialization priority
 *//**
 * @brief Initializer for @ref device.
 *
 * @param name_ Name of the device.
 * @param pm_ Reference to @ref pm_device (optional).
 * @param data_ Reference to device data.
 * @param config_ Reference to device config.
 * @param api_ Reference to device API ops.
 * @param state_ Reference to device state.
 * @param deps_ Reference to device dependencies.
 *//**
 * @brief Compile time check for device name length
 *
 * @param name Device name.
 *//**
 * @brief Maximum device name length.
 *
 * The maximum length is set so that device_get_binding() can be used from
 * userspace.
 *//**
 * @brief Init sub-priority of the device
 *
 * The sub-priority is defined by the devicetree ordinal, which ensures that
 * multiple drivers running at the same priority level run in an order that
 * respects the devicetree dependencies.
 *//* CONFIG_DEVICE_DEPS *//**
 * @brief Define device dependencies.
 *
 * Initial build provides a record that associates the device object with its
 * devicetree ordinal, and provides the dependency ordinals. These are provided
 * as weak definitions (to prevent the reference from being captured when the
 * original object file is compiled), and in a distinct pass1 section (which
 * will be replaced by postprocessing).
 *
 * Before processing in gen_device_deps.py, the array format is:
 * {
 *     DEVICE_ORDINAL (or DEVICE_HANDLE_NULL if not a devicetree node),
 *     List of devicetree dependency ordinals (if any),
 *     Z_DEVICE_DEPS_SEP,
 *     List of injected dependency ordinals (if any),
 *     Z_DEVICE_DEPS_SEP,
 *     List of devicetree supporting ordinals (if any),
 * }
 *
 * After processing in gen_device_deps.py, the format is updated to:
 * {
 *     List of existing devicetree dependency handles (if any),
 *     Z_DEVICE_DEPS_SEP,
 *     List of injected devicetree dependency handles (if any),
 *     Z_DEVICE_DEPS_SEP,
 *     List of existing devicetree support handles (if any),
 *     DEVICE_HANDLE_NULL
 * }
 *
 * It is also (experimentally) necessary to provide explicit alignment on each
 * object. Otherwise x86-64 builds will introduce padding between objects in the
 * same input section in individual object files, which will be retained in
 * subsequent links both wasting space and resulting in aggregate size changes
 * relative to pass2 when all objects will be in the same input section.
 *//** @brief Linker section were device dependencies are placed. *//**
 * @brief Expand extra dependencies with a comma in between.
 *
 * @param ... Extra dependencies.
 *//**
 * @brief Synthesize the name of the object that holds device ordinal and
 * dependency data.
 *
 * @param dev_id Device identifier.
 *//**
 * @brief Utility macro to define and initialize the device state.
 *
 * @param dev_id Device identifier.
 *//**
 * @brief Synthesize a unique name for the device state associated with
 * @p dev_id.
 *//**
 * @brief Verify that a device is ready for use.
 *
 * Indicates whether the provided device pointer is for a device known to be
 * in a state where it can be used with its standard API.
 *
 * This can be used with device pointers captured from DEVICE_DT_GET(), which
 * does not include the readiness checks of device_get_binding(). At minimum
 * this means that the device has been successfully initialized.
 *
 * @param dev pointer to the device in question.
 *
 * @retval true If the device is ready for use.
 * @retval false If the device is not ready for use or if a NULL device pointer
 * is passed as argument.
 *//**
 * @brief Verify that a device is ready for use.
 *
 * This is the implementation underlying device_is_ready(), without the overhead
 * of a syscall wrapper.
 *
 * @param dev pointer to the device in question.
 *
 * @retval true If the device is ready for use.
 * @retval false If the device is not ready for use or if a NULL device pointer
 * is passed as argument.
 *
 * @see device_is_ready()
 *//**
 * @brief Get access to the static array of static devices.
 *
 * @param devices where to store the pointer to the array of statically
 * allocated devices. The array must not be mutated through this pointer.
 *
 * @return the number of statically allocated devices.
 *//**
 * @brief Get a @ref device reference from its @ref device.name field.
 *
 * This function iterates through the devices on the system. If a device with
 * the given @p name field is found, and that device initialized successfully at
 * boot time, this function returns a pointer to the device.
 *
 * If no device has the given @p name, this function returns `NULL`.
 *
 * This function also returns NULL when a device is found, but it failed to
 * initialize successfully at boot time. (To troubleshoot this case, set a
 * breakpoint on your device driver's initialization function.)
 *
 * @param name device name to search for. A null pointer, or a pointer to an
 * empty string, will cause NULL to be returned.
 *
 * @return pointer to device structure with the given name; `NULL` if the device
 * is not found or if the device with that name's initialization function
 * failed.
 *//**
 * @brief Visit every device that @p dev directly supports.
 *
 * Zephyr maintains information about which devices are directly supported by
 * another device; for example an I2C controller will support an I2C-based
 * sensor driver. Supported devices can derive from statically-defined
 * devicetree relationships.
 *
 * This API supports operating on the set of supported devices. Example uses
 * include iterating over the devices connected to a regulator when it is
 * powered on.
 *
 * There is no guarantee on the order in which required devices are visited.
 *
 * If the @p visitor_cb function returns a negative value iteration is halted,
 * and the returned value from the visitor is returned from this function.
 *
 * @note This API is not available to unprivileged threads.
 *
 * @param dev a device of interest. The devices that this device supports
 * will be used as the set of devices to visit. This parameter must not be null.
 * @param visitor_cb the function that should be invoked on each device in the
 * support set. This parameter must not be null.
 * @param context state that is passed through to the visitor function. This
 * parameter may be null if @p visitor_cb tolerates a null @p context.
 *
 * @return The number of devices that were visited if all visits succeed, or the
 * negative value returned from the first visit that did not succeed.
 *//**
 * @brief Visit every device that @p dev directly requires.
 *
 * Zephyr maintains information about which devices are directly required by
 * another device; for example an I2C-based sensor driver will require an I2C
 * controller for communication. Required devices can derive from
 * statically-defined devicetree relationships or dependencies registered at
 * runtime.
 *
 * This API supports operating on the set of required devices. Example uses
 * include making sure required devices are ready before the requiring device is
 * used, and releasing them when the requiring device is no longer needed.
 *
 * There is no guarantee on the order in which required devices are visited.
 *
 * If the @p visitor_cb function returns a negative value iteration is halted,
 * and the returned value from the visitor is returned from this function.
 *
 * @note This API is not available to unprivileged threads.
 *
 * @param dev a device of interest. The devices that this device depends on will
 * be used as the set of devices to visit. This parameter must not be null.
 * @param visitor_cb the function that should be invoked on each device in the
 * dependency set. This parameter must not be null.
 * @param context state that is passed through to the visitor function. This
 * parameter may be null if @p visitor_cb tolerates a null @p context.
 *
 * @return The number of devices that were visited if all visits succeed, or
 * the negative value returned from the first visit that did not succeed.
 *//* Count supporting devices.
		 * Trailing NULL's can be injected by gen_device_deps.py due to
		 * CONFIG_PM_DEVICE_POWER_DOMAIN_DYNAMIC_NUM
		 *//* Fast forward to supporting devices *//**
 * @brief Get the set of handles that this device supports.
 *
 * This function returns a pointer to an array of device handles. The length of
 * the array is stored in the @p count parameter.
 *
 * The array contains a handle for each device that @p dev "supports" -- that
 * is, devices that require @p dev directly -- as determined from the
 * devicetree. This does not include transitive dependencies; you must
 * recursively determine those.
 *
 * @param dev the device for which supports are desired.
 * @param count pointer to where this function should store the length of the
 * returned array. No value is stored if the call returns a null pointer. The
 * value may be set to zero if nothing in the devicetree depends on @p dev.
 *
 * @return a pointer to a sequence of @p *count device handles, or a null
 * pointer if @p dev does not have any dependency data.
 *//* Fast forward to injected devices *//**
 * @brief Get the device handles for injected dependencies of this device.
 *
 * This function returns a pointer to an array of device handles. The length of
 * the array is stored in the @p count parameter.
 *
 * The array contains a handle for each device that @p dev manually injected as
 * a dependency, via providing extra arguments to Z_DEVICE_DEFINE. This does not
 * include transitive dependencies; you must recursively determine those.
 *
 * @param dev the device for which injected dependencies are desired.
 * @param count pointer to where this function should store the length of the
 * returned array. No value is stored if the call returns a null pointer. The
 * value may be set to zero if the device has no devicetree dependencies.
 *
 * @return a pointer to a sequence of @p *count device handles, or a null
 * pointer if @p dev does not have any dependency data.
 *//**
 * @brief Get the device handles for devicetree dependencies of this device.
 *
 * This function returns a pointer to an array of device handles. The length of
 * the array is stored in the @p count parameter.
 *
 * The array contains a handle for each device that @p dev requires directly, as
 * determined from the devicetree. This does not include transitive
 * dependencies; you must recursively determine those.
 *
 * @param dev the device for which dependencies are desired.
 * @param count pointer to where this function should store the length of the
 * returned array. No value is stored if the call returns a null pointer. The
 * value may be set to zero if the device has no devicetree dependencies.
 *
 * @return a pointer to a sequence of @p count device handles, or a null pointer
 * if @p dev does not have any dependency data.
 *//**
 * @brief Prototype for functions used when iterating over a set of devices.
 *
 * Such a function may be used in API that identifies a set of devices and
 * provides a visitor API supporting caller-specific interaction with each
 * device in the set.
 *
 * The visit is said to succeed if the visitor returns a non-negative value.
 *
 * @param dev a device in the set being iterated
 * @param context state used to support the visitor function
 *
 * @return A non-negative number to allow walking to continue, and a negative
 * error code to case the iteration to stop.
 *
 * @see device_required_foreach()
 * @see device_supported_foreach()
 *//**
 * @brief Get the device corresponding to a handle.
 *
 * @param dev_handle the device handle
 *
 * @return the device that has that handle, or a null pointer if @p dev_handle
 * does not identify a device.
 *//* TODO: If/when devices can be constructed that are not part of the
	 * fixed sequence we'll need another solution.
	 *//**
 * @brief Get the handle for a given device
 *
 * @param dev the device for which a handle is desired.
 *
 * @return the handle for the device, or DEVICE_HANDLE_NULL if the device does
 * not have an associated handle.
 *//**
	 * Reference to the device PM resources (only available if
	 * @kconfig{CONFIG_PM_DEVICE} is enabled).
	 *//**
	 * Optional pointer to dependencies associated with the device.
	 *
	 * This encodes a sequence of sets of device handles that have some
	 * relationship to this node. The individual sets are extracted with
	 * dedicated API, such as device_required_handles_get(). Only available
	 * if @kconfig{CONFIG_DEVICE_DEPS} is enabled.
	 *//** Address of the device instance private data *//** Address of the common device state *//** Address of the API structure exposed by the device instance *//** Address of device instance config information *//** Name of the device instance *//**
 * @brief Runtime device structure (in ROM) per driver instance
 *//** Indicates the device initialization function has been
	 * invoked.
	 *//**
	 * Device initialization return code (positive errno value).
	 *
	 * Device initialization functions return a negative errno code if they
	 * fail. In Zephyr, errno values do not exceed 255, so we can store the
	 * positive result value in a uint8_t type.
	 *//**
 * @brief Runtime device dynamic structure (in RAM) per driver instance
 *
 * Fields in this are expected to be default-initialized to zero. The
 * kernel driver infrastructure and driver access functions are
 * responsible for ensuring that any non-zero initialization is done
 * before they are accessed.
 *//**
 * @brief Get a @ref init_entry reference from a device identifier.
 *
 * @param dev_id Device identifier.
 *
 * @return A pointer to the init_entry object created for that device
 *//**
 * @brief Get a @ref init_entry reference from a devicetree node.
 *
 * @param node_id A devicetree node identifier
 *
 * @return A pointer to the @ref init_entry object created for that node
 *//**
 * @brief Declare a static device object
 *
 * This macro can be used at the top-level to declare a device, such
 * that DEVICE_GET() may be used before the full declaration in
 * DEVICE_DEFINE().
 *
 * This is often useful when configuring interrupts statically in a
 * device's init or per-instance config function, as the init function
 * itself is required by DEVICE_DEFINE() and use of DEVICE_GET()
 * inside it creates a circular dependency.
 *
 * @param dev_id Device identifier.
 *//**
 * @brief Obtain a pointer to a device object by name
 *
 * @details Return the address of a device object created by
 * DEVICE_DEFINE(), using the dev_id provided to DEVICE_DEFINE().
 *
 * @param dev_id Device identifier.
 *
 * @return A pointer to the device object created by DEVICE_DEFINE()
 *//**
 * @brief Utility macro to obtain an optional reference to a device.
 *
 * If the node identifier refers to a node with status `okay`, this returns
 * `DEVICE_DT_GET(node_id)`. Otherwise, it returns `NULL`.
 *
 * @param node_id devicetree node identifier
 *
 * @return a @ref device reference for the node identifier, which may be `NULL`.
 *//**
 * @brief Get a @ref device reference from a devicetree compatible.
 *
 * If an enabled devicetree node has the given compatible and a device object
 * was created from it, this returns a pointer to that device.
 *
 * If there are no such devices, this will fail at compile time.
 *
 * If there are multiple, this returns an arbitrary one.
 *
 * If this returns non-NULL, the device must be checked for readiness before
 * use, e.g. with device_is_ready().
 *
 * @param compat lowercase-and-underscores devicetree compatible
 * @return a pointer to a device
 *//**
 * @brief Get a @ref device reference from a devicetree compatible.
 *
 * If an enabled devicetree node has the given compatible and a device
 * object was created from it, this returns a pointer to that device.
 *
 * If there no such devices, this returns NULL.
 *
 * If there are multiple, this returns an arbitrary one.
 *
 * If this returns non-NULL, the device must be checked for readiness
 * before use, e.g. with device_is_ready().
 *
 * @param compat lowercase-and-underscores devicetree compatible
 * @return a pointer to a device, or NULL
 *//**
 * @brief Get a @ref device reference for an instance of a `DT_DRV_COMPAT`
 * compatible.
 *
 * This is equivalent to `DEVICE_DT_GET(DT_DRV_INST(inst))`.
 *
 * @param inst `DT_DRV_COMPAT` instance number
 * @return A pointer to the device object created for that instance
 *//**
 * @brief Get a @ref device reference from a devicetree node identifier.
 *
 * Returns a pointer to a device object created from a devicetree node, if any
 * device was allocated by a driver.
 *
 * If no such device was allocated, this will fail at linker time. If you get an
 * error that looks like `undefined reference to __device_dts_ord_<N>`, that is
 * what happened. Check to make sure your device driver is being compiled,
 * usually by enabling the Kconfig options it requires.
 *
 * @param node_id A devicetree node identifier
 *
 * @return A pointer to the device object created for that node
 *//**
 * @brief The name of the global device object for @p node_id
 *
 * Returns the name of the global device structure as a C identifier. The device
 * must be allocated using DEVICE_DT_DEFINE() or DEVICE_DT_INST_DEFINE() for
 * this to work.
 *
 * This macro is normally only useful within device driver source code. In other
 * situations, you are probably looking for DEVICE_DT_GET().
 *
 * @param node_id Devicetree node identifier
 *
 * @return The name of the device object as a C identifier
 *//**
 * @brief Like DEVICE_DT_DEFINE(), but uses an instance of a `DT_DRV_COMPAT`
 * compatible instead of a node identifier.
 *
 * @param inst Instance number. The `node_id` argument to DEVICE_DT_DEFINE() is
 * set to `DT_DRV_INST(inst)`.
 * @param ... Other parameters as expected by DEVICE_DT_DEFINE().
 *//**
 * @brief Create a device object from a devicetree node identifier and set it up
 * for boot time initialization.
 *
 * This macro defines a @ref device that is automatically configured by the
 * kernel during system initialization. The global device object's name as a C
 * identifier is derived from the node's dependency ordinal. @ref device.name is
 * set to `DEVICE_DT_NAME(node_id)`.
 *
 * The device is declared with extern visibility, so a pointer to a global
 * device object can be obtained with `DEVICE_DT_GET(node_id)` from any source
 * file that includes `<zephyr/device.h>`. Before using the pointer, the
 * referenced object should be checked using device_is_ready().
 *
 * @param node_id The devicetree node identifier.
 * @param init_fn Pointer to the device's initialization function, which will be
 * run by the kernel during system initialization. Can be `NULL`.
 * @param pm Pointer to the device's power management resources, a
 * @ref pm_device, which will be stored in @ref device.pm. Use `NULL` if the
 * device does not use PM.
 * @param data Pointer to the device's private mutable data, which will be
 * stored in @ref device.data.
 * @param config Pointer to the device's private constant data, which will be
 * stored in @ref device.config field.
 * @param level The device's initialization level (PRE_KERNEL_1, PRE_KERNEL_2 or
 * POST_KERNEL).
 * @param prio The device's priority within its initialization level. See
 * SYS_INIT() for details.
 * @param api Pointer to the device's API structure. Can be `NULL`.
 *//**
 * @brief Return a string name for a devicetree node.
 *
 * This macro returns a string literal usable as a device's name from a
 * devicetree node identifier.
 *
 * @param node_id The devicetree node identifier.
 *
 * @return The value of the node's `label` property, if it has one.
 * Otherwise, the node's full name in `node-name@unit-address` form.
 *//**
 * @brief Create a device object and set it up for boot time initialization.
 *
 * This macro defines a @ref device that is automatically configured by the
 * kernel during system initialization. This macro should only be used when the
 * device is not being allocated from a devicetree node. If you are allocating a
 * device from a devicetree node, use DEVICE_DT_DEFINE() or
 * DEVICE_DT_INST_DEFINE() instead.
 *
 * @param dev_id A unique token which is used in the name of the global device
 * structure as a C identifier.
 * @param name A string name for the device, which will be stored in
 * @ref device.name. This name can be used to look up the device with
 * device_get_binding(). This must be less than Z_DEVICE_MAX_NAME_LEN characters
 * (including terminating `NULL`) in order to be looked up from user mode.
 * @param init_fn Pointer to the device's initialization function, which will be
 * run by the kernel during system initialization. Can be `NULL`.
 * @param pm Pointer to the device's power management resources, a
 * @ref pm_device, which will be stored in @ref device.pm field. Use `NULL` if
 * the device does not use PM.
 * @param data Pointer to the device's private mutable data, which will be
 * stored in @ref device.data.
 * @param config Pointer to the device's private constant data, which will be
 * stored in @ref device.config.
 * @param level The device's initialization level (PRE_KERNEL_1, PRE_KERNEL_2 or
 * POST_KERNEL).
 * @param prio The device's priority within its initialization level. See
 * SYS_INIT() for details.
 * @param api Pointer to the device's API structure. Can be `NULL`.
 *//* Node paths can exceed the maximum size supported by
 * device_get_binding() in user mode; this macro synthesizes a unique
 * dev_id from a devicetree node while staying within this maximum
 * size.
 *
 * The ordinal used in this name can be mapped to the path by
 * examining zephyr/include/generated/devicetree_generated.h.
 *//**
 * @brief Expands to the name of a global device object.
 *
 * Return the full name of a device object symbol created by DEVICE_DEFINE(),
 * using the `dev_id` provided to DEVICE_DEFINE(). This is the name of the
 * global variable storing the device structure, not a pointer to the string in
 * the @ref device.name field.
 *
 * It is meant to be used for declaring extern symbols pointing to device
 * objects before using the DEVICE_GET macro to get the device object.
 *
 * This macro is normally only useful within device driver source code. In other
 * situations, you are probably looking for device_get_binding().
 *
 * @param dev_id Device identifier.
 *
 * @return The full name of the device object defined by device definition
 * macros.
 *//** @brief Flag value used to identify an unknown device. *//**
 * @brief Type used to represent a "handle" for a device.
 *
 * Every @ref device has an associated handle. You can get a pointer to a
 * @ref device from its handle and vice versa, but the handle uses less space
 * than a pointer. The device.h API mainly uses handles to store lists of
 * multiple devices in a compact way.
 *
 * The extreme values and zero have special significance. Negative values
 * identify functionality that does not correspond to a Zephyr device, such as
 * the system clock or a SYS_INIT() function.
 *
 * @see device_handle_get()
 * @see device_from_handle()
 *//**
 * @brief Flag value used in lists of device dependencies to indicate the end of
 * the list.
 *//**
 * @brief Flag value used in lists of device dependencies to separate distinct
 * groups.
 *//**
 * @brief Device Model
 * @defgroup device_model Device Model
 * @{
 */dev_handledevices/home/haojie/zephyrproject/zephyr/include/zephyr/pm/device.hpm_device_driver_initrcPM_DEVICE_ACTION_TURN_ONPM_DEVICE_ACTION_RESUMEpm_device_is_poweredpm_device_power_domain_removepm_device_power_domain_addpm_device_on_power_domainpm_device_state_is_lockedpm_device_state_unlockpm_device_state_lockpm_device_wakeup_is_capablepm_device_wakeup_is_enabledpm_device_wakeup_enablepm_device_is_busypm_device_is_any_busypm_device_busy_clearpm_device_busy_setpm_device_init_offpm_device_init_suspendedpm_device_state_getpm_device_state *PM_DEVICE_STATE_ACTIVEpm_device_children_action_runpm_device_action_runpm_device_state_strpm_device_action_failed_cb_tpm_device_action_cb_tpm_device_actionPM_DEVICE_ACTION_SUSPENDPM_DEVICE_ACTION_TURN_OFFpm_device_statePM_DEVICE_STATE_SUSPENDEDPM_DEVICE_STATE_SUSPENDINGPM_DEVICE_STATE_OFFpm_device_flagPM_DEVICE_FLAG_BUSYPM_DEVICE_FLAG_TURN_ON_FAILEDPM_DEVICE_FLAG_PD_CLAIMEDPM_DEVICE_FLAG_WS_CAPABLEPM_DEVICE_FLAG_WS_ENABLEDPM_DEVICE_FLAG_RUNTIME_ENABLEDPM_DEVICE_FLAG_STATE_LOCKEDPM_DEVICE_FLAG_PDPM_DEVICE_FLAG_RUNTIME_AUTOaction_cbPM_DEVICE_DT_INST_GET(idx)PM_DEVICE_DT_GET(DT_DRV_INST(idx))PM_DEVICE_DT_GET(node_id)PM_DEVICE_GET(Z_DEVICE_DT_DEV_ID(node_id))PM_DEVICE_GET(dev_id)Z_PM_DEVICE_GET(dev_id)PM_DEVICE_DT_INST_DEFINE(idx,pm_action_cb)Z_PM_DEVICE_DEFINE(DT_DRV_INST(idx), Z_DEVICE_DT_DEV_ID(DT_DRV_INST(idx)), pm_action_cb)PM_DEVICE_DT_DEFINE(node_id,pm_action_cb)Z_PM_DEVICE_DEFINE(node_id, Z_DEVICE_DT_DEV_ID(node_id), pm_action_cb)PM_DEVICE_DEFINE(dev_id,pm_action_cb)Z_PM_DEVICE_DEFINE(DT_INVALID_NODE, dev_id, pm_action_cb)Z_PM_DEVICE_DEFINE(node_id,dev_id,pm_action_cb)Z_PM_DEVICE_DEFINE_SLOT(dev_id)static const STRUCT_SECTION_ITERABLE_ALTERNATE(pm_device_slots, device, _CONCAT(__pm_slot_, dev_id))Z_PM_DEVICE_NAME(dev_id)_CONCAT(__pm_device_, dev_id)Z_PM_DEVICE_INIT(obj,node_id,pm_action_cb){ Z_PM_DEVICE_RUNTIME_INIT(obj) .action_cb = pm_action_cb, .state = PM_DEVICE_STATE_ACTIVE, .flags = ATOMIC_INIT(Z_PM_DEVICE_FLAGS(node_id)), Z_PM_DEVICE_POWER_DOMAIN_INIT(node_id) }Z_PM_DEVICE_FLAGS(node_id)(COND_CODE_1( DT_NODE_EXISTS(node_id), ((DT_PROP_OR(node_id, wakeup_source, 0) << PM_DEVICE_FLAG_WS_CAPABLE) | (DT_PROP_OR(node_id, zephyr_pm_device_runtime_auto, 0) << PM_DEVICE_FLAG_RUNTIME_AUTO) | (DT_NODE_HAS_COMPAT(node_id, power_domain) << PM_DEVICE_FLAG_PD)), (0)))Z_PM_DEVICE_POWER_DOMAIN_INIT(obj)Z_PM_DEVICE_RUNTIME_INIT(obj)ZEPHYR_INCLUDE_PM_DEVICE_H_defined(CONFIG_PM_DEVICE_RUNTIME) || defined(__DOXYGEN__)CONFIG_PM_DEVICE_POWER_DOMAINCONFIG_PM_DEVICE_RUNTIMECONFIG_PM_DEVICE/* CONFIG_PM_DEVICE *//* When power management is not enabled, all drivers should initialise to active state *//**
 * @brief Setup a device driver into the lowest valid power mode
 *
 * This helper function is intended to be called at the end of a driver
 * init function to automatically setup the device into the lowest power
 * mode. It assumes that the device has been configured as if it is in
 * @ref PM_DEVICE_STATE_OFF.
 *
 * @param dev Device instance.
 * @param action_cb Device PM control callback function.
 * @retval 0 On success.
 * @retval -errno Error code from @a action_cb on failure.
 *//**
 * @brief Check if the device is currently powered.
 *
 * @param dev Device instance.
 *
 * @retval true If device is currently powered, or is assumed to be powered
 * (i.e. it does not support PM or is not under a PM domain)
 * @retval false If device is not currently powered
 *//**
 * @brief Remove a device from a power domain.
 *
 * This function removes a device from a given power domain.
 *
 * @param dev Device to be removed from the power domain.
 * @param domain Power domain.
 *
 * @retval 0 If successful.
 * @retval -ENOSYS If the application was built without power domain support.
 * @retval -ENOENT If device is not in the given domain.
 *//**
 * @brief Add a device to a power domain.
 *
 * This function adds a device to a given power domain.
 *
 * @param dev Device to be added to the power domain.
 * @param domain Power domain.
 *
 * @retval 0 If successful.
 * @retval -EALREADY If device is already part of the power domain.
 * @retval -ENOSYS If the application was built without power domain support.
 * @retval -ENOSPC If there is no space available in the power domain to add the device.
 *//**
 * @brief Check if the device is on a switchable power domain.
 *
 * @param dev Device instance.
 *
 * @retval true If device is on a switchable power domain.
 * @retval false If device is not on a switchable power domain.
 *//**
 * @brief Check if the device pm is locked.
 *
 * @param dev Device instance.
 *
 * @retval true If device is locked.
 * @retval false If device is not locked.
 *//**
 * @brief Unlock the current device state.
 *
 * Unlocks a previously locked device pm.
 *
 * @see pm_device_state_lock
 *
 * @param dev Device instance.
 *//**
 * @brief Lock current device state.
 *
 * This function locks the current device power state. Once
 * locked the device power state will not be changed by
 * system power management or device runtime power
 * management until unlocked.
 *
 * @note The given device should not have device runtime enabled.
 *
 * @see pm_device_state_unlock
 *
 * @param dev Device instance.
 *//**
 * @brief Check if a device is wake up capable
 *
 * @param dev Device instance.
 *
 * @retval true If the device is wake up capable.
 * @retval false If the device is not wake up capable.
 *//**
 * @brief Check if a device is enabled as a wake up source.
 *
 * @param dev Device instance.
 *
 * @retval true if the wakeup source is enabled.
 * @retval false if the wakeup source is not enabled.
 *//**
 * @brief Enable or disable a device as a wake up source.
 *
 * A device marked as a wake up source will not be suspended when the system
 * goes into low-power modes, thus allowing to use it as a wake up source for
 * the system.
 *
 * @param dev Device instance.
 * @param enable @c true to enable or @c false to disable
 *
 * @retval true If the wakeup source was successfully enabled.
 * @retval false If the wakeup source was not successfully enabled.
 *//**
 * @brief Check if a device is busy.
 *
 * @param dev Device instance.
 *
 * @retval false If the device is not busy
 * @retval true If the device is busy
 *//**
 * @brief Check if any device is busy.
 *
 * @retval false If no device is busy
 * @retval true If one or more devices are busy
 *//**
 * @brief Clear a device busy status.
 *
 * @param dev Device instance.
 *
 * @see pm_device_busy_set()
 *//**
 * @brief Mark a device as busy.
 *
 * Devices marked as busy will not be suspended when the system goes into
 * low-power states. This can be useful if, for example, the device is in the
 * middle of a transaction.
 *
 * @param dev Device instance.
 *
 * @see pm_device_busy_clear()
 *//**
 * @brief Initialize a device state to #PM_DEVICE_STATE_OFF.
 *
 * By default device state is initialized to #PM_DEVICE_STATE_ACTIVE. In
 * general, this makes sense because the device initialization function will
 * resume and configure a device, leaving it operational. However, when power
 * domains are enabled, the device may be connected to a switchable power
 * source, in which case it won't be powered at boot. This function can
 * therefore be used to notify the PM subsystem that the device is in
 * #PM_DEVICE_STATE_OFF instead of the default.
 *
 * @param dev Device instance.
 *//**
 * @brief Initialize a device state to #PM_DEVICE_STATE_SUSPENDED.
 *
 * By default device state is initialized to #PM_DEVICE_STATE_ACTIVE. However
 * in order to save power some drivers may choose to only initialize the device
 * to the suspended state, or actively put the device into the suspended state.
 * This function can therefore be used to notify the PM subsystem that the
 * device is in #PM_DEVICE_STATE_SUSPENDED instead of the default.
 *
 * @param dev Device instance.
 *//**
 * @brief Obtain the power state of a device.
 *
 * @param dev Device instance.
 * @param state Pointer where device power state will be stored.
 *
 * @retval 0 If successful.
 * @retval -ENOSYS If device does not implement power management.
 *//**
 * @brief Run a pm action on all children of a device.
 *
 * This function calls all child devices PM control callback so that the device
 * does the necessary operations to execute the given action.
 *
 * @param dev Device instance.
 * @param action Device pm action.
 * @param failure_cb Function to call if a child fails the action, can be NULL.
 *//**
 * @brief Run a pm action on a device.
 *
 * This function calls the device PM control callback so that the device does
 * the necessary operations to execute the given action.
 *
 * @param dev Device instance.
 * @param action Device pm action.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If requested state is not supported.
 * @retval -EALREADY If device is already at the requested state.
 * @retval -EBUSY If device is changing its state.
 * @retval -ENOSYS If device does not support PM.
 * @retval -EPERM If device has power state locked.
 * @retval Errno Other negative errno on failure.
 *//**
 * @brief Get name of device PM state
 *
 * @param state State id which name should be returned
 *//**
 * @brief Obtain a reference to the device PM resources for the given instance.
 *
 * @param idx Instance index.
 *
 * @return Reference to the device PM resources (NULL if device
 * @kconfig{CONFIG_PM_DEVICE} is disabled).
 *//**
 * @brief Obtain a reference to the device PM resources for the given node.
 *
 * @param node_id Node identifier.
 *
 * @return Reference to the device PM resources (NULL if device
 * @kconfig{CONFIG_PM_DEVICE} is disabled).
 *//**
 * @brief Obtain a reference to the device PM resources for the given device.
 *
 * @param dev_id Device id.
 *
 * @return Reference to the device PM resources (NULL if device
 * @kconfig{CONFIG_PM_DEVICE} is disabled).
 *//**
 * Define device PM resources for the given instance.
 *
 * @note This macro is a no-op if @kconfig{CONFIG_PM_DEVICE} is not enabled.
 *
 * @param idx Instance index.
 * @param pm_action_cb PM control callback.
 *
 * @see #PM_DEVICE_DT_DEFINE, #PM_DEVICE_DEFINE
 *//**
 * Define device PM resources for the given node identifier.
 *
 * @note This macro is a no-op if @kconfig{CONFIG_PM_DEVICE} is not enabled.
 *
 * @param node_id Node identifier.
 * @param pm_action_cb PM control callback.
 *
 * @see #PM_DEVICE_DT_INST_DEFINE, #PM_DEVICE_DEFINE
 *//**
 * Define device PM resources for the given device name.
 *
 * @note This macro is a no-op if @kconfig{CONFIG_PM_DEVICE} is not enabled.
 *
 * @param dev_id Device id.
 * @param pm_action_cb PM control callback.
 *
 * @see #PM_DEVICE_DT_DEFINE, #PM_DEVICE_DT_INST_DEFINE
 *//**
 * Get a reference to the device PM resources.
 *
 * @param dev_id Device id.
 *//**
 * Define device PM resources for the given node identifier.
 *
 * @param node_id Node identifier (DT_INVALID_NODE if not a DT device).
 * @param dev_id Device id.
 * @param pm_action_cb PM control callback.
 *//**
 * @brief Define device PM slot.
 *
 * This macro defines a pointer to a device in the pm_device_slots region.
 * When invoked for each device with PM, it will effectively result in a device
 * pointer array with the same size of the actual devices with PM enabled. This
 * is used internally by the PM subsystem to keep track of suspended devices
 * during system power transitions.
 *
 * @param dev_id Device id.
 *//**
 * Get the name of device PM resources.
 *
 * @param dev_id Device id.
 *//**
 * @brief Utility macro to initialize #pm_device.
 *
 * @note #DT_PROP_OR is used to retrieve the wakeup_source property because
 * it may not be defined on all devices.
 *
 * @param obj Name of the #pm_device structure being initialized.
 * @param node_id Devicetree node for the initialized device (can be invalid).
 * @param pm_action_cb Device PM control callback function.
 *//**
 * @brief Utility macro to initialize #pm_device flags
 *
 * @param node_id Devicetree node for the initialized device (can be invalid).
 *//* CONFIG_PM_DEVICE_POWER_DOMAIN *//* CONFIG_PM_DEVICE_RUNTIME *//** Device PM action callback *//** Device power state *//* Device PM status flags. *//** Power Domain it belongs *//** Work object for asynchronous calls *//** Device usage count *//** Event var to listen to the sync request events *//** Lock to synchronize the get/put operations *//** Pointer to the device *//**
 * @brief Device PM info
 *//**
 * @brief Device PM action failed callback
 *
 * @param dev Device that failed the action.
 * @param err Return code of action failure.
 *
 * @return True to continue iteration, false to halt iteration.
 *//**
 * @brief Device PM action callback.
 *
 * @param dev Device instance.
 * @param action Requested action.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If the requested action is not supported.
 * @retval Errno Other negative errno on failure.
 *//**
	 * Turn on.
	 * @note
	 *     Action triggered only by a power domain.
	 *//**
	 * Turn off.
	 * @note
	 *     Action triggered only by a power domain.
	 *//** Resume. *//** Suspend. *//** @brief Device PM actions. *//**
	 * Device is turned off (power removed).
	 *
	 * @note
	 *     Device context is lost.
	 *//** Device is being suspended. *//**
	 * Device is suspended.
	 *
	 * @note
	 *     Device context may be lost.
	 *//** Device is in active or regular state. *//** @brief Device power states. *//** Indicates if device runtime PM should be automatically enabled *//** Indicates if the device is used as a power domain *//** Indicates if the device pm is locked.  *//** Indicates if device runtime is enabled  *//** Indicates if the device is being used as wakeup source. *//**
	 * Indicates whether or not the device is capable of waking the system
	 * up.
	 *//** Indicate if the device has claimed a power domain *//** Indicate if the device failed to power up. *//** Indicate if the device is busy or not. *//** @brief Device PM flags. *//**
 * @brief Device Power Management API
 * @defgroup subsys_pm_device Device
 * @ingroup subsys_pm
 * @{
 */actionfailure_cbz_x86_enable_pagingarch_thread_return_value_setarch_kernel_initZEPHYR_ARCH_X86_INCLUDE_IA32_KERNEL_ARCH_FUNC_H_/* ZEPHYR_ARCH_X86_INCLUDE_IA32_KERNEL_ARCH_FUNC_H_ *//* ASM code to fiddle with registers to enable the MMU with PAE paging *//* write into 'eax' slot created in z_swap() entry *//* No-op on this arch *//* For size_t *//*
 * Copyright (c) 2016 Wind River Systems, Inc.
 * Copyright (c) 2018 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */<ia32/kernel_arch_func.h>z_x86_irq_connect_on_vectorz_x86_allocate_vectorz_x86_prep_carch_is_in_isrZEPHYR_ARCH_X86_INCLUDE_KERNEL_ARCH_FUNC_H_/* ZEPHYR_ARCH_X86_INCLUDE_KERNEL_ARCH_FUNC_H_ *//*
 * Connect a vector
 *//*
 * Find a free IRQ vector at the specified priority, or return -1 if none left.
 * For multiple vector allocated one after another, prev_vector can be used to
 * speed up the allocation: it only needs to be filled with the previous
 * allocated vector, or -1 to start over.
 *//* Preparation steps needed for all threads if user mode is turned on.
 *
 * Returns the initial entry point to swap into.
 *//**
 * @brief Check if a memory address range falls within the stack
 *
 * Given a memory address range, ensure that it falls within the bounds
 * of the faulting context's stack.
 *
 * @param addr Starting address
 * @param size Size of the region, or 0 if we just want to see if addr is
 *             in bounds
 * @param cs Code segment of faulting context
 * @return true if addr/size region is not within the thread stack
 *//* Common handling for page fault exceptions *//* Called upon unrecoverable error; dump registers and transfer control to
 * kernel via z_fatal_error()
 *//* Called upon CPU exception that is unhandled and hence fatal; dump
 * interesting info and call z_x86_fatal_error()
 *//* CONFIG_X86_VERY_EARLY_CONSOLE *//* Setup ultra-minimal serial driver for printk() *//* On SMP, there is a race vs. the current CPU changing if we
	 * are preempted.  Need to mask interrupts while inspecting
	 * (note deliberate lack of gcc size suffix on the
	 * instructions, we need to work with both architectures here)
	 */prev_vectorarch_tls_stack_setuparch_coredump_tgt_code_getarch_coredump_info_dumparch_page_info_getarch_page_location_getarch_mem_scratcharch_mem_page_inarch_mem_page_outarch_reserved_pages_updatearch_page_phys_getarch_mem_unmaparch_mem_maparch_page_locationARCH_PAGE_LOCATION_PAGED_OUTARCH_PAGE_LOCATION_PAGED_INARCH_PAGE_LOCATION_BADZEPHYR_KERNEL_INCLUDE_KERNEL_ARCH_INTERFACE_H_CONFIG_ARCH_HAS_CUSTOM_BUSY_WAITCONFIG_ARCH_HAS_CUSTOM_SWAP_TO_MAIN/* ZEPHYR_KERNEL_INCLUDE_KERNEL_ARCH_INTERFACE_H_ *//* Include arch-specific inline function implementation *//**
 * @brief Setup Architecture-specific TLS area in stack
 *
 * This sets up the stack area for thread local storage.
 * The structure inside TLS area is architecture specific.
 *
 * @param new_thread New thread object
 * @param stack_ptr Stack pointer
 * @return Number of bytes taken by the TLS area
 *//**
 * @defgroup arch-tls Architecture-specific Thread Local Storage APIs
 * @ingroup arch-interface
 * @{
 *//**
 * @brief Get the target code specified by the architecture.
 *//**
 * @brief Architecture-specific handling during coredump
 *
 * This dumps architecture-specific information during coredump.
 *
 * @param esf Exception Stack Frame (arch-specific)
 *//**
 * @defgroup arch-coredump Architecture-specific core dump APIs
 * @ingroup arch-interface
 * @{
 *//** Do nothing and return. Yawn. *//**
 * Architecture-specific kernel initialization hook
 *
 * This function is invoked near the top of _Cstart, for additional
 * architecture-specific setup before the rest of the kernel is brought up.
 *//**
 * Early boot console output hook
 *
 * Definition of this function is optional. If implemented, any invocation
 * of printk() (or logging calls with CONFIG_LOG_MODE_MINIMAL which are backed by
 * printk) will default to sending characters to this function. It is
 * useful for early boot debugging before main serial or console drivers
 * come up.
 *
 * This can be overridden at runtime with __printk_hook_install().
 *
 * The default __weak implementation of this does nothing.
 *
 * @param c Character to print
 * @return The character printed
 *//**
 * @defgroup arch-misc Miscellaneous architecture APIs
 * @ingroup arch-interface
 * @{
 *//**
 * Retrieve page characteristics from the page table(s)
 *
 * The architecture is responsible for maintaining "accessed" and "dirty"
 * states of data pages to support marking eviction algorithms. This can
 * either be directly supported by hardware or emulated by modifying
 * protection policy to generate faults on reads or writes. In all cases
 * the architecture must maintain this information in some way.
 *
 * For the provided virtual address, report the logical OR of the accessed
 * and dirty states for the relevant entries in all active page tables in
 * the system if the page is mapped and not paged out.
 *
 * If clear_accessed is true, the ARCH_DATA_PAGE_ACCESSED flag will be reset.
 * This function will report its prior state. If multiple page tables are in
 * use, this function clears accessed state in all of them.
 *
 * This function is called with interrupts locked, so that the reported
 * information can't become stale while decisions are being made based on it.
 *
 * The return value may have other bits set which the caller must ignore.
 *
 * Clearing accessed state for data pages that are not ARCH_DATA_PAGE_LOADED
 * is undefined behavior.
 *
 * ARCH_DATA_PAGE_DIRTY and ARCH_DATA_PAGE_ACCESSED bits in the return value
 * are only significant if ARCH_DATA_PAGE_LOADED is set, otherwise ignore
 * them.
 *
 * ARCH_DATA_PAGE_NOT_MAPPED bit in the return value is only significant
 * if ARCH_DATA_PAGE_LOADED is un-set, otherwise ignore it.
 *
 * Unless otherwise specified, virtual data pages have the same mappings
 * across all page tables. Calling this function on data pages that are
 * exceptions to this rule (such as the scratch page) is undefined behavior.
 *
 * This API is part of infrastructure still under development and may change.
 *
 * @param addr Virtual address to look up in page tables
 * @param [out] location If non-NULL, updated with either physical page frame
 *                   address or backing store location depending on
 *                   ARCH_DATA_PAGE_LOADED state. This is not touched if
 *                   ARCH_DATA_PAGE_NOT_MAPPED.
 * @param clear_accessed Whether to clear ARCH_DATA_PAGE_ACCESSED state
 * @retval Value with ARCH_DATA_PAGE_* bits set reflecting the data page
 *         configuration
 *//**
 * @def ARCH_DATA_PAGE_NOT_MAPPED
 *
 * If ARCH_DATA_PAGE_LOADED is un-set, this will indicate that the page
 * is not mapped at all. This bit is undefined if ARCH_DATA_PAGE_LOADED is set.
 *//**
  * @def ARCH_DATA_PAGE_LOADED
  *
  * Bit indicating that the data page is loaded into a physical page frame.
  *
  * If un-set, the data page is paged out or not mapped.
  *//**
  * @def ARCH_DATA_PAGE_DIRTY
  *
  * Bit indicating the data page, if evicted, will need to be paged out.
  *
  * Set if the data page was modified since it was last paged out, or if
  * it has never been paged out before. Safe to set this if uncertain.
  *
  * This bit is undefined if ARCH_DATA_PAGE_LOADED is not set.
  *//**
 * @def ARCH_DATA_PAGE_ACCESSED
 *
 * Bit indicating the data page was accessed since the value was last cleared.
 *
 * Used by marking eviction algorithms. Safe to set this if uncertain.
 *
 * This bit is undefined if ARCH_DATA_PAGE_LOADED is not set.
 *//**
 * Fetch location information about a page at a particular address
 *
 * The function only needs to query the current set of page tables as
 * the information it reports must be common to all of them if multiple
 * page tables are in use. If multiple page tables are active it is unnecessary
 * to iterate over all of them. This may allow certain types of optimizations
 * (such as reverse page table mapping on x86).
 *
 * This function is called with interrupts locked, so that the reported
 * information can't become stale while decisions are being made based on it.
 *
 * Unless otherwise specified, virtual data pages have the same mappings
 * across all page tables. Calling this function on data pages that are
 * exceptions to this rule (such as the scratch page) is undefined behavior.
 * Just check the currently installed page tables and return the information
 * in that.
 *
 * @param addr Virtual data page address that took the page fault
 * @param [out] location In the case of ARCH_PAGE_FAULT_PAGED_OUT, the backing
 *        store location value used to retrieve the data page. In the case of
 *        ARCH_PAGE_FAULT_PAGED_IN, the physical address the page is mapped to.
 * @retval ARCH_PAGE_FAULT_PAGED_OUT The page was evicted to the backing store.
 * @retval ARCH_PAGE_FAULT_PAGED_IN The data page is resident in memory.
 * @retval ARCH_PAGE_FAULT_BAD The page is un-mapped or otherwise has had
 *         invalid access
 *//** The page is not mapped. *//** The page is resident in memory. *//** The page has been evicted to the backing store. *//**
 * Status of a particular page location.
 *//**
 * Update current page tables for a temporary mapping
 *
 * Map a physical page frame address to a special virtual address
 * Z_SCRATCH_PAGE, with read/write access to supervisor mode, such that
 * when this function returns, the calling context can read/write the page
 * frame's contents from the Z_SCRATCH_PAGE address.
 *
 * This mapping only needs to be done on the current set of page tables,
 * as it is only used for a short period of time exclusively by the caller.
 * This function is called with interrupts locked.
 *
 * This API is part of infrastructure still under development and may change.
 *//**
 * Update all page tables for a paged-in data page
 *
 * This function:
 * - Maps the specified virtual data page address to the provided physical
 *   page frame address, such that future memory accesses will function as
 *   expected. Access and caching attributes are undisturbed.
 * - Clears any accounting for "accessed" and "dirty" states.
 *
 * If multiple page tables are in use, this must update all page tables.
 * This function is called with interrupts locked.
 *
 * Calling this function on data pages which are already paged in is
 * undefined behavior.
 *
 * This API is part of infrastructure still under development and may change.
 *//**
 * Update all page tables for a paged-out data page
 *
 * This function:
 * - Sets the data page virtual address to trigger a fault if accessed that
 *   can be distinguished from access violations or un-mapped pages.
 * - Saves the provided location value so that it can retrieved for that
 *   data page in the page fault handler.
 * - The location value semantics are undefined here but the value will be
 *   always be page-aligned. It could be 0.
 *
 * If multiple page tables are in use, this must update all page tables.
 * This function is called with interrupts locked.
 *
 * Calling this function on data pages which are already paged out is
 * undefined behavior.
 *
 * This API is part of infrastructure still under development and may change.
 *//**
 * Update page frame database with reserved pages
 *
 * Some page frames within system RAM may not be available for use. A good
 * example of this is reserved regions in the first megabyte on PC-like systems.
 *
 * Implementations of this function should mark all relevant entries in
 * z_page_frames with K_PAGE_FRAME_RESERVED. This function is called at
 * early system initialization with mm_lock held.
 *//**
 * Get the mapped physical memory address from virtual address.
 *
 * The function only needs to query the current set of page tables as
 * the information it reports must be common to all of them if multiple
 * page tables are in use. If multiple page tables are active it is unnecessary
 * to iterate over all of them.
 *
 * Unless otherwise specified, virtual pages have the same mappings
 * across all page tables. Calling this function on data pages that are
 * exceptions to this rule (such as the scratch page) is undefined behavior.
 * Just check the currently installed page tables and return the information
 * in that.
 *
 * @param virt Page-aligned virtual address
 * @param[out] phys Mapped physical address (can be NULL if only checking
 *                  if virtual address is mapped)
 *
 * @retval 0 if mapping is found and valid
 * @retval -EFAULT if virtual address is not mapped
 *//**
 * Remove mappings for a provided virtual address range
 *
 * This is a low-level interface for un-mapping pages from the address space.
 * When this completes, the relevant page table entries will be updated as
 * if no mapping was ever made for that memory range. No previous context
 * needs to be preserved. This function must update mappings in all active
 * page tables.
 *
 * Behavior when providing unaligned addresses/sizes is undefined, these
 * are assumed to be aligned to CONFIG_MMU_PAGE_SIZE.
 *
 * Behavior when providing an address range that is not already mapped is
 * undefined.
 *
 * This function should never require memory allocations for paging structures,
 * and it is not necessary to free any paging structures. Empty page tables
 * due to all contained entries being un-mapped may remain in place.
 *
 * Implementations must invalidate TLBs as necessary.
 *
 * This API is part of infrastructure still under development and may change.
 *
 * @param addr Page-aligned base virtual address to un-map
 * @param size Page-aligned region size
 *//**
 * Map physical memory into the virtual address space
 *
 * This is a low-level interface to mapping pages into the address space.
 * Behavior when providing unaligned addresses/sizes is undefined, these
 * are assumed to be aligned to CONFIG_MMU_PAGE_SIZE.
 *
 * The core kernel handles all management of the virtual address space;
 * by the time we invoke this function, we know exactly where this mapping
 * will be established. If the page tables already had mappings installed
 * for the virtual memory region, these will be overwritten.
 *
 * If the target architecture supports multiple page sizes, currently
 * only the smallest page size will be used.
 *
 * The memory range itself is never accessed by this operation.
 *
 * This API must be safe to call in ISRs or exception handlers. Calls
 * to this API are assumed to be serialized, and indeed all usage will
 * originate from kernel/mm.c which handles virtual memory management.
 *
 * Architectures are expected to pre-allocate page tables for the entire
 * address space, as defined by CONFIG_KERNEL_VM_BASE and
 * CONFIG_KERNEL_VM_SIZE. This operation should never require any kind of
 * allocation for paging structures.
 *
 * Validation of arguments should be done via assertions.
 *
 * This API is part of infrastructure still under development and may
 * change.
 *
 * @param virt Page-aligned Destination virtual address to map
 * @param phys Page-aligned Source physical address to map
 * @param size Page-aligned size of the mapped memory region in bytes
 * @param flags Caching, access and control flags, see K_MAP_* macros
 *//**
 * @defgroup arch-mmu Architecture-specific memory-mapping APIs
 * @ingroup arch-interface
 * @{
 *//**
 * Test if the current context is in interrupt context
 *
 * XXX: This is inconsistently handled among arches wrt exception context
 * See: #17656
 *
 * @return true if we are in interrupt context
 *//**
 * @defgroup arch-irq Architecture-specific IRQ APIs
 * @ingroup arch-interface
 * @{
 *//** Halt the system, optionally propagating a reason code *//**
 * @defgroup arch-pm Architecture-specific power management APIs
 * @ingroup arch-interface
 * @{
 *//**
 * @brief Enable floating point context preservation
 *
 * The function is used to enable the preservation of floating
 * point context information for a particular thread.
 * This API depends on each architecture implimentation. If the architecture
 * does not support enabling, this API will always be failed.
 *
 * The @a options parameter indicates which floating point register sets will
 * be used by the specified thread. Currently it is used by x86 only.
 *
 * @param thread  ID of thread.
 * @param options architecture dependent options
 *
 * @retval 0        On success.
 * @retval -EINVAL  If the floating point enabling could not be performed.
 * @retval -ENOTSUP If the operation is not supported
 *//**
 * @brief Disable floating point context preservation
 *
 * The function is used to disable the preservation of floating
 * point context information for a particular thread.
 *
 * @note For ARM architecture, disabling floating point preservation may only
 * be requested for the current thread and cannot be requested in ISRs.
 *
 * @retval 0        On success.
 * @retval -EINVAL  If the floating point disabling could not be performed.
 * @retval -ENOTSUP If the operation is not supported
 *//* CONFIG_ARCH_HAS_CUSTOM_SWAP_TO_MAIN *//**
 * Custom logic for entering main thread context at early boot
 *
 * Used by architectures where the typical trick of setting up a dummy thread
 * in early boot context to "switch out" of isn't workable.
 *
 * @param main_thread main thread object
 * @param stack_ptr Initial stack pointer
 * @param _main Entry point for application main function.
 *//* CONFIG_USE_SWITCH i*//**
 * Set the return value for the specified thread.
 *
 * It is assumed that the specified @a thread is pending.
 *
 * @param thread Pointer to thread object
 * @param value value to set as return value
 *//**
 * Cooperatively context switch
 *
 * Must be called with interrupts locked with the provided key.
 * This is the older-style context switching method, which is incompatible
 * with SMP. New arch ports, either SMP or UP, are encouraged to implement
 * arch_switch() instead.
 *
 * @param key Interrupt locking key
 * @return If woken from blocking on some kernel object, the result of that
 *         blocking operation.
 *//** Cooperative context switch primitive
 *
 * The action of arch_switch() should be to switch to a new context
 * passed in the first argument, and save a pointer to the current
 * context into the address passed in the second argument.
 *
 * The actual type and interpretation of the switch handle is specified
 * by the architecture.  It is the same data structure stored in the
 * "switch_handle" field of a newly-created thread in arch_new_thread(),
 * and passed to the kernel as the "interrupted" argument to
 * z_get_next_switch_handle().
 *
 * Note that on SMP systems, the kernel uses the store through the
 * second pointer as a synchronization point to detect when a thread
 * context is completely saved (so another CPU can know when it is
 * safe to switch).  This store must be done AFTER all relevant state
 * is saved, and must include whatever memory barriers or cache
 * management code is required to be sure another CPU will see the
 * result correctly.
 *
 * The simplest implementation of arch_switch() is generally to push
 * state onto the thread stack and use the resulting stack pointer as the
 * switch handle.  Some architectures may instead decide to use a pointer
 * into the thread struct as the "switch handle" type.  These can legally
 * assume that the second argument to arch_switch() is the address of the
 * switch_handle field of struct thread_base and can use an offset on
 * this value to find other parts of the thread struct.  For example a (C
 * pseudocode) implementation of arch_switch() might look like:
 *
 *   void arch_switch(void *switch_to, void **switched_from)
 *   {
 *       struct k_thread *new = switch_to;
 *       struct k_thread *old = CONTAINER_OF(switched_from, struct k_thread,
 *                                           switch_handle);
 *
 *       // save old context...
 *       *switched_from = old;
 *       // restore new context...
 *   }
 *
 * Note that the kernel manages the switch_handle field for
 * synchronization as described above.  So it is not legal for
 * architecture code to assume that it has any particular value at any
 * other time.  In particular it is not legal to read the field from the
 * address passed in the second argument.
 *
 * @param switch_to Incoming thread's switch handle
 * @param switched_from Pointer to outgoing thread's switch handle storage
 *        location, which must be updated.
 *//** Handle arch-specific logic for setting up new threads
 *
 * The stack and arch-specific thread state variables must be set up
 * such that a later attempt to switch to this thread will succeed
 * and we will enter z_thread_entry with the requested thread and
 * arguments as its parameters.
 *
 * At some point in this function's implementation, z_setup_new_thread() must
 * be called with the true bounds of the available stack buffer within the
 * thread's stack object.
 *
 * The provided stack pointer is guaranteed to be properly aligned with respect
 * to the CPU and ABI requirements. There may be space reserved between the
 * stack pointer and the bounds of the stack buffer for initial stack pointer
 * randomization and thread-local storage.
 *
 * Fields in thread->base will be initialized when this is called.
 *
 * @param thread Pointer to uninitialized struct k_thread
 * @param stack Pointer to the stack object
 * @param stack_ptr Aligned initial stack pointer
 * @param entry Thread entry function
 * @param p1 1st entry point parameter
 * @param p2 2nd entry point parameter
 * @param p3 3rd entry point parameter
 *//**
 * @defgroup arch-threads Architecture thread APIs
 * @ingroup arch-interface
 * @{
 *//**
 * Architecture-specific implementation of busy-waiting
 *
 * @param usec_to_wait Wait period, in microseconds
 *//**
 * @defgroup arch-timing Architecture timing APIs
 * @{
 *//**
 * @file
 * @brief Internal kernel APIs implemented at the architecture layer.
 *
 * Not all architecture-specific defines are here, APIs that are used
 * by public functions and macros are defined in include/sys/arch_interface.h.
 *
 * For all inline functions prototyped here, the implementation is expected
 * to be provided by arch/ARCH/include/kernel_arch_func.h
 */clear_accessed__locale_t *locale_t__locale_t_SYS__LOCALE_H/* _SYS__LOCALE_H *//* Definition of opaque POSIX-1.2008 type locale_t for userspace. *//* Copyright (c) 2016 Corinna Vinschen <corinna@vinschen.de> *//* This is a dummy <sys/string.h> used as a placeholder for
   systems that need to have a special header file.  *//* Copyright (c) 2005 Jeff Johnston  <jjohnstn@redhat.com> */set_fortify_handler__chk_fail__stack_chk_fail__ssp_overlap(a,b,l)(((a) <= (b) && (b) < (a) + (l)) || ((b) <= (a) && (a) < (b) + (l)))__ssp_redirect0(rtype,fun,args,call)__ssp_redirect_raw(rtype, fun, args, call, 1, __ssp_bos0)__ssp_redirect(rtype,fun,args,call)__ssp_redirect_raw(rtype, fun, args, call, 1, __ssp_bos)__ssp_redirect_raw(rtype,fun,args,call,cond,bos)__ssp_decl(rtype, fun, args) { if (cond) __ssp_check(__buf, __len, bos); return __ssp_real_(fun) call; }__ssp_decl(rtype,fun,args)rtype __ssp_real_(fun) args __asm__(__ASMNAME(#fun)); __ssp_inline rtype fun args__ssp_check(buf,len,bos)if (bos(buf) != (size_t)-1 && len > bos(buf)) __chk_fail()__ssp_bos0(ptr)__builtin_object_size(ptr, 0)__ssp_bos(ptr)__builtin_object_size(ptr, __SSP_FORTIFY_LEVEL > 1)__ssp_inlineextern __inline__ __attribute__((__always_inline__, __gnu_inline__))__ssp_real(fun)__ssp_real_(fun)__ssp_real_ ## fun_SSP_SSP_H___SSP_FORTIFY_LEVEL == 0/* _SSP_SSP_H_ *//* __ssp_real is used by the implementation in libc *//*-
 * Copyright (c) 2006, 2011 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Christos Zoulas.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 *//*	$NetBSD: ssp.h,v 1.13 2015/09/03 20:43:47 plunky Exp $	*//home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/ssp<ssp/ssp.h>__strncat_ichkchar *__restrict__gnu_inlinestrncat__builtin___strncat_chk__strncpy_ichkstrncpy__builtin___strncpy_chk__strcat_ichkstrcat__builtin___strcat_chk__strcpy_ichkstrcpy__builtin___strcpy_chk__stpncpy_ichkstpncpy__builtin___stpncpy_chk__stpcpy_ichkstpcpy__builtin___stpcpy_chk__memset_ichk__mempcpy_ichkmempcpy__builtin___mempcpy_chk__memmove_ichkmemmove__builtin___memmove_chk__memcpy_ichk__strncpy_chk__strncat_chk__strcpy_chk__strcat_chk__stpcpy_chk__memset_chk__mempcpy_chk__memmove_chk__memcpy_chkstrncat(dst,src,len)__ssp_bos_check3(strncat, dst, src, len)strncpy(dst,src,len)__ssp_bos_check3(strncpy, dst, src, len)strcat(dst,src)__ssp_bos_check2(strcat, dst, src)strcpy(dst,src)__ssp_bos_check2(strcpy, dst, src)stpncpy(dst,src,len)__ssp_bos_check3(stpncpy, dst, src, len)stpcpy(dst,src)__ssp_bos_check2(stpcpy, dst, src)memset(dst,val,len)__ssp_bos_check3(memset, dst, val, len)memmove(dst,src,len)__ssp_bos_check3(memmove, dst, src, len)memcpy(dst,src,len)__ssp_bos_check3(memcpy, dst, src, len)__ssp_bos_icheck2_restrict(fun,type1,type2)__ssp_inline type1 __ ## fun ## _ichk(type1, type2); __ssp_inline type1 __ ## fun ## _ichk(type1 __restrict dst, type2 __restrict src) { return __builtin___ ## fun ## _chk(dst, src, __ssp_bos0(dst)); }__ssp_bos_icheck3(fun,type1,type2)__ssp_inline type1 __ ## fun ## _ichk(type1, type2, size_t); __ssp_inline type1 __ ## fun ## _ichk(type1 dst, type2 src, size_t len) { return __builtin___ ## fun ## _chk(dst, src, len, __ssp_bos0(dst)); }__ssp_bos_icheck3_restrict(fun,type1,type2)__ssp_inline type1 __ ## fun ## _ichk(type1 __restrict, type2 __restrict, size_t); __ssp_inline type1 __ ## fun ## _ichk(type1 __restrict dst, type2 __restrict src, size_t len) { return __builtin___ ## fun ## _chk(dst, src, len, __ssp_bos0(dst)); }__ssp_bos_check2(fun,dst,src)((__ssp_bos0(dst) != (size_t)-1) ? __builtin___ ## fun ## _chk(dst, src, __ssp_bos0(dst)) : __ ## fun ## _ichk(dst, src))__ssp_bos_check3(fun,dst,src,len)((__ssp_bos0(dst) != (size_t)-1) ? __builtin___ ## fun ## _chk(dst, src, len, __ssp_bos0(dst)) : __ ## fun ## _ichk(dst, src, len))_SSP_STRING_H___SSP_FORTIFY_LEVEL > 0__GNUC_PREREQ__(4,8) || defined(__clang__)/* _SSP_STRING_H_ *//* __SSP_FORTIFY_LEVEL > 0 *//*-
 * Copyright (c) 2006 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Christos Zoulas.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 *//*	$NetBSD: string.h,v 1.13 2014/11/29 13:23:48 pooka Exp $	*/<ssp/string.h><sys/string.h><sys/_locale.h>strsignalstrnlen_strerror_rstrerror_rstrndupstrdupfreememccpystrtok_rstrxfrm_lstrerror_lstrcoll_lstrxfrmstrtokstrstrstrspnstrrchrstrpbrkstrncmpstrlenstrerrorstrcspnstrcollstrcmpstrchrmemcmpmemchr_STRING_H__REENT_ONLY__MISC_VISIBLE || __POSIX_VISIBLE || __ZEPHYR_VISIBLE__MISC_VISIBLE || __POSIX_VISIBLE__MISC_VISIBLE || __POSIX_VISIBLE >= 200809 || __XSI_VISIBLE >= 4__ASMNAME__POSIX_VISIBLE >= 200809 || __ZEPHYR_VISIBLE__GNU_VISIBLE && defined(__GNUC__)__GNU_VISIBLE && !defined(basename)"__xpg_strerror_r"__USER_LABEL_PREFIX__/* _STRING_H_ *//* There are two common basename variants.  If you do NOT #include <libgen.h>
   and you do

     #define _GNU_SOURCE
     #include <string.h>

   you get the GNU version.  Otherwise you get the POSIX versionfor which you
   should #include <libgen.h>i for the function prototype.  POSIX requires that
   #undef basename will still let you invoke the underlying function.  However,
   this also implies that the POSIX version is used in this case.  That's made
   sure here. *//* __GNU_VISIBLE && __GNUC__ *//* Reentrant version of strerror.  *//* There are two common strerror_r variants.  If you request
   _GNU_SOURCE, you get the GNU version; otherwise you get the POSIX
   version.  POSIX requires that #undef strerror_r will still let you
   invoke the underlying function, but that requires gcc support.  *//*
 * string.h
 *
 * Definitions for memory and string functions.
 */__signowarn_unused_resultnothrow<kernel_arch_interface.h>z_handle_obj_poll_eventsz_mem_manage_boot_finishz_mem_manage_initz_stack_space_getz_early_rand_getz_thread_return_value_set_with_dataz_thread_essential_clearz_thread_essential_setz_thread_mallocz_thread_aligned_allocz_setup_new_threadz_thread_entryz_device_state_initz_cstartz_bss_zero_pinnedz_bss_zero_bootz_data_copyz_bss_zeroz_early_memcpyz_early_memsetz_init_thread_basez_thread_stack_element[2048]z_interrupt_stacksZ_KERNEL_STACK_SIZE_ADJUST(2048)(((((unsigned long)(2048) + ((unsigned long)(4UL) - 1)) / (unsigned long)(4UL)) * (unsigned long)(4UL)) + ((size_t)0))z_thread_stack_element[1][2048]z_idle_threadsz_main_threadz_thread_mark_switched_out()z_thread_mark_switched_in()z_thread_monitor_exit(thread)ZEPHYR_KERNEL_INCLUDE_KERNEL_INTERNAL_H_CONFIG_GEN_PRIV_STACKSCONFIG_INSTRUMENT_THREAD_SWITCHINGCONFIG_OBJ_CORE_STATS_THREADCONFIG_OBJ_CORE_STATS_SYSTEM/* ZEPHYR_KERNEL_INCLUDE_KERNEL_INTERNAL_H_ *//**
 * Increment the counter in the timing histogram.
 *
 * @param hist The timing histogram to be updated.
 * @param cycles Time spent in measured operation.
 *//**
 * Initialize the timing histograms for demand paging.
 *//**
 * Notify exit from kernel idling after PM operations
 *
 * This function would notify exit from kernel idling if a corresponding
 * pm_system_suspend() notification was handled and did not return
 * PM_STATE_ACTIVE.
 *
 * This function would be called from the ISR context of the event
 * that caused the exit from kernel idling. This will be called immediately
 * after interrupts are enabled. This is called to give a chance to do
 * any operations before the kernel would switch tasks or processes nested
 * interrupts. This is required for cpu low power states that would require
 * interrupts to be enabled while entering low power states. e.g. C1 in x86. In
 * those cases, the ISR would be invoked immediately after the event wakes up
 * the CPU, before code following the CPU wait, gets a chance to execute. This
 * can be ignored if no operation needs to be done at the wake event
 * notification.
 *//* When the kernel is about to go idle, it calls this function to notify the
 * power management subsystem, that the kernel is ready to enter the idle state.
 *
 * At this point, the kernel has disabled interrupts and computed the maximum
 * time the system can remain idle. The function passes the time that the system
 * can remain idle. The SOC interface performs power operations that can be done
 * in the available time. The power management operations must halt execution of
 * the CPU.
 *
 * This function assumes that a wake up event has already been set up by the
 * application.
 *
 * This function is entered with interrupts disabled. It should re-enable
 * interrupts if it had entered a power state.
 *
 * @return True if the system suspended, otherwise return false
 *//**
 * @brief Finalize page frame management at the end of boot process.
 *//* Init hook for page frame management, invoked immediately upon entry of
 * main thread, before POST_KERNEL tasks
 *//* CONFIG_INSTRUMENT_THREAD_SWITCHING *//* Should be called by the arch layer. This is the gdbstub main loop
 * and synchronously communicate with gdb on host.
 *//* This spinlock:
 *
 * - Protects the full set of active k_mem_domain objects and their contents
 * - Serializes calls to arch_mem_domain_* APIs
 *
 * If architecture code needs to access k_mem_domain structures or the
 * partitions they contain at any other point, this spinlock should be held.
 * Uniprocessor systems can get away with just locking interrupts but this is
 * not recommended.
 *//* Memory domain teardown hook, called from z_thread_abort() *//* Memory domain setup hook, called from z_setup_new_thread() *//* Calculate stack usage. *//* This is a arch function traditionally, but when the switch-based
 * z_swap() is in use it's a simple inline provided by the kernel.
 *//* CONFIG_THREAD_MONITOR *//* clean up when a thread is aborted *//* set and clear essential thread flag *//**
 * @brief Allocate some memory from the current thread's resource pool
 *
 * Threads may be assigned a resource pool, which will be used to allocate
 * memory on behalf of certain kernel and driver APIs. Memory reserved
 * in this way should be freed with k_free().
 *
 * If called from an ISR, the k_malloc() system heap will be used if it exists.
 *
 * @param size Memory allocation size
 * @return A pointer to the allocated memory, or NULL if there is insufficient
 * RAM in the pool or there is no pool to draw memory from
 *//**
 * @brief Allocate aligned memory from the current thread's resource pool
 *
 * Threads may be assigned a resource pool, which will be used to allocate
 * memory on behalf of certain kernel and driver APIs. Memory reserved
 * in this way should be freed with k_free().
 *
 * If called from an ISR, the k_malloc() system heap will be used if it exists.
 *
 * @param align Required memory alignment
 * @param size Memory allocation size
 * @return A pointer to the allocated memory, or NULL if there is insufficient
 * RAM in the pool or there is no pool to draw memory from
 *//* Do nothing *//* Early boot functions *//* Initialize a thread *//**
 * @file
 * @brief Architecture-independent private kernel APIs
 *
 * This file contains private kernel APIs that are not architecture-specific.
 *//*
 * Copyright (c) 2010-2012, 2014-2015 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */stack_startinitial_state/home/haojie/zephyrproject/zephyr/kernel/include/kernel_offsets.h"kernel_internal.h"<zephyr/pm/device.h>_OffsetAbsSymsoffsetof(_cpu_t, current)__builtin_offsetof (_cpu_t, current)_cpu_t *offsetof(_cpu_t, nested)__builtin_offsetof (_cpu_t, nested)offsetof(_cpu_t, irq_stack)__builtin_offsetof (_cpu_t, irq_stack)offsetof(_cpu_t, arch)__builtin_offsetof (_cpu_t, arch)offsetof(_kernel_t, cpus)__builtin_offsetof (_kernel_t, cpus)_kernel_t *z_kernel *offsetof(_kernel_t, ready_q)__builtin_offsetof (_kernel_t, ready_q)offsetof(_ready_q_t, cache)__builtin_offsetof (_ready_q_t, cache)_ready_q_t *_ready_q *offsetof(_thread_base_t, user_options)__builtin_offsetof (_thread_base_t, user_options)_thread_base_t *offsetof(_thread_t, base)__builtin_offsetof (_thread_t, base)_thread_t *offsetof(_thread_t, callee_saved)__builtin_offsetof (_thread_t, callee_saved)offsetof(_thread_t, arch)__builtin_offsetof (_thread_t, arch)offsetof(_thread_t, tls)__builtin_offsetof (_thread_t, tls)sizeof(z_interrupt_stacks[0])z_thread_stack_element(*)[2048]offsetof(struct pm_device, flags)__builtin_offsetof (struct pm_device, flags)pm_device *struct pm_device_PM_DEVICE_FLAG_PDoffsetof(_thread_arch_t, preempFloatReg)__builtin_offsetof (_thread_arch_t, preempFloatReg)_thread_arch_t *_thread_arch *sizeof(struct k_thread) - sizeof(tPreempFloatReg)offsetof(_callee_saved_t, esp)__builtin_offsetof (_callee_saved_t, esp)_callee_saved_t *_callee_saved *offsetof(z_arch_esf_t, eflags)__builtin_offsetof (z_arch_esf_t, eflags)offsetof(x86_boot_arg_t, boot_type)__builtin_offsetof (x86_boot_arg_t, boot_type)x86_boot_arg_t *x86_boot_arg *offsetof(x86_boot_arg_t, arg)__builtin_offsetof (x86_boot_arg_t, arg)offsetof(_thread_arch_t, flags)__builtin_offsetof (_thread_arch_t, flags)ZEPHYR_KERNEL_INCLUDE_KERNEL_OFFSETS_H_CONFIG_DEVICE_DEPS/* ZEPHYR_KERNEL_INCLUDE_KERNEL_OFFSETS_H_ *//* member offsets in the pm_device structure. Used in image post-processing *//* member offsets in the device structure. Used in image post-processing *//*
 * The final link step uses the symbol _OffsetAbsSyms to force the linkage of
 * offsets.o into the ELF image.
 *//* All of this is build time magic, but LCOV gets confused. Disable coverage
 * for this whole file.
 *
 * LCOV_EXCL_START
 *//home/haojie/zephyrproject/zephyr/arch/x86/core/offsets/ia32_offsets.c/home/haojie/zephyrproject/zephyr/arch/x86/core/offsets/offsets.c"ia32_offsets.c"<kernel_offsets.h><gen_offset.h>_X86_OFFSETS_INC_/* _X86_OFFSETS_INC_ *//* z_arch_esf_t structure member offsets *//**
 * size of the struct k_thread structure sans save area for floating
 * point regs
 *//* list of headers that define whose structure offsets will be generated *//**
 * @file
 * @brief Kernel structure member offset definition file
 *
 * This module is responsible for the generation of the absolute symbols whose
 * value represents the member offsets for various IA-32 structures.
 *
 * All of the absolute symbols defined by this module will be present in the
 * final kernel ELF image (due to the linker's reference to the _OffsetAbsSyms
 * symbol).
 *
 * INTERNAL
 * It is NOT necessary to define the offset for every member of a structure.
 * Typically, only those members that are accessed by assembly language routines
 * are defined; however, it doesn't hurt to define all fields for the sake of
 * completeness.
 *//home/haojie/zephyrproject/zephyr/arch/x86/core/offsets/home/haojie/zephyrproject/zephyr/include/zephyr/arch/x86/efi.hefi_boot_argacpi_rsdpefi_cr3efi_systabefi_get_acpi_rsdp(__VA_ARGS__...)efi_init(__VA_ARGS__...)EFI_BOOT_TYPEZEPHYR_ARCH_X86_INCLUDE_EFI_H_defined(CONFIG_X86_EFI)/* ZEPHYR_ARCH_X86_INCLUDE_EFI_H_ *//* CONFIG_X86_EFI *//** @brief Get the ACPI RSDP table pointer from EFI boot argument
 *
 * @return A valid pointer to ACPI RSDP table or NULL otherwise.
 *//** @brief Initialize usage of EFI gathered information
 *
 * @param efi_arg The given pointer to EFI prepared boot argument
 *//* EFI page table *//* EFI system table */z_x86_mmu_initz_x86_thread_page_tables_getpentry_t[]unsigned long long[]z_x86_cr2_getcr2z_x86_page_tables_getz_x86_cr3_getz_x86_cr3_set(phys & PTABLES_ALIGN) == 0U"unaligned page tables"z_x86_kernel_ptablesPTABLES_ALIGN0x1fUPF_SGXBIT(15)PF_PKPF_IDPF_RSVDPF_USPF_WRPF_PMMU_IGNORED2BITL(11)MMU_IGNORED1BITL(10)MMU_IGNORED0BITL(9)MMU_XDBITL(63)MMU_GBITL(8)MMU_PATBITL(7)MMU_PSMMU_DBITL(6)MMU_ABITL(5)MMU_PCDBITL(4)MMU_PWTBITL(3)MMU_USBITL(2)MMU_RWBITL(1)MMU_PBITL(0)PRI_ENTRY"0x%016llx"BITLBIT64XD_SUPPORTEDZEPHYR_ARCH_X86_INCLUDE_X86_MMU_Hdefined(CONFIG_USERSPACE) && !defined(CONFIG_X86_COMMON_PAGE_TABLE)/* ZEPHYR_ARCH_X86_INCLUDE_X86_MMU_H *//* Early-boot paging setup tasks, called from prep_c *//* Handling function for TLB shootdown inter-processor interrupts. *//* If KPTI is enabled, supervisor threads always use
		 * the kernel's page tables and not the page tables associated
		 * with their memory domain.
		 *//* Get the page tables used by this thread during normal execution *//* Kernel's page table. This is in CR3 for all supervisor threads.
 * if KPTI is enabled, we switch to this when handling exceptions or syscalls
 *//* Return cr2 value, which contains the page fault linear address.
 * See Section 6.15 of the IA32 Software Developer's Manual vol 3.
 * Used by page fault handling code.
 *//* Return the virtual address of the page tables installed in this CPU in CR3 *//* Return cr3 value, which is the physical (not virtual) address of the
 * current set of page tables
 *//* Set CR3 to a physical address. There must be a valid top-level paging
 * structure here or the CPU will triple fault. The incoming page tables must
 * have the same kernel mappings wrt supervisor mode. Don't use this function
 * unless you know exactly what you are doing.
 *//* Called from page fault handler. ptables here is the ptage tables for the
 * faulting user thread and not the current set of page tables
 *//* Defined in linker script. Contains all the data that must be mapped
 * in a KPTI table even though US bit is not set (trampoline stack, GDT,
 * IDT, etc)
 *//* Legacy function - set identity-mapped MMU stack guard page to RO in the
 * kernel's page tables to prevent writes and generate an exception
 *//**
 * Debug function for dumping out page tables
 *
 * Iterates through the entire linked set of page table structures,
 * dumping out codes for the configuration of each table entry.
 *
 * Entry codes:
 *
 *   . - not present
 *   w - present, writable, not executable
 *   a - present, writable, executable
 *   r - present, read-only, not executable
 *   x - present, read-only, executable
 *
 * Entry codes in uppercase indicate that user mode may access.
 *
 * Color is used to indicate the physical mapping characteristics:
 *
 *   yellow - Identity mapping (virt = phys)
 *    green - Fixed virtual memory mapping (virt = phys + constant)
 *  magenta - entry is child page table
 *     cyan - General mapped memory
 *
 * @param ptables Top-level pointer to the page tables, as programmed in CR3
 *//**
 * Fetch the page table entry for a virtual memory address
 *
 * @param paging_level [out] what paging level the entry was found at.
 *                     0=toplevel
 * @param val Value stored in page table entry, with address and flags
 * @param ptables Toplevel pointer to page tables
 * @param virt Virtual address to lookup
 *//**
 * Dump out page table entries for a particular virtual memory address
 *
 * For the provided memory address, dump out interesting information about
 * its mapping to the error log
 *
 * @param ptables Page tables to walk
 * @param virt Virtual address to inspect
 *//* 1 SGX-specific access control requirements *//* 1 protection-key violation *//* 1 instruction fetch *//* 1 reserved bit set *//* 0 Supervisor mode   1 User mode *//* 0 Read              1 Write *//* 0 Non-present page  1 Protection violation *//* Page fault error code flags. See Chapter 4.7 of the Intel SDM vol. 3A. *//* Unused PTE bits ignored by the CPU, which we use for our own OS purposes.
 * These bits ignored for all paging modes.
 *//** Global *//** Page Attribute (PTE) *//** Page Size (non PTE)*//** Dirty *//** Accessed *//** Page Cache Disable *//** Page Write Through *//** Present *//*
 * Common flags in the same bit position regardless of which structure level,
 * although not every flag is supported at every level, and some may be
 * ignored depending on the state of other bits (such as P or PS)
 *
 * These flags indicate bit position, and can be used for setting flags or
 * masks as needed.
 *//*
 * Copyright (c) 2011-2014 Wind River Systems, Inc.
 * Copyright (c) 2017-2020 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *
 * Internal memory management interfaces implemented in x86_mmu.c.
 * None of these are application-facing, use only if you know what you are
 * doing!
 *//home/haojie/zephyrproject/zephyr/arch/x86/core/prep_c.c<zephyr/arch/x86/efi.h>cpu_argCONFIG_X86_EFI_XXXXCONFIG_X86_EFI_XXXXCONFIG_X86_EFI 1(struct efi_boot_arg *)cpu_arg->argx86_64_irq_initx86_cpu_boot_arg!defined(CONFIG_X86_64)defined(CONFIG_LOAPIC)defined(CONFIG_SMP)/*
	 * Under QEMU and SeaBIOS, everything gets to be printed
	 * immediately after "Booting from ROM.." as there is no newline.
	 * This prevents parsing QEMU console output for the very first
	 * line where it needs to match from the beginning of the line.
	 * So add a dummy newline here so the next output is at
	 * the beginning of a line.
	 *//* Early global initialization functions, C domain. This runs only on the first
 * CPU for SMP systems.
 */CPUID_SPEC_CTRL_IBRSBIT(26)CPUID_SPEC_CTRL_SSBD0x1F0x0B0x07ZEPHYR_INCLUDE_ARCH_X86_CPUID_H_/* ZEPHYR_INCLUDE_ARCH_X86_CPUID_H_ *//* Bits to check in CPUID extended features *//*
 * Copyright (c) 2022 Intel Corp.
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/arch/x86/core/spec_ctrl.cdefined(CONFIG_DISABLE_SSBD) || defined(CONFIG_ENABLE_EXTENDED_IBRS)CONFIG_DISABLE_SSBDCONFIG_ENABLE_EXTENDED_IBRS/* CONFIG_DISABLE_SSBD || CONFIG_ENABLE_EXTENDED_IBRS *//*
 * See:
 * https://software.intel.com/security-software-guidance/api-app/sites/default/files/336996-Speculative-Execution-Side-Channel-Mitigations.pdf
 *//home/haojie/zephyrproject/zephyr/kernel/include/kernel_tls.hz_tls_copytdata_sizetbss_sizedestz_tls_data_sizeZEPHYR_KERNEL_INCLUDE_KERNEL_TLS_H_/* ZEPHYR_KERNEL_INCLUDE_KERNEL_TLS_H_ *//* Clear BSS data (tbss) *//* Copy initialized data (tdata) *//**
 * @brief Copy the TLS data/bss areas into destination
 *
 * This copies the TLS data into destination and clear the area
 * of TLS bss size after the data section.
 *
 * @param dest Pointer to destination
 *//**
 * @brief Return the total size of TLS data/bss areas
 *
 * This returns the total size of thread local storage (TLS)
 * data and bss areas as defined in the linker script.
 * Note that this does not include any architecture specific
 * bits required for proper functionality of TLS.
 *
 * @return Total size of TLS data/bss areas
 *//**
 * @file
 * @brief Kernel Thread Local Storage APIs.
 *
 * Kernel APIs related to thread local storage.
 *//home/haojie/zephyrproject/zephyr/arch/x86/core/tls.c<kernel_tls.h>/* Setup the TLS data *//*
	 * Set thread TLS pointer as this is used to populate
	 * FS/GS at context switch.
	 *//*
	 * TLS area for x86 and x86_64 has the data/bss first,
	 * then a pointer pointing to itself. The address to
	 * this pointer needs to be stored in register GS (x86)
	 * or FS (x86_64). GCC generates code which reads this
	 * pointer and offsets from this pointer are used to
	 * access data.
	 *//home/haojie/zephyrproject/zephyr/include/zephyr/sys/check.h/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/ctype.h/home/haojie/zephyrproject/zephyr/arch/x86/core/x86_mmu.c<ctype.h><zephyr/sys/check.h>ptelevelPOINTER_TO_UINT(virt) % CONFIG_MMU_PAGE_SIZE == 0U"unaligned address %p to %s"virt, __func__paging_levels!__builtin_types_compatible_p(__typeof__(paging_levels), __typeof__(&(paging_levels)[0]))char[1]const paging_levelconst paging_level[3]paging_level[3]const paging_level *paging_level *PTE_LEVEL-14-EFAULTMB(1)mark_addr_page_reservedaddr + lenret == 018446744073709551615MASK_ALLflags_to_entryentry_flags"bad memory mapping flags 0x%x"ENTRY_RWENTRY_US92233720368547758089223372036854777856ENTRY_XDrange_map_unlockedrange_mapret2"%s: %p -> %p (%zu) flags " PRI_ENTRY " mask " PRI_ENTRY " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, optionsLOG_LEVEL_DBG"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"__func__, (void *)phys, virt, size, entry_flags, mask, optionsUTIL_CAT(Z_LOG_FUNC_PREFIX_, 4U)Z_LOG_STR(4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)CONFIG_LOG_FUNC_NAME_PREFIX_DBG_XXXXCONFIG_LOG_FUNC_NAME_PREFIX_DBG_XXXXCONFIG_LOG_FUNC_NAME_PREFIX_DBG (1)UTIL_CAT(Z_LOG_FUNC_PREFIX_4U)(Z_LOG_STR_WITH_PREFIX("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))("%s: " "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (const char *)__func__ , __func__, (void *)phys, virt, size, entry_flags, mask, options)("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)Z_LOG_FUNC_PREFIX_4UNUM_VA_ARGS_LESS_1(_,"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)(Z_LOG_STR_WITH_PREFIX2("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))_,"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options__func__(void *)phys7, 6, 5, 4, 3, 2, 1, 0, ~NUM_VA_ARGS_LESS_1("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)(, GET_ARGS_LESS_N(1, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))(, __func__, (void *)phys, virt, size, entry_flags, mask, options)6, 5, 4, 3, 2, 1, 0, ~_ZZZZ7_ZZZZ7 (), __func__, (void *)phys, virt, size, entry_flags, mask, options_ZZZZ8_ZZZZ8 ("%s", (const char *)__func__)"%s: " "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (const char *)__func__ , __func__, (void *)phys, virt, size, entry_flags, mask, options_XXXX0 ("%s: " "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (const char *)__func__ , __func__, (void *)phys, virt, size, entry_flags, mask, options)REVERSE_ARGS("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)options , mask , entry_flags , size , virt , (void *)phys , __func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"Z_FOR_LOOP_7, Z_FOR_LOOP_6, Z_FOR_LOOP_5, Z_FOR_LOOP_4, Z_FOR_LOOP_3, Z_FOR_LOOP_2, Z_FOR_LOOP_1, Z_FOR_LOOP_0(void *)phys, virt, size, entry_flags, mask, optionsvirt, size, entry_flags, mask, optionssize, entry_flags, mask, optionsentry_flags, mask, optionsmask, optionsmask , entry_flags , size , virt , (void *)phys , __func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"entry_flags , size , virt , (void *)phys , __func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"size , virt , (void *)phys , __func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"virt , (void *)phys , __func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"(void *)phys , __func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"__func__ , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") = ("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0)(__auto_type "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" = ("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0)("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, __func__) = (__func__) + 0)(__auto_type _v1 = (__func__) + 0)(__func__)_ZZZZ1 (__func__)__auto_type _v1 = (__func__) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, (void *)phys) = ((void *)phys) + 0)(__auto_type _v2 = ((void *)phys) + 0)((void *)phys)(_v2)_ZZZZ2 ((void *)phys)_v2_ZZZZ2 ()__auto_type _v2 = ((void *)phys) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, virt) = (virt) + 0)(__auto_type _v3 = (virt) + 0)(virt)(_v3)_ZZZZ3_ZZZZ3 (virt)_v3_ZZZZ3 ()__auto_type _v3 = (virt) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(4, size) = (size) + 0)(__auto_type _v4 = (size) + 0)(size)(_v4)_ZZZZ4_ZZZZ4 (size)_v4_ZZZZ4 ()__auto_type _v4 = (size) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(5, entry_flags) = (entry_flags) + 0)(__auto_type _v5 = (entry_flags) + 0)(entry_flags)(_v5)_ZZZZ5_ZZZZ5 (entry_flags)_v5_ZZZZ5 ()__auto_type _v5 = (entry_flags) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(6, mask) = (mask) + 0)(__auto_type _v6 = (mask) + 0)(mask)(_v6)_ZZZZ6_ZZZZ6 (mask)_v6_ZZZZ6 ()__auto_type _v6 = (mask) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(7, options) = (options) + 0)(__auto_type _v7 = (options) + 0)(options)(_v7)_ZZZZ7 (options)_v7__auto_type _v7 = (options) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)_,"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7_v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7_ZZZZ8 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x";)NUM_VA_ARGS_LESS_1("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (6 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v7) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS(_v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)_v7 , _v6 , _v5 , _v4 , _v3 , _v2 , _v1Z_FOR_LOOP_6, Z_FOR_LOOP_5, Z_FOR_LOOP_4, Z_FOR_LOOP_3, Z_FOR_LOOP_2, Z_FOR_LOOP_1, Z_FOR_LOOP_0_v2 , _v3 , _v4 , _v5 , _v6 , _v7_v3 , _v4 , _v5 , _v6 , _v7_v4 , _v5 , _v6 , _v7_v5 , _v6 , _v7_v6 , _v7_v6 , _v5 , _v4 , _v3 , _v2 , _v1_v5 , _v4 , _v3 , _v2 , _v1_v4 , _v3 , _v2 , _v1_v3 , _v2 , _v1_v2 , _v1+_ZZZZ7 (0)((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (6 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v7) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))( bool can_simple = LOG_MSG_SIMPLE_CHECK("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = 0; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; ; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)), (0)))( 0)LOG_MSG_SIMPLE_ARG_CNT_CHECK("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_7("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))_LOG_MSG_SIMPLE_XXXX7_XXXX_LOG_MSG_SIMPLE_XXXX7_XXXX_LOG_MSG_SIMPLE_XXXX7 (1)_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_7("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", __func__, (void *)phys, virt, size, entry_flags, mask, options)))("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)(COND_CODE_0(NUM_VA_ARGS_LESS_1("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))))(_fmt, _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)(_fmt, GET_ARGS_LESS_N(1, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))_ZZZZ7 (_fmt)_fmt, _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7_XXXXCONFIG_LOG_FMT_SECTION (_fmt, _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)_ZZZZ8 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7); )( z_log_msg_simple_create_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)))(z_log_msg_simple_create_0(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"))(COND_CODE_1(7, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy) )( z_log_msg_simple_create_1(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy_v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy_v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy"%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy, dummy_v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy, dummy_v2 , _v3 , _v4 , _v5 , _v6 , _v7, dummy, dummy_v3 , _v4 , _v5 , _v6 , _v7, dummy, dummy_XXXX7_XXXX7 ( z_log_msg_simple_create_1(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ7 (z_log_msg_simple_create_0(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )_XXXX0 ( _Bool can_simple = 0; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; ; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (6 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v7) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (6 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v7) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (6 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v7) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (6 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v7) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))REVERSE_ARGS("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6 , _v7)_v7 , _v6 , _v5 , _v4 , _v3 , _v2 , _v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"_v6 , _v5 , _v4 , _v3 , _v2 , _v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"_v5 , _v4 , _v3 , _v2 , _v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"_v4 , _v3 , _v2 , _v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"_v3 , _v2 , _v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"_v2 , _v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"_v1 , "%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0, long double : 1, default : 0) && !0)_Generic(("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0))_Generic(("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("%s: %p -> %p (%zu) flags " "0x%016llx" " mask " "0x%016llx" " opt 0x%x") + 0))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_v2) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((_v2) + 0, long double : 1, default : 0) && !0)_Generic((_v2) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_v2) + 0))_Generic((_v2) + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((_v2) + 0))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_v3) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((_v3) + 0, long double : 1, default : 0) && !0)_Generic((_v3) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_v3) + 0))_Generic((_v3) + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((_v3) + 0))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_v4) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((_v4) + 0, long double : 1, default : 0) && !0)_Generic((_v4) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_v4) + 0))_Generic((_v4) + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((_v4) + 0))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_v5) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((_v5) + 0, long double : 1, default : 0) && !0)_Generic((_v5) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_v5) + 0))_Generic((_v5) + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((_v5) + 0))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_v6) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((_v6) + 0, long double : 1, default : 0) && !0)_Generic((_v6) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_v6) + 0))_Generic((_v6) + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((_v6) + 0))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_v7) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((_v7) + 0, long double : 1, default : 0) && !0)_Generic((_v7) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_v7) + 0))_Generic((_v7) + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((_v7) + 0))%c: %s: %p -> %p (%zu) flags 0x%016llx mask 0x%016llx opt 0x%x
char[64]const char[10]char[10]fallthrough%s: %p -> %p (%zu) flags 0x%016llx mask 0x%016llx opt 0x%xchar[59]const char **"invalid option for mapping"Z_LOG_STR(1U, "invalid option for mapping")(Z_LOG_STR_WITH_PREFIX("invalid option for mapping"))("%s: " "invalid option for mapping", (const char *)__func__)("invalid option for mapping")NUM_VA_ARGS_LESS_1(_,"invalid option for mapping")(Z_LOG_STR_WITH_PREFIX2("invalid option for mapping"))("%s: " "invalid option for mapping", (const char *)__func__ )_,"invalid option for mapping"NUM_VA_ARGS_LESS_1("invalid option for mapping")(, GET_ARGS_LESS_N(1, "invalid option for mapping"))(, )_ZZZZ1 ("%s", (const char *)__func__)"%s: " "invalid option for mapping", (const char *)__func___XXXX0 ("%s: " "invalid option for mapping", (const char *)__func__)REVERSE_ARGS("invalid option for mapping")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "invalid option for mapping") = ("invalid option for mapping") + 0)(__auto_type "invalid option for mapping" = ("invalid option for mapping") + 0)FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping")(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping")))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "invalid option for mapping";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping"))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "invalid option for mapping");)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping")_ZZZZ1 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "invalid option for mapping";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "invalid option for mapping";)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "invalid option for mapping"))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic(() + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS()0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping"))( bool can_simple = LOG_MSG_SIMPLE_CHECK("invalid option for mapping"); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping"))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = 1; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_0(_src, 1U, "invalid option for mapping");; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("invalid option for mapping"), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("invalid option for mapping")), (0)))( 1)LOG_MSG_SIMPLE_ARG_CNT_CHECK("invalid option for mapping")( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("invalid option for mapping"))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("invalid option for mapping"))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping"))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "invalid option for mapping")))(COND_CODE_0(NUM_VA_ARGS_LESS_1("invalid option for mapping"), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "invalid option for mapping"))))(_fmt, GET_ARGS_LESS_N(1, "invalid option for mapping"))(_fmt, )_XXXXCONFIG_LOG_FMT_SECTION (_fmt)_ZZZZ1 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "invalid option for mapping"); )( z_log_msg_simple_create_0(_src, 1U, "invalid option for mapping"); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "invalid option for mapping")))(z_log_msg_simple_create_0(_src, 1U, "invalid option for mapping"))(COND_CODE_1(0, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "invalid option for mapping", dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "invalid option for mapping", dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, "invalid option for mapping", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "invalid option for mapping", dummy) )( z_log_msg_simple_create_1(_src, 1U, "invalid option for mapping", (uint32_t)(uintptr_t)dummy) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "invalid option for mapping", dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "invalid option for mapping", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy) )"invalid option for mapping", dummy"invalid option for mapping", dummy, dummy_XXXX0 ( z_log_msg_simple_create_1(_src, 1U, "invalid option for mapping", (uint32_t)(uintptr_t)dummy) )z_log_msg_simple_create_2(_src, 1U, "invalid option for mapping", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy)z_log_msg_simple_create_0(_src, 1U, "invalid option for mapping")z_log_msg_simple_create_0(_src, 1U, "invalid option for mapping");_XXXX0 ( _Bool can_simple = 1; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_0(_src, 1U, "invalid option for mapping");; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "invalid option for mapping"))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic(() + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "invalid option for mapping"))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic(() + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("invalid option for mapping") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("invalid option for mapping") + 0, long double : 1, default : 0) && !0)_Generic(("invalid option for mapping") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("invalid option for mapping") + 0))_Generic(("invalid option for mapping") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("invalid option for mapping") + 0))!((options & OPTION_USER) == 0U)!((options & (1UL << (0))) == 0U)%c: invalid option for mapping
char[32]invalid option for mappingchar[27]-EINVALret2 != 0outrange_map_ptableszero_entry(OPTION_RESET | OPTION_CLEAR)!is_addr_aligned(phys) || !is_size_aligned(size)"entry_flags " PRI_ENTRY " overlaps address area", entry_flags"entry_flags " "0x%016llx" " overlaps address area", entry_flags"entry_flags " "0x%016llx" " overlaps address area"Z_LOG_STR(1U, "entry_flags " "0x%016llx" " overlaps address area", entry_flags)(Z_LOG_STR_WITH_PREFIX("entry_flags " "0x%016llx" " overlaps address area", entry_flags))("%s: " "entry_flags " "0x%016llx" " overlaps address area", (const char *)__func__ , entry_flags)("entry_flags " "0x%016llx" " overlaps address area", entry_flags)NUM_VA_ARGS_LESS_1(_,"entry_flags " "0x%016llx" " overlaps address area", entry_flags)(Z_LOG_STR_WITH_PREFIX2("entry_flags " "0x%016llx" " overlaps address area", entry_flags))_,"entry_flags " "0x%016llx" " overlaps address area", entry_flagsNUM_VA_ARGS_LESS_1("entry_flags " "0x%016llx" " overlaps address area", entry_flags)(, GET_ARGS_LESS_N(1, "entry_flags " "0x%016llx" " overlaps address area", entry_flags))(, entry_flags), entry_flags"%s: " "entry_flags " "0x%016llx" " overlaps address area", (const char *)__func__ , entry_flags_XXXX0 ("%s: " "entry_flags " "0x%016llx" " overlaps address area", (const char *)__func__ , entry_flags)REVERSE_ARGS("entry_flags " "0x%016llx" " overlaps address area", entry_flags)entry_flags , "entry_flags " "0x%016llx" " overlaps address area"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "entry_flags " "0x%016llx" " overlaps address area") = ("entry_flags " "0x%016llx" " overlaps address area") + 0)(__auto_type "entry_flags " "0x%016llx" " overlaps address area" = ("entry_flags " "0x%016llx" " overlaps address area") + 0)("entry_flags " "0x%016llx" " overlaps address area")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, entry_flags) = (entry_flags) + 0)(__auto_type _v1 = (entry_flags) + 0)_ZZZZ1 (entry_flags)__auto_type _v1 = (entry_flags) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags)"entry_flags " "0x%016llx" " overlaps address area" , _v1(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "entry_flags " "0x%016llx" " overlaps address area";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "entry_flags " "0x%016llx" " overlaps address area" , _v1);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags)_,"entry_flags " "0x%016llx" " overlaps address area" , _v1static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "entry_flags " "0x%016llx" " overlaps address area";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "entry_flags " "0x%016llx" " overlaps address area";)NUM_VA_ARGS_LESS_1("entry_flags " "0x%016llx" " overlaps address area" , _v1)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "entry_flags " "0x%016llx" " overlaps address area" , _v1))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags))( bool can_simple = LOG_MSG_SIMPLE_CHECK("entry_flags " "0x%016llx" " overlaps address area" , _v1); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("entry_flags " "0x%016llx" " overlaps address area" , _v1), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("entry_flags " "0x%016llx" " overlaps address area" , _v1)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("entry_flags " "0x%016llx" " overlaps address area" , _v1)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("entry_flags " "0x%016llx" " overlaps address area" , _v1))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("entry_flags " "0x%016llx" " overlaps address area" , _v1))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "entry_flags " "0x%016llx" " overlaps address area", entry_flags)))("entry_flags " "0x%016llx" " overlaps address area" , _v1)(COND_CODE_0(NUM_VA_ARGS_LESS_1("entry_flags " "0x%016llx" " overlaps address area" , _v1), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "entry_flags " "0x%016llx" " overlaps address area" , _v1))))(_fmt, GET_ARGS_LESS_N(1, "entry_flags " "0x%016llx" " overlaps address area" , _v1))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area" , _v1); )( z_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "entry_flags " "0x%016llx" " overlaps address area" , _v1)))(z_log_msg_simple_create_0(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area"))(COND_CODE_1(1, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area" , _v1, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area" , _v1, dummy, dummy) ) ))(z_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area" , _v1, dummy) )( z_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area" , _v1, dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)dummy) )"entry_flags " "0x%016llx" " overlaps address area" , _v1, dummy"entry_flags " "0x%016llx" " overlaps address area" , _v1, dummy, dummyz_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1)_ZZZZ1 (z_log_msg_simple_create_0(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area"))z_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 1U, "entry_flags " "0x%016llx" " overlaps address area", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "entry_flags " "0x%016llx" " overlaps address area" , _v1))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "entry_flags " "0x%016llx" " overlaps address area" , _v1))REVERSE_ARGS("entry_flags " "0x%016llx" " overlaps address area" , _v1)_v1 , "entry_flags " "0x%016llx" " overlaps address area"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("entry_flags " "0x%016llx" " overlaps address area") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("entry_flags " "0x%016llx" " overlaps address area") + 0, long double : 1, default : 0) && !0)_Generic(("entry_flags " "0x%016llx" " overlaps address area") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("entry_flags " "0x%016llx" " overlaps address area") + 0))_Generic(("entry_flags " "0x%016llx" " overlaps address area") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("entry_flags " "0x%016llx" " overlaps address area") + 0))!((entry_flags & paging_levels[0].mask) == 0U)%c: entry_flags 0x%016llx overlaps address area
entry_flags 0x%016llx overlaps address areachar[44]dest_virtentry_valpage_map_settable!((*entryp & MMU_PS) == 0U)!((*entryp & (1ULL << (7))) == 0U)"large page encountered"Z_LOG_STR(1U, "large page encountered")(Z_LOG_STR_WITH_PREFIX("large page encountered"))("%s: " "large page encountered", (const char *)__func__)("large page encountered")NUM_VA_ARGS_LESS_1(_,"large page encountered")(Z_LOG_STR_WITH_PREFIX2("large page encountered"))("%s: " "large page encountered", (const char *)__func__ )_,"large page encountered"NUM_VA_ARGS_LESS_1("large page encountered")(, GET_ARGS_LESS_N(1, "large page encountered"))"%s: " "large page encountered", (const char *)__func___XXXX0 ("%s: " "large page encountered", (const char *)__func__)REVERSE_ARGS("large page encountered")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "large page encountered") = ("large page encountered") + 0)(__auto_type "large page encountered" = ("large page encountered") + 0)FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered")(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered")))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "large page encountered";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered"))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "large page encountered");)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered")static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "large page encountered";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "large page encountered";)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "large page encountered"))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered"))( bool can_simple = LOG_MSG_SIMPLE_CHECK("large page encountered"); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered"))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = 1; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_0(_src, 1U, "large page encountered");; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("large page encountered"), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("large page encountered")), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("large page encountered")( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("large page encountered"))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("large page encountered"))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered"))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "large page encountered")))(COND_CODE_0(NUM_VA_ARGS_LESS_1("large page encountered"), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "large page encountered"))))(_fmt, GET_ARGS_LESS_N(1, "large page encountered"))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "large page encountered"); )( z_log_msg_simple_create_0(_src, 1U, "large page encountered"); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "large page encountered")))(z_log_msg_simple_create_0(_src, 1U, "large page encountered"))(COND_CODE_1(0, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "large page encountered", dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "large page encountered", dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, "large page encountered", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "large page encountered", dummy) )( z_log_msg_simple_create_1(_src, 1U, "large page encountered", (uint32_t)(uintptr_t)dummy) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "large page encountered", dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "large page encountered", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy) )"large page encountered", dummy"large page encountered", dummy, dummy_XXXX0 ( z_log_msg_simple_create_1(_src, 1U, "large page encountered", (uint32_t)(uintptr_t)dummy) )z_log_msg_simple_create_2(_src, 1U, "large page encountered", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy)z_log_msg_simple_create_0(_src, 1U, "large page encountered")z_log_msg_simple_create_0(_src, 1U, "large page encountered");_XXXX0 ( _Bool can_simple = 1; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_0(_src, 1U, "large page encountered");; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "large page encountered"))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "large page encountered"))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("large page encountered") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("large page encountered") + 0, long double : 1, default : 0) && !0)_Generic(("large page encountered") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("large page encountered") + 0))_Generic(("large page encountered") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("large page encountered") + 0))!(table != NULL)!(table != ((void *)0))"missing page table level %d when trying to map %p", level + 1, virt"missing page table level %d when trying to map %p"level + 1, virtZ_LOG_STR(1U, "missing page table level %d when trying to map %p", level + 1, virt)(Z_LOG_STR_WITH_PREFIX("missing page table level %d when trying to map %p", level + 1, virt))("%s: " "missing page table level %d when trying to map %p", (const char *)__func__ , level + 1, virt)("missing page table level %d when trying to map %p", level + 1, virt)NUM_VA_ARGS_LESS_1(_,"missing page table level %d when trying to map %p", level + 1, virt)(Z_LOG_STR_WITH_PREFIX2("missing page table level %d when trying to map %p", level + 1, virt))_,"missing page table level %d when trying to map %p", level + 1, virtlevel + 12, 1, 0, ~NUM_VA_ARGS_LESS_1("missing page table level %d when trying to map %p", level + 1, virt)(, GET_ARGS_LESS_N(1, "missing page table level %d when trying to map %p", level + 1, virt))(, level + 1, virt), level + 1, virt_ZZZZ3 ("%s", (const char *)__func__)"%s: " "missing page table level %d when trying to map %p", (const char *)__func__ , level + 1, virt_XXXX0 ("%s: " "missing page table level %d when trying to map %p", (const char *)__func__ , level + 1, virt)REVERSE_ARGS("missing page table level %d when trying to map %p", level + 1, virt)virt , level + 1 , "missing page table level %d when trying to map %p"Z_FOR_LOOP_2, Z_FOR_LOOP_1, Z_FOR_LOOP_0level + 1 , "missing page table level %d when trying to map %p"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "missing page table level %d when trying to map %p") = ("missing page table level %d when trying to map %p") + 0)(__auto_type "missing page table level %d when trying to map %p" = ("missing page table level %d when trying to map %p") + 0)("missing page table level %d when trying to map %p")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, level + 1) = (level + 1) + 0)(__auto_type _v1 = (level + 1) + 0)(level + 1)_ZZZZ1 (level + 1)__auto_type _v1 = (level + 1) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, virt) = (virt) + 0)(__auto_type _v2 = (virt) + 0)_ZZZZ2 (virt)__auto_type _v2 = (virt) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt)"missing page table level %d when trying to map %p" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "missing page table level %d when trying to map %p";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "missing page table level %d when trying to map %p" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt)_,"missing page table level %d when trying to map %p" , _v1 , _v2_v1 , _v2_ZZZZ3 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "missing page table level %d when trying to map %p";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "missing page table level %d when trying to map %p";)NUM_VA_ARGS_LESS_1("missing page table level %d when trying to map %p" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "missing page table level %d when trying to map %p" , _v1 , _v2))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS(_v1 , _v2)_ZZZZ2 (0)((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt))( bool can_simple = LOG_MSG_SIMPLE_CHECK("missing page table level %d when trying to map %p" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("missing page table level %d when trying to map %p" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("missing page table level %d when trying to map %p" , _v1 , _v2)), (0)))( _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0))LOG_MSG_SIMPLE_ARG_CNT_CHECK("missing page table level %d when trying to map %p" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("missing page table level %d when trying to map %p" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("missing page table level %d when trying to map %p" , _v1 , _v2))_Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0)Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "missing page table level %d when trying to map %p", level + 1, virt)))("missing page table level %d when trying to map %p" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("missing page table level %d when trying to map %p" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "missing page table level %d when trying to map %p" , _v1 , _v2))))(_fmt, _v1 , _v2)(_fmt, GET_ARGS_LESS_N(1, "missing page table level %d when trying to map %p" , _v1 , _v2))_ZZZZ2 (_fmt)_fmt, _v1 , _v2_XXXXCONFIG_LOG_FMT_SECTION (_fmt, _v1 , _v2)_ZZZZ3 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "missing page table level %d when trying to map %p" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "missing page table level %d when trying to map %p" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 1U, "missing page table level %d when trying to map %p"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "missing page table level %d when trying to map %p" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "missing page table level %d when trying to map %p" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "missing page table level %d when trying to map %p" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "missing page table level %d when trying to map %p" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"missing page table level %d when trying to map %p" , _v1 , _v2, dummy_v1 , _v2, dummy_v2, dummy"missing page table level %d when trying to map %p" , _v1 , _v2, dummy, dummy_v1 , _v2, dummy, dummy_v2, dummy, dummy_XXXX2_XXXX2 ( z_log_msg_simple_create_1(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 1U, "missing page table level %d when trying to map %p"))z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 1U, "missing page table level %d when trying to map %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "missing page table level %d when trying to map %p" , _v1 , _v2))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "missing page table level %d when trying to map %p" , _v1 , _v2))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))REVERSE_ARGS("missing page table level %d when trying to map %p" , _v1 , _v2)_v2 , _v1 , "missing page table level %d when trying to map %p"_v1 , "missing page table level %d when trying to map %p"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("missing page table level %d when trying to map %p") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("missing page table level %d when trying to map %p") + 0, long double : 1, default : 0) && !0)_Generic(("missing page table level %d when trying to map %p") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("missing page table level %d when trying to map %p") + 0))_Generic(("missing page table level %d when trying to map %p") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("missing page table level %d when trying to map %p") + 0))old_val_ptrentrypold_val%c: large page encountered
char[28]large page encounteredchar[23]%c: missing page table level %d when trying to map %p
char[55]missing page table level %d when trying to map %pchar[50]pte_atomic_updateuser_tableclearnew_valconst pentry_tconst pentry_t *atomic_pte_casatomic_pte_getpte_finalize_valuereset_pte92233720368547758149223372036854775801~K_MEM_PARTITION_PERM_MASK(~K_MEM_PARTITION_PERM_MASK)is_region_page_alignedassert_region_page_alignedis_size_aligned(CONFIG_MMU_PAGE_SIZE - 1)assert_size_alignedis_virt_addr_alignedassert_virt_addr_alignedis_addr_alignedassert_addr_alignedtlb_flush_pagepentry_getis_leafget_table_scopeget_entry_scope1ULtable_sizesizeof(pentry_t)get_num_entriesnext_tableget_entry_physget_entryget_entry_ptrget_indexpaging_levelchar[20512]8388608update_valupdate_maskVM_ADDR + VM_SIZE0x0 + 0x800000PT_AREA((uintptr_t)(0x1000 * 512U))209715110485759VM_ADDRPD_AREA(((uintptr_t)(0x1000 * 512U)) * 512U)1073741824107374182310821304312048020512INITIAL_PTABLE_SIZEdummy_pagetables.dummy_pagetableschar[18]const paging_level[]paging_level[]92233720368547717120x7FFFFFFFFFFFF000ULL30U512U21U5764607523034193920x07FFFFFFFFFFF000ULLx86_mmu_lock!IS_ENABLED(CONFIG_SMP)!0_XXXXCONFIG_SMPOPTION_CLEAROPTION_RESETOPTION_FLUSHOPTION_USER((INITIAL_PTABLE_PAGES * CONFIG_MMU_PAGE_SIZE) + 0x20)INITIAL_PTABLE_PAGES(NUM_TABLE_PAGES + CONFIG_X86_EXTRA_PAGE_TABLE_PAGES)NUM_TABLE_PAGES(NUM_PT + NUM_PD)NUM_PD((PD_END - PD_START) / PD_AREA)PD_END((uintptr_t)ROUND_UP(VM_ADDR + VM_SIZE, PD_AREA))PD_START((uintptr_t)ROUND_DOWN(VM_ADDR, PD_AREA))NUM_PT((PT_END - PT_START) / PT_AREA)PT_END((uintptr_t)ROUND_UP(VM_ADDR + VM_SIZE, PT_AREA))PT_START((uintptr_t)ROUND_DOWN(VM_ADDR, PT_AREA))VM_SIZE(PT_AREA * NUM_PD_ENTRIES)((uintptr_t)(CONFIG_MMU_PAGE_SIZE * NUM_PT_ENTRIES))NUM_PT_ENTRIESNUM_PD_ENTRIESNUM_PDPT_ENTRIESPDE_LEVEL(NUM_LEVELS - 2)(NUM_LEVELS - 1)NUM_LEVELSARRAY_SIZE(paging_levels)INT_FLAGS(MMU_P | MMU_RW | MMU_US)PTE_ZERO(MMU_XD | MMU_XD_ORIG)(MMU_US | MMU_US_ORIG)(MMU_RW | MMU_RW_ORIG)(~((pentry_t)0U))MASK_PERM(MMU_RW | MMU_US | MMU_XD)MMU_XD_ORIGMMU_US_ORIGMMU_RW_ORIGCOLOR_PAGE_TABLESDUMP_PAGE_TABLESZ_VM_KERNELCONFIG_X86_BOUNDS_CHECK_BYPASS_MITIGATION!defined(CONFIG_X86_KPTI) && !defined(CONFIG_X86_COMMON_PAGE_TABLE)_XXXXCONFIG_SMP 1/* Might as well also check if it's un-mapped, normally we don't
	 * fetch the PTE from the page tables until we are inside
	 * z_page_fault() and call arch_page_fault_status_get()
	 *//* Not mapped *//* TODO: since we only have to query the current set of page tables,
	 * could optimize this with recursive page table mapping
	 *//* We don't filter out any other bits in the PTE and the kernel
	 * ignores them. For the case of ARCH_DATA_PAGE_NOT_MAPPED,
	 * we use a bit which is never set in a real PTE (the PAT bit) in the
	 * current system.
	 *
	 * The other ARCH_DATA_PAGE_* macros are defined to their corresponding
	 * bits in the PTE.
	 *//* NOTE: We are truncating the PTE on PAE systems, whose pentry_t
	 * are larger than a uintptr_t.
	 *
	 * We currently aren't required to report back XD state (bit 63), and
	 * Zephyr just doesn't support large physical memory on 32-bit
	 * systems, PAE was only implemented for XD support.
	 *//* USERSPACE && ~X86_COMMON_PAGE_TABLE *//* Logical OR of relevant PTE in all page tables.
			 * addr/location and present state should be identical
			 * among them.
			 *//* IRQs are locked, safe to do this *//* Don't bother looking at other page tables if non-present as we
	 * are not required to report accurate accessed/dirty in this case
	 * and all mappings are otherwise the same.
	 *//* Un-mapped PTEs are completely zeroed. No need to report anything
	 * else in this case.
	 *//* In this configuration page_map_set() just queries the
		 * page table and makes no changes
		 *//* What to change, if anything, in the page_map_set() calls *//* Accessed bit set to guarantee the entry is not completely 0 in
	 * case of location value 0. A totally 0 PTE is un-mapped.
	 *//* CONFIG_ARCH_HAS_RESERVED_PAGE_FRAMES *//* CONFIG_X86_MEMMAP *//* If any of three above cases satisfied, exit switch
			 * and mark page reserved
			 *//* CONFIG_X86_PC_COMPATIBLE *//*
	 * Best is to do some E820 or similar enumeration to specifically
	 * identify all page frames which are reserved by the hardware or
	 * firmware. Or use x86_memmap[] with Multiboot if available.
	 *
	 * But still, reserve everything in the first megabyte of physical
	 * memory on PC-compatible platforms.
	 *//* Memory domain access is already programmed into the page tables.
	 * Need to enable access to this new user thread's stack buffer in
	 * its domain-specific page tables.
	 *//* Re run swap page table update logic since we're entering User mode.
	 * This will grant stack and memory domain access if it wasn't set
	 * already (in which case this returns very quickly).
	 *//* Only now is it safe to grant access to the stack buffer since any
	 * previous context has been erased.
	 *//* Clear any previous context in the stack buffer to prevent
	 * unintentional data leakage.
	 *//* Invoked from z_x86_userspace_enter *//* !CONFIG_X86_COMMON_PAGE_TABLE *//* Need to switch to using these new page tables, in case we drop
	 * to user mode before we are ever context switched out.
	 * IPI takes care of this if the thread is currently running on some
	 * other CPU.
	 *//* Check if we're doing a migration from a different memory domain
	 * and have to remove permissions from its old domain.
	 *
	 * XXX: The checks we have to do here and in
	 * arch_mem_domain_thread_remove() are clumsy, it may be worth looking
	 * into adding a specific arch_mem_domain_thread_migrate() API.
	 * See #29601
	 *//* Allow US access to the thread's stack in its new domain if
	 * we are migrating. If we are not migrating this is done in
	 * z_x86_current_stack_perms()
	 *//* This is only set for threads that were migrating from some other
	 * memory domain; new threads this is NULL.
	 *
	 * Note that NULL check on old_ptables must be done before any
	 * address translation or else (NULL + offset) != NULL.
	 *//* New memory domain we are being added to *//* Invoked from memory domain API calls, as well as during thread creation *//* Update the page tables with the partition info *//* Restore permissions on the thread's stack area since it is no
	 * longer a member of the domain.
	 *//* Thread is migrating to another memory domain and not
		 * exiting for good; we weren't called from
		 * z_thread_abort().  Resetting the stack region will
		 * take place in the forthcoming thread_add() call.
		 *//* Called on thread exit or when moving it to a different memory domain *//* Reset the partition's region back to defaults *//* Make a copy of the boot page tables created by gen_mmu.py *//* Allocate a page-sized top-level structure, either a PD or PML4 *//* PDPT is stored within the memory domain itself since it is
	 * much smaller than a full page
	 *//* If we're not using KPTI then we can use the build time page tables
	 * (which are mutable) as the set of page tables for the default
	 * memory domain, saving us some memory.
	 *
	 * We skip adding this domain to x86_domain_list since we already
	 * update z_x86_kernel_ptables directly in range_map().
	 *//* __ASSERT_ON *//* Assert that we have not already initialized this domain *//*
 * Arch interface implementations for memory domains and userspace
 *//* Page table links are by physical address. RAM
			 * for page tables is identity-mapped, but double-
			 * cast needed for PAE case where sizeof(void *) and
			 * sizeof(pentry_t) are not the same.
			 *//* large page: no lower level table *//* Non-present, skip *//* Recursive case: allocate sub-structures as needed and
		 * make recursive calls on them
		 *//* Base case: leaf page table *//**
*  Duplicate an entire set of page tables
 *
 * Uses recursion, but depth at any given moment is limited by the number of
 * paging levels.
 *
 * x86_mmu_lock must be held.
 *
 * @param dst a zeroed out chunk of memory of sufficient size for the indicated
 *            paging level.
 * @param src some paging structure from within the source page tables to copy
 *            at the indicated paging level
 * @param level Current paging level
 * @retval 0 Success
 * @retval -ENOMEM Insufficient page pool memory
 *//* Debugging function to show how many pages are free in the pool *//* Return a zeroed and suitably aligned memory page for page table data
 * from the global page pool
 *//*
 * Pool of free memory pages for copying page tables, as needed.
 *//* Memory domains each have a set of page tables assigned to them *//* Rest of the APIs don't need to do anything *//* If a partition was added or removed in the cached domain, update the
 * page tables.
 *//* ...and apply all the incoming domain's regions *//* Reset the current memory domain regions... *//* The incoming thread's domain is already applied *//* Step 2: The page tables always have some memory domain applied to
	 * them. If the incoming thread's memory domain is different,
	 * update the page tables
	 *//* Update cache *//* The incoming thread's stack region needs User permissions *//* Step 1: Make sure the thread stack is set up correctly for the
	 * for the incoming thread
	 *//* Incoming thread is not a user thread. Memory domains don't
		 * affect supervisor threads and we don't need to enable User
		 * bits for its stack buffer; do nothing.
		 *//* Cache of the current memory domain applied to the common page tables and
 * the stack buffer region that had User access granted.
 *//* Very low memory configuration. A single set of page tables is used for
 * all threads. This relies on some assumptions:
 *
 * - No KPTI. If that were supported, we would need both a kernel and user
 *   set of page tables.
 * - No SMP. If that were supported, we would need per-core page tables.
 * - Memory domains don't affect supervisor mode.
 * - All threads have the same virtual-to-physical mappings.
 * - Memory domain APIs can't be called by user mode.
 *
 * Because there is no SMP, only one set of page tables, and user threads can't
 * modify their own memory domains, we don't have to do much when
 * arch_mem_domain_* APIs are called. We do use a caching scheme to avoid
 * updating page tables if the last user thread scheduled was in the same
 * domain.
 *
 * We don't set CONFIG_ARCH_MEM_DOMAIN_DATA, since we aren't setting
 * up any arch-specific memory domain data (per domain page tables.)
 *
 * This is all nice and simple and saves a lot of memory. The cost is that
 * context switching is not trivial CR3 update. We have to reset all partitions
 * for the current domain configuration and then apply all the partitions for
 * the incoming thread's domain if they are not the same. We also need to
 * update permissions similarly on the thread stack region.
 *//* addr/size arbitrary, fix this up into an aligned region *//* Missing intermediate table, address is
				 * un-mapped
				 *//* US and RW bits still carry meaning if non-present.
			 * If the data page is paged out, access bits are
			 * preserved. If un-mapped, the whole entry is 0.
			 *//* We flipped this to prevent user access
				 * since just clearing US isn't sufficient
				 *//* CONFIG_X86_STACK_PROTECTION *//* Applied to all page tables as this affects supervisor mode.
	 * XXX: This never gets reset when the thread exits, which can
	 * cause problems if the memory is later used for something else.
	 * See #29499
	 *
	 * Guard page is always the first page of the stack object for both
	 * kernel and thread stacks.
	 *//* We booted with physical address space being identity mapped.
	 * As we are now executing in virtual address space,
	 * the identity map is no longer needed. So remove them.
	 *
	 * Without PAE, only need to remove the entries at the PD level.
	 * With PAE, need to also remove the entry at PDP level.
	 *//* Invoked to remove the identity mappings in the page tables,
 * they were only needed to transition the instruction pointer at early boot
 *//* set_pte *//* Need to get to the correct table *//* unmap region addr..addr+size, reset entries and flush TLB *//* map new region virt..virt+size to phys with provided arch-neutral flags *//* Translate flags argument into HW-recognized entry flags.
	 *
	 * Support for PAT is not implemented yet. Many systems may have
	 * BIOS-populated MTRR values such that these cache settings are
	 * redundant.
	 *//* All virtual-to-physical mappings are the same in all page tables.
	 * What can differ is only access permissions, defined by the memory
	 * domain associated with the page tables, and the threads that are
	 * members of that domain.
	 *
	 * Any new mappings need to be applied to all page tables.
	 *//* There's a gap in the "64-bit" address space, as 4-level paging
	 * requires bits 48 to 63 to be copies of bit 47. Test this
	 * by treating as a signed value and shifting.
	 *//**
 * Establish or update a memory mapping for all page tables
 *
 * The physical region noted from phys to phys + size will be mapped to
 * an equal sized virtual region starting at virt, with the provided flags.
 * The mask value denotes what bits in PTEs will actually be modified.
 *
 * See range_map_ptables() for additional details.
 *
 * @param virt Page-aligned starting virtual address
 * @param phys Page-aligned starting physical address. Ignored if the mask
 *             parameter does not enable address bits or OPTION_RESET used.
 *             This region is not directly examined, it will simply be
 *             programmed into the page tables.
 * @param size Size of the physical region to map
 * @param entry_flags Desired state of non-address PTE bits covered by mask,
 *                    ignored if OPTION_RESET
 * @param mask What bits in the PTE to actually modify; unset bits will
 *             be preserved. Ignored if OPTION_RESET.
 * @param options Control options. Do not set OPTION_USER here. OPTION_FLUSH
 *                will trigger a TLB shootdown after all tables are updated.
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters are supplied
 * @retval -EFAULT if errors encountered when updating page tables
 *//* This implementation is stack-efficient but not particularly fast.
	 * We do a full page table walk for every page we are updating.
	 * Recursive approaches are possible, but use much more stack space.
	 *//**
 * Map a physical region in a specific set of page tables.
 *
 * See documentation for page_map_set() for additional notes about masks and
 * supported options.
 *
 * It is vital to remember that all virtual-to-physical mappings must be
 * the same with respect to supervisor mode regardless of what thread is
 * scheduled (and therefore, if multiple sets of page tables exist, which one
 * is active).
 *
 * It is permitted to set up mappings without the Present bit set.
 *
 * @param ptables Page tables to modify
 * @param virt Base page-aligned virtual memory address to map the region.
 * @param phys Base page-aligned physical memory address for the region.
 *        Ignored if OPTION_RESET or OPTION_CLEAR. Also affected by the mask
 *        parameter. This address is not directly examined, it will simply be
 *        programmed into the PTE.
 * @param size Size of the physical region to map
 * @param entry_flags Non-address bits to set in every PTE. Ignored if
 *        OPTION_RESET. Also affected by the mask parameter.
 * @param mask What bits to update in each PTE. Un-set bits will never be
 *        modified. Ignored if OPTION_RESET or OPTION_CLEAR.
 * @param options Control options, described above
 *
 * @retval 0 if successful
 * @retval -EINVAL if invalid parameters are supplied
 * @retval -EFAULT if errors encountered when updating page tables
 *//* Cannot continue since table is NULL,
			 * and it cannot be dereferenced in next loop
			 * iteration.
			 *//* Cannot continue since we cannot split
			 * bigpage mappings.
			 *//* We bail out early here due to no support for
		 * splitting existing bigpage mappings.
		 * If the PS bit is not supported at some level (like
		 * in a PML4 entry) it is always reserved and must be 0
		 *//* Check if we're a PTE *//**
 * Low level page table update function for a virtual page
 *
 * For the provided set of page tables, update the PTE associated with the
 * virtual address to a new value, using the mask to control what bits
 * need to be preserved.
 *
 * It is permitted to set up mappings without the Present bit set, in which
 * case all other bits may be used for OS accounting.
 *
 * This function is atomic with respect to the page table entries being
 * modified by another CPU, using atomic operations to update the requested
 * bits and return the previous PTE value.
 *
 * Common mask values:
 *  MASK_ALL  - Update all PTE bits. Existing state totally discarded.
 *  MASK_PERM - Only update permission bits. All other bits and physical
 *              mapping preserved.
 *
 * @param ptables Page tables to modify
 * @param virt Virtual page table entry to update
 * @param entry_val Value to update in the PTE (ignored if OPTION_RESET or
 *        OPTION_CLEAR)
 * @param [out] old_val_ptr Filled in with previous PTE value. May be NULL.
 * @param mask What bits to update in the PTE (ignored if OPTION_RESET or
 *        OPTION_CLEAR)
 * @param options Control options, described above
 *
 * @retval 0 if successful
 * @retval -EFAULT if large page encountered or missing page table level
 *//* Page was flipped for KPTI. Un-flip it *//**
 * Atomically update bits in a page table entry
 *
 * This is atomic with respect to modifications by other CPUs or preempted
 * contexts, which can be very important when making decisions based on
 * the PTE's prior "dirty" state.
 *
 * @param pte Pointer to page table entry to update
 * @param update_val Updated bits to set/clear in PTE. Ignored with
 *        OPTION_RESET or OPTION_CLEAR.
 * @param update_mask Which bits to modify in the PTE. Ignored with
 *        OPTION_RESET or OPTION_CLEAR.
 * @param options Control flags
 * @retval Old PTE value
 *//* Indicates that the mapping will need to be cleared entirely. This is
 * mainly used for unmapping the memory region.
 *//* Indicates that each PTE's permission bits should be restored to their
 * original state when the memory was mapped. All other bits in the PTE are
 * preserved.
 *//* Indicates that the operation requires TLBs to be flushed as we are altering
 * existing mappings. Not needed for establishing new mappings
 *//* Indicates that the target page tables will be used by user mode threads.
 * This only has implications for CONFIG_X86_KPTI where user thread facing
 * page tables need nearly all pages that don't have the US bit to also
 * not be Present.
 *//* Atomic builtins for 64-bit values on 32-bit x86 require floating point.
 * Don't do this, just lock local interrupts. Needless to say, this
 * isn't workable if someone ever adds SMP to the 32-bit x86 port.
 *//* Non-PAE, pentry_t is same size as void ptr so use atomic_ptr_* APIs *//* Atomic functions for modifying PTEs. These don't map nicely to Zephyr's
 * atomic API since the only types supported are 'int' and 'void *' and
 * the size of pentry_t depends on other factors like PAE.
 *//* Wrapper functions for some gross stuff we have to do for Kernel
 * page table isolation. If these are User mode page tables, the user bit
 * isn't set, and this is not the shared page, all the bits in the PTE
 * are flipped. This serves three purposes:
 *  - The page isn't present, implementing page table isolation
 *  - Flipping the physical address bits cheaply mitigates L1TF
 *  - State is preserved; to get original PTE, just complement again
 *//* Now set permissions based on the stashed original values *//* Clear any existing state in permission bits *//* Reset permissions on a PTE to original state when the mapping was made *//*
 * Debug function for dumping out MMU table information to the LOG for a
 * specific virtual address, such as when we get an unexpected page fault.
 *//* Truncated *//* Enable to dump out the kernel's page table right before main() starts,
 * sometimes useful for deep debugging. May overwhelm twister.
 *//* Not present or big page, skip *//* Dump all linked child tables *//* Check if we're a page table *//* Account for the virtual memory "hole" with sign-extension *//* Un-mapped intermediate entry *//* Paged out *//* Non-identity mapped *//* Identity mapped *//* KPTI, un-flip it *//* Unmapped *//* Intermediate entry *//* General mapped pages *//* Permanent RAM mappings *//* Identity mappings *//* Uppercase indicates user mode access *//* RX *//* R *//* RWX *//* RW *//* Writable page *//* Unmapped entry *//* Add colors to page table dumps to indicate mapping type *//*
 * Debug functions. All conditionally compiled with CONFIG_EXCEPTION_DEBUG.
 *//* NOTE: This is not synchronous and the actual flush takes place some short
 * time after this exits.
 *//*
	 * In the future, we can consider making this smarter, such as
	 * propagating which page tables were modified (in case they are
	 * not active on this CPU) or an address range to call
	 * tlb_flush_page() on.
	 *//* We might have been moved to another memory domain, so always invoke
	 * z_x86_thread_page_tables_get() instead of using current CR3 value.
	 *//* We're always on the kernel's set of page tables in this context
	 * if KPTI is turned on
	 *//* Invalidate TLB entries corresponding to the page containing the
	 * specified address
	 *//* This does NOT (by design) un-flip KPTI PTEs, it's just the raw PTE value *//* Always true for PTE *//* Must have checked Present bit first! Non-present entries may have OS data
 * stored in any other bits
 *//* For a table at a particular level, size of the amount of virtual memory
 * that this entire table covers
 *//* For a table at a particular level, size of the amount of virtual memory
 * that an entry within the table covers
 *//* 4K for everything except PAE PDPTs *//* Number of table entries at this level *//* Return the virtual address of a linked table stored in the provided entry *//* Get the physical memory address associated with this table entry *//* For a table at a particular level, get the entry index that corresponds to
 * the provided virtual address
 *//*
 * Utility functions
 *//* "dummy" pagetables for the first-phase build. The real page tables
 * are produced by gen-mmu.py based on data read in zephyr-prebuilt.elf,
 * and this dummy array is discarded.
 *//* Toplevel PDPT wasn't included as it is not a page in size *//* Number of pages we need to reserve in the stack for per-thread page tables *//* !CONFIG_X86_64 *//* All pages needed for page tables, using computed values plus one more for
 * the top-level PML4
 *//* Number of PDPTs needed to cover the address space. 1 PDPT per 512GB of VM *//* Same semantics as above, but for the page directory pointer tables needed
 * to cover the address space. On 32-bit there is just one 4-entry PDPT.
 *//* 32-bit page tables just have one toplevel page directory *//* Number of page directories needed to cover the address space. Depends on the
 * specific bounds, but roughly 1 page directory per 1GB of RAM
 *//* Same semantics as above, but for the page directories needed to cover
 * system RAM.
 *//* Number of page tables needed to cover address space. Depends on the specific
 * bounds, but roughly 1 page table per 2MB of RAM
 *//* Define a range [PT_START, PT_END) which is the memory range
 * covered by all the page tables needed for the address space
 *//* Memory range covered by an instance of various table types *//* !CONFIG_X86_64 && !CONFIG_X86_PAE *//*
 * Macros for reserving space for page tables
 *
 * We need to reserve a block of memory equal in size to the page tables
 * generated by gen_mmu.py so that memory addresses do not shift between
 * build phases. These macros ultimately specify INITIAL_PAGETABLE_SIZE.
 *//* CONFIG_X86_64 || CONFIG_X86_PAE *//* Page Table *//* Page Directory *//* PAE version *//* Page Directory Pointer Table *//* Page Map Level 4 *//* Paging level ontology for the selected paging mode.
 *
 * See Figures 4-4, 4-7, 4-11 in the Intel SDM, vol 3A
 *//* Flags for all entries in intermediate paging levels.
 * Fortunately, the same bits are set for all intermediate levels for all
 * three paging modes.
 *
 * Obviously P is set.
 *
 * We want RW and US bit always set; actual access control will be
 * done at the leaf level.
 *
 * XD (if supported) always 0. Disabling execution done at leaf level.
 *
 * PCD/PWT always 0. Caching properties again done at leaf level.
 *//* Name of this level, for debug purposes *//* How many bits to right-shift a virtual address to obtain the
	 * appropriate entry within this table.
	 *
	 * The memory scope of each entry in this table is 1 << shift.
	 *//* Number of entries in this paging structure *//* What bits are used to store physical address *//* Data structure describing the characteristics of a particular paging
 * level
 *//*
 * Definitions for building an ontology of paging levels and capabilities
 * at each level
 *//* List of all active and initialized memory domains. This is used to make
 * sure all memory mappings are the same across all page tables when invoking
 * range_map()
 *//* Protects x86_domain_list and serializes instantiation of intermediate
 * paging structures.
 *//* Bit position which is always zero in a PTE. We'll use the PAT bit.
 * This helps disambiguate PTEs that do not have the Present bit set (MMU_P):
 * - If the entire entry is zero, it's an un-mapped virtual page
 * - If PTE_ZERO is set, we flipped this page due to KPTI
 * - Otherwise, this was a page-out
 *//* Bits to set at mapping time for particular permissions. We set the actual
 * page table bit effecting the policy and also the backup bit.
 *//* When we want to set up a new mapping, discarding any previous state *//* Bits in the PTE that form the set of permission bits, when resetting *//* We will use some ignored bits in the PTE to backup permission settings
 * when the mapping was made. This is used to un-apply memory domain memory
 * partitions to page tables when the partitions are removed.
 *//*
 * Copyright (c) 2011-2014 Wind River Systems, Inc.
 * Copyright (c) 2017-2020 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 */errorunknowndecltype(nullptr)char8_tchar16_tchar32_tunsigned shortsigned shortsigned intsigned longunsigned long longsigned long long__int128unsigned __int128signed __int128_Float16__fp16float__float128_Decimal32_Decimal64_Decimal128__bf16std::float16_t_Float32_Float32x_Float64_Float64x_Float128_Complex _Float16_Complex float_Complex _Float32x_Complex double_Complex _Float64x_Complex long double_Complex __float128_Complex _Float32_Complex _Float64_Complex _Float128_Imaginary float_Imaginary double_Imaginary long doubleauto__superpublicprotectedprivatepurevirtualdeclared_virtualinlineexplicitatomicfinaloverrideoptionalis_constexpris_constevalis_thread_localdeclared_constexprdeclared_constinit&&&register__blocknearfarsealedabstract__interfaceunaligneddllimportdllexportnakedmicrosoft_inlineforceinlineselectanynovtablenoinlinenoalias__ptr32__ptr64__sptr__uptrvarargsimplicit_inthas_trailing_return_type/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/CompilerIdC/CMakeCCompilerId.cmainrequireconst char[50]info_language_extensions_defaultINFO:extensions_default[ON]"INFO" ":" "extensions_default["
/* !defined(_MSC_VER) to exclude Clang's MSVC compatibility mode. */
#if (defined(__clang__) || defined(__GNUC__) ||                               \
     defined(__TI_COMPILER_VERSION__)) &&                                     \
  !defined(__STRICT_ANSI__) && !defined(_MSC_VER)
  "ON"
#else
  "OFF"
#endif
"]"info_language_standard_defaultINFO:standard_default[17]"INFO" ":" "standard_default[" C_VERSION "]"char[26]info_archINFO:arch[]"INFO" ":" "arch[" ARCHITECTURE_ID "]"char[12]info_platformINFO:platform[]"INFO" ":" "platform[" PLATFORM_ID "]"char[16]const char[]info_version'I''N''F''O'':''c''o''m''p''i''l''e''r''_''v''s''n''['1000000010000010000'.'']''\0'info_compilerINFO:compiler[GNU]"INFO" ":" "compiler[" COMPILER_ID "]"char[19]C_VERSION"17"HEX(n)('0' + ((n)>>28 & 0xF)), ('0' + ((n)>>24 & 0xF)), ('0' + ((n)>>20 & 0xF)), ('0' + ((n)>>16 & 0xF)), ('0' + ((n)>>12 & 0xF)), ('0' + ((n)>>8 & 0xF)), ('0' + ((n)>>4 & 0xF)), ('0' + ((n) & 0xF))DEC(n)('0' + (((n) / 10000000)%10)), ('0' + (((n) / 1000000)%10)), ('0' + (((n) / 100000)%10)), ('0' + (((n) / 10000)%10)), ('0' + (((n) / 1000)%10)), ('0' + (((n) / 100)%10)), ('0' + (((n) / 10)%10)), ('0' + ((n) % 10))ARCHITECTURE_IDPLATFORM_IDSTRINGIFY(X)STRINGIFY_HELPER(X)#XCOMPILER_VERSION_PATCHDEC(__GNUC_PATCHLEVEL__)COMPILER_VERSION_MINORDEC(__GNUC_MINOR__)COMPILER_VERSION_MAJORDEC(__GNUC__)COMPILER_ID"GNU"defined(__18CXX)defined(__CLASSIC_C__)!defined(__has_include)defined(__INTEL_COMPILER) || defined(__ICC)defined(_MSC_VER)__INTEL_COMPILER < 2021 || __INTEL_COMPILER == 202110 || __INTEL_COMPILER == 202111defined(__INTEL_COMPILER_UPDATE)defined(__INTEL_COMPILER_BUILD_DATE)defined(__GNUG__)defined(__GNUC_MINOR__)defined(__GNUC_PATCHLEVEL__)(defined(__clang__) && defined(__INTEL_CLANG_COMPILER)) || defined(__INTEL_LLVM_COMPILER)__INTEL_LLVM_COMPILER < 1000000Ldefined(__PATHCC__)defined(__PATHCC_PATCHLEVEL__)defined(__BORLANDC__) && defined(__CODEGEARC_VERSION__)defined(__BORLANDC__)defined(__WATCOMC__) && __WATCOMC__ < 1200(__WATCOMC__ % 10) > 0defined(__WATCOMC__)defined(__SUNPRO_C)__SUNPRO_C >= 0x5100defined(__HP_cc)defined(__DECC)defined(__IBMC__) && defined(__COMPILER_VER__)defined(__ibmxl__) && defined(__clang__)defined(__IBMC__) && !defined(__COMPILER_VER__) && __IBMC__ >= 800defined(__IBMC__) && !defined(__COMPILER_VER__) && __IBMC__ < 800defined(__NVCOMPILER)defined(__NVCOMPILER_PATCHLEVEL__)defined(__PGI)defined(__PGIC_PATCHLEVEL__)defined(_CRAYC)defined(__TI_COMPILER_VERSION__)defined(__CLANG_FUJITSU)defined(__FUJITSU)defined(__FCC_version__)defined(__FCC_major__)defined(__fcc_version)defined(__FCC_VERSION)defined(__ghs__)__GHS_VERSION_NUMBERdefined(__TINYC__)defined(__BCC__)defined(__SCO_VERSION__)defined(__ARMCC_VERSION) && !defined(__clang__)__ARMCC_VERSION >= 1000000defined(__clang__) && defined(__apple_build_version__)defined(__clang__) && defined(__ARMCOMPILER_VERSION)defined(__clang__)defined(_MSC_FULL_VER)_MSC_VER >= 1400defined(_MSC_BUILD)defined(__VISUALDSPVERSION__) || defined(__ADSPBLACKFIN__) || defined(__ADSPTS__) || defined(__ADSP21000__)defined(__VISUALDSPVERSION__)defined(__IAR_SYSTEMS_ICC__) || defined(__IAR_SYSTEMS_ICC)defined(__VER__) && defined(__ICCARM__)defined(__VER__) && (defined(__ICCAVR__) || defined(__ICCRX__) || defined(__ICCRH850__) || defined(__ICCRL78__) || defined(__ICC430__) || defined(__ICCRISCV__) || defined(__ICCV850__) || defined(__ICC8051__) || defined(__ICCSTM8__))defined(__SDCC_VERSION_MAJOR) || defined(SDCC)defined(__SDCC_VERSION_MAJOR)defined(__hpux) || defined(__hpua)SIMULATE_ID__QNXNTO__defined(__CRAYXT_COMPUTE_LINUX_TARGET)defined(__linux) || defined(__linux__) || defined(linux)defined(__MSYS__)defined(__MINGW32__)defined(__APPLE__)defined(_WIN32) || defined(__WIN32__) || defined(WIN32)defined(__FreeBSD__) || defined(__FreeBSD)defined(__NetBSD__) || defined(__NetBSD)defined(__OpenBSD__) || defined(__OPENBSD)defined(__sun) || defined(sun)defined(_AIX) || defined(__AIX) || defined(__AIX__) || defined(__aix) || defined(__aix__)defined(__hpux) || defined(__hpux__)defined(__HAIKU__)defined(__BeOS) || defined(__BEOS__) || defined(_BEOS)defined(__QNX__) || defined(__QNXNTO__)defined(__tru64) || defined(_tru64) || defined(__TRU64__)defined(__riscos) || defined(__riscos__)defined(__sinix) || defined(__sinix__) || defined(__SINIX__)defined(__UNIX_SV__)defined(__bsdos__)defined(_MPRAS) || defined(MPRAS)defined(__osf) || defined(__osf__)defined(_SCO_SV) || defined(SCO_SV) || defined(sco_sv)defined(__ultrix) || defined(__ultrix__) || defined(_ULTRIX)defined(__XENIX__) || defined(_XENIX) || defined(XENIX)defined(__LINUX__)defined(__DOS__)defined(__OS2__)defined(__WINDOWS__)defined(__VXWORKS__)defined(__INTEGRITY)defined(INT_178B)defined(_WIN32) && defined(_MSC_VER)defined(_M_IA64)defined(_M_ARM64EC)defined(_M_X64) || defined(_M_AMD64)defined(_M_IX86)defined(_M_ARM64)defined(_M_ARM)_M_ARM == 4_M_ARM == 5/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/CompilerIdC/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/home/haojie/zephyrproject/zephyr/build/CMakeFilesargcargvdefined(_M_MIPS)defined(_M_SH)defined(_M_I86)defined(__ICCARM__)defined(__ICCRX__)defined(__ICCRH850__)defined(__ICCRL78__)defined(__ICCRISCV__)defined(__ICCAVR__)defined(__ICC430__)defined(__ICCV850__)defined(__ICC8051__)defined(__ICCSTM8__)defined(__PPC64__)defined(__ppc__)defined(__ARM__)defined(__x86_64__)defined(__i386__)defined(__TI_ARM__)defined(__MSP430__)defined(__TMS320C28XX__)defined(__TMS320C6X__) || defined(_TMS320C6X)COMPILER_VERSIONdefined(COMPILER_VERSION_MAJOR)COMPILER_VERSION_TWEAKCOMPILER_VERSION_INTERNALdefined(COMPILER_VERSION_INTERNAL_STR)SIMULATE_VERSION_MAJORSIMULATE_VERSION_MINORSIMULATE_VERSION_PATCHSIMULATE_VERSION_TWEAK!defined(__STDC__) && !defined(__clang__)defined(_MSC_VER) || defined(__ibmxl__) || defined(__IBMC__)__STDC_VERSION__ > 201710L__STDC_VERSION__ >= 201710L__STDC_VERSION__ >= 201000L__STDC_VERSION__ >= 199901L(defined(__clang__) || defined(__GNUC__) ||                               \ID_VOID_MAIN201710L/*--------------------------------------------------------------------------*//* !defined(_MSC_VER) to exclude Clang's MSVC compatibility mode. *//* Construct the string literal in pieces to prevent the source from
   getting matched.  Store it in a pointer rather than an array
   because some compilers will just produce instructions to fill the
   array rather than assigning a pointer to a static array.  *//* Construct a string literal encoding the version number components. *//* Construct a string literal encoding the internal version number. *//* Construct a string literal encoding the version number. *//* Convert integer to hex digit literals.  *//* Convert integer to decimal digit literals.  *//* unknown architecture *//* For windows compilers MSVC and Intel we can determine
   the architecture of the compiler being used.  This is because
   the compilers do not have flags that can change the architecture,
   but rather depend on which compiler is being used
*//* unknown platform *//* regular Integrity *//* Identify known platforms by name.  *//* unknown compiler *//* These compilers are either not known or too old to define an
  identification macro.  Try to identify the platform and guess that
  it is the native compiler.  *//* SDCC = VRP *//* __VISUALDSPVERSION__ = 0xVVRRPP00 *//* _MSC_FULL_VER = VVRRPPPP *//* _MSC_FULL_VER = VVRRPPPPP *//* _MSC_VER = VVRR *//* __ARMCC_VERSION = VRPPPP *//* __ARMCC_VERSION = VRRPPPP *//* __GHS_VERSION_NUMBER = VVVVRP *//* __TI_COMPILER_VERSION__ = VVVRRRPPP *//* __IBMC__ = VRP *//* __DECC_VER = VVRRTPPPP *//* __HP_cc = VVRRPP *//* __SUNPRO_CC = 0xVRP *//* __SUNPRO_C = 0xVRRP *//* __WATCOMC__ = VVRP + 1100 *//* __WATCOMC__ = VVRR *//* __BORLANDC__ = 0xVRR *//* __INTEL_LLVM_COMPILER = VVVVRP prior to 2021.2.0, VVVVRRPP for 2021.2.0 and
 * later.  Look for 6 digit vs. 8 digit version number to decide encoding.
 * VVVV is no smaller than the current year when a version is released.
 *//* __INTEL_COMPILER_BUILD_DATE = YYYYMMDD *//* The third version component from --version is an update index,
      but no macro is provided for it.  *//* __INTEL_COMPILER = VRP prior to 2021, and then VVVV for 2021 and later,
     except that a few beta releases use the old format with V=2021.  *//* Version number components: V=Version, R=Revision, P=Patch
   Version date components:   YYYY=Year, MM=Month,   DD=Day  *//* If the compiler does not have __has_include, pretend the answer is
   always no.  *//* cv-qualifiers did not exist in K&R C */compiled as c++/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/CompilerIdCXX/CMakeCXXCompilerId.cppconst char[28]"INFO" ":" "standard_default["
#if CXX_STD > 202002L
  "23"
#elif CXX_STD > 201703L
  "20"
#elif CXX_STD >= 201703L
  "17"
#elif CXX_STD >= 201402L
  "14"
#elif CXX_STD >= 201103L
  "11"
#else
  "98"
#endif
"]"const char[26]const char[12]const char[16]const char[19]CXX_STDdefined(__COMO__)defined(__SUNPRO_CC)__SUNPRO_CC >= 0x5100defined(__HP_aCC)defined(__DECCXX)defined(__IBMCPP__) && defined(__COMPILER_VER__)defined(__IBMCPP__) && !defined(__COMPILER_VER__) && __IBMCPP__ >= 800defined(__IBMCPP__) && !defined(__COMPILER_VER__) && __IBMCPP__ < 800defined(__GNUC__) || defined(__GNUG__)/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/CompilerIdCXXdefined(__INTEL_COMPILER) && defined(_MSVC_LANG) && _MSVC_LANG < 201403Ldefined(__INTEL_CXX11_MODE__)defined(__cpp_aggregate_nsdmi)defined(_MSC_VER) && defined(_MSVC_LANG)CXX_STD > 202002LCXX_STD > 201703LCXX_STD >= 201703LCXX_STD >= 201402LCXX_STD >= 201103L201703L/* __IBMCPP__ = VRP *//* __DECCXX_VER = VVRRTPPPP *//* __HP_aCC = VVRRPP *//* __SUNPRO_CC = 0xVRRP *//* __COMO_VERSION__ = VRR *//* This source file must have a .cpp extension so that all C++ compilers
   recognize the extension without flags.  Borland does not know .cxx for
   example.  *//home/haojie/zephyrproject/zephyr/build/zephyr/misc/generated/configs.c_ConfigAbsSyms/* file is auto-generated, do not modify ! *//*
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/build/zephyr/misc/generated/home/haojie/zephyrproject/zephyr/build/zephyr/misc__ctype_lookup_l__locale_ctype_ptr_l__ctype_lookuptoupper_ltolower_lisxdigit_lisupper_lisspace_lispunct_lisprint_lislower_lisgraph_lisdigit_liscntrl_lisblank_lisalpha_lisalnum_lisblank' ''\t'touppertolowerisxdigitisupperisspaceispunctisprintislowerisgraphisdigitiscntrlisalphaisalnum_ctype_btolower(__c)__extension__ ({ __typeof__ (__c) __x = (__c); isupper (__x) ? (int) __x - 'A' + 'a' : (int) __x;})toupper(__c)__extension__ ({ __typeof__ (__c) __x = (__c); islower (__x) ? (int) __x - 'a' + 'A' : (int) __x;})isblank_l(__c,__l)__extension__ ({ __typeof__ (__c) __x = (__c); (__ctype_lookup_l(__x,__l)&_B) || (int) (__x) == '\t';})iscntrl_l(__c,__l)(__ctype_lookup_l(__c,__l)&_C)isgraph_l(__c,__l)(__ctype_lookup_l(__c,__l)&(_P|_U|_L|_N))isprint_l(__c,__l)(__ctype_lookup_l(__c,__l)&(_P|_U|_L|_N|_B))isalnum_l(__c,__l)(__ctype_lookup_l(__c,__l)&(_U|_L|_N))ispunct_l(__c,__l)(__ctype_lookup_l(__c,__l)&_P)isspace_l(__c,__l)(__ctype_lookup_l(__c,__l)&_S)isxdigit_l(__c,__l)(__ctype_lookup_l(__c,__l)&(_X|_N))isdigit_l(__c,__l)(__ctype_lookup_l(__c,__l)&_N)islower_l(__c,__l)((__ctype_lookup_l(__c,__l)&(_U|_L))==_L)isupper_l(__c,__l)((__ctype_lookup_l(__c,__l)&(_U|_L))==_U)isalpha_l(__c,__l)(__ctype_lookup_l(__c,__l)&(_U|_L))iscntrl(__c)(__ctype_lookup(__c)&_C)isgraph(__c)(__ctype_lookup(__c)&(_P|_U|_L|_N))isprint(__c)(__ctype_lookup(__c)&(_P|_U|_L|_N|_B))isalnum(__c)(__ctype_lookup(__c)&(_U|_L|_N))ispunct(__c)(__ctype_lookup(__c)&_P)isspace(__c)(__ctype_lookup(__c)&_S)isxdigit(__c)(__ctype_lookup(__c)&(_X|_N))isdigit(__c)(__ctype_lookup(__c)&_N)islower(__c)((__ctype_lookup(__c)&(_U|_L))==_L)isupper(__c)((__ctype_lookup(__c)&(_U|_L))==_U)isalpha(__c)(__ctype_lookup(__c)&(_U|_L))__CTYPE_PTR(__locale_ctype_ptr ())__locale_ctype_ptr()_ctype_(_ctype_b + 127)ALLOW_NEGATIVE_CTYPE_INDEX_B0200_X0100_C040_P020_S010_N04_L02_U01_CTYPE_H___POSIX_VISIBLE >= 200809 || __MISC_VISIBLE || defined (_LIBC)_DEFINING_ISBLANK__MISC_VISIBLE || __XSI_VISIBLECHAR_MIN == SCHAR_MINdefined(ALLOW_NEGATIVE_CTYPE_INDEX)!defined (_MB_EXTENDED_CHARSETS_ISO) && !defined (_MB_EXTENDED_CHARSETS_WINDOWS)/* _CTYPE_H_ *//* __POSIX_VISIBLE >= 200809 *//* _MB_EXTENDED_CHARSETS* *//* Allow a gcc warning if the user passed 'char', but defer to the
   function.  *//* Non-gcc versions will get the library versions, and will be
   slightly slower.  These macros are not NLS-aware so they are
   disabled if the system supports the extended character sets. */_l__l/home/haojie/zephyrproject/zephyr/build/zephyr/include/generated/syscalls/uart.huart_drv_cmduart_line_ctrl_getuart_line_ctrl_setuart_rx_disableuart_rx_enable_u16uint16_t *uart_rx_enableuart_tx_abortuart_tx_u16const uint16_tconst uint16_t *uart_txuart_irq_updateuart_irq_is_pendinguart_irq_err_disableuart_irq_err_enableuart_irq_rx_disableuart_irq_rx_enableuart_irq_tx_disableuart_irq_tx_enableuart_config_getuart_config *uart_configureconst uart_configconst uart_config *uart_poll_out_u16uart_poll_outuart_poll_in_u16uart_poll_inuart_err_checkZ_INCLUDE_SYSCALLS_UART_Hz_impl_uart_drv_cmdz_impl_uart_line_ctrl_getz_impl_uart_line_ctrl_setz_impl_uart_rx_disablez_impl_uart_rx_enable_u16z_impl_uart_rx_enablez_impl_uart_tx_abortz_impl_uart_tx_u16z_impl_uart_txz_impl_uart_irq_updatez_impl_uart_irq_is_pendingz_impl_uart_irq_err_disablez_impl_uart_irq_err_enablez_impl_uart_irq_rx_disablez_impl_uart_irq_rx_enablez_impl_uart_irq_tx_disablez_impl_uart_irq_tx_enablez_impl_uart_config_getz_impl_uart_configurez_impl_uart_poll_out_u16z_impl_uart_poll_outz_impl_uart_poll_in_u16z_impl_uart_poll_inz_impl_uart_err_checkcmdpctrlout_u16out_charp_u16p_char/home/haojie/zephyrproject/zephyr/include/zephyr/drivers/uart.h<syscalls/uart.h>-134-ENOTSUPuart_rx_buf_rsp_u16uart_rx_buf_rspuart_callback_setcallbackuart_irq_callback_setuart_irq_callback_user_data_setuart_irq_rx_readyuart_irq_tx_completeuart_irq_tx_readyuart_fifo_read_u16const intrx_datauart_fifo_readuart_fifo_fill_u16uart_fifo_fillconst uart_driver_apiconst uart_driver_api *uart_driver_api *uart_driver_apiuart_event *uart_callback_tuart_eventuart_event_datauart_event_rx_stopuart_event_rx_bufuart_event_rxuart_event_txuart_event_typeUART_TX_DONEUART_TX_ABORTEDUART_RX_RDYUART_RX_BUF_REQUESTUART_RX_BUF_RELEASEDUART_RX_DISABLEDUART_RX_STOPPEDuart_irq_config_func_tuart_irq_callback_user_data_tuart_configuart_config_flow_controlUART_CFG_FLOW_CTRL_NONEUART_CFG_FLOW_CTRL_RTS_CTSUART_CFG_FLOW_CTRL_DTR_DSRUART_CFG_FLOW_CTRL_RS485uart_config_data_bitsUART_CFG_DATA_BITS_5UART_CFG_DATA_BITS_6UART_CFG_DATA_BITS_7UART_CFG_DATA_BITS_8UART_CFG_DATA_BITS_9uart_config_stop_bitsUART_CFG_STOP_BITS_0_5UART_CFG_STOP_BITS_1UART_CFG_STOP_BITS_1_5UART_CFG_STOP_BITS_2uart_config_parityUART_CFG_PARITY_NONEUART_CFG_PARITY_ODDUART_CFG_PARITY_EVENUART_CFG_PARITY_MARKUART_CFG_PARITY_SPACEuart_rx_stop_reasonUART_ERROR_OVERRUN1 << 0UART_ERROR_PARITY1 << 1UART_ERROR_FRAMING1 << 2UART_BREAK1 << 3UART_ERROR_COLLISION1 << 4UART_ERROR_NOISE1 << 5uart_line_ctrlUART_LINE_CTRL_BAUD_RATEUART_LINE_CTRL_RTSUART_LINE_CTRL_DTRUART_LINE_CTRL_DCDUART_LINE_CTRL_DSRconfig_getconfigureerr_checkpoll_outpoll_inrx_stoprx_bufrxtxflow_ctrldata_bitsstop_bitsparitybaudrateZEPHYR_INCLUDE_DRIVERS_UART_H_CONFIG_UART_ASYNC_APICONFIG_UART_WIDE_DATACONFIG_UART_INTERRUPT_DRIVENCONFIG_UART_LINE_CTRLCONFIG_UART_DRV_CMDdefined(CONFIG_UART_INTERRUPT_DRIVEN) && defined(CONFIG_UART_WIDE_DATA)defined(CONFIG_UART_ASYNC_API) && defined(CONFIG_UART_WIDE_DATA)/* ZEPHYR_INCLUDE_DRIVERS_UART_H_ *//**
 * @brief Send extra command to driver.
 *
 * Implementation and accepted commands are driver specific.
 * Refer to the drivers for more information.
 *
 * @param dev UART device instance.
 * @param cmd Command to driver.
 * @param p Parameter to the command.
 *
 * @retval 0 If successful.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Retrieve line control for UART.
 *
 * @param dev UART device instance.
 * @param ctrl The line control to retrieve (see enum uart_line_ctrl).
 * @param val Pointer to variable where to store the line control value.
 *
 * @retval 0 If successful.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Manipulate line control for UART.
 *
 * @param dev UART device instance.
 * @param ctrl The line control to manipulate (see enum uart_line_ctrl).
 * @param val Value to set to the line control.
 *
 * @retval 0 If successful.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Disable RX
 *
 * #UART_RX_BUF_RELEASED event will be generated for every buffer scheduled,
 * after that #UART_RX_DISABLED event will be generated. Additionally, if there
 * is any pending received data, the #UART_RX_RDY event for that data will be
 * generated before the #UART_RX_BUF_RELEASED events.
 *
 * @param dev UART device instance.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EFAULT There is no active reception.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Provide wide data receive buffer in response to #UART_RX_BUF_REQUEST
 * event.
 *
 * Provide pointer to RX buffer, which will be used when current buffer is
 * filled.
 *
 * @note Providing buffer that is already in usage by driver leads to
 *       undefined behavior. Buffer can be reused when it has been released
 *       by driver.
 *
 * @param dev UART device instance.
 * @param buf Pointer to wide data receive buffer.
 * @param len Buffer length.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled
 * @retval -EBUSY Next buffer already set.
 * @retval -EACCES Receiver is already disabled (function called too late?).
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Provide receive buffer in response to #UART_RX_BUF_REQUEST event.
 *
 * Provide pointer to RX buffer, which will be used when current buffer is
 * filled.
 *
 * @note Providing buffer that is already in usage by driver leads to
 *       undefined behavior. Buffer can be reused when it has been released
 *       by driver.
 *
 * @param dev UART device instance.
 * @param buf Pointer to receive buffer.
 * @param len Buffer length.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EBUSY Next buffer already set.
 * @retval -EACCES Receiver is already disabled (function called too late?).
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Start receiving wide data through UART.
 *
 * Function sets given buffer as first buffer for receiving and returns
 * immediately. After that event handler, set using @ref uart_callback_set,
 * is called with #UART_RX_RDY or #UART_RX_BUF_REQUEST events.
 *
 * @param dev     UART device instance.
 * @param buf     Pointer to wide data receive buffer.
 * @param len     Buffer length.
 * @param timeout Inactivity period after receiving at least a byte which
 *		  triggers  #UART_RX_RDY event. Given in milliseconds.
 *		  @ref SYS_FOREVER_MS disables timeout. See
 *		  @ref uart_event_type for details.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EBUSY RX already in progress.
 * @retval -errno Other negative errno value in case of failure.
 *
 *//**
 * @brief Start receiving data through UART.
 *
 * Function sets given buffer as first buffer for receiving and returns
 * immediately. After that event handler, set using @ref uart_callback_set,
 * is called with #UART_RX_RDY or #UART_RX_BUF_REQUEST events.
 *
 * @param dev     UART device instance.
 * @param buf     Pointer to receive buffer.
 * @param len     Buffer length.
 * @param timeout Inactivity period after receiving at least a byte which
 *		  triggers  #UART_RX_RDY event. Given in microseconds.
 *		  @ref SYS_FOREVER_US disables timeout. See @ref uart_event_type
 *		  for details.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EBUSY RX already in progress.
 * @retval -errno Other negative errno value in case of failure.
 *
 *//**
 * @brief Abort current TX transmission.
 *
 * #UART_TX_DONE event will be generated with amount of data sent.
 *
 * @param dev UART device instance.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EFAULT There is no active transmission.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Send given number of datum from buffer through UART.
 *
 * Function returns immediately and event handler,
 * set using @ref uart_callback_set, is called after transfer is finished.
 *
 * @param dev     UART device instance.
 * @param buf     Pointer to wide data transmit buffer.
 * @param len     Length of wide data transmit buffer.
 * @param timeout Timeout in milliseconds. Valid only if flow control is
 *		  enabled. @ref SYS_FOREVER_MS disables timeout.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EBUSY If there is already an ongoing transfer.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Send given number of bytes from buffer through UART.
 *
 * Function returns immediately and event handler,
 * set using @ref uart_callback_set, is called after transfer is finished.
 *
 * @param dev     UART device instance.
 * @param buf     Pointer to transmit buffer.
 * @param len     Length of transmit buffer.
 * @param timeout Timeout in microseconds. Valid only if flow control is
 *		  enabled. @ref SYS_FOREVER_US disables timeout.
 *
 * @retval 0 If successful.
 * @retval -ENOTSUP If API is not enabled.
 * @retval -EBUSY If There is already an ongoing transfer.
 * @retval -errno Other negative errno value in case of failure.
 *//**
 * @brief Set event handler function.
 *
 * Since it is mandatory to set callback to use other asynchronous functions,
 * it can be used to detect if the device supports asynchronous API. Remaining
 * API does not have that detection.
 *
 * @param dev       UART device instance.
 * @param callback  Event handler.
 * @param user_data Data to pass to event handler function.
 *
 * @retval 0 If successful.
 * @retval -ENOSYS If not supported by the device.
 * @retval -ENOTSUP If API not enabled.
 *//**
 * @addtogroup uart_async
 * @{
 *//**
 * @brief Set the IRQ callback function pointer (legacy).
 *
 * This sets up the callback for IRQ. When an IRQ is triggered,
 * the specified function will be called with the device pointer.
 *
 * @param dev UART device instance.
 * @param cb Pointer to the callback function.
 *
 * @retval 0 On success.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Set the IRQ callback function pointer.
 *
 * This sets up the callback for IRQ. When an IRQ is triggered,
 * the specified function will be called with specified user data.
 * See description of uart_irq_update() for the requirements on ISR.
 *
 * @param dev UART device instance.
 * @param cb Pointer to the callback function.
 * @param user_data Data to pass to callback function.
 *
 * @retval 0 On success.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Start processing interrupts in ISR.
 *
 * This function should be called the first thing in the ISR. Calling
 * uart_irq_rx_ready(), uart_irq_tx_ready(), uart_irq_tx_complete()
 * allowed only after this.
 *
 * The purpose of this function is:
 *
 * * For devices with auto-acknowledge of interrupt status on register
 *   read to cache the value of this register (rx_ready, etc. then use
 *   this case).
 * * For devices with explicit acknowledgment of interrupts, to ack
 *   any pending interrupts and likewise to cache the original value.
 * * For devices with implicit acknowledgment, this function will be
 *   empty. But the ISR must perform the actions needs to ack the
 *   interrupts (usually, call uart_fifo_read() on rx_ready, and
 *   uart_fifo_fill() on tx_ready).
 *
 * @param dev UART device instance.
 *
 * @retval 1 On success.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Check if any IRQs is pending.
 *
 * @param dev UART device instance.
 *
 * @retval 1 If an IRQ is pending.
 * @retval 0 If an IRQ is not pending.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Disable error interrupt.
 *
 * @param dev UART device instance.
 *//**
 * @brief Enable error interrupt.
 *
 * @param dev UART device instance.
 *//**
 * @brief Check if UART RX buffer has a received char
 *
 * @details Check if UART RX buffer has at least one pending character
 * (i.e. uart_fifo_read() will succeed and return non-zero). This function
 * must be called in a UART interrupt handler, or its result is undefined.
 * Before calling this function in the interrupt handler, uart_irq_update()
 * must be called once per the handler invocation. It's unspecified whether
 * condition as returned by this function is level- or edge- triggered (i.e.
 * if this function returns true when RX FIFO is non-empty, or when a new
 * char was received since last call to it). See description of
 * uart_fifo_read() for implication of this.
 *
 * @param dev UART device instance.
 *
 * @retval 1 If a received char is ready.
 * @retval 0 If a received char is not ready.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Check if UART TX block finished transmission
 *
 * @details Check if any outgoing data buffered in UART TX block was
 * fully transmitted and TX block is idle. When this condition is
 * true, UART device (or whole system) can be power off. Note that
 * this function is *not* useful to check if UART TX can accept more
 * data, use uart_irq_tx_ready() for that. This function must be called
 * in a UART interrupt handler, or its result is undefined. Before
 * calling this function in the interrupt handler, uart_irq_update()
 * must be called once per the handler invocation.
 *
 * @param dev UART device instance.
 *
 * @retval 1 If nothing remains to be transmitted.
 * @retval 0 If transmission is not completed.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Disable RX interrupt.
 *
 * @param dev UART device instance.
 *//**
 * @brief Enable RX interrupt.
 *
 * @param dev UART device instance.
 *//**
 * @brief Check if UART TX buffer can accept a new char
 *
 * @details Check if UART TX buffer can accept at least one character
 * for transmission (i.e. uart_fifo_fill() will succeed and return
 * non-zero). This function must be called in a UART interrupt
 * handler, or its result is undefined. Before calling this function
 * in the interrupt handler, uart_irq_update() must be called once per
 * the handler invocation.
 *
 * @param dev UART device instance.
 *
 * @retval 1 If TX interrupt is enabled and at least one char can be
 *           written to UART.
 * @retval 0 If device is not ready to write a new byte.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Disable TX interrupt in IER.
 *
 * @param dev UART device instance.
 *//**
 * @brief Enable TX interrupt in IER.
 *
 * @param dev UART device instance.
 *//**
 * @brief Read wide data from FIFO.
 *
 * @details This function is expected to be called from UART
 * interrupt handler (ISR), if uart_irq_rx_ready() returns true.
 * Result of calling this function not from an ISR is undefined
 * (hardware-dependent). It's unspecified whether "RX ready"
 * condition as returned by uart_irq_rx_ready() is level- or
 * edge- triggered. That means that once uart_irq_rx_ready() is
 * detected, uart_fifo_read() must be called until it reads all
 * available data in the FIFO (i.e. until it returns less data
 * than was requested).
 *
 * @param dev UART device instance.
 * @param rx_data Wide data container.
 * @param size Container size.
 *
 * @return Number of datum read.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Read data from FIFO.
 *
 * @details This function is expected to be called from UART
 * interrupt handler (ISR), if uart_irq_rx_ready() returns true.
 * Result of calling this function not from an ISR is undefined
 * (hardware-dependent). It's unspecified whether "RX ready"
 * condition as returned by uart_irq_rx_ready() is level- or
 * edge- triggered. That means that once uart_irq_rx_ready() is
 * detected, uart_fifo_read() must be called until it reads all
 * available data in the FIFO (i.e. until it returns less data
 * than was requested).
 *
 * @param dev UART device instance.
 * @param rx_data Data container.
 * @param size Container size.
 *
 * @return Number of bytes read.
 * @retval -ENOSYS If this function is not implemented.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Fill FIFO with wide data.
 *
 * @details This function is expected to be called from UART
 * interrupt handler (ISR), if uart_irq_tx_ready() returns true.
 * Result of calling this function not from an ISR is undefined
 * (hardware-dependent). Likewise, *not* calling this function
 * from an ISR if uart_irq_tx_ready() returns true may lead to
 * undefined behavior, e.g. infinite interrupt loops. It's
 * mandatory to test return value of this function, as different
 * hardware has different FIFO depth (oftentimes just 1).
 *
 * @param dev UART device instance.
 * @param tx_data Wide data to transmit.
 * @param size Number of datum to send.
 *
 * @return Number of datum sent.
 * @retval -ENOSYS If this function is not implemented
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Fill FIFO with data.
 *
 * @details This function is expected to be called from UART
 * interrupt handler (ISR), if uart_irq_tx_ready() returns true.
 * Result of calling this function not from an ISR is undefined
 * (hardware-dependent). Likewise, *not* calling this function
 * from an ISR if uart_irq_tx_ready() returns true may lead to
 * undefined behavior, e.g. infinite interrupt loops. It's
 * mandatory to test return value of this function, as different
 * hardware has different FIFO depth (oftentimes just 1).
 *
 * @param dev UART device instance.
 * @param tx_data Data to transmit.
 * @param size Number of bytes to send.
 *
 * @return Number of bytes sent.
 * @retval -ENOSYS  if this function is not supported
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @addtogroup uart_interrupt
 * @{
 *//**
 * @brief Get UART configuration.
 *
 * Stores current UART configuration to *cfg, can be used to retrieve initial
 * configuration after device was initialized using data from DTS.
 *
 * @param dev UART device instance.
 * @param cfg UART configuration structure.
 *
 * @retval 0 If successful.
 * @retval -errno Negative errno code in case of failure.
 * @retval -ENOSYS If driver does not support getting current configuration.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Set UART configuration.
 *
 * Sets UART configuration using data from *cfg.
 *
 * @param dev UART device instance.
 * @param cfg UART configuration structure.
 *
 * @retval 0 If successful.
 * @retval -errno Negative errno code in case of failure.
 * @retval -ENOSYS If configuration is not supported by device
 *                  or driver does not support setting configuration in runtime.
 * @retval -ENOTSUP If API is not enabled.
 *//**
 * @brief Write a 16-bit datum to the device for output.
 *
 * This routine checks if the transmitter is full. When the
 * transmitter is not full, it writes a 16-bit datum to the data
 * register. It waits and blocks the calling thread, otherwise. This
 * function is a blocking call.
 *
 * To send a datum when hardware flow control is enabled, the handshake
 * signal CTS must be asserted.
 *
 * @param dev UART device instance.
 * @param out_u16 Wide data to send.
 *//**
 * @brief Write a character to the device for output.
 *
 * This routine checks if the transmitter is full.  When the
 * transmitter is not full, it writes a character to the data
 * register. It waits and blocks the calling thread, otherwise. This
 * function is a blocking call.
 *
 * To send a character when hardware flow control is enabled, the handshake
 * signal CTS must be asserted.
 *
 * @param dev UART device instance.
 * @param out_char Character to send.
 *//**
 * @brief Read a 16-bit datum from the device for input.
 *
 * This routine checks if the receiver has valid data.  When the
 * receiver has valid data, it reads a 16-bit datum from the device,
 * stores to the location pointed to by p_u16, and returns 0 to the
 * calling thread. It returns -1, otherwise. This function is a
 * non-blocking call.
 *
 * @param dev UART device instance.
 * @param p_u16 Pointer to 16-bit data.
 *
 * @retval 0  If data arrived.
 * @retval -1 If no data was available to read (i.e., the UART
 *            input buffer was empty).
 * @retval -ENOTSUP If API is not enabled.
 * @retval -ENOSYS If the function is not implemented.
 * @retval -EBUSY If async reception was enabled using @ref uart_rx_enable
 *//**
 * @brief Read a character from the device for input.
 *
 * This routine checks if the receiver has valid data.  When the
 * receiver has valid data, it reads a character from the device,
 * stores to the location pointed to by p_char, and returns 0 to the
 * calling thread. It returns -1, otherwise. This function is a
 * non-blocking call.
 *
 * @param dev UART device instance.
 * @param p_char Pointer to character.
 *
 * @retval 0 If a character arrived.
 * @retval -1 If no character was available to read (i.e. the UART
 *            input buffer was empty).
 * @retval -ENOSYS If the operation is not implemented.
 * @retval -EBUSY If async reception was enabled using @ref uart_rx_enable
 *//**
 * @defgroup uart_polling Polling UART API
 * @{
 *//**
 * @brief Check whether an error was detected.
 *
 * @param dev UART device instance.
 *
 * @retval 0 If no error was detected.
 * @retval err Error flags as defined in @ref uart_rx_stop_reason
 * @retval -ENOSYS If not implemented.
 *//** Set the irq callback function *//** Interrupt driven interrupt update function *//** Interrupt driven pending status function *//** Interrupt driven error disabling function *//** Interrupt driven error enabling function *//** Interrupt driven receiver ready function *//** Interrupt driven transfer complete function *//** Interrupt driven receiver disabling function *//** Interrupt driven receiver enabling function *//** Interrupt driven transfer ready function *//** Interrupt driven transfer disabling function *//** Interrupt driven transfer enabling function *//** Interrupt driven FIFO read function *//** Interrupt driven FIFO fill function *//** UART configuration functions *//** Console I/O function *//** @brief Driver API structure. *//**
 * @cond INTERNAL_HIDDEN
 *
 * For internal driver use only, skip these in public documentation.
 *//**
 * @typedef uart_callback_t
 * @brief Define the application callback function signature for
 * uart_callback_set() function.
 *
 * @param dev UART device instance.
 * @param evt Pointer to uart_event instance.
 * @param user_data Pointer to data specified by user.
 *//** @brief #UART_RX_STOPPED event data. *//** @brief #UART_RX_BUF_RELEASED event data. *//** @brief #UART_RX_RDY event data. *//** @brief #UART_TX_DONE and #UART_TX_ABORTED events data. *//** @brief Event data *//** @brief Type of event *//** @brief Structure containing information about current event. *//** @brief Last received data. *//** @brief Reason why receiving stopped *//** @brief UART RX stopped data. *//** @brief Pointer to buffer that is no longer in use. *//** @brief UART RX buffer released event data. *//** @brief Number of new bytes received. *//** @brief Currently received data offset in bytes. *//** @brief Pointer to current buffer. *//**
 * @brief UART RX event data.
 *
 * The data represented by the event is stored in rx.buf[rx.offset] to
 * rx.buf[rx.offset+rx.len].  That is, the length is relative to the offset.
 *//** @brief Number of bytes sent. *//** @brief UART TX event data. *//**
	 * @brief RX has stopped due to external event.
	 *
	 * Reason is one of uart_rx_stop_reason.
	 *//**
	 * @brief RX has been disabled and can be reenabled.
	 *
	 * This event is generated whenever receiver has been stopped, disabled
	 * or finished its operation and can be enabled again using
	 * uart_rx_enable
	 *//**
	 * @brief Buffer is no longer used by UART driver.
	 *//**
	 * @brief Driver requests next buffer for continuous reception.
	 *
	 * This event is triggered when receiving has started for a new buffer,
	 * i.e. it's time to provide a next buffer for a seamless switchover to
	 * it. For continuous reliable receiving, user should provide another RX
	 * buffer in response to this event, using uart_rx_buf_rsp function
	 *
	 * If uart_rx_buf_rsp is not called before current buffer
	 * is filled up, receiving will stop.
	 *//**
	 * @brief Received data is ready for processing.
	 *
	 * This event is generated in the following cases:
	 * - When RX timeout occurred, and data was stored in provided buffer.
	 *   This can happen multiple times in the same buffer.
	 * - When provided buffer is full.
	 * - After uart_rx_disable().
	 * - After stopping due to external event (#UART_RX_STOPPED).
	 *//**
	 * @brief Transmitting aborted due to timeout or uart_tx_abort call
	 *
	 * When flow control is enabled, there is a possibility that TX transfer
	 * won't finish in the allotted time. Some data may have been
	 * transferred, information about it can be found in event data.
	 *//** @brief Whole TX buffer was transmitted. *//**
 * @brief Types of events passed to callback in UART_ASYNC_API
 *
 * Receiving:
 * 1. To start receiving, uart_rx_enable has to be called with first buffer
 * 2. When receiving starts to current buffer,
 *    #UART_RX_BUF_REQUEST will be generated, in response to that user can
 *    either:
 *
 *    - Provide second buffer using uart_rx_buf_rsp, when first buffer is
 *      filled, receiving will automatically start to second buffer.
 *    - Ignore the event, this way when current buffer is filled
 *      #UART_RX_RDY event will be generated and receiving will be stopped.
 *
 * 3. If some data was received and timeout occurred #UART_RX_RDY event will be
 *    generated. It can happen multiples times for the same buffer. RX timeout
 *    is counted from last byte received i.e. if no data was received, there
 *    won't be any timeout event.
 * 4. #UART_RX_BUF_RELEASED event will be generated when the current buffer is
 *    no longer used by the driver. It will immediately follow #UART_RX_RDY event.
 *    Depending on the implementation buffer may be released when it is completely
 *    or partially filled.
 * 5. If there was second buffer provided, it will become current buffer and
 *    we start again at point 2.
 *    If no second buffer was specified receiving is stopped and
 *    #UART_RX_DISABLED event is generated. After that whole process can be
 *    repeated.
 *
 * Any time during reception #UART_RX_STOPPED event can occur. if there is any
 * data received, #UART_RX_RDY event will be generated. It will be followed by
 * #UART_RX_BUF_RELEASED event for every buffer currently passed to driver and
 * finally by #UART_RX_DISABLED event.
 *
 * Receiving can be disabled using uart_rx_disable, after calling that
 * function, if there is any data received, #UART_RX_RDY event will be
 * generated. #UART_RX_BUF_RELEASED event will be generated for every buffer
 * currently passed to driver and finally #UART_RX_DISABLED event will occur.
 *
 * Transmitting:
 * 1. Transmitting starts by uart_tx function.
 * 2. If whole buffer was transmitted #UART_TX_DONE is generated. If timeout
 *    occurred #UART_TX_ABORTED will be generated.
 *
 * Transmitting can be aborted using @ref uart_tx_abort, after calling that
 * function #UART_TX_ABORTED event will be generated.
 *
 *//**
 * @}
 *
 * @defgroup uart_async Async UART API
 * @{
 *//**
 * @brief For configuring IRQ on each individual UART device.
 *
 * @param dev UART device instance.
 *//**
 * @brief Define the application callback function signature for
 * uart_irq_callback_user_data_set() function.
 *
 * @param dev UART device instance.
 * @param user_data Arbitrary user data.
 *//**
 * @defgroup uart_interrupt Interrupt-driven UART API
 * @{
 *//**< Flow control setting, use @ref uart_config_flow_control *//**< Data bits, use @ref uart_config_data_bits *//**< Stop bits, use @ref uart_config_stop_bits *//**< Parity bit, use @ref uart_config_parity *//**< Baudrate setting in bps *//**
 * @brief UART controller configuration structure
 *//**< RS485 flow control *//**< DTR/DSR flow control *//**< RTS/CTS flow control *//**< No flow control *//**
 * @brief Hardware flow control options.
 *
 * With flow control set to none, any operations related to flow control
 * signals can be managed by user with uart_line_ctrl functions.
 * In other cases, flow control is managed by hardware/driver.
 *//**< 9 data bits *//**< 8 data bits *//**< 7 data bits *//**< 6 data bits *//**< 5 data bits *//** @brief Number of data bits. *//**< 2 stop bits *//**< 1.5 stop bits *//**< 1 stop bit *//**< 0.5 stop bit *//** @brief Number of stop bits. *//**< Space parity *//**< Mark parity *//**< Even parity *//**< Odd parity *//**< No parity *//** @brief Parity modes *//** @brief Noise error *//**
	 * @brief Collision error
	 *
	 * This error is raised when transmitted data does not match
	 * received data. Typically this is useful in scenarios where
	 * the TX and RX lines maybe connected together such as
	 * RS-485 half-duplex. This error is only valid on UARTs that
	 * support collision checking.
	 *//**
	 * @brief Break interrupt
	 *
	 * A break interrupt was received. This happens when the serial input
	 * is held at a logic '0' state for longer than the sum of
	 * start time + data bits + parity + stop bits.
	 *//** @brief Framing error *//** @brief Parity error *//** @brief Overrun error *//**
 * @brief Reception stop reasons.
 *
 * Values that correspond to events or errors responsible for stopping
 * receiving.
 *//**< Data Set Ready (DSR) *//**< Data Carrier Detect (DCD) *//**< Data Terminal Ready (DTR) *//**< Request To Send (RTS) *//**< Baud rate *//** @brief Line control signals. *//**
 * @brief UART Interface
 * @defgroup uart_interface UART Interface
 * @ingroup io_interfaces
 * @{
 *//**
 * @file
 * @brief Public APIs for UART drivers
 *//*
 * Copyright (c) 2018-2019 Nordic Semiconductor ASA
 * Copyright (c) 2015 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/console/console.hconsole_input_fnconsole_inputchar[128]lineis_mcumgr_unusedCONSOLE_MAX_LINE_LENZEPHYR_INCLUDE_DRIVERS_CONSOLE_CONSOLE_H_/* ZEPHYR_INCLUDE_DRIVERS_CONSOLE_CONSOLE_H_ *//** @brief Console input processing handler signature
 *
 *  Input processing is started when string is typed in the console.
 *  Carriage return is translated to NULL making string always NULL
 *  terminated. Application before calling register function need to
 *  initialize two fifo queues mentioned below.
 *
 *  @param avail k_fifo queue keeping available input slots
 *  @param lines k_fifo queue of entered lines which to be processed
 *         in the application code.
 *  @param completion callback for tab completion of entered commands
 *//** Buffer where the input line is recorded *//** Whether this is an mcumgr command *//** FIFO uses first word itself, reserve space *//** @brief Console input representation
 *
 * This struct is used to represent an input line from a console.
 * Recorded line must be NULL terminated.
 *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/console/home/haojie/zephyrproject/zephyr/include/zephyr/drivers/console/uart_console.hZEPHYR_INCLUDE_DRIVERS_CONSOLE_UART_CONSOLE_H_CONFIG_UART_CONSOLE_DEBUG_SERVER_HOOKSuart_register_input/* ZEPHYR_INCLUDE_DRIVERS_CONSOLE_UART_CONSOLE_H_ *//*
 * Allows having debug hooks in the console driver for handling incoming
 * control characters, and letting other ones through.
 *//** @brief Register uart input processing
 *
 *  Input processing is started when string is typed in the console.
 *  Carriage return is translated to NULL making string always NULL
 *  terminated. Application before calling register function need to
 *  initialize two fifo queues mentioned below.
 *
 *  @param avail k_fifo queue keeping available input slots
 *  @param lines k_fifo queue of entered lines which to be processed
 *         in the application code.
 *  @param completion callback for tab completion of entered commands
 *//*
 * Copyright (c) 2011, 2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* uart_console.h - uart console driver */availlinescompletion/home/haojie/zephyrproject/zephyr/include/zephyr/pm/device_runtime.hpm_device_runtime_is_enabledpm_device_runtime_put_asyncpm_device_runtime_putpm_device_runtime_getpm_device_runtime_disablepm_device_runtime_enablepm_device_runtime_auto_enableZEPHYR_INCLUDE_PM_DEVICE_RUNTIME_H_/* ZEPHYR_INCLUDE_PM_DEVICE_RUNTIME_H_ *//**
 * @brief Check if device runtime is enabled for a given device.
 *
 * @funcprops \pre_kernel_ok
 *
 * @param dev Device instance.
 *
 * @retval true If device has device runtime PM enabled.
 * @retval false If the device has device runtime PM disabled.
 *
 * @see pm_device_runtime_enable()
 *//**
 * @brief Suspend a device based on usage count (asynchronously).
 *
 * This function will schedule the device suspension if the device is no longer
 * required (usage count equal to 0). In all other cases, usage count will be
 * decremented (down to 0).
 *
 * @note Asynchronous operations are not supported when in pre-kernel mode. In
 * this case, the function will be blocking (equivalent to
 * pm_device_runtime_put()).
 *
 * @funcprops \pre_kernel_ok, \async, \isr_ok
 *
 * @param dev Device instance.
 *
 * @retval 0 If it succeeds. In case device runtime PM is not enabled or not
 * available this function will be a no-op and will also return 0.
 * @retval -EBUSY If the device is busy.
 * @retval -EALREADY If device is already suspended (can only happen if get/put
 * calls are unbalanced).
 *
 * @see pm_device_runtime_put()
 *//**
 * @brief Suspend a device based on usage count.
 *
 * This function will suspend the device if the device is no longer required
 * (usage count equal to 0). In case of suspend failure, usage count and device
 * state will be left unchanged. In all other cases, usage count will be
 * decremented (down to 0).
 *
 * @funcprops \pre_kernel_ok
 *
 * @param dev Device instance.
 *
 * @retval 0 If it succeeds. In case device runtime PM is not enabled or not
 * available this function will be a no-op and will also return 0.
 * @retval -EALREADY If device is already suspended (can only happen if get/put
 * calls are unbalanced).
 * @retval -errno Other negative errno, result of the action callback.
 *
 * @see pm_device_runtime_put_async()
 *//**
 * @brief Resume a device based on usage count.
 *
 * This function will resume the device if the device is suspended (usage count
 * equal to 0). In case of a resume failure, usage count and device state will
 * be left unchanged. In all other cases, usage count will be incremented.
 *
 * If the device is still being suspended as a result of calling
 * pm_device_runtime_put_async(), this function will wait for the operation to
 * finish to then resume the device.
 *
 * @note It is safe to use this function in contexts where blocking is not
 * allowed, e.g. ISR, provided the device PM implementation does not block.
 *
 * @funcprops \pre_kernel_ok
 *
 * @param dev Device instance.
 *
 * @retval 0 If it succeeds. In case device runtime PM is not enabled or not
 * available this function will be a no-op and will also return 0.
 * @retval -EWOUDBLOCK If call would block but it is not allowed (e.g. in ISR).
 * @retval -errno Other negative errno, result of the PM action callback.
 *//**
 * @brief Disable device runtime PM
 *
 * If the device is currently suspended it will be resumed.
 *
 * @funcprops \pre_kernel_ok
 *
 * @param dev Device instance.
 *
 * @retval 0 If the device runtime PM is disabled successfully.
 * @retval -ENOTSUP If the device does not support PM.
 * @retval -errno Other negative errno, result of resuming the device.
 *//**
 * @brief Enable device runtime PM
 *
 * This function will enable runtime PM on the given device. If the device is
 * in #PM_DEVICE_STATE_ACTIVE state, the device will be suspended.
 *
 * @funcprops \pre_kernel_ok
 *
 * @param dev Device instance.
 *
 * @retval 0 If the device runtime PM is enabled successfully.
 * @retval -EPERM If device has power state locked.
 * @retval -ENOTSUP If the device does not support PM.
 * @retval -errno Other negative errno, result of suspending the device.
 *
 * @see pm_device_init_suspended()
 *//**
 * @brief Automatically enable device runtime based on devicetree properties
 *
 * @note Must not be called from application code. See the
 * zephyr,pm-device-runtime-auto property in pm.yaml and z_sys_init_run_level.
 *
 * @param dev Device instance.
 *
 * @retval 0 If the device runtime PM is enabled successfully or it has not
 * been requested for this device in devicetree.
 * @retval -errno Other negative errno, result of enabled device runtime PM.
 *//**
 * @brief Device Runtime Power Management API
 * @defgroup subsys_pm_device_runtime Device Runtime
 * @ingroup subsys_pm
 * @{
 *//*
 * Copyright (c) 2015 Intel Corporation.
 * Copyright (c) 2021 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/drivers/console/uart_console.c<zephyr/pm/device_runtime.h><zephyr/drivers/console/uart_console.h><zephyr/drivers/console/console.h><zephyr/drivers/uart.h>uart_console_init-19-ENODEVuart_console_hook_install__printk_hook_install__stdout_hook_installconsole_outconst init_entry__init_uart_console_initPRE_KERNEL_1struct init_entry.z_init_PRE_KERNEL_160_0___init_const device *constuart_console_devCONFIG_UART_CONSOLE_MCUMGRdefined(CONFIG_PRINTK) || defined(CONFIG_STDOUT_CONSOLE)defined(CONFIG_STDOUT_CONSOLE)defined(CONFIG_PRINTK)defined(CONFIG_CONSOLE_HANDLER)defined(CONFIG_EARLY_CONSOLE)__alignof(struct init_entry)/* UART console initializes after the UART device itself *//**
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 *//**
 * @brief Install printk/stdout hook for UART console output
 *//* Drain the fifo *//* Ignore characters if there's no more buffer space *//* break to avoid double line*//* Handle special control characters *//* Handle escape mode *//* Handle ANSI escape mode *//* CONFIG_UART_CONSOLE_MCUMGR *//* Divert this byte from normal console handling if it is part
		 * of an mcumgr frame.
		 *//*
			 * The input hook indicates that no further processing
			 * should be done by this handler.
			 *//* Character(s) have been received *//* The received byte is part of an mcumgr command.  Process the byte
	 * and return true to indicate that normal console handling should
	 * ignore it.
	 *//* Not an mcumgr command; let the normal console handling
		 * process the byte.
		 *//**
 * @brief Attempts to process a received byte as part of an mcumgr frame.
 *
 * @param cmd The console command currently being received.
 * @param byte The byte just received.
 *
 * @return true if the command being received is an mcumgr frame; false if it
 * is a plain console command.
 *//* Non-mcumgr byte received. *//* First framing byte received. *//* Final framing byte received. *//* Already fully framed. *//**
 * These states indicate whether an mcumgr frame is being received.
 *//* Multi value sequence, e.g. Esc[Line;ColumnH *//* Move cursor back to right place *//* Echo back to console *//* Overrun issue. Stop the UART *//* ANSI escape sequences *//* Control characters *//* As errors cannot be returned, ignore the return value *//* Enabling the UART instance has failed but this
			 * function MUST return the byte output.
			 *//* CONFIG_UART_CONSOLE_DEBUG_SERVER_HOOKS *//**
 *
 * @brief Output one character to UART
 *
 * Outputs both line feed and carriage return in the case of a '\n'.
 *
 * @param c Character to output
 *
 * @return The character passed as input.
 *//**
 * @file
 * @brief UART-driven console
 *
 *
 * Serial console driver.
 * Hooks into the printk and fputc (for printf) modules. Poll driven.
 *//*
 * Copyright (c) 2011-2012, 2014-2015 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/drivers/console/home/haojie/zephyrproject/zephyr/drivershook/home/haojie/zephyrproject/zephyr/drivers/interrupt_controller/intc_ioapic_priv.hIOAPIC_VTD_INDEX(index)(index << 17)IOAPIC_VTD_REMAP_FORMATIOAPIC_VEC_MASK0x000000ffIOAPIC_DESTINATION0xff000000IOAPIC_VERSIONIOAPIC_PRQ0x00008000IOAPIC_MRE_POSIOAPIC_MRE_MASK0x00ff0000IOAPIC_DT_FSIOAPIC_DT_APICIOAPIC_REDTBLIOAPIC_BOOTIOAPIC_ARBIOAPIC_VERSIOAPIC_IDIOAPIC_EOI0x40IOAPIC_IRQPAIOAPIC_DATAIOAPIC_INDZEPHYR_DRIVERS_INTERRUPT_CONTROLLER_INTC_IOAPIC_PRIV_H_/* ZEPHYR_DRIVERS_INTERRUPT_CONTROLLER_INTC_IOAPIC_PRIV_H_ *//* We care only about the first 14 bits.
 * The 15th bits is in the first 32bits of RTE but since
 * we don't go up to that value, let's ignore it.
 *//* VTD related macros *//* Redirection table entry bits: lower 32 bit *//* Redirection table entry bits: upper 32 bit *//* version number *//* this has IRQ reg *//* Max Red. entry mask *//* Version register bits *//* Front side bus message*//* APIC serial bus *//* Interrupt delivery type *//* Redirection Table (24 * 64bit) *//* IOAPIC Boot Configuration *//* IOAPIC Arbitration ID *//* IOAPIC Version *//* IOAPIC ID *//* IO APIC indirect register offset *//* EOI Register *//* IRQ Pin Assertion Register *//* IO window (data) - pc.h *//* Index Register *//* IO APIC direct register offsets *//*
 * Copyright (c) 2012-2015 Wind River Systems, Inc.
 * Copyright (c) 2015 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* ioapic_priv.h - private IOAPIC APIs *//home/haojie/zephyrproject/zephyr/drivers/interrupt_controller/home/haojie/zephyrproject/zephyr/include/zephyr/drivers/interrupt_controller/ioapic.h/home/haojie/zephyrproject/zephyr/drivers/interrupt_controller/intc_ioapic.c"intc_ioapic_priv.h"<zephyr/drivers/interrupt_controller/ioapic.h>IoApicRedUpdateLoioApicRedSetHiioApicRedSetLoioApicRedGetLo__IoApicSetioapic_regs__IoApicGetz_ioapic_int_vec_setz_ioapic_irq_setrteValueIOAPIC_INT_MASKIOAPIC_LOGICAL67584-167772164278190080DEFAULT_RTE_DESTz_ioapic_irq_disablez_ioapic_irq_enablez_ioapic_num_rtesioapic_initixIOAPIC_FIXED__init___device_dts_ord_15ioapic_init, PM_DEVICE_DT_INST_GET(0), NULL, NULL, PRE_KERNEL_1, CONFIG_INTC_INIT_PRIORITY, NULLioapic_init, ((void *)0), ((void *)0), ((void *)0), PRE_KERNEL_1, 40, ((void *)0)DT_DRV_INST(0)DEVICE_DT_NAME(DT_N_S_ioapic_fec00000)&Z_DEVICE_STATE_NAME(Z_DEVICE_DT_DEV_ID(DT_N_S_ioapic_fec00000))&__devstate_dts_ord_15Z_DEVICE_INIT_SUB_PRIO(DT_N_S_ioapic_fec00000).z_init_PRE_KERNEL_140_00015_char[30]DEVICE_NAME_GET(dts_ord_15)._device.static.1_40_Z_DEVICE_DEPS_NAME(dts_ord_15)Z_DEVICE_SECTION_NAME(PRE_KERNEL_1, 40)1_40_CONCAT(1_40, _)1_40_char[22](.deps = (Z_DEVICE_DEPS_NAME(dts_ord_15)),)_XXXXCONFIG_DEVICE_DEPS_XXXXCONFIG_DEVICE_DEPS (.deps = (Z_DEVICE_DEPS_NAME(dts_ord_15)),)(.pm = (((void *)0)),)_XXXXCONFIG_PM_DEVICE_XXXXCONFIG_PM_DEVICE (.pm = (((void *)0)),)_FULL_NAMEioapic@fec00000__devstate___devstate_dts_ord_15.z_devstatestruct device_stateioapic_rtesz_mmio_rom__ioapic_regsz_mmio_ram__ioapic_regs(0xFF << 24)IOAPIC_REGDEVICE_MMIO_TOPLEVEL_GET(ioapic_regs)DT_DRV_COMPATdefined(CONFIG_INTEL_VTD_ICTL) &&				\__alignof(struct device_state)DT_N_INSTDT_DASH(0, intel_ioapic)_0_intel_ioapic0, intel_ioapicDT_DASH_PREFIX, 0, intel_ioapicNUM_VA_ARGS_LESS_1(DT_DASH_PREFIX, 0, intel_ioapic)MACRO_MC_DT_DASH_PREFIXintel_ioapic,DT_DASH_PREFIX(0)MACRO_MC_1(DT_DASH_PREFIX, intel_ioapic,,)_intel_ioapicioapic_pm_actionZ_DEVICE_DT_DEV_ID(DT_DRV_INST(0))DT_NODE_EXISTS(DT_N_S_ioapic_fec00000)(DT_DEP_ORD_STR_SORTABLE(DT_N_S_ioapic_fec00000))(00015)_ORD_STR_SORTABLEDT_CAT(DT_N_S_ioapic_fec00000, _EXISTS)__alignof(struct device)INIT_LEVEL_ORD(PRE_KERNEL_1)Z_INIT_EARLY_PRE_KERNEL_1(Z_INIT_ORD_EARLY)(COND_CODE_1(Z_INIT_PRE_KERNEL_1_PRE_KERNEL_1, (Z_INIT_ORD_PRE_KERNEL_1), (COND_CODE_1(Z_INIT_PRE_KERNEL_2_PRE_KERNEL_1, (Z_INIT_ORD_PRE_KERNEL_2), (COND_CODE_1(Z_INIT_POST_KERNEL_PRE_KERNEL_1, (Z_INIT_ORD_POST_KERNEL), (COND_CODE_1(Z_INIT_APPLICATION_PRE_KERNEL_1, (Z_INIT_ORD_APPLICATION), (COND_CODE_1(Z_INIT_SMP_PRE_KERNEL_1, (Z_INIT_ORD_SMP), (ZERO_OR_COMPILE_ERROR(0))))))))))))_XXXXZ_INIT_EARLY_PRE_KERNEL_1_XXXXZ_INIT_EARLY_PRE_KERNEL_1 (0)(Z_INIT_ORD_PRE_KERNEL_1)(COND_CODE_1(Z_INIT_PRE_KERNEL_2_PRE_KERNEL_1, (Z_INIT_ORD_PRE_KERNEL_2), (COND_CODE_1(Z_INIT_POST_KERNEL_PRE_KERNEL_1, (Z_INIT_ORD_POST_KERNEL), (COND_CODE_1(Z_INIT_APPLICATION_PRE_KERNEL_1, (Z_INIT_ORD_APPLICATION), (COND_CODE_1(Z_INIT_SMP_PRE_KERNEL_1, (Z_INIT_ORD_SMP), (ZERO_OR_COMPILE_ERROR(0))))))))))(((int) sizeof(char[1 - 2 * !(0)]) - 1))Z_INIT_PRE_KERNEL_2_PRE_KERNEL_1(Z_INIT_ORD_PRE_KERNEL_2)(2)(COND_CODE_1(Z_INIT_POST_KERNEL_PRE_KERNEL_1, (Z_INIT_ORD_POST_KERNEL), (COND_CODE_1(Z_INIT_APPLICATION_PRE_KERNEL_1, (Z_INIT_ORD_APPLICATION), (COND_CODE_1(Z_INIT_SMP_PRE_KERNEL_1, (Z_INIT_ORD_SMP), (ZERO_OR_COMPILE_ERROR(0))))))))_XXXXZ_INIT_PRE_KERNEL_2_PRE_KERNEL_1_XXXXZ_INIT_PRE_KERNEL_2_PRE_KERNEL_1 (2)((int) sizeof(char[1 - 2 * !(0)]) - 1)Z_INIT_POST_KERNEL_PRE_KERNEL_1(Z_INIT_ORD_POST_KERNEL)(3)(COND_CODE_1(Z_INIT_APPLICATION_PRE_KERNEL_1, (Z_INIT_ORD_APPLICATION), (COND_CODE_1(Z_INIT_SMP_PRE_KERNEL_1, (Z_INIT_ORD_SMP), (ZERO_OR_COMPILE_ERROR(0))))))_XXXXZ_INIT_POST_KERNEL_PRE_KERNEL_1_XXXXZ_INIT_POST_KERNEL_PRE_KERNEL_1 (3)Z_INIT_APPLICATION_PRE_KERNEL_1(Z_INIT_ORD_APPLICATION)(4)(COND_CODE_1(Z_INIT_SMP_PRE_KERNEL_1, (Z_INIT_ORD_SMP), (ZERO_OR_COMPILE_ERROR(0))))_XXXXZ_INIT_APPLICATION_PRE_KERNEL_1_XXXXZ_INIT_APPLICATION_PRE_KERNEL_1 (4)Z_INIT_SMP_PRE_KERNEL_1(Z_INIT_ORD_SMP)(5)(ZERO_OR_COMPILE_ERROR(0))_XXXXZ_INIT_SMP_PRE_KERNEL_1_XXXXZ_INIT_SMP_PRE_KERNEL_1 (5)(static)(Z_DEVICE_DEPS_DEFINE(DT_N_S_ioapic_fec00000, dts_ord_15, );)_XXXXCONFIG_DEVICE_DEPS (Z_DEVICE_DEPS_DEFINE(DT_N_S_ioapic_fec00000, dts_ord_15, );)DEVICE_NAME_GET("ioapic@fec00000")sizeof(Z_STRINGIFY("ioapic@fec00000")) <= Z_DEVICE_MAX_NAME_LENsizeof("\"ioapic@fec00000\"") <= 48UZ_STRINGIFY(DEVICE_NAME_GET("ioapic@fec00000")) " too long""DEVICE_NAME_GET(\"ioapic@fec00000\")" " too long"labelDT_NODE_FULL_NAME(DT_N_S_ioapic_fec00000)DT_NODE_HAS_PROP(DT_N_S_ioapic_fec00000, label)(DT_PROP(DT_N_S_ioapic_fec00000, label))(DT_N_S_ioapic_fec00000_P_label)("ioapic@fec00000")_XXXX0 (DT_N_S_ioapic_fec00000_P_label)DT_CAT4(DT_N_S_ioapic_fec00000, _P_, label, _EXISTS)DT_N_S_ioapic_fec00000_P_label_EXISTS_XXXXDT_N_S_ioapic_fec00000_P_label_EXISTS_XXXXDT_N_S_ioapic_fec00000_P_label_EXISTS 1/**
 * @brief Modify low 32 bits of Redirection Table entry
 *
 * This routine modifies selected portions of the low-order 32 bits of a
 * Redirection Table entry, as indicated by the associate bit mask.
 *
 * @param irq INTIN number
 * @param value Value to be written
 * @param mask  Mask of bits to be modified
 *//* register offset *//**
 * @brief Set high 32 bits of Redirection Table entry
 *
 * This routine writes the high-order 32 bits of a Redirection Table entry.
 *
 * @param irq INTIN number
 * @param upper32 Value to be written
 *//**
 * @brief Set low 32 bits of Redirection Table entry
 *
 * This routine writes the low-order 32 bits of a Redirection Table entry.
 *
 * @param irq INTIN number
 * @param lower32 Value to be written
 *//**
 * @brief Get low 32 bits of Redirection Table entry
 *
 * This routine reads the low-order 32 bits of a Redirection Table entry.
 *
 * @param irq INTIN number
 * @return 32 low-order bits
 *//* lock interrupts to ensure indirect addressing works "atomically" *//* interrupt lock level *//**
 * @brief Write a 32 bit IO APIC register
 *
 * This routine writes the specified IO APIC register using indirect addressing.
 *
 * @param offset Register offset (8 bits)
 * @param value Value to set the register
 *//* value *//**
 * @brief Read a 32 bit IO APIC register
 *
 * This routine reads the specified IO APIC register using indirect addressing.
 * @param offset Register offset (8 bits)
 *
 * @return register value
 *//**
 * @brief Program interrupt vector for specified irq
 *
 * The routine writes the interrupt vector in the Interrupt Redirection
 * Table for specified irq number
 *
 * @param irq Interrupt number
 * @param vector Vector number
 *//* the delivery mode is determined by the flags
		 * passed from drivers
		 *//* CONFIG_INTEL_VTD_ICTL && !CONFIG_INTEL_VTD_ICTL_XAPIC_PASSTHROUGH *//* Remapped: delivery mode is Fixed (000) and
		 * destination mode is no longer present as it is replaced by
		 * the 15th bit of irte index, which is always 0 in our case.
		 *//* Enable interrupt remapping format and set the irte index *//* value to copy into redirection table entry *//**
 * @brief Programs the interrupt redirection table
 *
 * This routine sets up the redirection table entry for the specified IRQ
 * @param irq Virtualized IRQ
 * @param vector Vector number
 * @param flags Interrupt flags
 *//*CONFIG_PM_DEVICE*//*
* Implements the driver control management functionality
* the *context may include IN data or/and OUT data
*//* dummy vector*//* Initialize the other RTEs to sane values *//* Appending the flags that are never modified *//* Get the saved flags *//*
		 * The following check is to figure out the registered
		 * IRQ lines, so as to limit ourselves to saving the
		 *  flags for them only.
		 *//*
	 * We support lowest priority and fixed mode only, so only one bit
	 * needs to be saved.
	 *//* Currently only the following four flags are modified *//**
 * @brief Disable a specified APIC interrupt input line
 *
 * This routine disables a specified APIC interrupt input line.
 * @param irq IRQ number to disable
 *//**
 * @brief Enable a specified APIC interrupt input line
 *
 * This routine enables a specified APIC interrupt input line.
 *
 * @param irq IRQ number to enable
 *//* dummy vector *//* redirection table index *//* Reading MRE: this will give the number of RTEs available *//**
 * @brief Initialize the IO APIC or xAPIC
 *
 * This routine initializes the IO APIC or xAPIC.
 *
 * @retval 0 on success.
 *//*
 * The functions irq_enable() and irq_disable() are implemented in the
 * interrupt controller driver due to the IRQ virtualization imposed by
 * the x86 architecture.
 *//* CONFIG_INTEL_VTD_ICTL && !INTEL_VTD_ICTL_XAPIC_PASSTHROUGH *//* Assume only one PCH in system (say client platform). *//* Allocating up to 256 irq bits bufffer for RTEs, RTEs are dynamically found
 * so let's just assume the maximum, it's only 128 bytes in total.
 *//*
 * Destination field (bits[56:63]) defines a set of processors, which is
 * used to be compared with local LDR to determine which local APICs accept
 * the interrupt.
 *
 * XAPIC: in logical destination mode and flat model (determined by DFR).
 * LDR bits[24:31] can accommodate up to 8 logical APIC IDs.
 *
 * X2APIC: in logical destination mode and cluster model.
 * In this case, LDR is read-only to system software and supports up to 16
 * logical IDs. (Cluster ID: don't care to IO APIC).
 *
 * In either case, regardless how many CPUs in the system, 0xff implies that
 * it's intended to deliver to all possible 8 local APICs.
 *//* public API declarations and registers *//* public API declarations *//**
 * @file
 * @brief Intel IO APIC/xAPIC driver
 *
 * This module is a driver for the IO APIC/xAPIC (Advanced Programmable
 * Interrupt Controller) for P6 (PentiumPro, II, III) family processors
 * and P7 (Pentium4) family processors.  The IO APIC/xAPIC is included
 * in the Intel's system chip set, such as ICH2.  Software intervention
 * may be required to enable the IO APIC/xAPIC in some chip sets.
 * The 8259A interrupt controller is intended for use in a uni-processor
 * system, IO APIC can be used in either a uni-processor or multi-processor
 * system.  The IO APIC handles interrupts very differently than the 8259A.
 * Briefly, these differences are:
 *  - Method of Interrupt Transmission. The IO APIC transmits interrupts
 *    through a 3-wire bus and interrupts are handled without the need for
 *    the processor to run an interrupt acknowledge cycle.
 *  - Interrupt Priority. The priority of interrupts in the IO APIC is
 *    independent of the interrupt number.  For example, interrupt 10 can
 *    be given a higher priority than interrupt 3.
 *  - More Interrupts. The IO APIC supports a total of 24 interrupts.
 *
 * The IO APIC unit consists of a set of interrupt input signals, a 24-entry
 * by 64-bit Interrupt Redirection Table, programmable registers, and a message
 * unit for sending and receiving APIC messages over the APIC bus or the
 * Front-Side (system) bus.  IO devices inject interrupts into the system by
 * asserting one of the interrupt lines to the IO APIC.  The IO APIC selects the
 * corresponding entry in the Redirection Table and uses the information in that
 * entry to format an interrupt request message.  Each entry in the Redirection
 * Table can be individually programmed to indicate edge/level sensitive interrupt
 * signals, the interrupt vector and priority, the destination processor, and how
 * the processor is selected (statically and dynamically).  The information in
 * the table is used to transmit a message to other APIC units (via the APIC bus
 * or the Front-Side (system) bus).  IO APIC is used in the Symmetric IO Mode.
 * The base address of IO APIC is determined in loapic_init() and stored in the
 * global variable ioApicBase and ioApicData.
 * The lower 32 bit value of the redirection table entries for IRQ 0
 * to 15 are edge triggered positive high, and for IRQ 16 to 23 are level
 * triggered positive low.
 *
 * This implementation doesn't support multiple IO APICs.
 *
 * INCLUDE FILES: ioapic.h loapic.h
 *
 *//*
 * Copyright (c) 1997-1998, 2000-2002, 2004, 2006-2008, 2011-2015 Wind River
 * Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */upper32lower32DEVICE_NAME_GET("ioapic@fec00000") too longIOAPIC_EXTINT0x00000700IOAPIC_INIT0x00000500IOAPIC_NMI0x00000400IOAPIC_SMI0x00000200IOAPIC_LOWEST0x000001000x00000000IOAPIC_DELIVERY_MODE_MASKIOAPIC_PHYSICAL0x00002000IOAPIC_POLARITY_MASKIOAPIC_REMOTE0x00004000IOAPIC_TRIGGER_MASKZEPHYR_INCLUDE_DRIVERS_IOAPIC_H_/* ZEPHYR_INCLUDE_DRIVERS_IOAPIC_H_ *//*
 * Redirection table entry bits: lower 32 bit
 * Used as flags argument in ioapic_irq_set
 *//*
 * Copyright (c) 2012-2015 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* ioapic.h - public IOAPIC APIs *//home/haojie/zephyrproject/zephyr/drivers/interrupt_controller/intc_loapic.cpRegblockblock > 0__builtin_expectoldLevel4294901759~LOAPIC_LVT_MASKEDLOAPIC_VECTOR4294967040~LOAPIC_VECTORloapic_initloApicMaxLvtLOAPIC_ENABLELOAPIC_MAXLVT_MASK0xffffffffLOAPIC_MODELOAPIC_LOW9984LOAPIC_LEVEL42752108288(LOAPIC_MODE | LOAPIC_LOW |
		  LOAPIC_LEVEL | LOAPIC_LVT_MASKED)4294859007~(LOAPIC_MODE | LOAPIC_LOW |
		  LOAPIC_LEVEL | LOAPIC_LVT_MASKED)LOAPIC_EXTLOAPIC_HIGHLOAPIC_EDGE(LOAPIC_EXT | LOAPIC_HIGH | LOAPIC_EDGE)LOAPIC_NMI(LOAPIC_NMI | LOAPIC_HIGH | LOAPIC_EDGE)LOAPIC_LVT_P6LOAPIC_LVT_PENTIUM4send_eoi__init___device_dts_ord_11loapic_init, PM_DEVICE_DT_INST_GET(0), NULL, NULL, PRE_KERNEL_1, CONFIG_INTC_INIT_PRIORITY, NULLloapic_init, ((void *)0), ((void *)0), ((void *)0), PRE_KERNEL_1, 40, ((void *)0)DEVICE_DT_NAME(DT_N_S_loapic_fee00000)&Z_DEVICE_STATE_NAME(Z_DEVICE_DT_DEV_ID(DT_N_S_loapic_fee00000))&__devstate_dts_ord_11Z_DEVICE_INIT_SUB_PRIO(DT_N_S_loapic_fee00000).z_init_PRE_KERNEL_140_00011_DEVICE_NAME_GET(dts_ord_11)Z_DEVICE_DEPS_NAME(dts_ord_11)(.deps = (Z_DEVICE_DEPS_NAME(dts_ord_11)),)_XXXXCONFIG_DEVICE_DEPS (.deps = (Z_DEVICE_DEPS_NAME(dts_ord_11)),)loapic@fee00000__devstate_dts_ord_11LOAPIC_SUSPEND_BITS_REQD(ROUND_UP((LOAPIC_IRQ_COUNT * LOAPIC_SSPND_BITS_PER_IRQ), 32))LOAPIC_SSPND_BITS_PER_IRQLOAPIC_SPURIOUS_VECTOR_IDCONFIG_LOAPIC_SPURIOUS_VECTOR_IDLOAPIC_FOCUS_DISABLELOAPIC_REMOTELOAPIC_PENDLOAPIC_IDLELOAPIC_SMILOAPIC_FIXEDLOAPIC_LVT_P5LOAPIC_PENTIUM40x00000014LOAPIC_VERSION_MASKCONFIG_LOAPIC_SPURIOUS_VECTOR_ID == -1CONFIG_LOAPIC_SPURIOUS_VECTORDT_DASH(0, intel_loapic)_0_intel_loapic0, intel_loapicDT_DASH_PREFIX, 0, intel_loapicNUM_VA_ARGS_LESS_1(DT_DASH_PREFIX, 0, intel_loapic)intel_loapic,MACRO_MC_1(DT_DASH_PREFIX, intel_loapic,,)_intel_loapicloapic_pm_actionDT_NODE_EXISTS(DT_N_S_loapic_fee00000)(DT_DEP_ORD_STR_SORTABLE(DT_N_S_loapic_fee00000))(00011)DT_CAT(DT_N_S_loapic_fee00000, _EXISTS)(Z_DEVICE_DEPS_DEFINE(DT_N_S_loapic_fee00000, dts_ord_11, );)_XXXXCONFIG_DEVICE_DEPS (Z_DEVICE_DEPS_DEFINE(DT_N_S_loapic_fee00000, dts_ord_11, );)DEVICE_NAME_GET("loapic@fee00000")sizeof(Z_STRINGIFY("loapic@fee00000")) <= Z_DEVICE_MAX_NAME_LENsizeof("\"loapic@fee00000\"") <= 48UZ_STRINGIFY(DEVICE_NAME_GET("loapic@fee00000")) " too long""DEVICE_NAME_GET(\"loapic@fee00000\")" " too long"DT_NODE_FULL_NAME(DT_N_S_loapic_fee00000)DT_NODE_HAS_PROP(DT_N_S_loapic_fee00000, label)(DT_PROP(DT_N_S_loapic_fee00000, label))(DT_N_S_loapic_fee00000_P_label)("loapic@fee00000")_XXXX0 (DT_N_S_loapic_fee00000_P_label)DT_CAT4(DT_N_S_loapic_fee00000, _P_, label, _EXISTS)DT_N_S_loapic_fee00000_P_label_EXISTS_XXXXDT_N_S_loapic_fee00000_P_label_EXISTS_XXXXDT_N_S_loapic_fee00000_P_label_EXISTS 1/* Configure vector and enable the required ones*//* Assuming all loapic device registers lose their state, the call to
	 * z_loapic_init(), should bring all the registers to a sane state.
	 *//* Since vector numbers are already present in RAM/ROM,
			 * We save only the mask bits here.
			 *//* local vector table entry value *//* Block 0 bits never lit up as these are all exception or reserved
	 * vectors
	 *//**
 * @brief Find the currently executing interrupt vector, if any
 *
 * This routine finds the vector of the interrupt that is being processed.
 * The ISR (In-Service Register) register contain the vectors of the interrupts
 * in service. And the higher vector is the identification of the interrupt
 * being currently processed.
 *
 * This function must be called with interrupts locked in interrupt context.
 *
 * ISR registers' offsets:
 * --------------------
 * | Offset | bits    |
 * --------------------
 * | 0100H  |   0:31  |
 * | 0110H  |  32:63  |
 * | 0120H  |  64:95  |
 * | 0130H  |  96:127 |
 * | 0140H  | 128:159 |
 * | 0150H  | 160:191 |
 * | 0160H  | 192:223 |
 * | 0170H  | 224:255 |
 * --------------------
 *
 * @return The vector of the interrupt that is currently being processed, or -1
 * if no IRQ is being serviced.
 *//* set the mask bit in the LVT *//*
	 * See the comments in _LoApicLvtVecSet() regarding IRQ to LVT mappings
	 * and ths assumption concerning LVT spacing.
	 *//* previous interrupt lock level *//**
 * @brief Disable an individual LOAPIC interrupt (IRQ)
 *
 * @param irq the IRQ number of the interrupt
 *
 * This routine clears the interrupt mask bit in the LVT for the specified IRQ
 *//* clear the mask bit in the LVT *//**
 * @brief Enable an individual LOAPIC interrupt (IRQ)
 *
 * @param irq the IRQ number of the interrupt
 *
 * This routine clears the interrupt mask bit in the LVT for the specified IRQ
 *//* update the 'vector' bits in the LVT *//*
	 * The following mappings are used:
	 *
	 *   IRQ0 -> LOAPIC_TIMER
	 *   IRQ1 -> LOAPIC_THERMAL
	 *   IRQ2 -> LOAPIC_PMC
	 *   IRQ3 -> LOAPIC_LINT0
	 *   IRQ4 -> LOAPIC_LINT1
	 *   IRQ5 -> LOAPIC_ERROR
	 *
	 * It's assumed that LVTs are spaced by 0x10 bytes
	 *//* vector to copy into the LVT *//* IRQ number of the interrupt *//**
 * @brief Set the vector field in the specified RTE
 *
 * This associates an IRQ with the desired vector in the IDT.
 *//**
 * @brief Dummy initialization function.
 *
 * The local APIC is initialized via z_loapic_enable() long before the
 * kernel runs through its device initializations, so this is unneeded.
 *//* discard a pending interrupt if any *//* lock the Local APIC interrupts *//* set LINT1: NMI, high-polarity, edge-trigger, not-masked *//* set LINT0: extInt, high-polarity, edge-trigger, not-masked *//* program Local Vector Table for the Virtual Wire Mode *//* no DFR in x2APIC mode *//* Flat model *//* reset the DFR, TPR, TIMER_CONFIG, and TIMER_ICR *//*
	 * turn on x2APIC mode. we trust the config option, so
	 * we don't check CPUID to see if x2APIC is supported.
	 *//*
	 * enable the local APIC. note that we use xAPIC mode here, since
	 * x2APIC access is not enabled until the next step (if at all).
	 *//*
	 * in xAPIC and flat model, bits 24-31 in LDR (Logical APIC ID) are
	 * bitmap of target logical APIC ID and it supports maximum 8 local
	 * APICs.
	 *
	 * The logical APIC ID could be arbitrarily selected by system software
	 * and is different from local APIC ID in local APIC ID register.
	 *
	 * We choose 0 for BSP, and the index to x86_cpuboot[] for secondary
	 * CPUs.
	 *
	 * in X2APIC, LDR is read-only.
	 *//* local APIC Max LVT *//**
 * @brief Enable and initialize the local APIC.
 *
 * Called from early assembly layer (e.g., crt0.S).
 *//* Just the one for enable disable*//* Focus Processor Checking *//* APIC Enabled *//* Local APIC Spurious-Interrupt Register Bits *//* trigger mode: Level *//* trigger mode: Edge *//* remote IRR *//* polarity: Low *//* polarity: High *//* delivery status: Pend *//* delivery status: Idle *//* delivery mode: ExtINT *//* delivery mode: NMI *//* delivery mode: SMI *//* delivery mode: FIXED *//* delivery mode *//* vectorNo *//* Local APIC Vector Table Bits *//* LO APIC LVT - P5 *//* LO APIC LVT - P6 *//* LO APIC LVT - Pentium4 *//* LO APIC in Pentium4 *//* LO APIC Max LVT mask *//* LO APIC Version mask *//* Local APIC Version Register Bits *//*
 * driver for x86 CPU local APIC (as an interrupt controller)
 *//*
 * Copyright (c) 1984-2008, 2011-2015 Wind River Systems, Inc.
 * SPDX-License-Identifier: Apache-2.0
 */DEVICE_NAME_GET("loapic@fee00000") too long/home/haojie/zephyrproject/zephyr/drivers/interrupt_controller/intc_system_apic.cirq <= HARDWARE_IRQ_LIMIT"invalid irq line"HARDWARE_IRQ_LIMIT((z_loapic_irq_base() + LOAPIC_IRQ_COUNT) - 1)IS_IOAPIC_IRQ(irq)(irq < z_loapic_irq_base())/**
 * @brief Disable an individual interrupt (IRQ)
 *
 * The irq_disable() routine is provided by the interrupt controller driver due
 * to the IRQ virtualization that is performed by this platform.  See the
 * comments in _interrupt_vector_allocate() for more information regarding IRQ
 * virtualization.
 *//**
 * @brief Enable an individual interrupt (IRQ)
 *
 * The public interface for enabling/disabling a specific IRQ for the IA-32
 * architecture is defined as follows in include/arch/x86/arch.h
 *
 *   extern void  irq_enable  (unsigned int irq);
 *   extern void  irq_disable (unsigned int irq);
 *
 * The irq_enable() routine is provided by the interrupt controller driver due
 * to the IRQ virtualization that is performed by this platform.  See the
 * comments in _interrupt_vector_allocate() for more information regarding IRQ
 * virtualization.
 *//**
 * @brief Program interrupt controller
 *
 * This routine programs the interrupt controller with the given vector
 * based on the given IRQ parameter.
 *
 * Drivers call this routine instead of IRQ_CONNECT() when interrupts are
 * configured statically.
 *
 * The Galileo board virtualizes IRQs as follows:
 *
 * - The first z_ioapic_num_rtes() IRQs are provided by the IOAPIC so the
 *     IOAPIC is programmed for these IRQs
 * - The remaining IRQs are provided by the LOAPIC and hence the LOAPIC is
 *     programmed.
 *
 * @param vector the vector number
 * @param irq the virtualized IRQ
 * @param flags interrupt flags
 *//**
 * @file
 * @brief  system module for variants with LOAPIC
 *
 *//*
 * Copyright (c) 2013-2015, Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/clock_control.hclock_control_configureconst clock_control_driver_apiconst clock_control_driver_api *clock_control_driver_api *clock_control_set_rateclock_control_get_rateclock_control_get_statusCLOCK_CONTROL_STATUS_UNKNOWNclock_control_async_onclock_control_offclock_control_onclock_control_driver_apiclock_control_configure_fnclock_control_setclock_control_get_status_fnclock_control_async_on_fnclock_control_getclock_controlclock_control_cb_tclock_control_subsys_rate_tclock_control_subsys_tclock_control_statusCLOCK_CONTROL_STATUS_STARTINGCLOCK_CONTROL_STATUS_OFFCLOCK_CONTROL_STATUS_ONset_rateget_statusget_rateasync_onCLOCK_CONTROL_SUBSYS_ALLZEPHYR_INCLUDE_DRIVERS_CLOCK_CONTROL_H_/* ZEPHYR_INCLUDE_DRIVERS_CLOCK_CONTROL_H_ *//**
 * @brief Configure a source clock
 *
 * This function is non-blocking and can be called from any context.
 * On success, the selected clock is configured as per caller's request.
 *
 * It is caller's responsibility to ensure that subsequent calls to the API
 * provide the right information to allows clock_control driver to perform
 * the right action (such as using the right clock source on clock_control_get_rate
 * call).
 *
 * @p data is implementation specific and could be used to convey
 * supplementary information required for expected clock configuration.
 *
 * @param dev Device structure whose driver controls the clock
 * @param sys Opaque data representing the clock
 * @param data Opaque data providing additional input for clock configuration
 *
 * @retval 0 On success
 * @retval -ENOSYS If the device driver does not implement this call
 * @retval -errno Other negative errno on failure.
 *//**
 * @brief Set the rate of the clock controlled by the device.
 *
 * On success, the new clock rate is set and ready when this function
 * returns. This function may sleep, and thus can only be called from
 * thread context.
 *
 * @param dev Device structure whose driver controls the clock.
 * @param sys Opaque data representing the clock.
 * @param rate Opaque data representing the clock rate to be used.
 *
 * @retval -EALREADY if clock was already in the given rate.
 * @retval -ENOTSUP If the requested mode of operation is not supported.
 * @retval -ENOSYS if the interface is not implemented.
 * @retval other negative errno on vendor specific error.
 *//**
 * @brief Obtain the clock rate of given sub-system
 * @param dev Pointer to the device structure for the clock controller driver
 *        instance
 * @param sys A pointer to an opaque data representing the sub-system
 * @param[out] rate Subsystem clock rate
 * @retval 0 on successful rate reading.
 * @retval -EAGAIN if rate cannot be read. Some drivers do not support returning the rate when the
 *         clock is off.
 * @retval -ENOTSUP if reading the clock rate is not supported for the given sub-system.
 * @retval -ENOSYS if the interface is not implemented.
 *//**
 * @brief Get clock status.
 *
 * @param dev Device.
 * @param sys A pointer to an opaque data representing the sub-system.
 *
 * @return Status.
 *//**
 * @brief Request clock to start with notification when clock has been started.
 *
 * Function is non-blocking and can be called from any context. User callback is
 * called when clock is started.
 *
 * @param dev	    Device.
 * @param sys	    A pointer to an opaque data representing the sub-system.
 * @param cb	    Callback.
 * @param user_data User context passed to the callback.
 *
 * @retval 0 if start is successfully initiated.
 * @retval -EALREADY if clock was already started and is starting or running.
 * @retval -ENOTSUP If the requested mode of operation is not supported.
 * @retval -ENOSYS if the interface is not implemented.
 * @retval other negative errno on vendor specific error.
 *//**
 * @brief Disable a clock controlled by the device
 *
 * This function is non-blocking and can be called from any context.
 * On success, the clock is disabled when this function returns.
 *
 * @param dev Device structure whose driver controls the clock
 * @param sys Opaque data representing the clock
 * @return 0 on success, negative errno on failure.
 *//**
 * @brief Enable a clock controlled by the device
 *
 * On success, the clock is enabled and ready when this function
 * returns. This function may sleep, and thus can only be called from
 * thread context.
 *
 * Use @ref clock_control_async_on() for non-blocking operation.
 *
 * @param dev Device structure whose driver controls the clock.
 * @param sys Opaque data representing the clock.
 * @return 0 on success, negative errno on failure.
 *//** @brief Callback called on clock started.
 *
 * @param dev		Device structure whose driver controls the clock.
 * @param subsys	Opaque data representing the clock.
 * @param user_data	User data.
 *//**
 * clock_control_subsys_rate_t is a type to identify a clock
 * controller sub-system rate.  Such data pointed is opaque and
 * relevant only to set the clock controller rate of the driver
 * instance being used.
 *//**
 * clock_control_subsys_t is a type to identify a clock controller sub-system.
 * Such data pointed is opaque and relevant only to the clock controller
 * driver instance being used.
 *//**
 * @brief Current clock status.
 *//* Used to select all subsystem of a clock controller *//* Clock control API *//**
 * @brief Clock Control Interface
 * @defgroup clock_control_interface Clock Control Interface
 * @ingroup io_interfaces
 * @{
 *//**
 * @file
 * @brief Public Clock Control APIs
 *//*
 * Copyright (c) 2015 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* clock_control.h - public clock controller driver API */rate/home/haojie/zephyrproject/zephyr/include/zephyr/pm/policy.hpm_policy_event_unregisterpm_policy_event *evtpm_policy_event_updatetime_uspm_policy_event_registerpm_policy_latency_request_removepm_policy_latency_request *reqpm_policy_latency_request_updatevalue_uspm_policy_latency_request_addpm_policy_state_lock_is_activepm_policy_state_lock_putpm_policy_state_lock_getpm_policy_next_statepm_policy_eventpm_policy_latency_requestpm_policy_latency_subscriptionpm_policy_latency_changed_cb_tvalue_cycPM_ALL_SUBSTATES(UINT8_MAX)ZEPHYR_INCLUDE_PM_POLICY_H_/* ZEPHYR_INCLUDE_PM_POLICY_H_ *//**
 * @brief Unregister an event.
 *
 * @param evt Event.
 *
 * @see pm_policy_event_register
 *//**
 * @brief Update an event.
 *
 * @param evt Event.
 * @param time_us When the event will occur, in microseconds from now.
 *
 * @see pm_policy_event_register
 *//**
 * @brief Register an event.
 *
 * Events in the power-management policy context are defined as any source that
 * will wake up the system at a known time in the future. By registering such
 * event, the policy manager will be able to decide whether certain power states
 * are worth entering or not.
 *
 * @note It is mandatory to unregister events once they have happened by using
 * pm_policy_event_unregister(). Not doing so is an API contract violation,
 * because the system would continue to consider them as valid events in the
 * *far* future, that is, after the cycle counter rollover.
 *
 * @param evt Event.
 * @param time_us When the event will occur, in microseconds from now.
 *
 * @see pm_policy_event_unregister
 *//**
 * @brief Unsubscribe to maximum latency changes.
 *
 * @param req Subscription request.
 *//**
 * @brief Subscribe to maximum latency changes.
 *
 * @param req Subscription request.
 * @param cb Callback function (NULL to disable).
 *//**
 * @brief Remove a latency requirement.
 *
 * @param req Latency request.
 *//**
 * @brief Update a latency requirement.
 *
 * @param req Latency request.
 * @param value_us New maximum allowed latency in microseconds.
 *//**
 * @brief Add a new latency requirement.
 *
 * The system will not enter any power state that would make the system to
 * exceed the given latency value.
 *
 * @param req Latency request.
 * @param value_us Maximum allowed latency in microseconds.
 *//**
 * @brief Check if a power state lock is active (not allowed).
 *
 * @param state Power state.
 * @param substate_id Power substate ID. Use PM_ALL_SUBSTATES to affect all the
 *		      substates in the given power state.
 *
 * @retval true if power state lock is active.
 * @retval false if power state lock is not active.
 *//**
 * @brief Decrease a power state lock counter.
 *
 * @param state Power state.
 * @param substate_id Power substate ID. Use PM_ALL_SUBSTATES to affect all the
 *		      substates in the given power state.
 *
 * @see pm_policy_state_lock_get()
 *//**
 * @brief Increase a power state lock counter.
 *
 * A power state will not be allowed on the first call of
 * pm_policy_state_lock_get(). Subsequent calls will just increase a reference
 * count, thus meaning this API can be safely used concurrently. A state will
 * be allowed again after pm_policy_state_lock_put() is called as many times as
 * pm_policy_state_lock_get().
 *
 * Note that the PM_STATE_ACTIVE state is always allowed, so calling this API
 * with PM_STATE_ACTIVE will have no effect.
 *
 * @param state Power state.
 * @param substate_id Power substate ID. Use PM_ALL_SUBSTATES to affect all the
 *		      substates in the given power state.
 *
 * @see pm_policy_state_lock_put()
 *//** Special value for 'all substates'. *//**
 * @brief Function to get the next PM state
 *
 * This function is called by the power subsystem when the system is
 * idle and returns the most appropriate state based on the number of
 * ticks to the next event.
 *
 * @param cpu CPU index.
 * @param ticks The number of ticks to the next scheduled event.
 *
 * @return The power state the system should use for the given cpu. The function
 * will return NULL if system should remain into PM_STATE_ACTIVE.
 *//**
 * @brief Event.
 *
 * @note All fields in this structure are meant for private usage.
 *//**
 * @brief Latency request.
 *
 * @note All fields in this structure are meant for private usage.
 *//**
 * @brief Latency change subscription.
 *
 * @note All fields in this structure are meant for private usage.
 *//**
 * @brief Callback to notify when maximum latency changes.
 *
 * @param latency New maximum latency. Positive value represents latency in
 * microseconds. SYS_FOREVER_US value lifts the latency constraint. Other values
 * are forbidden.
 *//**
 * @brief System Power Management Policy API
 * @defgroup subsys_pm_sys_policy Policy
 * @ingroup subsys_pm_sys
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/serial/uart_ns16550.hCMD_SET_DLFZEPHYR_INCLUDE_DRIVERS_SERIAL_UART_NS16550_H_/* ZEPHYR_INCLUDE_DRIVERS_SERIAL_UART_NS16550_H_ *//**
 * @brief Set DLF
 *
 * @note This only applies to Synopsys Designware UART IP block.
 *//**
 * @file
 *
 * @brief Public header file for the NS16550 UART
 *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/serial/home/haojie/zephyrproject/zephyr/drivers/serial/uart_ns16550.c<zephyr/drivers/serial/uart_ns16550.h><zephyr/pm/policy.h><zephyr/drivers/clock_control.h>uart_ns16550_err_checkuart_ns16550_dev_data *const uart_ns16550_device_configconst uart_ns16550_device_config *uart_ns16550_device_config *const uart_ns16550_device_config *constdev_cfgcheckLSR_EOB_MASKuart_ns16550_poll_outuart_ns16550_poll_inLSR_RXRDYuart_ns16550_initz_device_mmio_rom *UART_NS16550_DT_PROP_IOMAPPED_HELPERio_mapped, 0DT_HAS_COMPAT_STATUS_OKAY(DT_DRV_COMPAT)(UTIL_CAT(DT_FOREACH_OKAY_INST_VARGS_, DT_DRV_COMPAT)(UART_NS16550_DT_PROP_IOMAPPED_HELPER, io_mapped, 0))(1 || 1 ||)DT_CAT(DT_COMPAT_HAS_OKAY_, ns16550)DT_COMPAT_HAS_OKAY_DT_FOREACH_OKAY_INST_VARGS_DT_DASH(0, ns16550)_0_ns165500, ns16550DT_DASH_PREFIX, 0, ns16550NUM_VA_ARGS_LESS_1(DT_DASH_PREFIX, 0, ns16550)ns16550,MACRO_MC_1(DT_DASH_PREFIX, ns16550,,)_ns16550DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_3f8, io_mapped)(DT_PROP(DT_N_S_soc_S_uart_3f8, io_mapped))DT_DRV_INST(1)DT_DASH(1, ns16550)_1_ns165501, ns16550DT_DASH_PREFIX, 1, ns16550NUM_VA_ARGS_LESS_1(DT_DASH_PREFIX, 1, ns16550)DT_DASH_PREFIX(1)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_2f8, io_mapped)(DT_PROP(DT_N_S_soc_S_uart_2f8, io_mapped))DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, io_mapped, _EXISTS)1 || 1 ||resetsDT_INST_NODE_HAS_PROP_AND_OR(UTIL_CAT(DT_FOREACH_OKAY_INST_VARGS_, DT_DRV_COMPAT)(DT_INST_NODE_HAS_PROP_AND_OR, resets))(0 || 0 ||)DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, resets, _EXISTS)DT_N_S_soc_S_uart_3f8_P_resets_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_resets_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_resets_EXISTS 1DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, resets, _EXISTS)DT_N_S_soc_S_uart_2f8_P_resets_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_resets_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_resets_EXISTS 10 || 0 ||pcieUTIL_CAT(DT_CAT(DT_COMPAT_, ns16550), _BUS_pcie)DT_COMPAT_ns16550_BUS_pcieDT_CAT(DT_COMPAT_, ns16550)DT_COMPAT_ns16550_BUS_pcieDT_COMPAT__XXXXDT_COMPAT_ns16550_BUS_pcie_XXXXDT_COMPAT_ns16550_BUS_pcie 1uart_ns16550_config_getuart_ns16550_configureuart_ns16550_dev_data *constdev_datamdcpclkuart_cfgLCR_CS5LCR_CS6LCR_CS7LCR_CS8LCR_1_STBLCR_2_STBLCR_PDISLCR_EPSMCR_OUT2FCR_MODE0FCR_FIFO_8IIR_FEdlf(UTIL_CAT(DT_FOREACH_OKAY_INST_VARGS_, DT_DRV_COMPAT)(DT_INST_NODE_HAS_PROP_AND_OR, dlf))DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, dlf, _EXISTS)DT_N_S_soc_S_uart_3f8_P_dlf_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_dlf_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_dlf_EXISTS 1DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, dlf, _EXISTS)DT_N_S_soc_S_uart_2f8_P_dlf_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_dlf_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_dlf_EXISTS 1pcp(UTIL_CAT(DT_FOREACH_OKAY_INST_VARGS_, DT_DRV_COMPAT)(DT_INST_NODE_HAS_PROP_AND_OR, pcp))DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, pcp, _EXISTS)DT_N_S_soc_S_uart_3f8_P_pcp_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_pcp_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_pcp_EXISTS 1DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, pcp, _EXISTS)DT_N_S_soc_S_uart_2f8_P_pcp_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_pcp_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_pcp_EXISTS 1set_baud_ratedivisorlcr_cacheLCR_DLAB0xffget_uart_burdrate_divisorget_port/home/haojie/zephyrproject/zephyr/drivers/serialbaud_ratereg_intervalns16550_inbyteCONFIG_UART_NS16550_ACCESS_WORD_ONLY_XXXXCONFIG_UART_NS16550_ACCESS_WORD_ONLY_XXXXCONFIG_UART_NS16550_ACCESS_WORD_ONLY 1ns16550_outbyteuart_ns16550_dev_datauart_ns16550_device_configfifo_size_mmioio_mapclock_subsysclock_devsys_clk_freq__init___device_dts_ord_26UART_NS16550_DEVICE_INITDT_FOREACH_OKAY_INST_&uart_ns16550_init, NULL, &uart_ns16550_dev_data_1, &uart_ns16550_dev_cfg_1, PRE_KERNEL_1, CONFIG_SERIAL_INIT_PRIORITY, &uart_ns16550_driver_api&uart_ns16550_init, ((void *)0), &uart_ns16550_dev_data_1, &uart_ns16550_dev_cfg_1, PRE_KERNEL_1, 50, &uart_ns16550_driver_api&uart_ns16550_init&uart_ns16550_dev_data_1&uart_ns16550_dev_cfg_1&uart_ns16550_driver_apiDEVICE_DT_NAME(DT_N_S_soc_S_uart_2f8)&Z_DEVICE_STATE_NAME(Z_DEVICE_DT_DEV_ID(DT_N_S_soc_S_uart_2f8))&__devstate_dts_ord_26Z_DEVICE_INIT_SUB_PRIO(DT_N_S_soc_S_uart_2f8).z_init_PRE_KERNEL_150_00026_DEVICE_NAME_GET(dts_ord_26)._device.static.1_50_Z_DEVICE_DEPS_NAME(dts_ord_26)Z_DEVICE_SECTION_NAME(PRE_KERNEL_1, 50)1_50_CONCAT(1_50, _)1_50_uart@2f8__devstate_dts_ord_26uart_ns16550_dev_data_1current_speeduart_ns16550_dev_cfg_1clock_frequencyreg_shift__init___device_dts_ord_27&uart_ns16550_init, NULL, &uart_ns16550_dev_data_0, &uart_ns16550_dev_cfg_0, PRE_KERNEL_1, CONFIG_SERIAL_INIT_PRIORITY, &uart_ns16550_driver_api&uart_ns16550_init, ((void *)0), &uart_ns16550_dev_data_0, &uart_ns16550_dev_cfg_0, PRE_KERNEL_1, 50, &uart_ns16550_driver_api&uart_ns16550_dev_data_0&uart_ns16550_dev_cfg_0DEVICE_DT_NAME(DT_N_S_soc_S_uart_3f8)&Z_DEVICE_STATE_NAME(Z_DEVICE_DT_DEV_ID(DT_N_S_soc_S_uart_3f8))&__devstate_dts_ord_27Z_DEVICE_INIT_SUB_PRIO(DT_N_S_soc_S_uart_3f8).z_init_PRE_KERNEL_150_00027_DEVICE_NAME_GET(dts_ord_27)Z_DEVICE_DEPS_NAME(dts_ord_27)uart@3f8__devstate_dts_ord_27uart_ns16550_dev_data_0uart_ns16550_dev_cfg_0uart_ns16550_driver_apiuart_ns16550, CONFIG_UART_LOG_LEVEL(Z_LOG_EVAL(CONFIG_LOG_OVERRIDE_LEVEL, (1), (Z_LOG_EVAL(_LOG_LEVEL_RESOLVE(uart_ns16550, CONFIG_UART_LOG_LEVEL), (1), (0))) ))(Z_LOG_EVAL(_LOG_LEVEL_RESOLVE(uart_ns16550, CONFIG_UART_LOG_LEVEL), (1), (0)))_LOG_LEVEL_RESOLVE(uart_ns16550, CONFIG_UART_LOG_LEVEL)GET_ARG_N(1, uart_ns16550, CONFIG_UART_LOG_LEVEL)uart_ns16550CONFIG_UART_LOG_LEVELlog_dynamic_uart_ns16550log_const_uart_ns16550char[11]UART_NS16550_DEVICE_INIT(n)COND_CODE_1(DT_INST_ON_BUS(n, pcie), (UART_NS16550_DEVICE_PCIE_INIT(n)), (UART_NS16550_DEVICE_IO_MMIO_INIT(n)))UART_NS16550_DEVICE_PCIE_INIT(n)UART_NS16550_PCIE_IRQ_FUNC_DECLARE(n); DEVICE_PCIE_INST_DECLARE(n); IF_ENABLED(DT_INST_NODE_HAS_PROP(n, pinctrl_0), (PINCTRL_DT_INST_DEFINE(n))); static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_ ## n = { UART_NS16550_COMMON_DEV_CFG_INITIALIZER(n) DEV_CONFIG_PCIE_IRQ_FUNC_INIT(n) DEVICE_PCIE_INST_INIT(n, pcie) }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_ ## n = { UART_NS16550_COMMON_DEV_DATA_INITIALIZER(n) }; DEVICE_DT_INST_DEFINE(n, &uart_ns16550_init, NULL, &uart_ns16550_dev_data_ ## n, &uart_ns16550_dev_cfg_ ## n, COND_CODE_1(CONFIG_UART_NS16550_PARENT_INIT_LEVEL, (POST_KERNEL), (PRE_KERNEL_1)), CONFIG_SERIAL_INIT_PRIORITY, &uart_ns16550_driver_api); UART_NS16550_PCIE_IRQ_FUNC_DEFINE(n)UART_NS16550_DEVICE_IO_MMIO_INIT(n)UART_NS16550_IRQ_FUNC_DECLARE(n); IF_ENABLED(DT_INST_NODE_HAS_PROP(n, pinctrl_0), (PINCTRL_DT_INST_DEFINE(n))); static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_ ## n = { COND_CODE_1(DT_INST_PROP_OR(n, io_mapped, 0), (.port = DT_INST_REG_ADDR(n),), (DEVICE_MMIO_ROM_INIT(DT_DRV_INST(n)),)) IF_ENABLED(DT_INST_PROP_OR(n, io_mapped, 0), (.io_map = true,)) UART_NS16550_COMMON_DEV_CFG_INITIALIZER(n) DEV_CONFIG_IRQ_FUNC_INIT(n) }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_ ## n = { UART_NS16550_COMMON_DEV_DATA_INITIALIZER(n) }; DEVICE_DT_INST_DEFINE(n, &uart_ns16550_init, NULL, &uart_ns16550_dev_data_ ## n, &uart_ns16550_dev_cfg_ ## n, PRE_KERNEL_1, CONFIG_SERIAL_INIT_PRIORITY, &uart_ns16550_driver_api); UART_NS16550_IRQ_FUNC_DEFINE(n)UART_NS16550_COMMON_DEV_DATA_INITIALIZER(n).uart_config.baudrate = DT_INST_PROP_OR(n, current_speed, 0), .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = COND_CODE_1(DT_INST_PROP_OR(n, hw_flow_control, 0), (UART_CFG_FLOW_CTRL_RTS_CTS), (UART_CFG_FLOW_CTRL_NONE)), IF_ENABLED(DT_INST_NODE_HAS_PROP(n, dlf), (.dlf = DT_INST_PROP_OR(n, dlf, 0),))UART_NS16550_COMMON_DEV_CFG_INITIALIZER(n)COND_CODE_1(DT_INST_NODE_HAS_PROP(n, clock_frequency), ( .sys_clk_freq = DT_INST_PROP(n, clock_frequency), .clock_dev = NULL, .clock_subsys = NULL, ), ( .sys_clk_freq = 0, .clock_dev = DEVICE_DT_GET(DT_INST_CLOCKS_CTLR(n)), .clock_subsys = (clock_control_subsys_t) DT_INST_PHA( 0, clocks, clkid), ) ) IF_ENABLED(DT_INST_NODE_HAS_PROP(n, pcp), (.pcp = DT_INST_PROP_OR(n, pcp, 0),)) .reg_interval = (1 << DT_INST_PROP(n, reg_shift)), IF_ENABLED(DT_INST_NODE_HAS_PROP(n, pinctrl_0), (.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_DRV_INST(n)),)) IF_ENABLED(DT_INST_NODE_HAS_PROP(n, resets), (.reset_spec = RESET_DT_SPEC_INST_GET(n),))UART_NS16550_PCIE_IRQ_FUNC_DEFINE(n)UART_NS16550_PCIE_IRQ_FUNC_DECLARE(n)DEV_CONFIG_PCIE_IRQ_FUNC_INIT(n)UART_NS16550_IRQ_FUNC_DEFINE(n)UART_NS16550_IRQ_FUNC_DECLARE(n)DEV_CONFIG_IRQ_FUNC_INIT(n)UART_NS16550_IRQ_CONFIG_PCIE(n)static void uart_ns16550_irq_config_func ## n(const struct device *dev) { BUILD_ASSERT(DT_INST_IRQN(n) == PCIE_IRQ_DETECT, "Only runtime IRQ configuration is supported"); BUILD_ASSERT(IS_ENABLED(CONFIG_DYNAMIC_INTERRUPTS), "NS16550 PCIe requires dynamic interrupts"); const struct uart_ns16550_device_config *dev_cfg = dev->config; unsigned int irq = pcie_alloc_irq(dev_cfg->pcie->bdf); if (irq == PCIE_CONF_INTR_IRQ_NONE) { return; } pcie_connect_dynamic_irq(dev_cfg->pcie->bdf, irq, DT_INST_IRQ(n, priority), (void (*)(const void *))uart_ns16550_isr, DEVICE_DT_INST_GET(n), UART_NS16550_IRQ_FLAGS(n)); pcie_irq_enable(dev_cfg->pcie->bdf, irq); }UART_NS16550_IRQ_CONFIG(n)static void uart_ns16550_irq_config_func ## n(const struct device *dev) { ARG_UNUSED(dev); IRQ_CONNECT(DT_INST_IRQN(n), DT_INST_IRQ(n, priority), uart_ns16550_isr, DEVICE_DT_INST_GET(n), UART_NS16550_IRQ_FLAGS(n)); irq_enable(DT_INST_IRQN(n)); }UART_NS16550_IRQ_FLAGS(n)COND_CODE_1(DT_INST_IRQ_HAS_CELL(n, sense), (DT_INST_IRQ(n, sense)), (0))IIRC(dev)(((struct uart_ns16550_dev_data *)(dev)->data)->iir_cache)PCP(dev)(get_port(dev) + REG_PCP)DLF(dev)(get_port(dev) + REG_DLF)MDR1(dev)(get_port(dev) + REG_MDR1 * reg_interval(dev))MSR(dev)(get_port(dev) + REG_MSR * reg_interval(dev))LSR(dev)(get_port(dev) + REG_LSR * reg_interval(dev))MDC(dev)(get_port(dev) + REG_MDC * reg_interval(dev))LCR(dev)(get_port(dev) + REG_LCR * reg_interval(dev))FCR(dev)(get_port(dev) + REG_FCR * reg_interval(dev))IIR(dev)(get_port(dev) + REG_IIR * reg_interval(dev))IER(dev)(get_port(dev) + REG_IER * reg_interval(dev))BRDH(dev)(get_port(dev) + REG_BRDH * reg_interval(dev))BRDL(dev)(get_port(dev) + REG_BRDL * reg_interval(dev))RDR(dev)(get_port(dev) + REG_RDR * reg_interval(dev))THR(dev)(get_port(dev) + REG_THR * reg_interval(dev))MSR_DCD0x80MSR_RIMSR_DSRMSR_CTSMSR_DDCDMSR_DRIMSR_DDSRMSR_DCTSLSR_TEMT0x1ELSR_BILSR_FELSR_PELSR_OEMCR_AFCEMCR_LOOPMCR_OUT1LCR_SBRKLCR_SPLCR_PENFCR_FIFO_64FCR_FIFO_140xC0FCR_FIFO_4FCR_MODE1MDR1_DISABLE(7)MDR1_CIR_MODE(6)MDR1_FIR_MODEMDR1_MIR_MODEMDR1_UART_13XMDR1_UART_16XMDR1_SIR_MODEMDR1_STD_MODEMDR1_MODE_SELECT_FIELD_SHIFTBIT_MASK(0)MDR1_MODE_SELECT_FIELD_MASKBIT_MASK(3)PCP_EN0x00000001PCP_UPDATEIIR_CH0x0CIIR_ID0x06IIR_MASKIIR_LSIIR_RBRFIIR_THREIIR_NIPIIR_MSTATIER_MSIIER_LSRIER_TBEIER_RXRDYREG_MDR1REG_PCPREG_DLFREG_MSRREG_MDCREG_IIRREG_RDRUART_NS16550_IOPORT_ENABLED(DT_INST_FOREACH_STATUS_OKAY_VARGS(UART_NS16550_DT_PROP_IOMAPPED_HELPER, io_mapped, 0) 0)UART_NS16550_DT_PROP_IOMAPPED_HELPER(inst,prop,def)DT_INST_PROP_OR(inst, prop, def) ||UART_NS16550_RESET_ENABLEDDT_ANY_INST_HAS_PROP_STATUS_OKAY(resets)UART_NS16550_DLF_ENABLEDDT_ANY_INST_HAS_PROP_STATUS_OKAY(dlf)UART_NS16550_PCP_ENABLEDDT_ANY_INST_HAS_PROP_STATUS_OKAY(pcp)defined(CONFIG_PINCTRL)DT_ANY_INST_ON_BUS_STATUS_OKAY(pcie)CONFIG_UART_NS16550_ITE_HIGH_SPEED_BUADRATEdefined(CONFIG_UART_INTERRUPT_DRIVEN) || defined(CONFIG_UART_ASYNC_API)defined(CONFIG_UART_INTERRUPT_DRIVEN) && defined(CONFIG_PM)CONFIG_UART_NS16550_TI_K3defined(CONFIG_UART_NS16550_VARIANT_NS16750) || \CONFIG_UART_NS16550_VARIANT_NS16750defined(CONFIG_UART_NS16550_VARIANT_NS16950)CONFIG_UART_NS16550_WA_ISR_REENABLE_INTERRUPTCONFIG_UART_NS16550_LINE_CTRLCONFIG_UART_NS16550_DRV_CMDDT_NODE_EXISTS(DT_N_S_soc_S_uart_3f8)DT_CAT(DT_N_S_soc_S_uart_3f8, _EXISTS)(Z_DEVICE_DEPS_DEFINE(DT_N_S_soc_S_uart_3f8, dts_ord_27, );)_XXXXCONFIG_DEVICE_DEPS (Z_DEVICE_DEPS_DEFINE(DT_N_S_soc_S_uart_3f8, dts_ord_27, );)DEVICE_NAME_GET("uart@3f8")sizeof(Z_STRINGIFY("uart@3f8")) <= Z_DEVICE_MAX_NAME_LENsizeof("\"uart@3f8\"") <= 48UZ_STRINGIFY(DEVICE_NAME_GET("uart@3f8")) " too long""DEVICE_NAME_GET(\"uart@3f8\")" " too long"DT_NODE_FULL_NAME(DT_N_S_soc_S_uart_3f8)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_3f8, label)(DT_PROP(DT_N_S_soc_S_uart_3f8, label))(DT_N_S_soc_S_uart_3f8_P_label)("uart@3f8")_XXXX0 (DT_N_S_soc_S_uart_3f8_P_label)DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, label, _EXISTS)DT_N_S_soc_S_uart_3f8_P_label_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_label_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_label_EXISTS 1DT_INST_PROP_OR(1, io_mapped, 0)(.port = DT_INST_REG_ADDR(1),)(.port = 760,)(DEVICE_MMIO_ROM_INIT(DT_DRV_INST(1)),)(._mmio = { .phys_addr = 760, .size = 256 },)DT_INST_NODE_HAS_PROP(1, pinctrl_0)(PINCTRL_DT_INST_DEFINE(1))_XXXX0 (PINCTRL_DT_INST_DEFINE(1))pinctrl_0DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, pinctrl_0, _EXISTS)DT_N_S_soc_S_uart_2f8_P_pinctrl_0_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_pinctrl_0_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_pinctrl_0_EXISTS 1&uart_ns16550_init, NULL, &uart_ns16550_dev_data_1, &uart_ns16550_dev_cfg_1, COND_CODE_1(CONFIG_UART_NS16550_PARENT_INIT_LEVEL, (POST_KERNEL), (PRE_KERNEL_1)), CONFIG_SERIAL_INIT_PRIORITY, &uart_ns16550_driver_apiDT_NODE_EXISTS(DT_N_S_soc_S_uart_2f8)(DT_DEP_ORD_STR_SORTABLE(DT_N_S_soc_S_uart_2f8))(00026)hw_flow_controlDT_INST_PROP_OR(1, hw_flow_control, 0)(UART_CFG_FLOW_CTRL_RTS_CTS)(UART_CFG_FLOW_CTRL_NONE)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_2f8, current_speed)(DT_PROP(DT_N_S_soc_S_uart_2f8, current_speed))(115200)DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, current_speed, _EXISTS)DT_INST_NODE_HAS_PROP(1, resets)(.reset_spec = RESET_DT_SPEC_INST_GET(1),)_XXXX0 (.reset_spec = RESET_DT_SPEC_INST_GET(1),)(.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_DRV_INST(1)),)(.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_N_S_soc_S_uart_2f8),)_XXXX0 (.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_N_S_soc_S_uart_2f8),)DT_CAT(DT_N_S_soc_S_uart_2f8, _EXISTS)(Z_DEVICE_DEPS_DEFINE(DT_N_S_soc_S_uart_2f8, dts_ord_26, );)_XXXXCONFIG_DEVICE_DEPS (Z_DEVICE_DEPS_DEFINE(DT_N_S_soc_S_uart_2f8, dts_ord_26, );)DEVICE_NAME_GET("uart@2f8")sizeof(Z_STRINGIFY("uart@2f8")) <= Z_DEVICE_MAX_NAME_LENsizeof("\"uart@2f8\"") <= 48UZ_STRINGIFY(DEVICE_NAME_GET("uart@2f8")) " too long""DEVICE_NAME_GET(\"uart@2f8\")" " too long"DT_NODE_FULL_NAME(DT_N_S_soc_S_uart_2f8)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_2f8, label)(DT_PROP(DT_N_S_soc_S_uart_2f8, label))(DT_N_S_soc_S_uart_2f8_P_label)("uart@2f8")_XXXX0 (DT_N_S_soc_S_uart_2f8_P_label)DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, label, _EXISTS)DT_N_S_soc_S_uart_2f8_P_label_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_label_EXISTS_XXXXDT_N_S_soc_S_uart_2f8_P_label_EXISTS 1(UTIL_CAT(DT_FOREACH_OKAY_INST_, DT_DRV_COMPAT)(UART_NS16550_DEVICE_INIT))(; ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_0 = { .port = 1016, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_0 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_27 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@3f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@3f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_27 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@3f8", .config = (&uart_ns16550_dev_cfg_0), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_27), .data = (&uart_ns16550_dev_data_0), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00027""_"))) __init___device_dts_ord_27 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_27, }; ; ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_1 = { .port = 760, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_1 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_26 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@2f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@2f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_26 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@2f8", .config = (&uart_ns16550_dev_cfg_1), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_26), .data = (&uart_ns16550_dev_data_1), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00026""_"))) __init___device_dts_ord_26 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_26, };); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_0 = { .port = 1016, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_0 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_27 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@3f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@3f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_27 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@3f8", .config = (&uart_ns16550_dev_cfg_0), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_27), .data = (&uart_ns16550_dev_data_0), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00027""_"))) __init___device_dts_ord_27 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_27, }; ; ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_1 = { .port = 760, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_1 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_26 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@2f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@2f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_26 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@2f8", .config = (&uart_ns16550_dev_cfg_1), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_26), .data = (&uart_ns16550_dev_data_1), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00026""_"))) __init___device_dts_ord_26 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_26, };DT_INST_ON_BUS(1, pcie)(UART_NS16550_DEVICE_PCIE_INIT(1))(; DEVICE_PCIE_INST_DECLARE(1); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_1 = { .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), DEVICE_PCIE_INST_INIT(1, pcie) }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_1 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_26 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@2f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@2f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_26 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@2f8", .config = (&uart_ns16550_dev_cfg_1), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_26), .data = (&uart_ns16550_dev_data_1), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00026""_"))) __init___device_dts_ord_26 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_26, }; )(UART_NS16550_DEVICE_IO_MMIO_INIT(1))(; ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_1 = { .port = 760, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_1 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_26 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@2f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@2f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_26 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@2f8", .config = (&uart_ns16550_dev_cfg_1), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_26), .data = (&uart_ns16550_dev_data_1), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00026""_"))) __init___device_dts_ord_26 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_26, }; )_XXXX0 (; DEVICE_PCIE_INST_DECLARE(1); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_1 = { .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), DEVICE_PCIE_INST_INIT(1, pcie) }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_1 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_26 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@2f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@2f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_26 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@2f8", .config = (&uart_ns16550_dev_cfg_1), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_26), .data = (&uart_ns16550_dev_data_1), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00026""_"))) __init___device_dts_ord_26 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_26, }; ); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_1 = { .port = 760, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_1 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_26 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@2f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@2f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_26 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@2f8", .config = (&uart_ns16550_dev_cfg_1), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_26), .data = (&uart_ns16550_dev_data_1), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00026""_"))) __init___device_dts_ord_26 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_26, };(.deps = (Z_DEVICE_DEPS_NAME(dts_ord_26)),)_XXXXCONFIG_DEVICE_DEPS (.deps = (Z_DEVICE_DEPS_NAME(dts_ord_26)),)DT_INST_NODE_HAS_PROP(1, dlf)(.dlf = DT_INST_PROP_OR(1, dlf, 0),)(.dlf = 0,)_XXXX0 (.dlf = 0,)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_2f8, dlf)(DT_PROP(DT_N_S_soc_S_uart_2f8, dlf))(DT_N_S_soc_S_uart_2f8_P_dlf)_XXXX0 (DT_N_S_soc_S_uart_2f8_P_dlf)_XXXX0 (UART_CFG_FLOW_CTRL_RTS_CTS)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_2f8, hw_flow_control)(DT_PROP(DT_N_S_soc_S_uart_2f8, hw_flow_control))DT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, hw_flow_control, _EXISTS)DT_INST_NODE_HAS_PROP(1, pcp)(.pcp = DT_INST_PROP_OR(1, pcp, 0),)(.pcp = 0,)DT_INST_NODE_HAS_PROP(1, clock_frequency)( .sys_clk_freq = DT_INST_PROP(1, clock_frequency), .clock_dev = NULL, .clock_subsys = NULL, )( .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), )( .sys_clk_freq = 0, .clock_dev = DEVICE_DT_GET(DT_INST_CLOCKS_CTLR(1)), .clock_subsys = (clock_control_subsys_t) DT_INST_PHA( 0, clocks, clkid), )( .sys_clk_freq = 0, .clock_dev = (&__device_dts_ord_DT_N_S_soc_S_uart_2f8_P_clocks_IDX_0_PH_ORD), .clock_subsys = (clock_control_subsys_t) DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_VAL_clkid, ).sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0),clocksclkid_IDX__VAL_DT_INST_CLOCKS_CTLR(1)DT_N_S_soc_S_uart_2f8_P_clocks_IDX_0_PHZ_DEVICE_DT_DEV_ID(DT_N_S_soc_S_uart_2f8_P_clocks_IDX_0_PH)dts_ord_DT_N_S_soc_S_uart_2f8_P_clocks_IDX_0_PH_ORDDT_DEP_ORD(DT_N_S_soc_S_uart_2f8_P_clocks_IDX_0_PH)DT_N_S_soc_S_uart_2f8_P_clocks_IDX_0_PH_ORD_PHDT_CAT4(DT_N_S_soc_S_uart_2f8, _P_, clock_frequency, _EXISTS)_XXXX0 (.pcp = 0,)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_2f8, pcp)(DT_PROP(DT_N_S_soc_S_uart_2f8, pcp))(DT_N_S_soc_S_uart_2f8_P_pcp)_XXXX0 (DT_N_S_soc_S_uart_2f8_P_pcp)(.io_map = true,)(.io_map = 1,).io_map = 1,.port = 760,CONFIG_UART_NS16550_PARENT_INIT_LEVEL(POST_KERNEL)(PRE_KERNEL_1)_XXXXCONFIG_UART_NS16550_PARENT_INIT_LEVEL_XXXXCONFIG_UART_NS16550_PARENT_INIT_LEVEL (POST_KERNEL)DT_CAT3(DT_N_S_soc_S_uart_2f8, _BUS_, pcie)DT_N_S_soc_S_uart_2f8_BUS_pcie_XXXXDT_N_S_soc_S_uart_2f8_BUS_pcie_XXXXDT_N_S_soc_S_uart_2f8_BUS_pcie 1_BUS_DT_INST_ON_BUS(0, pcie)(UART_NS16550_DEVICE_PCIE_INIT(0))(; DEVICE_PCIE_INST_DECLARE(0); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_0 = { .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), DEVICE_PCIE_INST_INIT(0, pcie) }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_0 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_27 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@3f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@3f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_27 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@3f8", .config = (&uart_ns16550_dev_cfg_0), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_27), .data = (&uart_ns16550_dev_data_0), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00027""_"))) __init___device_dts_ord_27 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_27, }; )(UART_NS16550_DEVICE_IO_MMIO_INIT(0))(; ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_0 = { .port = 1016, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_0 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_27 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@3f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@3f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_27 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@3f8", .config = (&uart_ns16550_dev_cfg_0), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_27), .data = (&uart_ns16550_dev_data_0), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00027""_"))) __init___device_dts_ord_27 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_27, }; )_XXXX0 (; DEVICE_PCIE_INST_DECLARE(0); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_0 = { .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), DEVICE_PCIE_INST_INIT(0, pcie) }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_0 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_27 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@3f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@3f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_27 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@3f8", .config = (&uart_ns16550_dev_cfg_0), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_27), .data = (&uart_ns16550_dev_data_0), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00027""_"))) __init___device_dts_ord_27 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_27, }; ); ; static const struct uart_ns16550_device_config uart_ns16550_dev_cfg_0 = { .port = 1016, .io_map = 1, .sys_clk_freq = 1843200, .clock_dev = ((void *)0), .clock_subsys = ((void *)0), .reg_interval = (1 << 0), }; static struct uart_ns16550_dev_data uart_ns16550_dev_data_0 = { .uart_config.baudrate = 115200, .uart_config.parity = UART_CFG_PARITY_NONE, .uart_config.stop_bits = UART_CFG_STOP_BITS_1, .uart_config.data_bits = UART_CFG_DATA_BITS_8, .uart_config.flow_ctrl = UART_CFG_FLOW_CTRL_NONE, }; static __attribute__((__aligned__(__alignof(struct device_state)))) struct device_state __devstate_dts_ord_27 __attribute__((__section__(".z_devstate"))); _Static_assert(sizeof("\"uart@3f8\"") <= 48U, "" "DEVICE_NAME_GET(\"uart@3f8\")" " too long"); const __attribute__((__aligned__(__alignof(struct device)))) struct device __device_dts_ord_27 __attribute__((section("." "_device" "." "static" "." "1_50_"))) __attribute__((__used__)) = { .name = "uart@3f8", .config = (&uart_ns16550_dev_cfg_0), .api = (&uart_ns16550_driver_api), .state = (&__devstate_dts_ord_27), .data = (&uart_ns16550_dev_data_0), }; static const __attribute__((__aligned__(__alignof(struct init_entry)))) struct init_entry __attribute__((__used__)) __attribute__((__section__( ".z_init_" "PRE_KERNEL_1" "50""_" "00027""_"))) __init___device_dts_ord_27 = { .init_fn = {.dev = (&uart_ns16550_init)}, .dev = &__device_dts_ord_27, };(DT_DEP_ORD_STR_SORTABLE(DT_N_S_soc_S_uart_3f8))(00027)(.deps = (Z_DEVICE_DEPS_NAME(dts_ord_27)),)_XXXXCONFIG_DEVICE_DEPS (.deps = (Z_DEVICE_DEPS_NAME(dts_ord_27)),)&uart_ns16550_init, NULL, &uart_ns16550_dev_data_0, &uart_ns16550_dev_cfg_0, COND_CODE_1(CONFIG_UART_NS16550_PARENT_INIT_LEVEL, (POST_KERNEL), (PRE_KERNEL_1)), CONFIG_SERIAL_INIT_PRIORITY, &uart_ns16550_driver_apiDT_INST_NODE_HAS_PROP(0, dlf)(.dlf = DT_INST_PROP_OR(0, dlf, 0),)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_3f8, dlf)(DT_PROP(DT_N_S_soc_S_uart_3f8, dlf))(DT_N_S_soc_S_uart_3f8_P_dlf)_XXXX0 (DT_N_S_soc_S_uart_3f8_P_dlf)DT_INST_NODE_HAS_PROP(0, pcp)(.pcp = DT_INST_PROP_OR(0, pcp, 0),)DT_INST_NODE_HAS_PROP(0, clock_frequency)( .sys_clk_freq = DT_INST_PROP(0, clock_frequency), .clock_dev = NULL, .clock_subsys = NULL, )( .sys_clk_freq = 0, .clock_dev = DEVICE_DT_GET(DT_INST_CLOCKS_CTLR(0)), .clock_subsys = (clock_control_subsys_t) DT_INST_PHA( 0, clocks, clkid), )( .sys_clk_freq = 0, .clock_dev = (&__device_dts_ord_DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_PH_ORD), .clock_subsys = (clock_control_subsys_t) DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_VAL_clkid, )DT_INST_CLOCKS_CTLR(0)DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_PHZ_DEVICE_DT_DEV_ID(DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_PH)dts_ord_DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_PH_ORDDT_DEP_ORD(DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_PH)DT_N_S_soc_S_uart_3f8_P_clocks_IDX_0_PH_ORDDT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, clock_frequency, _EXISTS)DT_INST_PROP_OR(0, hw_flow_control, 0)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_3f8, current_speed)(DT_PROP(DT_N_S_soc_S_uart_3f8, current_speed))DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, current_speed, _EXISTS)DT_INST_NODE_HAS_PROP(0, resets)(.reset_spec = RESET_DT_SPEC_INST_GET(0),)_XXXX0 (.reset_spec = RESET_DT_SPEC_INST_GET(0),)DT_INST_NODE_HAS_PROP(0, pinctrl_0)(.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_DRV_INST(0)),)(.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_N_S_soc_S_uart_3f8),)_XXXX0 (.pincfg = PINCTRL_DT_DEV_CONFIG_GET(DT_N_S_soc_S_uart_3f8),)DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_3f8, hw_flow_control)(DT_PROP(DT_N_S_soc_S_uart_3f8, hw_flow_control))DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, hw_flow_control, _EXISTS)DT_CAT4(DT_N_S_soc_S_uart_3f8, _P_, pinctrl_0, _EXISTS)DT_N_S_soc_S_uart_3f8_P_pinctrl_0_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_pinctrl_0_EXISTS_XXXXDT_N_S_soc_S_uart_3f8_P_pinctrl_0_EXISTS 1DT_NODE_HAS_PROP(DT_N_S_soc_S_uart_3f8, pcp)(DT_PROP(DT_N_S_soc_S_uart_3f8, pcp))(DT_N_S_soc_S_uart_3f8_P_pcp)_XXXX0 (DT_N_S_soc_S_uart_3f8_P_pcp)DT_INST_PROP_OR(0, io_mapped, 0)(.port = DT_INST_REG_ADDR(0),)(.port = 1016,)(DEVICE_MMIO_ROM_INIT(DT_DRV_INST(0)),)(._mmio = { .phys_addr = 1016, .size = 256 },)(PINCTRL_DT_INST_DEFINE(0))_XXXX0 (PINCTRL_DT_INST_DEFINE(0)).port = 1016,DT_CAT3(DT_N_S_soc_S_uart_3f8, _BUS_, pcie)DT_N_S_soc_S_uart_3f8_BUS_pcie_XXXXDT_N_S_soc_S_uart_3f8_BUS_pcie_XXXXDT_N_S_soc_S_uart_3f8_BUS_pcie 1_str(UTIL_CAT(uart_ns16550, _str))(uart_ns16550_str)(STRINGIFY(uart_ns16550))("uart_ns16550")log_constlog_source_const_dataZ_LOG_ITEM_CONST_DATA(uart_ns16550)struct log_source_const_data_log_const_CONCAT(log_const_uart_ns16550, _)log_const_uart_ns16550___alignof(struct log_source_const_data)LOG_IN_CPLUSPLUS(extern)_XXXXLOG_IN_CPLUSPLUS_XXXXLOG_IN_CPLUSPLUS (extern)( static const char UTIL_CAT(uart_ns16550, _str)[] __in_section(_log_strings, static, _CONCAT(uart_ns16550, _)) __used __noasan = STRINGIFY(uart_ns16550);)( static const char uart_ns16550_str[] __attribute__((section("." "_log_strings" "." "static" "." "uart_ns16550_"))) __attribute__((__used__)) = "uart_ns16550";)_XXXXCONFIG_LOG_FMT_SECTION ( static const char uart_ns16550_str[] __attribute__((section("." "_log_strings" "." "static" "." "uart_ns16550_"))) __attribute__((__used__)) = "uart_ns16550";)_CONCAT(uart_ns16550, _)uart_ns16550_Z_DO_LOG_MODULE_REGISTER(uart_ns16550, CONFIG_UART_LOG_LEVEL)(_LOG_MODULE_DATA_CREATE(GET_ARG_N(1, uart_ns16550, CONFIG_UART_LOG_LEVEL), _LOG_LEVEL_RESOLVE(uart_ns16550, CONFIG_UART_LOG_LEVEL)))(const __attribute__((__aligned__(__alignof(struct log_source_const_data)))) struct log_source_const_data log_const_uart_ns16550 __attribute__((section("." "_log_const" "." "static" "." "log_const_uart_ns16550_"))) __attribute__((__used__)) = { .name = "uart_ns16550", .level = 0U }; )_XXXX0 (const __attribute__((__aligned__(__alignof(struct log_source_const_data)))) struct log_source_const_data log_const_uart_ns16550 __attribute__((section("." "_log_const" "." "static" "." "log_const_uart_ns16550_"))) __attribute__((__used__)) = { .name = "uart_ns16550", .level = 0U }; )(_LOG_MODULE_DYNAMIC_DATA_CREATE(uart_ns16550);)(__attribute__((__aligned__(__alignof(struct log_source_dynamic_data)))) struct log_source_dynamic_data log_dynamic_uart_ns16550 __attribute__((section("." "_log_dynamic" "." "static" "." "log_dynamic_uart_ns16550_"))) __attribute__((__used__)) ;)_XXXXCONFIG_LOG_RUNTIME_FILTERING (__attribute__((__aligned__(__alignof(struct log_source_dynamic_data)))) struct log_source_dynamic_data log_dynamic_uart_ns16550 __attribute__((section("." "_log_dynamic" "." "static" "." "log_dynamic_uart_ns16550_"))) __attribute__((__used__)) ;)log_dynamiclog_source_dynamic_dataLOG_ITEM_DYNAMIC_DATA(uart_ns16550)struct log_source_dynamic_data_log_dynamic_CONCAT(log_dynamic_uart_ns16550, _)log_dynamic_uart_ns16550___alignof(struct log_source_dynamic_data)_XXXXCONFIG_LOG_FMT_SECTION (uart_ns16550_str)"uart_ns16550"/* CONFIG_UART_INTERRUPT_DRIVEN *//* !CONFIG_UART_INTERRUPT_DRIVEN *//* PCI(e) with auto IRQ detection *//* IO-port or MMIO based UART *//* CONFIG_UART_NS16550_DRV_CMD *//**
 * @brief Send extra command to driver
 *
 * @param dev UART device struct
 * @param cmd Command to driver
 * @param p Parameter to the command
 *
 * @return 0 if successful, failed otherwise
 *//* CONFIG_UART_NS16550_LINE_CTRL *//**
 * @brief Manipulate line control for UART.
 *
 * @param dev UART device struct
 * @param ctrl The line control to be manipulated
 * @param val Value to set the line control
 *
 * @return 0 if successful, failed otherwise
 *//**
 * @brief Interrupt service routine.
 *
 * This simply calls the callback function, if one exists.
 *
 * @param arg Argument to ISR.
 *//**
 * @brief Set the callback function pointer for IRQ.
 *
 * @param dev UART device struct
 * @param cb Callback function pointer.
 *//**
 * @brief Update cached contents of IIR
 *
 * @param dev UART device struct
 *
 * @return Always 1
 *//**
 * @brief Check if any IRQ is pending
 *
 * @param dev UART device struct
 *
 * @return 1 if an IRQ is pending, 0 otherwise
 *//**
 * @brief Disable error interrupt in IER
 *
 * @param dev UART device struct
 *
 * @return 1 if an IRQ is ready, 0 otherwise
 *//**
 * @brief Enable error interrupt in IER
 *
 * @param dev UART device struct
 *//**
 * @brief Check if Rx IRQ has been raised
 *
 * @param dev UART device struct
 *
 * @return 1 if an IRQ is ready, 0 otherwise
 *//**
 * @brief Disable RX interrupt in IER
 *
 * @param dev UART device struct
 *//**
 * @brief Enable RX interrupt in IER
 *
 * @param dev UART device struct
 *//**
 * @brief Check if nothing remains to be transmitted
 *
 * @param dev UART device struct
 *
 * @return 1 if nothing remains to be transmitted, 0 otherwise
 *//**
 * @brief Check if Tx IRQ has been raised
 *
 * @param dev UART device struct
 *
 * @return 1 if an IRQ is ready, 0 otherwise
 *//*
		 * Power state to be enabled. Some platforms have multiple
		 * states and need to be given a constraint release according
		 * to different states.
		 *//**
 * @brief Disable TX interrupt in IER
 *
 * @param dev UART device struct
 *//*
		 * Power state to be disabled. Some platforms have multiple
		 * states and need to be given a constraint set according to
		 * different states.
		 *//**
 * @brief Enable TX interrupt in IER
 *
 * @param dev UART device struct
 *//**
 * @brief Read data from FIFO
 *
 * @param dev UART device struct
 * @param rxData Data container
 * @param size Container size
 *
 * @return Number of bytes read
 *//**
 * @brief Fill FIFO with data
 *
 * @param dev UART device struct
 * @param tx_data Data to transmit
 * @param size Number of bytes to send
 *
 * @return Number of bytes sent
 *//**
 * @brief Check if an error was received
 *
 * @param dev UART device struct
 *
 * @return one of UART_ERROR_OVERRUN, UART_ERROR_PARITY, UART_ERROR_FRAMING,
 * UART_BREAK if an error was detected, 0 otherwise.
 *//**
 * @brief Output a character in polled mode.
 *
 * Checks if the transmitter is empty. If empty, a character is written to
 * the data register.
 *
 * If the hardware flow control is enabled then the handshake signal CTS has to
 * be asserted in order to send a character.
 *
 * @param dev UART device struct
 * @param c Character to send
 *//* got a character *//**
 * @brief Poll the device for input.
 *
 * @param dev UART device struct
 * @param c Pointer to character
 *
 * @return 0 if a character arrived, -1 if the input buffer if empty.
 *//* Map directly from DTS *//* DT_ANY_INST_ON_BUS_STATUS_OKAY(pcie) *//* Assert the UART reset line if it is defined. *//**
 * @brief Initialize individual UART port
 *
 * This routine is called to reset the chip in a quiescent state.
 *
 * @param dev UART device struct
 *
 * @return 0 if successful, failed otherwise
 *//* UART_NS16550_RESET_ENABLED *//**
 * @brief Toggle the reset UART line
 *
 * This routine is called to bring UART IP out of reset state.
 *
 * @param reset_spec Reset controller device configuration struct
 *
 * @return 0 if successful, failed otherwise
 *//* CONFIG_UART_USE_RUNTIME_CONFIGURE *//* disable interrupts  *//* clear the port *//*
	 * Program FIFO: enabled, mode 0 (set for compatibility with quark),
	 * generate the interrupt at 8th byte
	 * Clear TX and RX FIFO
	 *//* data bits, stop bits, parity, clear DLAB *//* Local structure to hold temporary values to pass to ns16550_outbyte() *//*
	 * set clock frequency from clock_frequency property if valid,
	 * otherwise, get clock frequency from clock manager
	 *//* temp for return value if error occurs in this locked region *//* restore the DLAB to access the baud rate divisor registers *//* set the DLAB to access the baud rate divisor registers *//* baud rate divisor *//* Set ECSPMR register as default *//*
		 * This bit indicates that the supported baud rate of
		 * UART1/UART2 can be up to 230.4k and 460.8k.
		 * Other bits are reserved and have no setting, so we
		 * directly write the ECSPMR register.
		 *//* Baud rate divisor for high speed *//*
	 * calculate baud rate divisor. a variant of
	 * (uint32_t)(pclk / (16.0 * baud_rate) + 0.5)
	 *//* MMIO mapped *//**< DLF value *//**< Callback function arg *//**< Callback function pointer *//**< cache of IIR since it clears when read *//** Device data structure *//* device config *//* IT8XXX2 UART high speed baud rate settings *//* EC high speed select *//* Fields for ITE IT8XXX2 UART module *//* EC Serial port mode reg *//* Register definitions (ITE_IT8XXX2) *//* complement of dcd *//* complement of ring signal *//* complement of dsr *//* complement of cts *//* data carrier change *//* ring change *//* dsr change *//* cts change *//* constants for modem status register *//* transmitter empty *//* transmit holding register empty *//* Error or Break mask *//* break interrupt *//* framing error *//* parity error *//* overrun error *//* receiver data available *//* constants for line status register *//* auto flow control enable *//* loop back *//* output #2 *//* output #1 *//* rts output *//* dtr output *//* constants for the modem control register *//* divisor latch access enable *//* break control bit *//* stick parity select *//* even parity select *//* parity disable *//* parity enable *//* 1 stop bit *//* 2 stop bits *//* 8 bits data size *//* 7 bits data size *//* 6 bits data size *//* 5 bits data size *//* constants for line control register *//* Enable 64 bytes FIFO *//*
 * UART NS16750 supports 64 bytes FIFO, which can be enabled
 * via the FCR register
 *//* 14 bytes in RCVR FIFO *//* 8 bytes in RCVR FIFO *//* 4 bytes in RCVR FIFO *//* 1 byte in RCVR FIFO *//* RCVR FIFO interrupt levels: trigger interrupt with this bytes in FIFO *//* set receiver in mode 1 *//* set receiver in mode 0 *//*
 * Per PC16550D (Literature Number: SNLS378B):
 *
 * RXRDY, Mode 0: When in the 16450 Mode (FCR0 = 0) or in
 * the FIFO Mode (FCR0 = 1, FCR3 = 0) and there is at least 1
 * character in the RCVR FIFO or RCVR holding register, the
 * RXRDY pin (29) will be low active. Once it is activated the
 * RXRDY pin will go inactive when there are no more charac-
 * ters in the FIFO or holding register.
 *
 * RXRDY, Mode 1: In the FIFO Mode (FCR0 = 1) when the
 * FCR3 = 1 and the trigger level or the timeout has been
 * reached, the RXRDY pin will go low active. Once it is acti-
 * vated it will go inactive when there are no more characters
 * in the FIFO or holding register.
 *
 * TXRDY, Mode 0: In the 16450 Mode (FCR0 = 0) or in the
 * FIFO Mode (FCR0 = 1, FCR3 = 0) and there are no charac-
 * ters in the XMIT FIFO or XMIT holding register, the TXRDY
 * pin (24) will be low active. Once it is activated the TXRDY
 * pin will go inactive after the first character is loaded into the
 * XMIT FIFO or holding register.
 *
 * TXRDY, Mode 1: In the FIFO Mode (FCR0 = 1) when
 * FCR3 = 1 and there are no characters in the XMIT FIFO, the
 * TXRDY pin will go low active. This pin will become inactive
 * when the XMIT FIFO is completely full.
 *//* Modes available for TI K3 UART module *//* Fields for TI K3 UART module *//* enable clock output *//* update clock *//* equates for Apollo Lake clock control register (PRV_CLOCK_PARAMS) *//* clear XMIT FIFO *//* clear RCVR FIFO *//* equates for FIFO control register *//* Character timeout*//* FIFO mode enabled *//* interrupt ID mask without NIP *//* interrupt id bits mask  *//* receiver line status interrupt *//* receiver buffer register full interrupt *//* transmit holding register empty interrupt *//* no interrupt pending    *//* modem status interrupt  *//* equates for interrupt identification register *//* modem status interrupts *//* line status interrupts *//* transmit bit enable *//* receiver data ready *//* equates for interrupt enable register *//* Mode control reg. (TI_K3) *//* PRV_CLOCK_PARAMS (Apollo Lake) *//* Divisor Latch Fraction         *//* Modem status reg.              *//* Line status reg.               *//* Modem control reg.             *//* Line control reg.              *//* FIFO control reg.              *//* Interrupt ID reg.              *//* Interrupt enable reg.          *//* Baud rate divisor (MSB)        *//* Baud rate divisor (LSB)        *//* Receiver data reg.             *//* Transmitter holding reg.       *//* register definitions *//* If any node has property io-mapped set, we need to support IO port
 * access in the code and device config struct.
 *
 * Note that DT_ANY_INST_HAS_PROP_STATUS_OKAY() always returns true
 * as io-mapped property is considered always exists and present,
 * even if its value is zero. Therefore we cannot use it, and has to
 * resort to the follow helper to see if any okay nodes have io-mapped
 * as 1.
 *//* Is UART module 'resets' line property defined *//**
 * @brief NS16550 Serial Driver
 *
 * This is the driver for the Intel NS16550 UART Chip used on the PC 386.
 * It uses the SCCs in asynchronous mode only.
 *
 * Before individual UART port can be used, uart_ns16550_port_init() has to be
 * called to setup the port.
 *//*
 * Copyright (c) 2010, 2012-2015 Wind River Systems, Inc.
 * Copyright (c) 2020-2023 Intel Corp.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//* ns16550.c - NS16550D serial driver */DEVICE_NAME_GET("uart@2f8") too longDEVICE_NAME_GET("uart@3f8") too long/home/haojie/zephyrproject/zephyr/include/zephyr/dt-bindings/interrupt-controller/intel-ioapic.hIRQ_TYPE_FIXED_LEVEL_LOW(IRQ_DELIVERY_FIXED | IRQ_TYPE_LEVEL | IRQ_TYPE_LOW)IRQ_TYPE_FIXED_LEVEL_HIGH(IRQ_DELIVERY_FIXED | IRQ_TYPE_LEVEL | IRQ_TYPE_HIGH)IRQ_TYPE_FIXED_EDGE_FALLING(IRQ_DELIVERY_FIXED | IRQ_TYPE_EDGE | IRQ_TYPE_LOW)IRQ_TYPE_FIXED_EDGE_RISING(IRQ_DELIVERY_FIXED | IRQ_TYPE_EDGE | IRQ_TYPE_HIGH)IRQ_TYPE_LOWEST_LEVEL_LOW(IRQ_DELIVERY_LOWEST | IRQ_TYPE_LEVEL | IRQ_TYPE_LOW)IRQ_TYPE_LOWEST_LEVEL_HIGH(IRQ_DELIVERY_LOWEST | IRQ_TYPE_LEVEL | IRQ_TYPE_HIGH)IRQ_TYPE_LOWEST_EDGE_FALLING(IRQ_DELIVERY_LOWEST | IRQ_TYPE_EDGE | IRQ_TYPE_LOW)IRQ_TYPE_LOWEST_EDGE_RISING(IRQ_DELIVERY_LOWEST | IRQ_TYPE_EDGE | IRQ_TYPE_HIGH)IRQ_DELIVERY_FIXEDIRQ_DELIVERY_LOWESTIRQ_TYPE_HIGHIRQ_TYPE_LOWIRQ_TYPE_EDGEIRQ_TYPE_LEVELZEPHYR_INCLUDE_DT_BINDINGS_INTERRUPT_CONTROLLER_INTEL_IOAPIC_H_/* for interrupts that want to be delivered to all CPUs, e.g. HPET *//*
 * for most device interrupts, lowest priority delivery is preferred
 * since this ensures only one CPU gets the interrupt in SMP systems.
 *//home/haojie/zephyrproject/zephyr/include/zephyr/dt-bindings/interrupt-controller/home/haojie/zephyrproject/zephyr/include/zephyr/drivers/timer/system_timer.h/home/haojie/zephyrproject/zephyr/drivers/timer/hpet.c<zephyr/dt-bindings/interrupt-controller/intel-ioapic.h><zephyr/drivers/timer/system_timer.h>sys_clock_driver_inithzhpet_regsDT_INST_IRQN(0)DT_INST_IRQ(0, priority)hpet_isrDT_INST_IRQ(0, sense)_IRQ_IDX_senseDT_DASH(0, intel_hpet)_0_intel_hpet0, intel_hpetDT_DASH_PREFIX, 0, intel_hpetNUM_VA_ARGS_LESS_1(DT_DASH_PREFIX, 0, intel_hpet)intel_hpet,MACRO_MC_1(DT_DASH_PREFIX, intel_hpet,,)_intel_hpetIS_ENABLED(CONFIG_MULTI_LEVEL_INTERRUPTS)(DT_MULTI_LEVEL_IRQN_INTERNAL(DT_N_S_soc_S_hpet_fed00000, 0))(DT_IRQN_BY_IDX_INTERNAL(DT_N_S_soc_S_hpet_fed00000, 0))CONFIG_MULTI_LEVEL_INTERRUPTS_XXXXCONFIG_MULTI_LEVEL_INTERRUPTS_XXXXCONFIG_MULTI_LEVEL_INTERRUPTS 1DT_HAS_GPARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)(DT_IRQN_L3_INTERNAL(DT_N_S_soc_S_hpet_fed00000, 0))((IRQ_TO_L3(2) | IRQ_TO_L2(DT_N_S_ioapic_fec00000_IRQ_IDX_0_VAL_irq) | DT_N_S_ioapic_fec00000_P_interrupt_parent_IRQ_IDX_0_VAL_irq))(COND_CODE_1(DT_HAS_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000), (DT_IRQN_L2_INTERNAL(DT_N_S_soc_S_hpet_fed00000, 0)), (DT_IRQN_BY_IDX_INTERNAL(DT_N_S_soc_S_hpet_fed00000, 0))))DT_HAS_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)(DT_HAS_PARENT_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)))DT_NODE_HAS_PROP(DT_N_S_soc_S_hpet_fed00000, interrupt_parent)(IF_ENABLED(DT_IS_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)), (COND_CODE_0(DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)), (0), (1)))))interrupt_parentDT_CAT4(DT_N_S_soc_S_hpet_fed00000, _P_, interrupt_parent, _EXISTS)DT_IS_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000))(COND_CODE_0(DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)), (0), (1)))DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)interrupt_controllerDT_CAT4(DT_N_S_ioapic_fec00000, _P_, interrupt_controller, _EXISTS)DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000))_IRQ_NUMDT_NODE_HAS_PROP(DT_N_S_ioapic_fec00000, interrupt_parent)(IF_ENABLED(DT_IS_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(DT_N_S_ioapic_fec00000)), (COND_CODE_0(DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(DT_N_S_ioapic_fec00000)), (0), (1)))))DT_CAT4(DT_N_S_ioapic_fec00000, _P_, interrupt_parent, _EXISTS)DT_N_S_ioapic_fec00000_P_interrupt_parent_EXISTS_XXXXDT_N_S_ioapic_fec00000_P_interrupt_parent_EXISTS_XXXXDT_N_S_ioapic_fec00000_P_interrupt_parent_EXISTS 1DT_IS_INTC_INTERNAL(DT_PARENT_INTC_INTERNAL(DT_N_S_ioapic_fec00000))(COND_CODE_0(DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(DT_N_S_ioapic_fec00000)), (0), (1)))DT_PARENT_INTC_INTERNAL(DT_N_S_ioapic_fec00000)DT_N_S_ioapic_fec00000_P_interrupt_parentDT_CAT4(DT_N_S_ioapic_fec00000_P_interrupt_parent, _P_, interrupt_controller, _EXISTS)DT_N_S_ioapic_fec00000_P_interrupt_parent_P_interrupt_controller_EXISTS_XXXXDT_N_S_ioapic_fec00000_P_interrupt_parent_P_interrupt_controller_EXISTS_XXXXDT_N_S_ioapic_fec00000_P_interrupt_parent_P_interrupt_controller_EXISTS 1DT_NUM_IRQS(DT_PARENT_INTC_INTERNAL(DT_N_S_ioapic_fec00000))DT_N_S_ioapic_fec00000_P_interrupt_parent_IRQ_NUM_ZZZZDT_N_S_ioapic_fec00000_P_interrupt_parent_IRQ_NUM_ZZZZDT_N_S_ioapic_fec00000_P_interrupt_parent_IRQ_NUM (0)_XXXX0 ()DT_GPARENT_INTC_INTERNAL(DT_N_S_soc_S_hpet_fed00000)(DT_IRQN_L2_INTERNAL(DT_N_S_soc_S_hpet_fed00000, 0))((IRQ_TO_L2(2) | DT_N_S_ioapic_fec00000_IRQ_IDX_0_VAL_irq))_XXXX0 ((IRQ_TO_L2(2) | DT_N_S_ioapic_fec00000_IRQ_IDX_0_VAL_irq))_XXXX_XXXX ((IRQ_TO_L3(2) | IRQ_TO_L2(DT_N_S_ioapic_fec00000_IRQ_IDX_0_VAL_irq) | DT_N_S_ioapic_fec00000_P_interrupt_parent_IRQ_IDX_0_VAL_irq))_XXXX0 (2)1000000000000000HPET_COUNTER_CLK_PERIODDT_CAT6(DT_N_S_soc_S_hpet_fed00000, _IRQ_IDX_, 0, _VAL_, sense, _EXISTS)no_legacy_irqsys_clock_idle_exitsys_clock_elapsed!IS_ENABLED(CONFIG_TICKLESS_KERNEL)nowsys_clock_set_timeout4294967294~GCONF_ENABLEHPET_MAX_TICKSHPET_MAX_TICKS/2((int32_t)0x7fffffff)/2cycsmp_timer_initconfig_timer00x1f158720x1f << 9(0x1f << 9)4294951423~(0x1f << 9)16648(uint32_t)(TIMER_CONF_MODE32 | TIMER_CONF_PERIODIC |
			TIMER_CONF_FSB_EN)((uint32_t)(TIMER_CONF_MODE32 | TIMER_CONF_PERIODIC |
			TIMER_CONF_FSB_EN))4294950647~((uint32_t)(TIMER_CONF_MODE32 | TIMER_CONF_PERIODIC |
			TIMER_CONF_FSB_EN))diffhpet_timer_comparator_set_safe(int64_t)(next - now) <= 0bumphpet_timer_comparator_set0x1080x10chpet_timer_conf_sethpet_timer_conf_gethpet_gconf_sethpet_gconf_gethpet_counter_clk_period_gethpet_counter_get0xf0/home/haojie/zephyrproject/zephyr/drivers/timer__init_sys_clock_driver_initPRE_KERNEL_2.z_init_PRE_KERNEL_20_0_char[25]cyc_per_ticklast_elapsedlast_ticklast_countz_mmio_rom__hpet_regsz_mmio_ram__hpet_regs((int32_t)0x7fffffff)(1000000000000000ULL)TIMER0_COMPARATOR_HIGH_REGHPET_REG_ADDR(0x10c)TIMER0_COMPARATOR_LOW_REGHPET_REG_ADDR(0x108)TIMER0_CONF_REGHPET_REG_ADDR(0x100)MAIN_COUNTER_HIGH_REGHPET_REG_ADDR(0xf4)MAIN_COUNTER_LOW_REGHPET_REG_ADDR(0xf0)INTR_STATUS_REGHPET_REG_ADDR(0x20)GCONF_REGHPET_REG_ADDR(0x10)CLK_PERIOD_REGHPET_REG_ADDR(0x04)HPET_REG_ADDR(off)((mm_reg_t)(DEVICE_MMIO_TOPLEVEL_GET(hpet_regs) + (off)))TIMER_CONF_FSB_ENBIT(14)TIMER_CONF_MODE32TIMER_CONF_VAL_SETTIMER_CONF_PERIODICTIMER_CONF_INT_ENABLETIMER_CONF_INT_LEVELTIMER0_INT_STSGCONF_LRGCONF_ENABLEdefined(CONFIG_TEST)HPET_USE_CUSTOM_REG_ACCESS_FUNCS(DT_INST_IRQ_HAS_CELL(0, sense))HPET_INT_LEVEL_TRIGGER((DT_INST_IRQ(0, sense) & IRQ_TYPE_LEVEL) == IRQ_TYPE_LEVEL)defined(CONFIG_TICKLESS_KERNEL)DT_INST_IRQ_HAS_CELL(0, sense)(DT_INST_PROP(0, no_legacy_irq) == 0)/* Note: we set the legacy routing bit, because otherwise
	 * nothing in Zephyr disables the PIT which then fires
	 * interrupts into the same IRQ.  But that means we're then
	 * forced to use IRQ2 contra the way the kconfig IRQ selection
	 * is supposed to work.  Should fix this.
	 *//* Noop, the HPET is a single system-wide device and it's
	 * configured to deliver interrupts to every CPU, so there's
	 * nothing to do at initialization on auxiliary CPUs.
	 *//* Set level trigger if selected *//* 5-bit IRQ field starting at bit 9 *//* Qemu in SMP mode has observed the clock going
		 * "backwards" relative to interrupts already received
		 * on the other CPU, despite the HPET being
		 * theoretically a global device.
		 *//*
	 * Clear interrupt only if level trigger is selected.
	 * When edge trigger is selected, spec says only 0 can
	 * be written.
	 *//* ensure the comparator is always set ahead of the current counter value *//**
 * @brief Write to General Interrupt Status Register
 *
 * This is used to acknowledge and clear interrupt bits.
 *
 * @param val Value to be written to the register
 *//* (DT_INST_IRQ_HAS_CELL(0, sense)) *//*
 * HPET_INT_LEVEL_TRIGGER is used to set HPET interrupt as level trigger
 * for ARM CPU with NVIC like EHL PSE, whose DTS interrupt setting
 * has no "sense" cell.
 *//* COUNTER_CLK_PERIOD (CLK_PERIOD_REG) is in femtoseconds (1e-15 sec) *//* HPET_USE_CUSTOM_REG_ACCESS_FUNCS *//**
 * @brief Write to the Timer Comparator Value Register
 *
 * This writes the specified value to the Timer Comparator
 * Value Register of Timer #0.
 *
 * @param val Value to be written to the register
 *//*
 * The following register access functions should work on generic x86
 * hardware. If the targeted SoC requires special handling of HPET
 * registers, these functions will need to be implemented in the SoC
 * layer by first defining the macro HPET_USE_CUSTOM_REG_ACCESS_FUNCS
 * in soc.h to signal such intent.
 *
 * This is a list of functions which must be implemented in the SoC
 * layer:
 *   void hpet_timer_comparator_set(uint32_t val)
 *//**
 * @brief Write to the Timer Configuration Register
 *
 * This writes the specified value to the Timer Configuration
 * Register of Timer #0.
 *
 * @param val Value to be written to the register
 *//**
 * @brief Return the value of the Timer Configuration Register
 *
 * This reads and returns the value of the Timer Configuration
 * Register of Timer #0.
 *
 * @return Value of the Timer Configuration Register
 *//**
 * @brief Write to General Configuration Register
 *
 * @param val Value to be written to the register
 *//**
 * @brief Return the value of the General Configuration Register
 *
 * @return Value of the General Configuration Register
 *//**
 * @brief Get COUNTER_CLK_PERIOD
 *
 * Read and return the COUNTER_CLK_PERIOD, which is the high
 * 32-bit of the General Capabilities and ID Register. This can
 * be used to calculate the frequency of the main counter.
 *
 * Usually the period is in femtoseconds. If this is not
 * the case, define HPET_COUNTER_CLK_PERIOD in soc.h so
 * it can be used to calculate frequency.
 *
 * @return COUNTER_CLK_PERIOD
 *//**
 * @brief Return the value of the main counter.
 *
 * @return Value of Main Counter
 *//* Timer 0 Comparator Register *//* Timer 0 Configuration and Capabilities register *//* Main Counter Register *//* General Interrupt Status register *//* General Configuration register *//* High dword of General Capabilities and ID register *//* enable                   *//* FSB interrupt delivery   *//* Timer Configuration and Capabilities register *//* disables PIT              *//* legacy interrupt routing, *//**
 * @file
 * @brief HPET (High Precision Event Timers) driver
 *
 * HPET hardware contains a number of timers which can be used by
 * the operating system, where the number of timers is implementation
 * specific. The timers are implemented as a single up-counter with
 * a set of comparators where the counter increases monotonically.
 * Each timer has a match register and a comparator, and can generate
 * an interrupt when the value in the match register equals the value of
 * the free running counter. Some of these timers can be enabled to
 * generate periodic interrupt.
 *
 * The HPET registers are usually mapped to memory space on x86
 * hardware. If this is not the case, custom register access functions
 * can be used by defining macro HPET_USE_CUSTOM_REG_ACCESS_FUNCS in
 * soc.h, and implementing necessary initialization and access
 * functions as described below.
 *
 * HPET_COUNTER_CLK_PERIOD can be overridden in soc.h if
 * COUNTER_CLK_PERIOD is not in femtoseconds (1e-15 sec).
 *//*
 * Copyright (c) 2018-2021 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/drivers/timer/sys_clock_init.c/* Weak-linked noop defaults for optional driver interfaces*//**
 * @file
 * @brief Initialize system clock driver
 *
 * Initializing the timer driver is done in this module to reduce code
 * duplication.
 *//home/haojie/zephyrproject/zephyr/build/zephyr/include/generated/version.h/home/haojie/zephyrproject/zephyr/kernel/banner.c<version.h>boot_bannerBUILD_VERSIONzephyr-v3.5.0-1144-g4df07224f8dc*** Booting Zephyr OS build zephyr-v3.5.0-1144-g4df07224f8dc ***
"*** " CONFIG_BOOT_BANNER_STRING " " BANNER_VERSION BANNER_POSTFIX " ***\n"char[66]BANNER_VERSIONSTRINGIFY(BUILD_VERSION)BANNER_POSTFIXdefined(CONFIG_BOOT_DELAY) && (CONFIG_BOOT_DELAY > 0)/* CONFIG_BOOT_BANNER *//* defined(CONFIG_BOOT_DELAY) && (CONFIG_BOOT_DELAY > 0) */sys_clock_disablesys_clock_announceZEPHYR_INCLUDE_DRIVERS_SYSTEM_TIMER_H_/* ZEPHYR_INCLUDE_DRIVERS_SYSTEM_TIMER_H_ *//**
 * @brief 64 bit hardware cycle counter
 *
 * As for sys_clock_cycle_get_32(), but with a 64 bit return value.
 * Not all hardware has 64 bit counters.  This function need be
 * implemented only if CONFIG_TIMER_HAS_64BIT_CYCLE_COUNTER is set.
 *
 * @note
 * If the counter clock is large enough for sys_clock_cycle_get_32() to wrap
 * its full range within a few seconds (i.e. CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC
 * is greater than 50Mhz) then it is recommended to implement this API.
 *
 * @return The current cycle time.  This should count up monotonically
 * through the full 64 bit space, wrapping at 2^64-1.  Hardware with
 * fewer bits of precision in the timer is generally not expected to
 * implement this API.
 *//**
 * @brief Hardware cycle counter
 *
 * Timer drivers are generally responsible for the system cycle
 * counter as well as the tick announcements.  This function is
 * generally called out of the architecture layer (@see
 * arch_k_cycle_get_32()) to implement the cycle counter, though the
 * user-facing API is owned by the architecture, not the driver.  The
 * rate must match CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC.
 *
 * @note
 * If the counter clock is large enough for this to wrap its full range
 * within a few seconds (i.e. CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC is greater
 * than 50Mhz) then it is recommended to also implement
 * sys_clock_cycle_get_64().
 *
 * @return The current cycle time.  This should count up monotonically
 * through the full 32 bit space, wrapping at 0xffffffff.  Hardware
 * with fewer bits of precision in the timer is expected to synthesize
 * a 32 bit count.
 *//**
 * @brief Disable system timer.
 *
 * @note Not all system timer drivers has the capability of being disabled.
 * The config @kconfig{CONFIG_SYSTEM_TIMER_HAS_DISABLE_SUPPORT} can be used to
 * check if the system timer has the capability of being disabled.
 *//**
 * @brief Ticks elapsed since last sys_clock_announce() call
 *
 * Queries the clock driver for the current time elapsed since the
 * last call to sys_clock_announce() was made.  The kernel will call
 * this with appropriate locking, the driver needs only provide an
 * instantaneous answer.
 *//**
 * @brief Announce time progress to the kernel
 *
 * Informs the kernel that the specified number of ticks have elapsed
 * since the last call to sys_clock_announce() (or system startup for
 * the first call).  The timer driver is expected to delivery these
 * announcements as close as practical (subject to hardware and
 * latency limitations) to tick boundaries.
 *
 * @param ticks Elapsed time, in ticks
 *//**
 * @brief Timer idle exit notification
 *
 * This notifies the timer driver that the system is exiting the idle
 * and allows it to do whatever bookkeeping is needed to restore timer
 * operation and compute elapsed ticks.
 *
 * @note Legacy timer drivers also use this opportunity to call back
 * into sys_clock_announce() to notify the kernel of expired ticks.
 * This is allowed for compatibility, but not recommended.  The kernel
 * will figure that out on its own.
 *//**
 * @brief Set system clock timeout
 *
 * Informs the system clock driver that the next needed call to
 * sys_clock_announce() will not be until the specified number of ticks
 * from the the current time have elapsed.  Note that spurious calls
 * to sys_clock_announce() are allowed (i.e. it's legal to announce
 * every tick and implement this function as a noop), the requirement
 * is that one tick announcement should occur within one tick BEFORE
 * the specified expiration (that is, passing ticks==1 means "announce
 * the next tick", this convention was chosen to match legacy usage).
 * Similarly a ticks value of zero (or even negative) is legal and
 * treated identically: it simply indicates the kernel would like the
 * next tick announcement as soon as possible.
 *
 * Note that ticks can also be passed the special value K_TICKS_FOREVER,
 * indicating that no future timer interrupts are expected or required
 * and that the system is permitted to enter an indefinite sleep even
 * if this could cause rollover of the internal counter (i.e. the
 * system uptime counter is allowed to be wrong
 *
 * Note also that it is conventional for the kernel to pass INT_MAX
 * for ticks if it wants to preserve the uptime tick count but doesn't
 * have a specific event to await.  The intent here is that the driver
 * will schedule any needed timeout as far into the future as
 * possible.  For the specific case of INT_MAX, the next call to
 * sys_clock_announce() may occur at any point in the future, not just
 * at INT_MAX ticks.  But the correspondence between the announced
 * ticks and real-world time must be correct.
 *
 * A final note about SMP: note that the call to sys_clock_set_timeout()
 * is made on any CPU, and reflects the next timeout desired globally.
 * The resulting calls(s) to sys_clock_announce() must be properly
 * serialized by the driver such that a given tick is announced
 * exactly once across the system.  The kernel does not (cannot,
 * really) attempt to serialize things by "assigning" timeouts to
 * specific CPUs.
 *
 * @param ticks Timeout in tick units
 * @param idle Hint to the driver that the system is about to enter
 *        the idle state immediately after setting the timeout
 *//**
 * @brief System Clock APIs
 * @defgroup clock_apis System Clock APIs
 * @{
 *//**
 * @file
 * @brief Timer driver API
 *
 * Declare API implemented by system timer driver and used by kernel components.
 *//*
 * Copyright (c) 2015 Wind River Systems, Inc.
 * Copyright (c) 2019 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/drivers/timer/home/haojie/zephyrproject/zephyr/kernel/busy_wait.cbusy_waitstart_cyclescycles_to_wait(uint64_t)USEC_PER_SECcurrent_cyclesdefined(CONFIG_ARCH_HAS_CUSTOM_BUSY_WAIT)defined(CONFIG_SYS_CLOCK_EXISTS)/*
	 * Crude busy loop for the purpose of being able to configure out
	 * system timer support.
	 *//* this handles the rollover on an unsigned 32-bit value *//* use 64-bit math to prevent overflow when multiplying *//home/haojie/zephyrproject/zephyr/kernel/include/wait_q.h/home/haojie/zephyrproject/zephyr/include/zephyr/internal/syscall_handler.h/home/haojie/zephyrproject/zephyr/kernel/condvar.c<zephyr/internal/syscall_handler.h><wait_q.h>waitpending_threadbroadcast/* Initialize and link statically defined condvars *//* Initialize condvar object type *//* wake up any threads that are waiting to write */ZEPHYR_INCLUDE_SYSCALL_HANDLER_H_/* ZEPHYR_INCLUDE_SYSCALL_HANDLER_H_ *//**
 * @brief Runtime check kernel object pointer for non-init functions
 *
 * See description of _SYSCALL_IS_OBJ. Triggers a fatal error if the object is
 * initialized. Intended for init functions where objects, once initialized,
 * can only be re-used when their initialization state expires due to some
 * other mechanism.
 *
 * @param ptr Untrusted kernel object pointer
 * @param type Expected kernel object type
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check kernel object pointer for non-init functions
 *
 * See description of _SYSCALL_IS_OBJ. No initialization checks are done.
 * Intended for init functions where objects may be re-initialized at will.
 *
 * @param ptr Untrusted kernel object pointer
 * @param type Expected kernel object type
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check kernel object pointer for non-init functions
 *
 * Calls k_object_validate and triggers a kernel oops if the check fails.
 * For use in system call handlers which are not init functions; a fatal
 * error will occur if the object is not initialized.
 *
 * @param ptr Untrusted kernel object pointer
 * @param type Expected kernel object type
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check that device object is of a specific driver type
 *
 * Checks that the driver object passed in is initialized, the caller has
 * correct permissions, and that it belongs to the specified driver
 * subsystems. Additionally, all devices store a structure pointer of the
 * driver's API. If this doesn't match the value provided, the check will fail.
 *
 * This provides an easy way to determine if a device object not only
 * belongs to a particular subsystem, but is of a specific device driver
 * implementation. Useful for defining out-of-subsystem system calls
 * which are implemented for only one driver.
 *
 * @param _device Untrusted device pointer
 * @param _dtype Expected kernel object type for the provided device pointer
 * @param _api Expected driver API structure memory address
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check driver object pointer for presence of operation
 *
 * Validates if the driver object is capable of performing a certain operation.
 *
 * @param ptr Untrusted device instance object pointer
 * @param api_name Name of the driver API struct (e.g. gpio_driver_api)
 * @param op Driver operation (e.g. manage_callback)
 *
 * @return 0 on success, nonzero on failure
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Validate user thread has read/write permission for sized array
 *
 * Used when the memory region is expressed in terms of number of elements and
 * each element size, handles any overflow issues with computing the total
 * array bounds. Otherwise see _SYSCALL_MEMORY_WRITE.
 *
 * @param ptr Memory area to examine
 * @param nmemb Number of elements in the array
 * @param size Size of each array element
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Validate user thread has read permission for sized array
 *
 * Used when the memory region is expressed in terms of number of elements and
 * each element size, handles any overflow issues with computing the total
 * array bounds. Otherwise see _SYSCALL_MEMORY_READ.
 *
 * @param ptr Memory area to examine
 * @param nmemb Number of elements in the array
 * @param size Size of each array element
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check that a user thread has write permission to a memory area
 *
 * Checks that the particular memory area is readable and writable by the
 * currently running thread if the CPU was in user mode, and generates a kernel
 * oops if it wasn't. Prevents userspace from getting the kernel to read or
 * modify memory the thread does not have access to, or passing in garbage
 * pointers that would crash/pagefault the kernel if dereferenced.
 *
 * @param ptr Memory area to examine
 * @param size Size of the memory area
 * @return 0 on success, nonzero on failure
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check that a user thread has read permission to a memory area
 *
 * Checks that the particular memory area is readable by the currently running
 * thread if the CPU was in user mode, and generates a kernel oops if it
 * wasn't. Prevents userspace from getting the kernel to read memory the thread
 * does not have access to, or passing in garbage pointers that would
 * crash/pagefault the kernel if dereferenced.
 *
 * @param ptr Memory area to examine
 * @param size Size of the memory area
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime check that a user thread has read and/or write permission to
 *        a memory area
 *
 * Checks that the particular memory area is readable and/or writeable by the
 * currently running thread if the CPU was in user mode, and generates a kernel
 * oops if it wasn't. Prevents userspace from getting the kernel to read and/or
 * modify memory the thread does not have access to, or passing in garbage
 * pointers that would crash/pagefault the kernel if dereferenced.
 *
 * @param ptr Memory area to examine
 * @param size Size of the memory area
 * @param write If the thread should be able to write to this memory, not just
 *		read it
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime expression check for system call arguments
 *
 * Used in handler functions to perform various runtime checks on arguments,
 * and generate a kernel oops if anything is not expected.
 *
 * @param expr Boolean expression to verify, a false result will trigger an
 *             oops. A stringified version of this expression will be printed.
 * @return 0 on success, nonzero on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Runtime expression check for system call arguments
 *
 * Used in handler functions to perform various runtime checks on arguments,
 * and generate a kernel oops if anything is not expected, printing a custom
 * message.
 *
 * @param expr Boolean expression to verify, a false result will trigger an
 *             oops
 * @param fmt Printf-style format string (followed by appropriate variadic
 *            arguments) to print on verification failure
 * @return False on success, True on failure
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Induce a kernel oops
 *
 * This macro can be used to induce a kernel oops which will kill the
 * calling thread.
 *
 * @param expr Expression to be evaluated
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Copy a C string from userspace into a provided buffer
 *
 * Given a C string and maximum length, copy the string into a buffer.
 *
 * Checks are performed to ensure that the string is valid memory and that
 * the caller has access to it in user mode.
 *
 * @param dst Destination buffer
 * @param src Source string pointer, in userspace
 * @param maxlen Maximum size of the string including trailing NULL
 * @retval 0 on success
 * @retval EINVAL if the source string is too long with respect
 *	to maxlen
 * @retval EFAULT On memory access error
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Copy a C string from userspace into a resource pool allocation
 *
 * Given a C string and maximum length, duplicate the string using an
 * allocation from the calling thread's resource pool. This will need to be
 * freed later with k_free().
 *
 * Checks are performed to ensure that the string is valid memory and that
 * the caller has access to it in user mode.
 *
 * @param src Source string pointer, in userspace
 * @param maxlen Maximum size of the string including trailing NULL
 * @return The duplicated string, or NULL if an error occurred.
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Copy data to user mode
 *
 * Given a userspace pointer and a size, copies data to it from a provided
 * source buffer, performing checks to ensure that the caller would have
 * appropriate access when in user mode.
 *
 * @param dst Destination memory buffer, in userspace
 * @param src Source memory buffer
 * @param size Number of bytes to copy
 * @retval 0 On success
 * @retval EFAULT On memory access error
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Copy data from user mode
 *
 * Given a userspace pointer and a size, copies data from it into a provided
 * destination buffer, performing checks to ensure that the caller would have
 * appropriate access when in user mode.
 *
 * @param dst Destination memory buffer
 * @param src Source memory buffer, in userspace
 * @param size Number of bytes to copy
 * @retval 0 On success
 * @retval EFAULT On memory access error
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Copy data from userspace into a resource pool allocation
 *
 * Given a pointer and a size, allocate a similarly sized buffer in the
 * caller's resource pool and copy all the data within it to the newly
 * allocated buffer. This will need to be freed later with k_free().
 *
 * Checks are done to ensure that the current thread would have read
 * access to the provided buffer.
 *
 * @param src Source memory address
 * @param size Size of the memory buffer
 * @return An allocated buffer with the data copied within it, or NULL
 *	if some error condition occurred
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * @brief Obtain the size of a C string passed from user mode
 *
 * Given a C string pointer and a maximum size, obtain the true
 * size of the string (not including the trailing NULL byte) just as
 * if calling strnlen() on it, with the same semantics of strnlen() with
 * respect to the return value and the maxlen parameter.
 *
 * Any memory protection faults triggered by the examination of the string
 * will be safely handled and an error code returned.
 *
 * NOTE: Doesn't guarantee that user mode has actual access to this
 * string, you will need to still do a K_SYSCALL_MEMORY_READ()
 * with the obtained size value to guarantee this.
 *
 * @param src String to measure size of
 * @param maxlen Maximum number of characters to examine
 * @param err Pointer to int, filled in with -1 on memory error, 0 on
 *	success
 * @return undefined on error, or strlen(src) if that is less than maxlen, or
 *	maxlen if there were no NULL terminating characters within the
 *	first maxlen bytes.
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * Initialize and reset permissions to only access by the caller
 *
 * Intended for scenarios where objects are fetched from slab pools
 * and may have had different permissions set during prior usage.
 *
 * This is only intended for pools of objects, where such objects are
 * acquired and released to the pool. If an object has already been used,
 * we do not want stale permission information hanging around, the object
 * should only have permissions on the caller. Objects which are not
 * managed by a pool-like mechanism should not use this API.
 *
 * The object will be marked as initialized and the calling thread
 * granted access to it.
 *
 * @param obj Address of the kernel object
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * Clear initialization state of a kernel object
 *
 * Intended for thread objects upon thread exit, or for other kernel objects
 * that were released back to an object pool.
 *
 * @param obj Address of the kernel object
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *//**
 * Revoke access to all objects for the provided thread
 *
 * @note Unlike k_thread_perms_clear(), this function will not clear
 * permissions on public objects.
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 * @param thread Thread object to revoke access
 *//**
 * Revoke a thread's permission to a kernel object
 *
 * @param ko Kernel object metadata to update
 * @param thread The thread to grant permission
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 *//**
 * Grant a thread permission to a kernel object
 *
 * @param ko Kernel object metadata to update
 * @param thread The thread to grant permission
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 *//**
 * Copy all kernel object permissions from the parent to the child
 *
 * @param parent Parent thread, to get permissions from
 * @param child Child thread, to copy permissions to
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 *//**
 * Iterate over all the kernel object metadata in the system
 *
 * @param func function to run on each struct k_object
 * @param context Context pointer to pass to each invocation
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 *//**
 * Kernel object validation function
 *
 * Retrieve metadata for a kernel object. This function is implemented in
 * the gperf script footer, see gen_kobject_list.py
 *
 * @param obj Address of kernel object to get metadata
 * @return Kernel object's metadata, or NULL if the parameter wasn't the
 * memory address of a kernel object
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 *//**
 * Dump out error information on failed k_object_validate() call
 *
 * @param retval Return value from k_object_validate()
 * @param obj Kernel object we were trying to verify
 * @param ko If retval=-EPERM, struct k_object * that was looked up, or NULL
 * @param otype Expected type of the kernel object
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 *//**
 * Ensure a system object is a valid object of the expected type
 *
 * Searches for the object and ensures that it is indeed an object
 * of the expected type, that the caller has the right permissions on it,
 * and that the object has been initialized.
 *
 * This function is intended to be called on the kernel-side system
 * call handlers to validate kernel object pointers passed in from
 * userspace.
 *
 * @param ko Kernel object metadata pointer, or NULL
 * @param otype Expected type of the kernel object, or K_OBJ_ANY if type
 *	  doesn't matter
 * @param init Indicate whether the object needs to already be in initialized
 *             or uninitialized state, or that we don't care
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 * @return 0 If the object is valid
 *         -EBADF if not a valid object of the specified type
 *         -EPERM If the caller does not have permissions
 *         -EINVAL Object is not initialized
 *//* This gets set on entry to the syscall's generasted z_mrsh
	 * function and then cleared on exit. This code path is only
	 * encountered when a syscall is made from user mode, system
	 * calls from supervisor mode bypass everything directly to
	 * the implementation function.
	 *//**
 * Return true if we are currently handling a system call from user mode
 *
 * Inside z_vrfy functions, we always know that we are handling
 * a system call invoked from user context.
 *
 * However, some checks that are only relevant to user mode must
 * instead be placed deeper within the implementation. This
 * API is useful to conditionally make these checks.
 *
 * For performance reasons, whenever possible, checks should be placed
 * in the relevant z_vrfy function since these are completely skipped
 * when a syscall is invoked.
 *
 * This will return true only if we are handling a syscall for a
 * user thread. If the system call was invoked from supervisor mode,
 * or we are not handling a system call, this will return false.
 *
 * @note This is an internal API. Do not use unless you are extending
 *       functionality in the Zephyr tree.
 *
 * @return whether the current context is handling a syscall for a user
 *         mode thread
 *//**
 * @brief User mode and Syscall APIs
 * @defgroup syscall_apis User mode and Syscall APIs
 * @ingroup internal_api
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/internal/home/haojie/zephyrproject/zephyr/kernel/device.ccnt&cntdev <= TYPE_SECTION_END(device)"unexpected list end location"/* Iterate over fixed devices *//*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 *//* Split the search into two loops: in the common scenario, where
	 * device names are stored in ROM (and are referenced by the user
	 * with CONFIG_* macros), only cheap pointer comparisons will be
	 * performed. Reserve string comparisons for a fallback.
	 *//* A null string identifies no device.  So does an empty
	 * string.
	 *//**
 * @brief Initialize state for all static devices.
 *
 * The state object is always zero-initialized, but this may not be
 * sufficient.
 *//*
 * Copyright (c) 2015-2016 Intel Corporation.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/kernel/dynamic_disabled.c/*
 * Copyright (c) 2022, Meta
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/kernel/errno.c_k_neg_eagain-11-EAGAINdefined(CONFIG_LIBC_ERRNO)defined(CONFIG_ERRNO_IN_TLS)/* CONFIG_ERRNO *//* CONFIG_ERRNO_IN_TLS *//* Initialized to the lowest address in the stack so the thread can
	 * directly read/write it
	 *//* nothing needed here *//*
 * Define _k_neg_eagain for use in assembly files as errno.h is
 * not assembly language safe.
 * FIXME: wastes 4 bytes
 *//** @file
 *
 * @brief Per-thread errno accessor function
 *
 * Allow accessing the errno for the current thread without involving the
 * context switching.
 *//home/haojie/zephyrproject/zephyr/include/zephyr/debug/coredump.hcoredump_cmdquery_idcoredump_querycoredump_buffer_outputcoredump_memory_dumpstart_addrend_addrcoredumpcoredump_cmd_copy_argcoredump_cmd_idCOREDUMP_CMD_CLEAR_ERRORCOREDUMP_CMD_VERIFY_STORED_DUMPCOREDUMP_CMD_ERASE_STORED_DUMPCOREDUMP_CMD_COPY_STORED_DUMPCOREDUMP_CMD_INVALIDATE_STORED_DUMPCOREDUMP_CMD_MAXcoredump_query_idCOREDUMP_QUERY_GET_ERRORCOREDUMP_QUERY_HAS_STORED_DUMPCOREDUMP_QUERY_GET_STORED_DUMP_SIZECOREDUMP_QUERY_MAXZEPHYR_INCLUDE_DEBUG_COREDUMP_H_/* ZEPHYR_INCLUDE_DEBUG_COREDUMP_H_ *//**
 * @fn int coredump_cmd(enum coredump_cmd_id cmd_id, void *arg);
 * @brief Perform command on coredump subsystem.
 *
 * Perform command on coredump subsystem, for example, output the stored
 * coredump via logging.
 *
 * @param[in] cmd_id Command ID
 * @param[in,out] arg Pointer to argument for exchanging information
 * @return Depends on the command
 *//**
 * @fn int coredump_query(enum coredump_query_id query_id, void *arg);
 * @brief Perform query on coredump subsystem.
 *
 * Query the coredump subsystem for information, for example, if there is
 * an error.
 *
 * @param[in] query_id Query ID
 * @param[in,out] arg Pointer to argument for exchanging information
 * @return Depends on the query
 *//**
 * @fn int coredump_buffer_output(uint8_t *buf, size_t buflen);
 * @brief Output the buffer via coredump
 *
 * This outputs the buffer of byte array to the coredump backend.
 * For example, this can be called to output the coredump section
 * containing registers, or a section for memory dump.
 *
 * @param buf Buffer to be send to coredump output
 * @param buflen Buffer length
 *//**
 * @fn void coredump_memory_dump(uintptr_t start_addr, uintptr_t end_addr);
 * @brief Dump memory region
 *
 * @param start_addr Start address of memory region to be dumped
 * @param end_addr End address of memory region to be dumped
 *//**
 * @fn void coredump(unsigned int reason, const z_arch_esf_t *esf, struct k_thread *thread);
 * @brief Perform coredump.
 *
 * Normally, this is called inside z_fatal_error() to generate coredump
 * when a fatal error is encountered. This can also be called on demand
 * whenever a coredump is desired.
 *
 * @param reason Reason for the fatal error
 * @param esf Exception context
 * @param thread Thread information to dump
 *//* CONFIG_DEBUG_COREDUMP *//* Perform command on backend *//* Perform query on backend *//* Raw buffer output *//* Signal to backend of the end of coredump. *//* Signal to backend of the start of coredump. *//* Address of end of memory region *//* Address of start of memory region *//* Header version *//* COREDUMP_MEM_HDR_ID *//* Memory block header *//* Number of bytes in this block (excluding header) *//* COREDUMP_ARCH_HDR_ID *//* Architecture-specific block header *//* Coredump Reason given *//* Pointer size in Log2 *//* Target code *//* 'Z', 'E' *//* Coredump header *//** Copy length *//** Copy destination buffer *//** Copy offset *//** Coredump copy command (@ref COREDUMP_CMD_COPY_STORED_DUMP) argument definition *//**
	 * Max value for command ID.
	 *//**
	 * Invalidate the stored coredump. This is faster than
	 * erasing the whole partition.
	 *
	 * Returns:
	 * - 0 if successful.
	 * - -ENOTSUP if this command is not supported.
	 * - Otherwise, error code from backend.
	 *//**
	 * Copy the raw stored coredump.
	 *
	 * Returns:
	 * - copied size if successful
	 * - 0 if stored coredump is not found
	 * - -ENOTSUP if this command is not supported.
	 * - Otherwise, error code from backend.
	 *//**
	 * Erase the stored coredump.
	 *
	 * Returns:
	 * - 0 if successful.
	 * - -ENOTSUP if this command is not supported.
	 * - Otherwise, error code from backend.
	 *//**
	 * Verify that the stored coredump is valid.
	 *
	 * Returns:
	 * - 1 if valid.
	 * - 0 if not valid or no stored coredump.
	 * - -ENOTSUP if this command is not supported.
	 * - Otherwise, error code from backend.
	 *//**
	 * Clear error code from backend.
	 *
	 * Returns 0 if successful, failed otherwise.
	 *//** Command ID *//**
	 * Max value for query ID.
	 *//**
	 * Returns:
	 * - coredump raw size from backend, 0 if none.
	 * - -ENOTSUP if this query is not supported.
	 * - Otherwise, error code from backend.
	 *//**
	 * Check if there is a stored coredump from backend.
	 *
	 * Returns:
	 * - 1 if there is a stored coredump, 0 if none.
	 * - -ENOTSUP if this query is not supported.
	 * - Otherwise, error code from backend.
	 *//**
	 * Returns error code from backend.
	 *//** Query ID *//**
 * @file
 *
 * @defgroup coredump_apis Coredump APIs
 * @ingroup os_services
 * @brief Coredump APIs
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/debug/home/haojie/zephyrproject/zephyr/include/zephyr/logging/log_ctrl.h/home/haojie/zephyrproject/zephyr/include/zephyr/logging/log_backend.h/home/haojie/zephyrproject/zephyr/include/zephyr/logging/log_output.h/home/haojie/zephyrproject/zephyr/include/zephyr/logging/log_internal.h/home/haojie/zephyrproject/zephyr/include/zephyr/sys/mpsc_pbuf.h/home/haojie/zephyrproject/zephyr/build/zephyr/include/generated/syscalls/log_ctrl.h/home/haojie/zephyrproject/zephyr/kernel/fatal.c<zephyr/debug/coredump.h><zephyr/logging/log_ctrl.h>">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), _current_cpu->id">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"reason, reason_to_str(reason), (&_kernel.cpus[0])->idZ_LOG_STR(1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)(Z_LOG_STR_WITH_PREFIX(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))("%s: " ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (const char *)__func__ , reason, reason_to_str(reason), (&_kernel.cpus[0])->id)(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)NUM_VA_ARGS_LESS_1(_,">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)(Z_LOG_STR_WITH_PREFIX2(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))_,">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->idreason_to_str(reason)(&_kernel.cpus[0])->id3, 2, 1, 0, ~NUM_VA_ARGS_LESS_1(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)(, GET_ARGS_LESS_N(1, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))(, reason, reason_to_str(reason), (&_kernel.cpus[0])->id), reason, reason_to_str(reason), (&_kernel.cpus[0])->id_ZZZZ4 ("%s", (const char *)__func__)"%s: " ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (const char *)__func__ , reason, reason_to_str(reason), (&_kernel.cpus[0])->id_XXXX0 ("%s: " ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (const char *)__func__ , reason, reason_to_str(reason), (&_kernel.cpus[0])->id)REVERSE_ARGS(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)(&_kernel.cpus[0])->id , reason_to_str(reason) , reason , ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"Z_FOR_LOOP_3, Z_FOR_LOOP_2, Z_FOR_LOOP_1, Z_FOR_LOOP_0reason_to_str(reason), (&_kernel.cpus[0])->idreason_to_str(reason) , reason , ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"reason , ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") = (">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0)(__auto_type ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" = (">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0)(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, reason) = (reason) + 0)(__auto_type _v1 = (reason) + 0)(reason)_ZZZZ1 (reason)__auto_type _v1 = (reason) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, reason_to_str(reason)) = (reason_to_str(reason)) + 0)(__auto_type _v2 = (reason_to_str(reason)) + 0)(reason_to_str(reason))_ZZZZ2 (reason_to_str(reason))__auto_type _v2 = (reason_to_str(reason)) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, (&_kernel.cpus[0])->id) = ((&_kernel.cpus[0])->id) + 0)(__auto_type _v3 = ((&_kernel.cpus[0])->id) + 0)((&_kernel.cpus[0])->id)_ZZZZ3 ((&_kernel.cpus[0])->id)__auto_type _v3 = ((&_kernel.cpus[0])->id) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)_,">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3_v1 , _v2 , _v3_ZZZZ4 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d";)NUM_VA_ARGS_LESS_1(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS(_v1 , _v2 , _v3)_v2 , _v3_ZZZZ3 (0)((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))( bool can_simple = LOG_MSG_SIMPLE_CHECK(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))_LOG_MSG_SIMPLE_XXXX3_XXXX_LOG_MSG_SIMPLE_XXXX3_XXXX_LOG_MSG_SIMPLE_XXXX3 (1)_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", reason, reason_to_str(reason), (&_kernel.cpus[0])->id)))(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3)(COND_CODE_0(NUM_VA_ARGS_LESS_1(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3), (_fmt), (_fmt, GET_ARGS_LESS_N(1, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))))(_fmt, _v1 , _v2 , _v3)(_fmt, GET_ARGS_LESS_N(1, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))_ZZZZ3 (_fmt)_fmt, _v1 , _v2 , _v3_XXXXCONFIG_LOG_FMT_SECTION (_fmt, _v1 , _v2 , _v3)_ZZZZ4 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3); )( z_log_msg_simple_create_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3)))(z_log_msg_simple_create_0(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"))(COND_CODE_1(3, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3, dummy) )( z_log_msg_simple_create_1(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3, dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3, dummy_v1 , _v2 , _v3, dummy_v2 , _v3, dummy">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3, dummy, dummy_v1 , _v2 , _v3, dummy, dummy_v2 , _v3, dummy, dummy_v3, dummy, dummy_XXXX3_XXXX3 ( z_log_msg_simple_create_1(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ3 (z_log_msg_simple_create_0(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"))_XXXX0 ( z_log_msg_simple_create_2(_src, 1U, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))REVERSE_ARGS(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d" , _v1 , _v2 , _v3)_v3 , _v2 , _v1 , ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"_v2 , _v1 , ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"_v1 , ">>> ZEPHYR FATAL ERROR %d: %s on CPU %d"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic((">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0, long double : 1, default : 0) && !0)_Generic((">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0))_Generic((">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__((">>> ZEPHYR FATAL ERROR %d: %s on CPU %d") + 0))%c: >>> ZEPHYR FATAL ERROR %d: %s on CPU %d
char[45]>>> ZEPHYR FATAL ERROR %d: %s on CPU %dchar[40]"Current thread: %p (%s)", thread, thread_name_get(thread)"Current thread: %p (%s)"thread, thread_name_get(thread)Z_LOG_STR(1U, "Current thread: %p (%s)", thread, thread_name_get(thread))(Z_LOG_STR_WITH_PREFIX("Current thread: %p (%s)", thread, thread_name_get(thread)))("%s: " "Current thread: %p (%s)", (const char *)__func__ , thread, thread_name_get(thread))("Current thread: %p (%s)", thread, thread_name_get(thread))NUM_VA_ARGS_LESS_1(_,"Current thread: %p (%s)", thread, thread_name_get(thread))(Z_LOG_STR_WITH_PREFIX2("Current thread: %p (%s)", thread, thread_name_get(thread)))_,"Current thread: %p (%s)", thread, thread_name_get(thread)thread_name_get(thread)NUM_VA_ARGS_LESS_1("Current thread: %p (%s)", thread, thread_name_get(thread))(, GET_ARGS_LESS_N(1, "Current thread: %p (%s)", thread, thread_name_get(thread)))(, thread, thread_name_get(thread)), thread, thread_name_get(thread)"%s: " "Current thread: %p (%s)", (const char *)__func__ , thread, thread_name_get(thread)_XXXX0 ("%s: " "Current thread: %p (%s)", (const char *)__func__ , thread, thread_name_get(thread))REVERSE_ARGS("Current thread: %p (%s)", thread, thread_name_get(thread))thread_name_get(thread) , thread , "Current thread: %p (%s)"thread , "Current thread: %p (%s)"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "Current thread: %p (%s)") = ("Current thread: %p (%s)") + 0)(__auto_type "Current thread: %p (%s)" = ("Current thread: %p (%s)") + 0)("Current thread: %p (%s)")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, thread) = (thread) + 0)(__auto_type _v1 = (thread) + 0)(thread)_ZZZZ1 (thread)__auto_type _v1 = (thread) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, thread_name_get(thread)) = (thread_name_get(thread)) + 0)(__auto_type _v2 = (thread_name_get(thread)) + 0)(thread_name_get(thread))_ZZZZ2 (thread_name_get(thread))__auto_type _v2 = (thread_name_get(thread)) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread))"Current thread: %p (%s)" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread))))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "Current thread: %p (%s)";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread)))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "Current thread: %p (%s)" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread))_,"Current thread: %p (%s)" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "Current thread: %p (%s)";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "Current thread: %p (%s)";)NUM_VA_ARGS_LESS_1("Current thread: %p (%s)" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "Current thread: %p (%s)" , _v1 , _v2))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread)))( bool can_simple = LOG_MSG_SIMPLE_CHECK("Current thread: %p (%s)" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread)))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("Current thread: %p (%s)" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("Current thread: %p (%s)" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("Current thread: %p (%s)" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("Current thread: %p (%s)" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("Current thread: %p (%s)" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread)))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Current thread: %p (%s)", thread, thread_name_get(thread))))("Current thread: %p (%s)" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("Current thread: %p (%s)" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "Current thread: %p (%s)" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "Current thread: %p (%s)" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "Current thread: %p (%s)" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "Current thread: %p (%s)" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 1U, "Current thread: %p (%s)"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "Current thread: %p (%s)" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "Current thread: %p (%s)" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "Current thread: %p (%s)" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "Current thread: %p (%s)" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"Current thread: %p (%s)" , _v1 , _v2, dummy"Current thread: %p (%s)" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 1U, "Current thread: %p (%s)"))z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 1U, "Current thread: %p (%s)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "Current thread: %p (%s)" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "Current thread: %p (%s)" , _v1 , _v2))REVERSE_ARGS("Current thread: %p (%s)" , _v1 , _v2)_v2 , _v1 , "Current thread: %p (%s)"_v1 , "Current thread: %p (%s)"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("Current thread: %p (%s)") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("Current thread: %p (%s)") + 0, long double : 1, default : 0) && !0)_Generic(("Current thread: %p (%s)") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("Current thread: %p (%s)") + 0))_Generic(("Current thread: %p (%s)") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("Current thread: %p (%s)") + 0))%c: Current thread: %p (%s)
char[29]Current thread: %p (%s)char[24]k_thread **CONFIG_TEST_XXXXCONFIG_TEST_XXXXCONFIG_TEST 1reason != K_ERR_KERNEL_PANIC"Attempted to recover from a kernel panic condition"!IS_ENABLED(CONFIG_TEST)reason_to_strCPU exception"CPU exception"Unhandled interrupt"Unhandled interrupt"Stack overflow"Stack overflow"Kernel oops"Kernel oops"Kernel panic"Kernel panic"char[13]Unknown error"Unknown error"thread_name_getthread_name"unknown"char[8]"Halting system"Z_LOG_STR(1U, "Halting system")(Z_LOG_STR_WITH_PREFIX("Halting system"))("%s: " "Halting system", (const char *)__func__)("Halting system")NUM_VA_ARGS_LESS_1(_,"Halting system")(Z_LOG_STR_WITH_PREFIX2("Halting system"))("%s: " "Halting system", (const char *)__func__ )_,"Halting system"NUM_VA_ARGS_LESS_1("Halting system")(, GET_ARGS_LESS_N(1, "Halting system"))"%s: " "Halting system", (const char *)__func___XXXX0 ("%s: " "Halting system", (const char *)__func__)REVERSE_ARGS("Halting system")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "Halting system") = ("Halting system") + 0)(__auto_type "Halting system" = ("Halting system") + 0)FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system")(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system")))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "Halting system";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system"))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "Halting system");)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system")static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "Halting system";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "Halting system";)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "Halting system"))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system"))( bool can_simple = LOG_MSG_SIMPLE_CHECK("Halting system"); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system"))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = 1; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_0(_src, 1U, "Halting system");; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("Halting system"), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("Halting system")), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("Halting system")( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("Halting system"))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("Halting system"))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system"))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "Halting system")))(COND_CODE_0(NUM_VA_ARGS_LESS_1("Halting system"), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "Halting system"))))(_fmt, GET_ARGS_LESS_N(1, "Halting system"))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "Halting system"); )( z_log_msg_simple_create_0(_src, 1U, "Halting system"); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "Halting system")))(z_log_msg_simple_create_0(_src, 1U, "Halting system"))(COND_CODE_1(0, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "Halting system", dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "Halting system", dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, "Halting system", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "Halting system", dummy) )( z_log_msg_simple_create_1(_src, 1U, "Halting system", (uint32_t)(uintptr_t)dummy) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "Halting system", dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "Halting system", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy) )"Halting system", dummy"Halting system", dummy, dummy_XXXX0 ( z_log_msg_simple_create_1(_src, 1U, "Halting system", (uint32_t)(uintptr_t)dummy) )z_log_msg_simple_create_2(_src, 1U, "Halting system", (uint32_t)(uintptr_t)dummy, (uint32_t)(uintptr_t)dummy)z_log_msg_simple_create_0(_src, 1U, "Halting system")z_log_msg_simple_create_0(_src, 1U, "Halting system");_XXXX0 ( _Bool can_simple = 1; if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_0(_src, 1U, "Halting system");; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "Halting system"))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "Halting system"))!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("Halting system") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("Halting system") + 0, long double : 1, default : 0) && !0)_Generic(("Halting system") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("Halting system") + 0))_Generic(("Halting system") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("Halting system") + 0))%c: Halting system
Halting systemdefined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)defined(CONFIG_STACK_SENTINEL)/*CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION *//* Abort the thread only if the fault is not due to
			 * a spurious ISR handler triggered.
			 *//* CONFIG_STACK_SENTINEL *//* Abort the thread only on STACK Sentinel check fail. *//* Test mode *//* CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION *//* FIXME: #17656 *//* If the system fatal error handler returns, then kill the faulting
	 * thread; a policy decision was made not to hang the system.
	 *
	 * Policy for fatal errors in ISRs: unconditionally panic.
	 *
	 * There is one exception to this policy: a stack sentinel
	 * check may be performed (on behalf of the current thread)
	 * during ISR exit, but in this case the thread should be
	 * aborted.
	 *
	 * Note that k_thread_abort() returns on some architectures but
	 * not others; e.g. on ARC, x86_64, Xtensa with ASM2, ARM
	 *//* FIXME: This doesn't seem to work as expected on all arches.
	 * Need a reliable way to determine whether the fault happened when
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 *//* twister looks for the "ZEPHYR FATAL ERROR" string, don't
	 * change it without also updating twister
	 *//* We can't allow this code to be preempted, but don't need to
	 * synchronize between CPUs, so an arch-layer lock is
	 * appropriate.
	 *//* Spin endlessly *//* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 *//home/haojie/zephyrproject/zephyr/kernel/idle.c!arch_irq_unlocked(arch_irq_lock())"this is meant to be called with IRQs disabled"_current->base.prio >= 0CONFIG_SCHED_IPI_SUPPORTED_XXXXCONFIG_SCHED_IPI_SUPPORTED_XXXXCONFIG_SCHED_IPI_SUPPORTED 1!IS_ENABLED(CONFIG_SCHED_IPI_SUPPORTED)volatile int!defined(CONFIG_PREEMPT_ENABLED)!defined(CONFIG_USE_SWITCH) || defined(CONFIG_SPARC)/* A legacy mess: the idle thread is by definition
		 * preemptible as far as the modern scheduler is
		 * concerned, but older platforms use
		 * CONFIG_PREEMPT_ENABLED=n as an optimization hint
		 * that interrupt exit always returns to the
		 * interrupted context.  So in that setup we need to
		 * explicitly yield in the idle thread otherwise
		 * nothing else will run once it starts.
		 *//*
		 * Call the suspend hook function of the soc interface
		 * to allow entry into a low power state. The function
		 * returns false if low power state was not entered, in
		 * which case, kernel does normal idle processing.
		 *
		 * This function is entered with interrupts disabled.
		 * If a low power state was entered, then the hook
		 * function should enable inerrupts before exiting.
		 * This is because the kernel does not do its own idle
		 * processing in those cases i.e. skips k_cpu_idle().
		 * The kernel's idle processing re-enables interrupts
		 * which is essential for the kernel's scheduling
		 * logic.
		 *//* Note weird API: k_cpu_idle() is called with local
		 * CPU interrupts masked, and returns with them
		 * unmasked.  It does not take a spinlock or other
		 * higher level construct.
		 *//* Empty loop *//* SMP systems without a working IPI can't actual
		 * enter an idle state, because they can't be notified
		 * of scheduler changes (i.e. threads they should
		 * run).  They just spin instead, with a minimal
		 * relaxation loop to prevent hammering the scheduler
		 * lock and/or timer driver.  This is intended as a
		 * fallback configuration for new platform bringup.
		 *//* Some CPU low power states require notification at the ISR
	 * to allow any operations that needs to be done before kernel
	 * switches task or processes nested interrupts.
	 * This can be simply ignored if not required.
	 *//* private kernel APIs *//home/haojie/zephyrproject/zephyr/arch/x86/include/ia32/offsets_short_arch.h_thread_offset_to_preempFloatReg(___thread_t_arch_OFFSET + ___thread_arch_t_preempFloatReg_OFFSET)_thread_offset_to_esp(___thread_t_callee_saved_OFFSET + ___callee_saved_t_esp_OFFSET)_thread_offset_to_excNestCount(___thread_t_arch_OFFSET + ___thread_arch_t_excNestCount_OFFSET)_kernel_offset_to_isf(___kernel_t_arch_OFFSET + ___kernel_arch_t_isf_OFFSET)ZEPHYR_ARCH_X86_INCLUDE_IA32_OFFSETS_SHORT_ARCH_H_/* ZEPHYR_ARCH_X86_INCLUDE_IA32_OFFSETS_SHORT_ARCH_H_ *//* end - threads *//* threads *//* end - kernel *//* kernel *//home/haojie/zephyrproject/zephyr/arch/x86/include/offsets_short_arch.h<ia32/offsets_short_arch.h>_thread_offset_to_flags(___thread_t_arch_OFFSET + ___thread_arch_t_flags_OFFSET)ZEPHYR_ARCH_X86_INCLUDE_OFFSETS_SHORT_ARCH_H_/* ZEPHYR_ARCH_X86_INCLUDE_OFFSETS_SHORT_ARCH_H_ *//home/haojie/zephyrproject/zephyr/kernel/include/offsets_short.h<offsets_short_arch.h>_thread_offset_to_user_options(___thread_t_base_OFFSET + ___thread_base_t_user_options_OFFSET)_thread_offset_to_tls(___thread_t_tls_OFFSET)_thread_offset_to_callee_saved(___thread_t_callee_saved_OFFSET)_kernel_offset_to_ready_q_cache(___kernel_t_ready_q_OFFSET + ___ready_q_t_cache_OFFSET)_kernel_offset_to_current_fp(___kernel_t_current_fp_OFFSET)_kernel_offset_to_idle(___kernel_t_idle_OFFSET)_kernel_offset_to_current(___cpu_t_current_OFFSET)_kernel_offset_to_irq_stack(___cpu_t_irq_stack_OFFSET)_kernel_offset_to_nested(___cpu_t_nested_OFFSET)ZEPHYR_KERNEL_INCLUDE_OFFSETS_SHORT_H_/* ZEPHYR_KERNEL_INCLUDE_OFFSETS_SHORT_H_ *//* base *//* main *//* CONFIG_FPU_SHARING *//* Relies on _kernel.cpu being the first member of _kernel and having 1 element
 *//home/haojie/zephyrproject/zephyr/include/zephyr/debug/stack.hlog_stack_usageZEPHYR_INCLUDE_DEBUG_STACK_H_/* ZEPHYR_INCLUDE_DEBUG_STACK_H_ *//**
 * @file debug/stack.h
 * Stack usage analysis helpers
 *//home/haojie/zephyrproject/zephyr/build/zephyr/include/generated/syscalls/entropy.hentropy_get_entropyZ_INCLUDE_SYSCALLS_ENTROPY_Hz_impl_entropy_get_entropy/home/haojie/zephyrproject/zephyr/include/zephyr/drivers/entropy.h<syscalls/entropy.h>entropy_get_entropy_isrconst entropy_driver_apiconst entropy_driver_api *entropy_driver_api *!api->get_entropy_israpi->get_entropy != NULL"Callback pointer should not be NULL"entropy_driver_apientropy_get_entropy_isr_tentropy_get_entropy_tget_entropy_isrget_entropyENTROPY_BUSYWAITZEPHYR_INCLUDE_DRIVERS_ENTROPY_H_/* ZEPHYR_INCLUDE_DRIVERS_ENTROPY_H_ *//**
 * @brief Fills a buffer with entropy in a non-blocking or busy-wait manner.
 * 	  Callable from ISRs.
 *
 * @param dev Pointer to the device structure.
 * @param buffer Buffer to fill with entropy.
 * @param length Buffer length.
 * @param flags Flags to modify the behavior of the call.
 * @retval number of bytes filled with entropy or -error.
 *//**
 * @brief Fills a buffer with entropy. Blocks if required in order to
 *        generate the necessary random data.
 *
 * @param dev Pointer to the entropy device.
 * @param buffer Buffer to fill with entropy.
 * @param length Buffer length.
 * @retval 0 on success.
 * @retval -ERRNO errno code on error.
 *//**
 * @brief Entropy driver API structure.
 *
 * This is the mandatory API any Entropy driver needs to expose.
 *//**
 * @typedef entropy_get_entropy_isr_t
 * @brief Callback API to get entropy from an ISR.
 *
 * See entropy_get_entropy_isr() for argument description
 *//**
 * @typedef entropy_get_entropy_t
 * @brief Callback API to get entropy.
 *
 * @note This call has to be thread safe to satisfy requirements
 * of the random subsystem.
 *
 * See entropy_get_entropy() for argument description
 *//** @brief Driver is allowed to busy-wait for random data to be ready *//**
 * @brief Entropy Interface
 * @defgroup entropy_interface Entropy Interface
 * @ingroup io_interfaces
 * @{
 *//*
 * Copyright (c) 2016 ARM Ltd.
 * Copyright (c) 2017 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//**
 * @file drivers/entropy.h
 *
 * @brief Public APIs for the entropy driver.
 */<zephyr/logging/log_msg.h>log_output_timestamp_to_uslog_output_timestamp_freq_setlog_output_hostname_setconst log_outputconst log_output *log_output *log_output_control_block *log_output_ctx_setlog_output_flushlog_output_dropped_processlog_output_msg_syst_processlog_output_processlog_output_msg_processlog_format_func_t_getlog_format_func_tlog_outputlog_output_control_blocklog_output_func_tcontrol_blockhostnamectxLOG_OUTPUT_DEFINE(_name,_func,_buf,_size)static struct log_output_control_block _name ## _control_block; static const struct log_output _name = { .func = _func, .control_block = &_name ## _control_block, .buf = _buf, .size = _size, }LOG_OUTPUT_CUSTOMLOG_OUTPUT_DICTLOG_OUTPUT_SYSTLOG_OUTPUT_TEXTLOG_OUTPUT_FLAG_THREADLOG_OUTPUT_FLAG_FORMAT_SYSLOGLOG_OUTPUT_FLAG_CRLF_LFONLYLOG_OUTPUT_FLAG_CRLF_NONELOG_OUTPUT_FLAG_LEVELLOG_OUTPUT_FLAG_FORMAT_TIMESTAMPLOG_OUTPUT_FLAG_TIMESTAMPLOG_OUTPUT_FLAG_COLORSZEPHYR_INCLUDE_LOGGING_LOG_OUTPUT_H_/* ZEPHYR_INCLUDE_LOGGING_LOG_OUTPUT_H_ *//** @brief Convert timestamp of the message to us.
 *
 * @param timestamp Message timestamp
 *
 * @return Timestamp value in us.
 *//** @brief Set timestamp frequency.
 *
 * @param freq Frequency in Hz.
 *//** @brief Function for setting hostname of this device
 *
 * @param output	Pointer to the log output instance.
 * @param hostname	Hostname of this device
 *//** @brief Function for setting user context passed to the output function.
 *
 * @param output	Pointer to the log output instance.
 * @param ctx		User context.
 *//** @brief Flush output buffer.
 *
 * @param output Pointer to the log output instance.
 *//** @brief Process dropped messages indication.
 *
 * Function prints error message indicating lost log messages.
 *
 * @param output Pointer to the log output instance.
 * @param cnt        Number of dropped messages.
 *//** @brief Process log messages v2 to SYS-T format.
 *
 * Function is using provided context with the buffer and output function to
 * process formatted string and output the data in sys-t log output format.
 *
 * @param log_output Pointer to the log output instance.
 * @param msg Log message.
 * @param flags Optional flags. See @ref LOG_OUTPUT_FLAGS.
 *//** @brief Process input data to a readable string.
 *
 * @param log_output	Pointer to the log output instance.
 * @param timestamp	Timestamp.
 * @param domain	Domain name string. Can be NULL.
 * @param source	Source name string. Can be NULL.
 * @param tid		Thread ID.
 * @param level		Criticality level.
 * @param package	Cbprintf package with a logging message string.
 * @param data		Data passed to hexdump API. Can bu NULL.
 * @param data_len	Data length.
 * @param flags		Formatting flags. See @ref LOG_OUTPUT_FLAGS.
 *//** @brief Process log messages v2 to readable strings.
 *
 * Function is using provided context with the buffer and output function to
 * process formatted string and output the data.
 *
 * @param log_output Pointer to the log output instance.
 * @param msg Log message.
 * @param flags Optional flags. See @ref LOG_OUTPUT_FLAGS.
 *//** @brief Create log_output instance.
 *
 * @param _name Instance name.
 * @param _func Function for processing output data.
 * @param _buf  Pointer to the output buffer.
 * @param _size Size of the output buffer.
 *//**
 * @brief Declaration of the get routine for function pointer table format_table.
 *//**
 * @brief Typedef of the function pointer table "format_table".
 *
 * @param output Pointer to log_output struct.
 * @param msg Pointer to log_msg struct.
 * @param flags Flags used for text formatting options.
 *
 * @return Function pointer based on Kconfigs defined for backends.
 *//** @brief Log_output instance structure. *//* @brief Control block structure for log_output instance.  *//**
 * @brief Prototype of the function processing output data.
 *
 * @param buf The buffer data.
 * @param size The buffer size.
 * @param ctx User context.
 *
 * @return Number of bytes processed, dropped or discarded.
 *
 * @note If the log output function cannot process all of the data, it is
 *       its responsibility to mark them as dropped or discarded by returning
 *       the corresponding number of bytes dropped or discarded to the caller.
 *//** @brief Supported backend logging format types for use
 * with log_format_set() API to switch log format at runtime.
 *//**@} *//** @brief Flag thread id or name prefix. *//** @brief Flag forcing syslog format specified in RFC 5424
 *//** @brief Flag forcing a single LF character for line breaks. *//** @brief Flag preventing the logger from adding CR and LF characters. *//** @brief Flag forcing severity level prefix. *//** @brief Flag forcing timestamp formatting. *//** @brief Flag forcing timestamp *//** @brief Flag forcing ANSI escape code colors, red (errors), yellow
 *         (warnings).
 *//**@defgroup LOG_OUTPUT_FLAGS Log output formatting flags.
 * @{
 *//**
 * @brief Log output API
 * @defgroup log_output Log output API
 * @ingroup logger
 * @{
 *//*
 * Copyright (c) 2018 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/loggingoutputtimestampfreqmsgsourcetidpackagedata_lenlog_type<zephyr/logging/log_output.h>log_backend_notifyconst log_backendconst log_backend *log_backend *const log_backend *constlog_backend_evt_arg *backend != NULLconst log_backend_apiconst log_backend_api *log_backend_api *log_format_table_sizelog_backend_format_setlog_backend_is_activelog_backend_control_block *log_backend_deactivatelog_backend_activatelog_backend_count_getlog_backendstruct log_backend_log_backendlog_backend[]log_backend_getbackend&backendconst log_backend **log_backend **log_backend_id_getlog_backend_id_setlog_backend_paniclog_backend_droppedlog_backend_msg_processlog_msg_generic *msg != NULLlog_backend_is_readylog_backend_initlog_backend_apilog_backend_control_blocklog_backend_evt_arglog_backend_evtLOG_BACKEND_EVT_PROCESS_THREAD_DONELOG_BACKEND_EVT_MAXnotifyformat_setis_readyinitpanicdroppedprocessautostartactive_log_backend_list_end_log_backend_list_startLOG_BACKEND_DEFINE(_name,_api,_autostart,__VA_ARGS__...)static struct log_backend_control_block UTIL_CAT(backend_cb_, _name) = { COND_CODE_0(NUM_VA_ARGS_LESS_1(_, ## __VA_ARGS__), (), (.ctx = __VA_ARGS__,)) .id = 0, .active = false, }; static const STRUCT_SECTION_ITERABLE(log_backend, _name) = { .api = &_api, .cb = &UTIL_CAT(backend_cb_, _name), .name = STRINGIFY(_name), .autostart = _autostart }ZEPHYR_INCLUDE_LOGGING_LOG_BACKEND_H_/* ZEPHYR_INCLUDE_LOGGING_LOG_BACKEND_H_ *//**
 * @brief Notify a backend of an event.
 *
 * @param backend Pointer to the backend instance.
 * @param event Event to be notified.
 * @param arg Pointer to the argument(s).
 *//** @brief Set logging format.
 *
 * @param backend Pointer to the backend instance.
 * @param log_type Log format.
 *
 * @retval -ENOTSUP If the backend does not support changing format types.
 * @retval -EINVAL If the input is invalid.
 * @retval 0 for success.
 *//**
 * @brief Check state of the backend.
 *
 * @param[in] backend  Pointer to the backend instance.
 *
 * @return True if backend is active, false otherwise.
 *//**
 * @brief Deactivate backend.
 *
 * @param[in] backend  Pointer to the backend instance.
 *//**
 * @brief Activate backend.
 *
 * @param[in] backend  Pointer to the backend instance.
 * @param[in] ctx      User context.
 *//**
 * @brief Get number of backends.
 *
 * @return Number of backends.
 *//**
 * @brief Get backend.
 *
 * @param[in] idx  Pointer to the backend instance.
 *
 * @return    Pointer to the backend instance.
 *//**
 * @brief Get backend id.
 *
 * @note It is used internally by the logger.
 *
 * @param[in] backend  Pointer to the backend instance.
 * @return    Id.
 *//**
 * @brief Set backend id.
 *
 * @note It is used internally by the logger.
 *
 * @param backend  Pointer to the backend instance.
 * @param id       ID.
 *//**
 * @brief Reconfigure backend to panic mode.
 *
 * @param[in] backend  Pointer to the backend instance.
 *//**
 * @brief Notify backend about dropped log messages.
 *
 * Function is optional.
 *
 * @param[in] backend  Pointer to the backend instance.
 * @param[in] cnt      Number of dropped logs since last notification.
 *//**
 * @brief Process message.
 *
 * Function is used in deferred and immediate mode. On return, message content
 * is processed by the backend and memory can be freed.
 *
 * @param[in] backend  Pointer to the backend instance.
 * @param[in] msg      Pointer to message with log entry.
 *//**
 * @brief Poll for backend readiness.
 *
 * If backend is ready immediately after initialization then backend may not
 * provide this function.
 *
 * @param[in] backend  Pointer to the backend instance.
 *
 * @retval 0 if backend is ready.
 * @retval -EBUSY if backend is not yet ready.
 *//**
 * @brief Initialize or initiate the logging backend.
 *
 * If backend initialization takes longer time it could block logging thread
 * if backend is autostarted. That is because all backends are initilized in
 * the context of the logging thread. In that case, backend shall provide
 * function for polling for readiness (@ref log_backend_is_ready).
 *
 * @param[in] backend  Pointer to the backend instance.
 *//**
 * @brief Macro for creating a logger backend instance.
 *
 * @param _name		Name of the backend instance.
 * @param _api		Logger backend API.
 * @param _autostart	If true backend is initialized and activated together
 *			with the logger subsystem.
 * @param ...		Optional context.
 *//**
 * @brief Logger backend structure.
 *//* Initialization level. *//**
 * @brief Logger backend control block.
 *//**
 * @brief Logger backend API.
 *//** @brief Unspecified argument(s). *//**
 * @brief Argument(s) for backend events.
 *//** @brief Maximum number of backend events *//**
	 * @brief Event when process thread finishes processing.
	 *
	 * This event is emitted when the process thread finishes
	 * processing pending log messages.
	 *
	 * @note This is not emitted when there are no pending
	 *       log messages being processed.
	 *
	 * @note Deferred mode only.
	 *//**
 * @brief Backend events
 *//* Forward declaration of the log_backend type. *//**
 * @brief Logger backend interface
 * @defgroup log_backend Logger backend interface
 * @ingroup logger
 * @{
 */<zephyr/sys/mpsc_packet.h>mpsc_pbuf_get_max_utilizationmpsc_pbuf_buffer *mpsc_pbuf_get_utilizationmpsc_pbuf_is_pendingmpsc_pbuf_freeconst mpsc_pbuf_genericconst mpsc_pbuf_generic *mpsc_pbuf_generic *mpsc_pbuf_claimmpsc_pbuf_put_dataconst uint32_t *mpsc_pbuf_put_word_extmpsc_pbuf_put_wordmpsc_pbuf_commitmpsc_pbuf_allocmpsc_pbuf_initconst mpsc_pbuf_buffer_configconst mpsc_pbuf_buffer_config *mpsc_pbuf_buffer_config *mpsc_pbuf_buffer_configconst mpsc_pbuf_bufferconst mpsc_pbuf_buffer *mpsc_pbuf_notify_dropmpsc_pbuf_buffermpsc_pbuf_get_wlenget_wlennotify_dropmax_usagerd_idxtmp_rd_idxwr_idxtmp_wr_idxMPSC_PBUF_FULLMPSC_PBUF_MAX_UTILIZATIONMPSC_PBUF_MODE_OVERWRITEMPSC_PBUF_SIZE_POW2ZEPHYR_INCLUDE_SYS_MPSC_PBUF_H_/* ZEPHYR_INCLUDE_SYS_MPSC_PBUF_H_ *//** @brief Get maximum memory utilization.
 *
 * @param[in, out] buffer Buffer.
 * @param[out]     max    Maximum buffer usage in bytes.
 *
 * retval 0 if utilization data collected successfully.
 * retval -ENOTSUP if Collecting utilization data is not supported.
 *//** @brief Get current memory utilization.
 *
 * @param[in, out] buffer Buffer.
 * @param[out]     size   Buffer size in bytes.
 * @param[out]     now    Current buffer usage in bytes.
 *//** @brief Check if there are any message pending.
 *
 * @param buffer Buffer.
 *
 * @retval true if pending.
 * @retval false if no message is pending.
 *//** @brief Free a packet.
 *
 * @param buffer Buffer.
 *
 * @param packet Packet.
 *//** @brief Claim the first pending packet.
 *
 * @param buffer Buffer.
 *
 * @return Pointer to the claimed packet or null if none available.
 *//** @brief Put a packet into a buffer.
 *
 * Copy data into a buffer.
 * Note that 2 bits of a first word is used by the buffer.
 *
 * @param buffer Buffer.
 *
 * @param data First word of data must contain MPSC_PBUF_HDR with valid bit set.
 *
 * @param wlen Packet size in words.
 *//** @brief Put a packet consisting of a word and a pointer.
 *  *
 * Function is optimized for storing packet consisting of a word and a pointer.
 * Note that 2 bits of a first word is used by the buffer.
 *
 * @param buffer Buffer.
 *
 * @param word First word of a packet consisting of MPSC_PBUF_HDR with valid
 * bit set and data on remaining bits.
 *
 * @param data User data.
 *//** @brief Put single word packet into a buffer.
 *
 * Function is optimized for storing a packet which fit into a single word.
 * Note that 2 bits of that word is used by the buffer.
 *
 * @param buffer Buffer.
 *
 * @param word Packet content consisting of MPSC_PBUF_HDR with valid bit set
 * and data on remaining bits.
 *//** @brief Commit a packet.
 *
 * @param buffer Buffer.
 *
 * @param packet Pointer to a packet allocated by @ref mpsc_pbuf_alloc.
 *//** @brief Allocate a packet.
 *
 * If a buffer is configured to overwrite mode then if there is no space to
 * allocate a new buffer, oldest packets are dropped. Otherwise allocation
 * fails and null pointer is returned.
 *
 * @param buffer Buffer.
 *
 * @param wlen Number of words to allocate.
 *
 * @param timeout Timeout. If called from thread context it will pend for given
 * timeout if packet cannot be allocated before dropping the oldest or
 * returning null.
 *
 * @return Pointer to the allocated space or null if it cannot be allocated.
 *//** @brief Initialize a packet buffer.
 *
 * @param buffer Buffer.
 *
 * @param config Configuration.
 *//* Configuration flags. *//* Callbacks. *//* Buffer size in 32 bit words. *//* Pointer to a memory used for storing packets. *//** @brief MPSC packet buffer configuration. *//* Store max buffer usage. *//* Buffer. *//** Callback for getting packet length. *//** User callback called whenever packet is dropped.
	 *
	 * May be NULL if unneeded.
	 *//** Lock. *//** Flags. *//** Read index. *//** Temporary read index. *//** Write index. *//** Temporary write index. *//** @brief MPSC packet buffer structure. *//** @brief Callback called when packet is dropped.
 *
 * @param buffer Packet buffer.
 *
 * @param packet Packet that is being dropped.
 *//** @brief Callback prototype for getting length of a packet.
 *
 * @param packet User packet.
 *
 * @return Size of the packet in 32 bit words.
 *//* Forward declaration *//** @brief Flag indicated that buffer is currently full. *//** @brief Flag indicating that maximum buffer usage is tracked. *//** @brief Flag indicating buffer full policy.
 *
 * If flag is set then when allocating from a full buffer oldest packets are
 * dropped. When flag is not set then allocation returns null.
 *//** @brief Flag indicating that buffer size is power of 2.
 *
 * When buffer size is power of 2 then optimizations are applied.
 *//**@defgroup MPSC_PBUF_FLAGS MPSC packet buffer flags
 * @{
 *//*
 * Multi producer, single consumer packet buffer allows to allocate variable
 * length consecutive space for storing a packet. When space is allocated
 * it can be filled by the user (except for the first 2 bits) and when packet
 * is ready it is committed. It is allowed to allocate another packet before
 * committing the previous one.
 *
 * If buffer is full and packet cannot be allocated then null is returned unless
 * overwrite mode is selected. In that mode, oldest entry are dropped (user is
 * notified) until allocation succeeds. It can happen that candidate for
 * dropping is currently being claimed. In that case, it is omitted and next
 * packet is dropped and claimed packet is marked as invalid when freeing.
 *
 * Reading packets is performed in two steps. First packet is claimed. Claiming
 * returns pointer to the packet within the buffer. Packet is freed when no
 * longer in use.
 *//**
 * @brief Multi producer, single consumer packet buffer API
 * @defgroup mpsc_buf MPSC (Multi producer, single consumer) packet buffer API
 * @ingroup kernel_apis
 * @{
 *//*
 * Copyright (c) 2021 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 */maxpacketwlenword<zephyr/sys/mpsc_pbuf.h><zephyr/logging/log_core.h>z_log_timestampz_log_is_local_domainCONFIG_LOG_MULTIDOMAIN_XXXXCONFIG_LOG_MULTIDOMAIN_XXXXCONFIG_LOG_MULTIDOMAIN 1!IS_ENABLED(CONFIG_LOG_MULTIDOMAIN)z_log_get_tagz_log_notify_dropitemz_log_msg_pendingz_log_msg_freez_log_msg_claimk_timeout_t *z_log_msg_commitz_log_msg_initz_log_ext_domain_countz_log_sources_countlog_source_const_data[]z_log_dynamic_filters_getlog_source_dynamic_data[]z_log_notify_backend_enabledz_log_links_activatez_log_links_initiatez_log_runtime_filters_initz_log_freez_log_dropped_pendingz_log_dropped_read_and_clearz_log_droppedlog_msg_ptrlog_mpsc_pbufZEPHYR_INCLUDE_LOGGING_LOG_INTERNAL_H_/* ZEPHYR_INCLUDE_LOGGING_LOG_INTERNAL_H_ *//** @brief Get timestamp.
 *
 * @return Timestamp.
 *//** @brief Check if domain is local.
 *
 * @param domain_id Domain ID.
 *
 * @return True if domain is local.
 *//** @brief Get tag.
 *
 * @return Tag. Null if feature is disabled.
 *//** @brief Check if there are any message pending.
 *
 * @retval true if at least one message is pending.
 * @retval false if no message is pending.
 *//** @brief Free message.
 *
 * @param msg Message.
 *//** @brief Get pending log message.
 *
 * @param[out] backoff Recommended backoff needed to maintain ordering of processed
 * messages. Used only when links are using dedicated buffers.
 *
 * @param Message or null if no pending messages.
 *//** @brief Commit log message.
 *
 * @param msg Message.
 *//** @brief Initialize module for handling logging message. *//** @brief Return number of external domains.
 *
 * @return Number of external domains.
 *//** @brief Get number of registered sources. *//** @brief Get pointer to the filter set of the log source.
 *
 * @param source_id Source ID.
 *
 * @return Pointer to the filter set.
 *//* Notify log_core that a backend was enabled. *//* Activate links.
 * Attemp to activate links,
 *
 * @param active_mask     Mask with links to activate. N bit set indicates that Nth
 * link should be activated.
 *
 * @param[in, out] offset Offset assigned to domains. Initialize to 0 before first use.
 *
 * @return Mask with links that still remain inactive.
 *//* Initialize links. *//* Initialize runtime filters *//** @brief Free allocated buffer.
 *
 * @param buf Buffer.
 *//** @brief Check if there are any pending drop notifications.
 *
 * @retval true Pending unreported drop indications.
 * @retval false No pending unreported drop indications.
 *//** @brief Read and clear current drop indications counter.
 *
 * @return Dropped count.
 *//** @brief Indicate to the log core that one log message has been dropped.
 *
 * @param buffered True if dropped message was already buffered and it is being
 * dropped to free space for another message. False if message is being dropped
 * because allocation failed.
 *//** @brief Structure wrapper to be used for memory section. *//* Header contains declarations of functions used internally in the logging,
 * shared between various portions of logging subsystem. Functions are internal
 * not intended to be used outside, including logging backends.
 */domain_idsource_idbackoffactive_maskbufferedlog_filter_setz_impl_log_filter_setlog_buffered_cntz_impl_log_buffered_cntlog_processz_impl_log_processlog_panicz_impl_log_panicZ_INCLUDE_SYSCALLS_LOG_CTRL_H<syscalls/log_ctrl.h><zephyr/logging/log_internal.h><zephyr/logging/log_backend.h>log_mem_get_max_usagelog_mem_get_usagelog_set_taglog_data_pendingCONFIG_LOG_MODE_DEFERRED_XXXXCONFIG_LOG_MODE_DEFERRED_XXXXCONFIG_LOG_MODE_DEFERRED 1log_format_set_all_active_backendslog_backend_get_by_namelog_backend_disablelog_backend_enablelog_filter_getlog_source_id_getlog_domain_name_getlog_domains_countlog_source_name_getlog_src_cnt_getlog_set_timestamp_funclog_thread_setlog_initlog_core_initlog_timestamp_get_tLOG_PROCESS()LOG_PANIC()LOG_INIT()LOG_CORE_INIT()ZEPHYR_INCLUDE_LOGGING_LOG_CTRL_H_defined(CONFIG_LOG) && !defined(CONFIG_LOG_MODE_MINIMAL)defined(CONFIG_LOG_FRONTEND_ONLY)/* ZEPHYR_INCLUDE_LOGGING_LOG_CTRL_H_ *//* Empty *//* !CONFIG_LOG_FRONTEND_ONLY *//**
 * @brief Get maximum memory usage.
 *
 * Requires CONFIG_LOG_MEM_UTILIZATION option.
 *
 * @param[out] max Maximum number of bytes used for pending log messages.
 *
 * @retval -EINVAL if logging mode does not use the buffer.
 * @retval -ENOTSUP if instrumentation is not enabled.
 * not been enabled.
 *
 * @retval 0 successfully collected usage data.
 *//**
 * @brief Get current memory usage.
 *
 * @param[out] buf_size Capacity of the buffer used for storing log messages.
 * @param[out] usage Number of bytes currently containing pending log messages.
 *
 * @retval -EINVAL if logging mode does not use the buffer.
 * @retval 0 successfully collected usage data.
 *//**
 * @brief Configure tag used to prefix each message.
 *
 * @param tag Tag.
 *
 * @retval 0 on successful operation.
 * @retval -ENOTSUP if feature is disabled.
 * @retval -ENOMEM if string is longer than the buffer capacity. Tag will be trimmed.
 *//**
 * @brief Check if there is pending data to be processed by the logging subsystem.
 *
 * Function can be used to determine if all logs have been flushed. Function
 * returns false when deferred mode is not enabled.
 *
 * @retval true There is pending data.
 * @retval false No pending data to process.
 *//** @brief Sets logging format for all active backends.
 *
 * @param log_type Log format.
 *
 * @retval Pointer to the last backend that failed, NULL for success.
 *//**
 * @brief Get backend by name.
 *
 * @param[in] backend_name Name of the backend as defined by the LOG_BACKEND_DEFINE.
 *
 * @retval Pointer to the backend instance if found, NULL if backend is not found.
 *//**
 *
 * @brief Disable backend.
 *
 * @param backend	Backend instance.
 *//**
 *
 * @brief Enable backend with initial maximum filtering level.
 *
 * @param backend	Backend instance.
 * @param ctx		User context.
 * @param level		Severity level.
 *//**
 * @brief Set filter on given source for the provided backend.
 *
 * @param backend	Backend instance. NULL for all backends.
 * @param domain_id	ID of the domain.
 * @param source_id	Source (module or instance) ID.
 * @param level		Severity level.
 *
 * @return Actual level set which may be limited by compiled level. If filter
 *	   was set for all backends then maximal level that was set is returned.
 *//**
 * @brief Get source filter for the provided backend.
 *
 * @param backend	Backend instance.
 * @param domain_id	ID of the domain.
 * @param source_id	Source (module or instance) ID.
 * @param runtime	True for runtime filter or false for compiled in.
 *
 * @return		Severity level.
 *//**
 * @brief Function for finding source ID based on source name.
 *
 * @param name Source name
 *
 * @return Source ID or negative number when source ID is not found.
 *//** @brief Get name of the domain.
 *
 * @param domain_id Domain ID.
 *
 * @return Domain name.
 *//** @brief Return number of domains present in the system.
 *
 * There will be at least one local domain.
 *
 * @return Number of domains.
 *//** @brief Get name of the source (module or instance).
 *
 * @param domain_id Domain ID.
 * @param source_id Source ID.
 *
 * @return Source name or NULL if invalid arguments.
 *//** @brief Get number of independent logger sources (modules and instances)
 *
 * @param domain_id Domain ID.
 *
 * @return Number of sources.
 *//**
 * @brief Return number of buffered log messages.
 *
 * @return Number of currently buffered log messages.
 *//**
 * @brief Process one pending log message.
 *
 * @retval true There is more messages pending to be processed.
 * @retval false No messages pending.
 *//**
 * @brief Switch the logger subsystem to the panic mode.
 *
 * Returns immediately if the logger is already in the panic mode.
 *
 * @details On panic the logger subsystem informs all backends about panic mode.
 *          Backends must switch to blocking mode or halt. All pending logs
 *          are flushed after switching to panic mode. In panic mode, all log
 *          messages must be processed in the context of the call.
 *//**
 * @brief Function for providing timestamp function.
 *
 * @param timestamp_getter	Timestamp function.
 * @param freq			Timestamping frequency.
 *
 * @return 0 on success or error.
 *//**
 * @brief Function for providing thread which is processing logs.
 *
 * See CONFIG_LOG_PROCESS_TRIGGER_THRESHOLD.
 *
 * @note Function has asserts and has no effect when CONFIG_LOG_PROCESS_THREAD is set.
 *
 * @param process_tid Process thread id. Used to wake up the thread.
 *//**
 * @brief Function for user initialization of the logger.
 *
 *//** @brief Function system initialization of the logger.
 *
 * Function is called during start up to allow logging before user can
 * explicitly initialize the logger.
 *//**
 * @brief Logger control API
 * @defgroup log_ctrl Logger control API
 * @ingroup logger
 * @{
 *//**
 * @brief Logger
 * @defgroup logger Logger system
 * @ingroup logging
 * @{
 * @}
 */usagebackend_nameruntimetimestamp_getterprocess_tid/home/haojie/zephyrproject/zephyr/include/zephyr/debug/gcov.hgcov_static_initgcov_coverage_dumpZEPHYR_INCLUDE_DEBUG_GCOV_H_/* ZEPHYR_INCLUDE_DEBUG_GCOV_H_ *//home/haojie/zephyrproject/zephyr/include/zephyr/timing/types.htiming_tZEPHYR_INCLUDE_TIMING_TYPES_H_/* ZEPHYR_INCLUDE_TIMING_TYPES_H_ *//home/haojie/zephyrproject/zephyr/include/zephyr/timing/home/haojie/zephyrproject/zephyr/include/zephyr/timing/timing.h<zephyr/timing/types.h>board_timing_freq_get_mhzboard_timing_cycles_to_ns_avgboard_timing_cycles_to_nsboard_timing_freq_getboard_timing_cycles_getvolatile timing_tvolatile timing_t *volatile timing_t *constboard_timing_counter_getboard_timing_stopboard_timing_startboard_timing_initsoc_timing_freq_get_mhzsoc_timing_cycles_to_ns_avgsoc_timing_cycles_to_nssoc_timing_freq_getsoc_timing_cycles_getsoc_timing_counter_getsoc_timing_stopsoc_timing_startsoc_timing_initZEPHYR_INCLUDE_TIMING_TIMING_H_defined(CONFIG_BOARD_HAS_TIMING_FUNCTIONS)defined(CONFIG_SOC_HAS_TIMING_FUNCTIONS)/* ZEPHYR_INCLUDE_TIMING_TIMING_H_ *//**
 * @brief Get frequency of counter used (in MHz).
 *
 * @return Frequency of counter used for timing in MHz.
 *//**
 * @brief Convert number of @p cycles into nanoseconds with averaging.
 *
 * @param cycles Number of cycles
 * @param count Times of accumulated cycles to average over
 * @return Converted time value
 *//**
 * @brief Convert number of @p cycles into nanoseconds.
 *
 * @param cycles Number of cycles
 * @return Converted time value
 *//**
 * @brief Get frequency of counter used (in Hz).
 *
 * @return Frequency of counter used for timing in Hz.
 *//**
 * @brief Get number of cycles between @p start and @p end.
 *
 * For some architectures or SoCs, the raw numbers from counter
 * need to be scaled to obtain actual number of cycles.
 *
 * @param start Pointer to counter at start of a measured execution.
 * @param end Pointer to counter at stop of a measured execution.
 * @return Number of cycles between start and end.
 *//**
 * @brief Return timing counter.
 *
 * @return Timing counter.
 *//**
 * @brief Signal the end of the timing information gathering.
 *
 * Signal to the timing subsystem that timing information
 * is no longer being gathered from this point forward.
 *//**
 * @brief Signal the start of the timing information gathering.
 *
 * Signal to the timing subsystem that timing information
 * will be gathered from this point forward.
 *//**
 * @brief Initialize the timing subsystem.
 *
 * Perform the necessary steps to initialize the timing subsystem.
 *//**
 * @brief Timing Measurement APIs
 * @defgroup timing_api Timing APIs
 * @ingroup os_services
 * @{
 */cycles/home/haojie/zephyrproject/zephyr/kernel/init.c<zephyr/timing/timing.h><zephyr/debug/gcov.h><zephyr/drivers/entropy.h><zephyr/debug/stack.h><offsets_short.h>INIT_LEVEL_EARLYINIT_LEVEL_PRE_KERNEL_1INIT_LEVEL_PRE_KERNEL_2sizeof(val)28629335557779417572862933555777941757ULL30370004933037000493ULL(uint64_t)CONFIG_TIMER_RANDOM_INITIAL_STATEswitch_to_main_threadprepare_multithreadingz_thread_stack_element[1024]z_main_stack__attribute__((section("." "noinit" "." "\"/home/haojie/zephyrproject/zephyr/kernel/init.c\"" "." "0")))"main"char[5]z_interrupt_stacks[id]__attribute__((section("." "noinit" "." "\"/home/haojie/zephyrproject/zephyr/kernel/init.c\"" "." "2")))K_KERNEL_STACK_SIZEOF(z_interrupt_stacks[id])init_idle_threadz_thread_stack_element[320]z_idle_stacks__attribute__((section("." "noinit" "." "\"/home/haojie/zephyrproject/zephyr/kernel/init.c\"" "." "1")))Z_KERNEL_STACK_SIZE_ADJUST(320)(((((unsigned long)(320) + ((unsigned long)(4UL) - 1)) / (unsigned long)(4UL)) * (unsigned long)(4UL)) + ((size_t)0))z_thread_stack_element[1][320]z_thread_stack_element(*)[320]tnamebg_thread_mainINIT_LEVEL_POST_KERNELINIT_LEVEL_APPLICATION~K_ESSENTIALz_sys_init_run_levelconst init_entry *init_entry *const init_entry *[]init_entry *[]levelsconst init_entry *[6]init_entry *[6]const init_entry **init_entry **const init_entry[]init_entry[]CONFIG_SKIP_BSS_CLEAR_XXXXCONFIG_SKIP_BSS_CLEAR_XXXXCONFIG_SKIP_BSS_CLEAR 1init_level.noinit."/home/haojie/zephyrproject/zephyr/kernel/init.c".2__FILE__"/home/haojie/zephyrproject/zephyr/kernel/init.c"__COUNTER__char[60]__init_end__init_APPLICATION_start__init_POST_KERNEL_start__init_PRE_KERNEL_2_start__init_PRE_KERNEL_1_start__init_EARLY_start__init_start.noinit."/home/haojie/zephyrproject/zephyr/kernel/init.c".1.noinit."/home/haojie/zephyrproject/zephyr/kernel/init.c".0CONFIG_MP_NUM_CPUS == CONFIG_MP_MAX_NUM_CPUS1 == 1"CONFIG_MP_NUM_CPUS and CONFIG_MP_MAX_NUM_CPUS need to be set the same"CONFIG_CODE_DATA_RELOCATIONCONFIG_STACK_CANARIESCONFIG_STACK_CANARIES_TLSdefined(CONFIG_CPP)CONFIG_COVERAGE_DUMPdefined(CONFIG_MULTITHREADING)CONFIG_THREAD_NAMECONFIG_MP_MAX_NUM_CPUS > 1CONFIG_ENTROPY_HAS_DRIVERCONFIG_TIMING_FUNCTIONS_NEED_AT_BOOTARCH_SWITCH_TO_MAIN_NO_MULTITHREADINGZ_DO_LOG_MODULE_REGISTER(os, CONFIG_KERNEL_LOG_LEVEL)(_LOG_MODULE_DATA_CREATE(GET_ARG_N(1, os, CONFIG_KERNEL_LOG_LEVEL), _LOG_LEVEL_RESOLVE(os, CONFIG_KERNEL_LOG_LEVEL)))(const __attribute__((__aligned__(__alignof(struct log_source_const_data)))) struct log_source_const_data log_const_os __attribute__((section("." "_log_const" "." "static" "." "log_const_os_"))) __attribute__((__used__)) = { .name = "os", .level = 0U }; )_XXXX0 (const __attribute__((__aligned__(__alignof(struct log_source_const_data)))) struct log_source_const_data log_const_os __attribute__((section("." "_log_const" "." "static" "." "log_const_os_"))) __attribute__((__used__)) = { .name = "os", .level = 0U }; )(_LOG_MODULE_DYNAMIC_DATA_CREATE(os);)(__attribute__((__aligned__(__alignof(struct log_source_dynamic_data)))) struct log_source_dynamic_data log_dynamic_os __attribute__((section("." "_log_dynamic" "." "static" "." "log_dynamic_os_"))) __attribute__((__used__)) ;)_XXXXCONFIG_LOG_RUNTIME_FILTERING (__attribute__((__aligned__(__alignof(struct log_source_dynamic_data)))) struct log_source_dynamic_data log_dynamic_os __attribute__((section("." "_log_dynamic" "." "static" "." "log_dynamic_os_"))) __attribute__((__used__)) ;)LOG_ITEM_DYNAMIC_DATA(os)__UINT8_MAX___CONCAT(log_dynamic_os, _)log_dynamic_os_(UTIL_CAT(os, _str))(os_str)(STRINGIFY(os))("os")_XXXXCONFIG_LOG_FMT_SECTION (os_str)"os"Z_LOG_ITEM_CONST_DATA(os)_CONCAT(log_const_os, _)log_const_os_( static const char UTIL_CAT(os, _str)[] __in_section(_log_strings, static, _CONCAT(os, _)) __used __noasan = STRINGIFY(os);)( static const char os_str[] __attribute__((section("." "_log_strings" "." "static" "." "os_"))) __attribute__((__used__)) = "os";)_XXXXCONFIG_LOG_FMT_SECTION ( static const char os_str[] __attribute__((section("." "_log_strings" "." "static" "." "os_"))) __attribute__((__used__)) = "os";)_CONCAT(os, _)os_/* Initialize kernel object type *//* Initialize CPU object type *//*
	 * Compiler can't tell that the above routines won't return and issues
	 * a warning unless we explicitly tell it that control never gets this
	 * far.
	 *//* LCOV_EXCL_START
	 * We've already dumped coverage data at this point.
	 *//* Custom ARCH-specific routine to switch to main()
	 * in the case of no multi-threading.
	 *//* CONFIG_STACK_CANARIES *//* perform basic hardware initialization *//* do any necessary initialization of static devices *//* Note: The z_ready_thread() call in prepare_multithreading() requires
	 * a dummy thread even if CONFIG_ARCH_HAS_CUSTOM_SWAP_TO_MAIN=y
	 *//* perform any architecture-specific initialization *//* initialize early init calls *//* gcov hook needed to get the coverage report.*//**
 *
 * @brief Initialize kernel
 *
 * This routine is invoked when the system is ready to run C code. The
 * processor must be running in 32-bit mode, and the BSS must have been
 * cleared/zeroed.
 *
 * @return Does not return
 *//* Try to see if driver provides an ISR-specific API *//*
	 * Context switch to main task (entry function is _main()): the
	 * current fake thread is not on a wait queue or ready queue, so it
	 * will never be rescheduled in.
	 *//*
	 * prime the cache with the main thread since:
	 *
	 * - the cache can never be NULL
	 * - the main thread will be the one to run first
	 * - no other thread is initialized yet and thus their priority fields
	 *   contain garbage, which would prevent the cache loading algorithm
	 *   to work as intended
	 *//* _kernel.ready_q is all zeroes *//**
 *
 * @brief Initializes kernel data structures
 *
 * This routine initializes various kernel data structures, including
 * the init and idle threads and any architecture-specific initialization.
 *
 * Note that all fields of "_kernel" are set to zero on entry, which may
 * be all the initialization many of them require.
 *
 * @return initial stack pointer for the main thread
 *//*
	 * Increment number of CPUs active. The pm subsystem
	 * will keep track of this from here.
	 *//* CONFIG_THREAD_NAME *//* LCOV_EXCL_LINE ... because we just dumped final coverage data *//* Dump coverage data once the main() has exited. *//* Mark nonessential since main() has no more work to do *//* Final init level before app starts *//* Invoked here such that backing store or eviction algorithms may
	 * initialize kernel objects, and that all POST_KERNEL and later tasks
	 * may perform memory management tasks (except for z_phys_map() which
	 * is allowed at any time)
	 *//**
 * @brief Mainline for kernel's background thread
 *
 * This routine completes kernel initialization by invoking the remaining
 * init functions, then invokes application's main() routine.
 *//* Run automatic device runtime enablement *//* Mark device initialized. If initialization
				 * failed, record the error condition.
				 *//* End marker *//**
 * @brief Execute all the init entry initialization functions at a given level
 *
 * @details Invokes the initialization routine for each init entry object
 * created by the INIT_ENTRY_DEFINE() macro using the specified level.
 * The linker script places the init entry objects in memory in the order
 * they need to be invoked, with symbols indicating where one level leaves
 * off and the next one begins.
 *
 * @param level init level to run.
 *//**
 * @brief Clear BSS within the pinned region
 *
 * This routine clears the BSS within the pinned region.
 * This is separate from z_bss_zero() as pinned region may
 * contain symbols required for the boot process before
 * paging is initialized.
 *//**
 * @brief Clear BSS within the bot region
 *
 * This routine clears the BSS within the boot region.
 * This is separate from z_bss_zero() as boot region may
 * contain symbols required for the boot process before
 * paging is initialized.
 *//* CONFIG_CODE_DATA_RELOCATION *//**
 * @brief Clear BSS
 *
 * This routine clears the BSS region, so all bytes are 0.
 *//**
 * @brief equivalent of memcpy() for early boot usage
 *
 * Architectures that can't safely use the regular (optimized) memcpy very
 * early during boot because e.g. hardware isn't yet sufficiently initialized
 * may override this with their own safe implementation.
 *//**
 * @brief equivalent of memset() for early boot usage
 *
 * Architectures that can't safely use the regular (optimized) memset very
 * early during boot because e.g. hardware isn't yet sufficiently initialized
 * may override this with their own safe implementation.
 *//* LCOV_EXCL_START
 *
 * This code is called so early in the boot process that code coverage
 * doesn't work properly. In addition, not all arches call this code,
 * some like x86 do this with optimized assembly
 *//*
 * storage space for the interrupt stack
 *
 * Note: This area is used as the system stack during kernel initialization,
 * since the kernel hasn't yet set up its own stack areas. The dual purposing
 * of this area is safe since interrupts are disabled until the kernel context
 * switches to the init thread.
 *//* init/main and idle threads *//* the only struct z_kernel instance *//**
 * @file
 * @brief Kernel initialization module
 *
 * This module contains routines that are used to initialize the kernel.
 */CONFIG_MP_NUM_CPUS and CONFIG_MP_MAX_NUM_CPUS need to be set the same/home/haojie/zephyrproject/zephyr/kernel/kheap.callocsizeof(void *)timeout, retaligned_alloc!arch_is_in_isr() || K_TIMEOUT_EQ(timeout, K_NO_WAIT)blocked_alloc!IS_ENABLED(CONFIG_MULTITHREADING)statics_initstruct k_heap_k_heapk_heap[]h <= TYPE_SECTION_END(k_heap)__init_statics_init_prestatics_init_pre.z_init_PRE_KERNEL_130_0__k_heap_list_end_k_heap_list_startdefined(CONFIG_DEMAND_PAGING) && !defined(CONFIG_LINKER_GENERIC_SECTIONS_PRESENT_AT_BOOT)/**
			 * @todo	Trace attempt to avoid empty trace segments
			 *//* CONFIG_DEMAND_PAGING && !CONFIG_LINKER_GENERIC_SECTIONS_PRESENT_AT_BOOT *//* Need to wait for paging mechanism to be initialized before
 * heaps that are not in pinned sections can be initialized.
 *//* During pre-kernel init, z_sys_post_kernel == false,
		 * initialize if within pinned region. Otherwise skip.
		 * In post-kernel init, z_sys_post_kernel == true, skip those in
		 * pinned region as they have already been initialized and
		 * possibly already in use. Otherwise initialize.
		 *//* Some heaps may not present at boot, so we need to wait for
		 * paging mechanism to be initialized before we can initialize
		 * each heap.
		 *//home/haojie/zephyrproject/zephyr/kernel/mailbox.csending_thread__f&mbox->tx_msg_queue&(&mbox->tx_msg_queue)->waitq.treebase.qnode_rb__typeof__(*(sending_thread))SAME_TYPE(*(n), ((__typeof__(*(sending_thread)) *)0)->base.qnode_rb) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((__typeof__(*(sending_thread)) *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))*(n)((__typeof__(*(sending_thread)) *)0)->base.qnode_rbtimeout, resulttimeout, -ENOMSG-35-ENOMSGmbox_message_data_checkrx_msg->tx_datarx_msg->sizek_mbox_async *asyncasync_putk_mbox_async **mbox_message_putreceiving_threadmessage_put&mbox->rx_msg_queue&(&mbox->rx_msg_queue)->waitq.tree__typeof__(*(receiving_thread))SAME_TYPE(*(n), ((__typeof__(*(receiving_thread)) *)0)->base.qnode_rb) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((__typeof__(*(receiving_thread)) *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))((__typeof__(*(receiving_thread)) *)0)->base.qnode_rbmbox_message_disposeasync_semmbox_message_matchtemp_info(k_tid_t)K_ANYinit_mbox_module"/home/haojie/zephyrproject/zephyr/kernel/mailbox.c"k_mbox_async[10]async_msg.noinit."/home/haojie/zephyrproject/zephyr/kernel/mailbox.c".1char[63]mbox_async_freembox_async_allock_mbox_async__init_init_mbox_moduleasync_msg_free._k_stack.static.async_msg_free_struct k_stack_k_stack_CONCAT(async_msg_free, _)async_msg_free_char[33]_k_stack_buf_async_msg_free&async_msg_free.wait_qstack_data_t[10]unsigned long[10].noinit."/home/haojie/zephyrproject/zephyr/kernel/mailbox.c".0__alignof(struct k_stack)/* Initialize and link satically defined mailboxes *//* Initialize mailbox object type *//* consume message data immediately, if needed *//* wait until a matching sender appears or a timeout occurs *//* don't wait for a matching sender to appear *//* didn't find a matching sender *//* take sender out of mailbox's tx queue *//* search mailbox's tx queue for a compatible sender *//* save receiver id so it can be used during message matching *//* keep message around for later data retrieval *//* there is no data to get, so just dispose of message *//* retrieve data now, then dispose of message *//**
 * @brief Handle immediate consumption of received mailbox message data.
 *
 * Checks to see if received message data should be kept for later retrieval,
 * or if the data should consumed immediately and the message disposed of.
 *
 * The data is consumed immediately in either of the following cases:
 *     1) The receiver requested immediate retrieval by supplying a buffer
 *        to receive the data.
 *     2) There is no data to be retrieved. (i.e. Data size is 0 bytes.)
 *
 * @param rx_msg Pointer to receive message descriptor.
 * @param buffer Pointer to buffer to receive data.
 *
 * @return 0
 *//* copy message data to buffer, then dispose of message *//* handle case where data is to be discarded *//*
	 * allocate an asynchronous message descriptor, configure both parts,
	 * then send the message asynchronously
	 *//* configure things for a synchronous send, then send the message *//* synchronous send: sender waits on tx queue for receiver or timeout *//* asynchronous send: dummy thread waits on tx queue for receiver *//* didn't find a matching receiver: don't wait for one *//*
			 * synchronous send: pend current thread (unqueued)
			 * until the receiver consumes the message
			 *//*
			 * asynchronous send: swap out current thread
			 * if receiver has priority, otherwise let it continue
			 *
			 * note: dummy sending thread sits (unqueued)
			 * until the receiver consumes the message
			 *//* ready receiver for execution *//* take receiver out of rx queue *//* search mailbox's rx queue for a compatible receiver *//* finish readying sending thread (actual or dummy) for send *//* save sender id so it can be used during message matching *//**
 * @brief Send a mailbox message.
 *
 * Helper routine that handles both synchronous and asynchronous sends.
 *
 * @param mbox Pointer to the mailbox object.
 * @param tx_msg Pointer to transmit message descriptor.
 * @param timeout Maximum time (milliseconds) to wait for the message to be
 *        received (although not necessarily completely processed).
 *        Use K_NO_WAIT to return immediately, or K_FOREVER to wait as long
 *        as necessary.
 *
 * @return 0 if successful, -ENOMSG if failed immediately, -EAGAIN if timed out
 *//* synchronous send: wake up sending thread *//*
	 * asynchronous send: free asynchronous message descriptor +
	 * dummy thread pair, then give semaphore (if needed)
	 *//* update data size field for sender *//* recover sender info *//* do nothing if message was disposed of when it was received *//**
 * @brief Dispose of received message.
 *
 * Notifies the sender that message processing is complete.
 *
 * @param rx_msg Pointer to receive message descriptor.
 *//* update syncing thread field for receiver only *//* update data location fields for receiver only *//* update data size field for receiver only *//* update application info fields for both descriptors *//* update thread identifier fields for both descriptors *//**
 * @brief Check compatibility of sender's and receiver's message descriptors.
 *
 * Compares sender's and receiver's message descriptors to see if they are
 * compatible. If so, the descriptor fields are updated to reflect that a
 * match has occurred.
 *
 * @param tx_msg Pointer to transmit message descriptor.
 * @param rx_msg Pointer to receive message descriptor.
 *
 * @return 0 if successfully matched, otherwise -1.
 *//* CONFIG_NUM_MBOX_ASYNC_MSGS *//* Complete initialization of statically defined mailboxes. *//* CONFIG_NUM_MBOX_ASYNC_MSGS > 0 *//*
	 * Create pool of asynchronous message descriptors.
	 *
	 * A dummy thread requires minimal initialization, since it never gets
	 * to execute. The _THREAD_DUMMY flag is sufficient to distinguish a
	 * dummy thread from a real one. The threads are *not* added to the
	 * kernel's list of known threads.
	 *
	 * Once initialized, the address of each descriptor is added to a stack
	 * that governs access to them.
	 *//* array of asynchronous message descriptors *//*
 * Do run-time initialization of mailbox object subsystem.
 *//* free an asynchronous message descriptor *//* allocate an asynchronous message descriptor *//* stack of unused asynchronous message descriptors *//* transmit message descriptor *//* dummy thread object *//* asynchronous message descriptor type *//**
 * @brief Mailboxes.
 *//home/haojie/zephyrproject/zephyr/kernel/main_weak.c/* NOP default main() if the application does not provide one. *//* Linkers may treat weak functions differently if they are located within
 * the same object that calls the symbol or not.
 *
 * For example, when using armlink, then if the weak symbol is inside the object
 * referring to it the weak symbol will be used. This will result in the symbol
 * being multiply defined because both the weak and strong symbols are used.
 *
 * To GNU ld, it doesn't matter if the weak symbol is placed in the same object
 * which uses the weak symbol. GNU ld will always link to the strong version.
 *
 * Having the weak main symbol in an independent file ensures that it will be
 * correctly treated by multiple linkers.
 *//*
 * Copyright (c) 2010-2014 Wind River Systems, Inc.
 * Copyright (c) 2021 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 */CHECKIF(expr)if (expr)ZEPHYR_INCLUDE_SYS_CHECK_H_defined(CONFIG_ASSERT_ON_ERRORS)defined(CONFIG_NO_RUNTIME_CHECKS)/* ZEPHYR_INCLUDE_SYS_CHECK_H_ */z_waitq_headz_waitq_init_WAIT_Q_FOR_EACH(wq,thread_ptr)RB_FOR_EACH_CONTAINER(&(wq)->waitq.tree, thread_ptr, base.qnode_rb)ZEPHYR_KERNEL_INCLUDE_WAIT_Q_H_/* ZEPHYR_KERNEL_INCLUDE_WAIT_Q_H_ *//* !CONFIG_WAITQ_SCALABLE *//* !CONFIG_WAITQ_SCALABLE: *//* wait queue for multiple threads on kernel objects */w/home/haojie/zephyrproject/zephyr/kernel/mem_slab.c((char *)mem >= slab->buffer) && ((((char *)mem - slab->buffer) % slab->info.block_size) == 0) && ((char *)mem <= (slab->buffer + (slab->info.block_size * (slab->info.num_blocks - 1))))"Invalid memory pointer provided"-12-ENOMEMinit_mem_slab_obj_core_liststruct k_mem_slab_k_mem_slabk_mem_slab[]slab <= TYPE_SECTION_END(k_mem_slab)create_free_listj((slab->info.block_size | (uintptr_t)slab->buffer) & (sizeof(void *) - 1)) != 0U__init_init_mem_slab_obj_core_list_k_mem_slab_list_end_k_mem_slab_list_startCONFIG_OBJ_CORE_STATS_MEM_SLAB/* wait for a free block or timeout *//* don't wait for a free block to become available *//* take a free block *//* Initialize statically defined mem_slabs *//* Initialize mem_slab object type *//**
 * @brief Complete initialization of statically defined memory slabs.
 *
 * Perform any initialization that wasn't done at build time.
 *
 * @return 0 on success, fails otherwise.
 *//* blocks must be word aligned *//**
 * @brief Initialize kernel memory slab subsystem.
 *
 * Perform any initialization of memory slabs that wasn't done at build time.
 * Currently this just involves creating the list of free blocks for each slab.
 *
 * @retval 0 on success.
 * @retval -EINVAL if @p slab contains invalid configuration and/or values.
 *//home/haojie/zephyrproject/zephyr/include/zephyr/sys/math_extras.h/home/haojie/zephyrproject/zephyr/include/zephyr/sys/math_extras_impl.h/home/haojie/zephyrproject/zephyr/kernel/mempool.c<zephyr/sys/math_extras.h>k_heap **heap_refk_heap_sys*heap_refz_heap_aligned_alloc__alignsizeof(heap_ref)align == 0 || ((uintptr_t)mem & (align - 1)) == 0"misaligned memory at %p (align = %zu)"mem, align_SYSTEM_HEAP/*
	 * Adjust the size to make room for our heap reference.
	 * Merge a rewind bit with align value (see sys_heap_aligned_alloc()).
	 * This allows for storing the heap pointer right below the aligned
	 * boundary without wasting any memory.
	 *//home/haojie/zephyrproject/zephyr/include/zephyr/sys/bitarray.h/home/haojie/zephyrproject/zephyr/kernel/mmu.c<zephyr/sys/bitarray.h>(((uint8_t *)(&z_mapped_end)) - ((uint8_t *)(&z_mapped_start)))char(*)[]"free page frames: %zu", z_free_page_count"free page frames: %zu"Z_LOG_STR(4U, "free page frames: %zu", z_free_page_count)(Z_LOG_STR_WITH_PREFIX("free page frames: %zu", z_free_page_count))("%s: " "free page frames: %zu", (const char *)__func__ , z_free_page_count)("free page frames: %zu", z_free_page_count)NUM_VA_ARGS_LESS_1(_,"free page frames: %zu", z_free_page_count)(Z_LOG_STR_WITH_PREFIX2("free page frames: %zu", z_free_page_count))_,"free page frames: %zu", z_free_page_countNUM_VA_ARGS_LESS_1("free page frames: %zu", z_free_page_count)(, GET_ARGS_LESS_N(1, "free page frames: %zu", z_free_page_count))(, z_free_page_count), z_free_page_count"%s: " "free page frames: %zu", (const char *)__func__ , z_free_page_count_XXXX0 ("%s: " "free page frames: %zu", (const char *)__func__ , z_free_page_count)REVERSE_ARGS("free page frames: %zu", z_free_page_count)z_free_page_count , "free page frames: %zu"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "free page frames: %zu") = ("free page frames: %zu") + 0)(__auto_type "free page frames: %zu" = ("free page frames: %zu") + 0)("free page frames: %zu")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, z_free_page_count) = (z_free_page_count) + 0)(__auto_type _v1 = (z_free_page_count) + 0)(z_free_page_count)_ZZZZ1 (z_free_page_count)__auto_type _v1 = (z_free_page_count) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count)"free page frames: %zu" , _v1(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "free page frames: %zu";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "free page frames: %zu" , _v1);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count)_,"free page frames: %zu" , _v1static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "free page frames: %zu";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "free page frames: %zu";)NUM_VA_ARGS_LESS_1("free page frames: %zu" , _v1)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "free page frames: %zu" , _v1))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count))( bool can_simple = LOG_MSG_SIMPLE_CHECK("free page frames: %zu" , _v1); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("free page frames: %zu" , _v1), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("free page frames: %zu" , _v1)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("free page frames: %zu" , _v1)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("free page frames: %zu" , _v1))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("free page frames: %zu" , _v1))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "free page frames: %zu", z_free_page_count)))("free page frames: %zu" , _v1)(COND_CODE_0(NUM_VA_ARGS_LESS_1("free page frames: %zu" , _v1), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "free page frames: %zu" , _v1))))(_fmt, GET_ARGS_LESS_N(1, "free page frames: %zu" , _v1))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "free page frames: %zu" , _v1); )( z_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "free page frames: %zu" , _v1)))(z_log_msg_simple_create_0(_src, 4U, "free page frames: %zu"))(COND_CODE_1(1, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "free page frames: %zu" , _v1, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "free page frames: %zu" , _v1, dummy, dummy) ) ))(z_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "free page frames: %zu" , _v1, dummy) )( z_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "free page frames: %zu" , _v1, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)dummy) )"free page frames: %zu" , _v1, dummy"free page frames: %zu" , _v1, dummy, dummyz_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1)_ZZZZ1 (z_log_msg_simple_create_0(_src, 4U, "free page frames: %zu"))z_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 4U, "free page frames: %zu", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "free page frames: %zu" , _v1))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "free page frames: %zu" , _v1))REVERSE_ARGS("free page frames: %zu" , _v1)_v1 , "free page frames: %zu"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("free page frames: %zu") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("free page frames: %zu") + 0, long double : 1, default : 0) && !0)_Generic(("free page frames: %zu") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("free page frames: %zu") + 0))_Generic(("free page frames: %zu") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("free page frames: %zu") + 0))%c: free page frames: %zu
free page frames: %zuaddr_offsetsize + addr_offsetaligned_virtaligned_size != 0U"0-length mapping at 0x%lx"aligned_virt < (aligned_virt + (aligned_size - 1))"wraparound for virtual address 0x%lx (size %zu)"aligned_virt, aligned_size"arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset"arch_mem_unmap(0x%lx, %zu) offset %lu"aligned_virt, aligned_size, addr_offsetZ_LOG_STR(4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)(Z_LOG_STR_WITH_PREFIX("arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))("%s: " "arch_mem_unmap(0x%lx, %zu) offset %lu", (const char *)__func__ , aligned_virt, aligned_size, addr_offset)("arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)NUM_VA_ARGS_LESS_1(_,"arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)(Z_LOG_STR_WITH_PREFIX2("arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))_,"arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offsetNUM_VA_ARGS_LESS_1("arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)(, GET_ARGS_LESS_N(1, "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))(, aligned_virt, aligned_size, addr_offset), aligned_virt, aligned_size, addr_offset"%s: " "arch_mem_unmap(0x%lx, %zu) offset %lu", (const char *)__func__ , aligned_virt, aligned_size, addr_offset_XXXX0 ("%s: " "arch_mem_unmap(0x%lx, %zu) offset %lu", (const char *)__func__ , aligned_virt, aligned_size, addr_offset)REVERSE_ARGS("arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)addr_offset , aligned_size , aligned_virt , "arch_mem_unmap(0x%lx, %zu) offset %lu"aligned_size, addr_offsetaligned_size , aligned_virt , "arch_mem_unmap(0x%lx, %zu) offset %lu"aligned_virt , "arch_mem_unmap(0x%lx, %zu) offset %lu"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "arch_mem_unmap(0x%lx, %zu) offset %lu") = ("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0)(__auto_type "arch_mem_unmap(0x%lx, %zu) offset %lu" = ("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0)("arch_mem_unmap(0x%lx, %zu) offset %lu")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, aligned_virt) = (aligned_virt) + 0)(__auto_type _v1 = (aligned_virt) + 0)(aligned_virt)_ZZZZ1 (aligned_virt)__auto_type _v1 = (aligned_virt) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, aligned_size) = (aligned_size) + 0)(__auto_type _v2 = (aligned_size) + 0)(aligned_size)_ZZZZ2 (aligned_size)__auto_type _v2 = (aligned_size) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, addr_offset) = (addr_offset) + 0)(__auto_type _v3 = (addr_offset) + 0)(addr_offset)_ZZZZ3 (addr_offset)__auto_type _v3 = (addr_offset) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)"arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "arch_mem_unmap(0x%lx, %zu) offset %lu";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)_,"arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "arch_mem_unmap(0x%lx, %zu) offset %lu";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "arch_mem_unmap(0x%lx, %zu) offset %lu";)NUM_VA_ARGS_LESS_1("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))( bool can_simple = LOG_MSG_SIMPLE_CHECK("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_unmap(0x%lx, %zu) offset %lu", aligned_virt, aligned_size, addr_offset)))("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3)(COND_CODE_0(NUM_VA_ARGS_LESS_1("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))))(_fmt, GET_ARGS_LESS_N(1, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3); )( z_log_msg_simple_create_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3)))(z_log_msg_simple_create_0(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu"))(COND_CODE_1(3, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3, dummy) )( z_log_msg_simple_create_1(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3, dummy"arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3, dummy, dummy_XXXX3 ( z_log_msg_simple_create_1(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ3 (z_log_msg_simple_create_0(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "arch_mem_unmap(0x%lx, %zu) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3))REVERSE_ARGS("arch_mem_unmap(0x%lx, %zu) offset %lu" , _v1 , _v2 , _v3)_v3 , _v2 , _v1 , "arch_mem_unmap(0x%lx, %zu) offset %lu"_v2 , _v1 , "arch_mem_unmap(0x%lx, %zu) offset %lu"_v1 , "arch_mem_unmap(0x%lx, %zu) offset %lu"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("arch_mem_unmap(0x%lx, %zu) offset %lu") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0, long double : 1, default : 0) && !0)_Generic(("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0))_Generic(("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("arch_mem_unmap(0x%lx, %zu) offset %lu") + 0))%c: arch_mem_unmap(0x%lx, %zu) offset %lu
char[43]arch_mem_unmap(0x%lx, %zu) offset %luchar[38]aligned_physalign_boundarydest_addrnum_bits!(flags & K_MEM_DIRECT_MAP)"The direct-map is not enabled"aligned_phys < (aligned_phys + (aligned_size - 1))"wraparound for physical address 0x%lx (size %zu)"aligned_phys, aligned_sizeCONFIG_KERNEL_DIRECT_MAP_XXXXCONFIG_KERNEL_DIRECT_MAP_XXXXCONFIG_KERNEL_DIRECT_MAP 1((uint8_t *)0x0)dest_addr + aligned_size(((uint8_t *)0x0) + ((size_t)0x800000))adjusted_startadjusted_endadjusted_szsys_bitarray_t *sys_bitarray *(uintptr_t)dest_addr < ((uintptr_t)dest_addr + (size - 1))"wraparound for virtual address %p (size %zu)"dest_addr, size"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"dest_addr, aligned_phys, aligned_size, flags, addr_offsetZ_LOG_STR(4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)(Z_LOG_STR_WITH_PREFIX("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))("%s: " "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (const char *)__func__ , dest_addr, aligned_phys, aligned_size, flags, addr_offset)("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)NUM_VA_ARGS_LESS_1(_,"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)(Z_LOG_STR_WITH_PREFIX2("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))_,"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset5, 4, 3, 2, 1, 0, ~NUM_VA_ARGS_LESS_1("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)(, GET_ARGS_LESS_N(1, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))(, dest_addr, aligned_phys, aligned_size, flags, addr_offset)4, 3, 2, 1, 0, ~, dest_addr, aligned_phys, aligned_size, flags, addr_offset_ZZZZ6 ("%s", (const char *)__func__)"%s: " "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (const char *)__func__ , dest_addr, aligned_phys, aligned_size, flags, addr_offset_XXXX0 ("%s: " "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (const char *)__func__ , dest_addr, aligned_phys, aligned_size, flags, addr_offset)REVERSE_ARGS("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)addr_offset , flags , aligned_size , aligned_phys , dest_addr , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"Z_FOR_LOOP_5, Z_FOR_LOOP_4, Z_FOR_LOOP_3, Z_FOR_LOOP_2, Z_FOR_LOOP_1, Z_FOR_LOOP_0aligned_phys, aligned_size, flags, addr_offsetaligned_size, flags, addr_offsetflags, addr_offsetflags , aligned_size , aligned_phys , dest_addr , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"aligned_size , aligned_phys , dest_addr , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"aligned_phys , dest_addr , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"dest_addr , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") = ("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0)(__auto_type "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" = ("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0)("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, dest_addr) = (dest_addr) + 0)(__auto_type _v1 = (dest_addr) + 0)(dest_addr)_ZZZZ1 (dest_addr)__auto_type _v1 = (dest_addr) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, aligned_phys) = (aligned_phys) + 0)(__auto_type _v2 = (aligned_phys) + 0)(aligned_phys)_ZZZZ2 (aligned_phys)__auto_type _v2 = (aligned_phys) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, aligned_size) = (aligned_size) + 0)(__auto_type _v3 = (aligned_size) + 0)_ZZZZ3 (aligned_size)__auto_type _v3 = (aligned_size) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(4, flags) = (flags) + 0)(__auto_type _v4 = (flags) + 0)(flags)_ZZZZ4 (flags)__auto_type _v4 = (flags) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(5, addr_offset) = (addr_offset) + 0)(__auto_type _v5 = (addr_offset) + 0)_ZZZZ5 (addr_offset)__auto_type _v5 = (addr_offset) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)_,"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5_v1 , _v2 , _v3 , _v4 , _v5_ZZZZ6 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu";)NUM_VA_ARGS_LESS_1("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS(_v1 , _v2 , _v3 , _v4 , _v5)Z_FOR_LOOP_4, Z_FOR_LOOP_3, Z_FOR_LOOP_2, Z_FOR_LOOP_1, Z_FOR_LOOP_0_v2 , _v3 , _v4 , _v5_v3 , _v4 , _v5_v4 , _v5_ZZZZ5 (0)((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))( bool can_simple = LOG_MSG_SIMPLE_CHECK("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_5("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))_LOG_MSG_SIMPLE_XXXX5_XXXX_LOG_MSG_SIMPLE_XXXX5_XXXX_LOG_MSG_SIMPLE_XXXX5 (1)_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_5("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", dest_addr, aligned_phys, aligned_size, flags, addr_offset)))("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5)(COND_CODE_0(NUM_VA_ARGS_LESS_1("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))))(_fmt, _v1 , _v2 , _v3 , _v4 , _v5)(_fmt, GET_ARGS_LESS_N(1, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))_ZZZZ5 (_fmt)_fmt, _v1 , _v2 , _v3 , _v4 , _v5_XXXXCONFIG_LOG_FMT_SECTION (_fmt, _v1 , _v2 , _v3 , _v4 , _v5)_ZZZZ6 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5); )( z_log_msg_simple_create_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5)))(z_log_msg_simple_create_0(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"))(COND_CODE_1(5, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5, dummy) )( z_log_msg_simple_create_1(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5, dummy_v1 , _v2 , _v3 , _v4 , _v5, dummy_v2 , _v3 , _v4 , _v5, dummy"arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5, dummy, dummy_v1 , _v2 , _v3 , _v4 , _v5, dummy, dummy_v2 , _v3 , _v4 , _v5, dummy, dummy_v3 , _v4 , _v5, dummy, dummy_XXXX5_XXXX5 ( z_log_msg_simple_create_1(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ5 (z_log_msg_simple_create_0(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))REVERSE_ARGS("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu" , _v1 , _v2 , _v3 , _v4 , _v5)_v5 , _v4 , _v3 , _v2 , _v1 , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"_v4 , _v3 , _v2 , _v1 , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"_v3 , _v2 , _v1 , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"_v2 , _v1 , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"_v1 , "arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0, long double : 1, default : 0) && !0)_Generic(("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0))_Generic(("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu") + 0))%c: arch_mem_map(%p, 0x%lx, %zu, %x) offset %lu
arch_mem_map(%p, 0x%lx, %zu, %x) offset %lufail"memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags"memory mapping 0x%lx (size %zu, flags 0x%x) failed"phys, size, flagsZ_LOG_STR(1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)(Z_LOG_STR_WITH_PREFIX("memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))("%s: " "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (const char *)__func__ , phys, size, flags)("memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)NUM_VA_ARGS_LESS_1(_,"memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)(Z_LOG_STR_WITH_PREFIX2("memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))_,"memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flagsNUM_VA_ARGS_LESS_1("memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)(, GET_ARGS_LESS_N(1, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))(, phys, size, flags), phys, size, flags"%s: " "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (const char *)__func__ , phys, size, flags_XXXX0 ("%s: " "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (const char *)__func__ , phys, size, flags)REVERSE_ARGS("memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)flags , size , phys , "memory mapping 0x%lx (size %zu, flags 0x%x) failed"size, flagssize , phys , "memory mapping 0x%lx (size %zu, flags 0x%x) failed"phys , "memory mapping 0x%lx (size %zu, flags 0x%x) failed"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "memory mapping 0x%lx (size %zu, flags 0x%x) failed") = ("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0)(__auto_type "memory mapping 0x%lx (size %zu, flags 0x%x) failed" = ("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0)("memory mapping 0x%lx (size %zu, flags 0x%x) failed")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, phys) = (phys) + 0)(__auto_type _v1 = (phys) + 0)(phys)_ZZZZ1 (phys)__auto_type _v1 = (phys) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, size) = (size) + 0)(__auto_type _v2 = (size) + 0)_ZZZZ2 (size)__auto_type _v2 = (size) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, flags) = (flags) + 0)(__auto_type _v3 = (flags) + 0)_ZZZZ3 (flags)__auto_type _v3 = (flags) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)"memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "memory mapping 0x%lx (size %zu, flags 0x%x) failed";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)_,"memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "memory mapping 0x%lx (size %zu, flags 0x%x) failed";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "memory mapping 0x%lx (size %zu, flags 0x%x) failed";)NUM_VA_ARGS_LESS_1("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))( bool can_simple = LOG_MSG_SIMPLE_CHECK("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping 0x%lx (size %zu, flags 0x%x) failed", phys, size, flags)))("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3)(COND_CODE_0(NUM_VA_ARGS_LESS_1("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))))(_fmt, GET_ARGS_LESS_N(1, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3); )( z_log_msg_simple_create_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3)))(z_log_msg_simple_create_0(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed"))(COND_CODE_1(3, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3, dummy) )( z_log_msg_simple_create_1(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3, dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3, dummy"memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3, dummy, dummy_XXXX3 ( z_log_msg_simple_create_1(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ3 (z_log_msg_simple_create_0(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed"))_XXXX0 ( z_log_msg_simple_create_2(_src, 1U, "memory mapping 0x%lx (size %zu, flags 0x%x) failed", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3))REVERSE_ARGS("memory mapping 0x%lx (size %zu, flags 0x%x) failed" , _v1 , _v2 , _v3)_v3 , _v2 , _v1 , "memory mapping 0x%lx (size %zu, flags 0x%x) failed"_v2 , _v1 , "memory mapping 0x%lx (size %zu, flags 0x%x) failed"_v1 , "memory mapping 0x%lx (size %zu, flags 0x%x) failed"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("memory mapping 0x%lx (size %zu, flags 0x%x) failed") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0, long double : 1, default : 0) && !0)_Generic(("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0))_Generic(("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("memory mapping 0x%lx (size %zu, flags 0x%x) failed") + 0))%c: memory mapping 0x%lx (size %zu, flags 0x%x) failed
char[56]memory mapping 0x%lx (size %zu, flags 0x%x) failedchar[51]arch_virt_region_alignvirt_region_alignpage_frames_initialized"%s called too early"(size_t)CONFIG_MMU_PAGE_SIZEtotal_sizePOINTER_TO_UINT(addr) >= CONFIG_MMU_PAGE_SIZE(CONFIG_MMU_PAGE_SIZE * 2)"%s: cannot find preceding guard page for (%p, %zu)"__func__, addr, size"%s: cannot find succeeding guard page for (%p, %zu)""%s: cannot unmap an unmapped address %p"__func__, pos"%s: 0x%lx is not a page frame"__func__, physz_page_frame_is_mapped(pf)"%s: 0x%lx is not a mapped page frame"!(((flags & K_MEM_PERM_USER) != 0U) && ((flags & K_MEM_MAP_UNINIT) != 0U))"user access to anonymous uninitialized pages is forbidden""unaligned size %zu passed to %s"size, __func__size != 0"zero sized memory mapping"(flags & K_MEM_CACHE_MASK) == 0U"%s does not support explicit cache settings"map_anon_page131072uninit"memory mapping anon page %p -> 0x%lx", addr, phys"memory mapping anon page %p -> 0x%lx"addr, physZ_LOG_STR(4U, "memory mapping anon page %p -> 0x%lx", addr, phys)(Z_LOG_STR_WITH_PREFIX("memory mapping anon page %p -> 0x%lx", addr, phys))("%s: " "memory mapping anon page %p -> 0x%lx", (const char *)__func__ , addr, phys)("memory mapping anon page %p -> 0x%lx", addr, phys)NUM_VA_ARGS_LESS_1(_,"memory mapping anon page %p -> 0x%lx", addr, phys)(Z_LOG_STR_WITH_PREFIX2("memory mapping anon page %p -> 0x%lx", addr, phys))_,"memory mapping anon page %p -> 0x%lx", addr, physNUM_VA_ARGS_LESS_1("memory mapping anon page %p -> 0x%lx", addr, phys)(, GET_ARGS_LESS_N(1, "memory mapping anon page %p -> 0x%lx", addr, phys))(, addr, phys), addr, phys"%s: " "memory mapping anon page %p -> 0x%lx", (const char *)__func__ , addr, phys_XXXX0 ("%s: " "memory mapping anon page %p -> 0x%lx", (const char *)__func__ , addr, phys)REVERSE_ARGS("memory mapping anon page %p -> 0x%lx", addr, phys)phys , addr , "memory mapping anon page %p -> 0x%lx"addr , "memory mapping anon page %p -> 0x%lx"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "memory mapping anon page %p -> 0x%lx") = ("memory mapping anon page %p -> 0x%lx") + 0)(__auto_type "memory mapping anon page %p -> 0x%lx" = ("memory mapping anon page %p -> 0x%lx") + 0)("memory mapping anon page %p -> 0x%lx")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, addr) = (addr) + 0)(__auto_type _v1 = (addr) + 0)(addr)_ZZZZ1 (addr)__auto_type _v1 = (addr) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, phys) = (phys) + 0)(__auto_type _v2 = (phys) + 0)_ZZZZ2 (phys)__auto_type _v2 = (phys) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys)"memory mapping anon page %p -> 0x%lx" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "memory mapping anon page %p -> 0x%lx";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys)_,"memory mapping anon page %p -> 0x%lx" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "memory mapping anon page %p -> 0x%lx";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "memory mapping anon page %p -> 0x%lx";)NUM_VA_ARGS_LESS_1("memory mapping anon page %p -> 0x%lx" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "memory mapping anon page %p -> 0x%lx" , _v1 , _v2))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys))( bool can_simple = LOG_MSG_SIMPLE_CHECK("memory mapping anon page %p -> 0x%lx" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("memory mapping anon page %p -> 0x%lx" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("memory mapping anon page %p -> 0x%lx" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("memory mapping anon page %p -> 0x%lx" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("memory mapping anon page %p -> 0x%lx" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("memory mapping anon page %p -> 0x%lx" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "memory mapping anon page %p -> 0x%lx", addr, phys)))("memory mapping anon page %p -> 0x%lx" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("memory mapping anon page %p -> 0x%lx" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 4U, "memory mapping anon page %p -> 0x%lx"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"memory mapping anon page %p -> 0x%lx" , _v1 , _v2, dummy"memory mapping anon page %p -> 0x%lx" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 4U, "memory mapping anon page %p -> 0x%lx"))z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "memory mapping anon page %p -> 0x%lx", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "memory mapping anon page %p -> 0x%lx" , _v1 , _v2))REVERSE_ARGS("memory mapping anon page %p -> 0x%lx" , _v1 , _v2)_v2 , _v1 , "memory mapping anon page %p -> 0x%lx"_v1 , "memory mapping anon page %p -> 0x%lx"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("memory mapping anon page %p -> 0x%lx") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("memory mapping anon page %p -> 0x%lx") + 0, long double : 1, default : 0) && !0)_Generic(("memory mapping anon page %p -> 0x%lx") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("memory mapping anon page %p -> 0x%lx") + 0))_Generic(("memory mapping anon page %p -> 0x%lx") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("memory mapping anon page %p -> 0x%lx") + 0))%c: memory mapping anon page %p -> 0x%lx
char[42]memory mapping anon page %p -> 0x%lxchar[37]frame_mapped_set!z_page_frame_is_reserved(pf)"attempted to map a reserved page frame""page frame 0x%lx: " "attempted to map a reserved page frame"z_page_frame_to_phys(pf)!z_page_frame_is_mapped(pf) || z_page_frame_is_pinned(pf)"non-pinned and already mapped to %p"pf->addr"page frame 0x%lx: " "non-pinned and already mapped to %p"z_page_frame_to_phys(pf),pf->addrpage_frame_free_lockedfree_page_frame_list_initfree_page_frame_list_putz_page_frame_is_available(pf)"unavailable page put on free list""page frame 0x%lx: " "unavailable page put on free list"free_page_frame_list_getstruct z_page_frameSAME_TYPE(*(node), ((struct z_page_frame *)0)->node) || SAME_TYPE(*(node), void)__builtin_types_compatible_p(__typeof__(*(node)), __typeof__(((struct z_page_frame *)0)->node)) || __builtin_types_compatible_p(__typeof__(*(node)), __typeof__(void))*(node)((struct z_page_frame *)0)->node"unavailable but somehow on free list""page frame 0x%lx: " "unavailable but somehow on free list"virt_region_allocalloc_size!virt_region_inited"insufficient virtual address space (requested %zu)", size"insufficient virtual address space (requested %zu)"Z_LOG_STR(1U, "insufficient virtual address space (requested %zu)", size)(Z_LOG_STR_WITH_PREFIX("insufficient virtual address space (requested %zu)", size))("%s: " "insufficient virtual address space (requested %zu)", (const char *)__func__ , size)("insufficient virtual address space (requested %zu)", size)NUM_VA_ARGS_LESS_1(_,"insufficient virtual address space (requested %zu)", size)(Z_LOG_STR_WITH_PREFIX2("insufficient virtual address space (requested %zu)", size))_,"insufficient virtual address space (requested %zu)", sizeNUM_VA_ARGS_LESS_1("insufficient virtual address space (requested %zu)", size)(, GET_ARGS_LESS_N(1, "insufficient virtual address space (requested %zu)", size))(, size), size"%s: " "insufficient virtual address space (requested %zu)", (const char *)__func__ , size_XXXX0 ("%s: " "insufficient virtual address space (requested %zu)", (const char *)__func__ , size)REVERSE_ARGS("insufficient virtual address space (requested %zu)", size)size , "insufficient virtual address space (requested %zu)"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "insufficient virtual address space (requested %zu)") = ("insufficient virtual address space (requested %zu)") + 0)(__auto_type "insufficient virtual address space (requested %zu)" = ("insufficient virtual address space (requested %zu)") + 0)("insufficient virtual address space (requested %zu)")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, size) = (size) + 0)(__auto_type _v1 = (size) + 0)_ZZZZ1 (size)__auto_type _v1 = (size) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size)"insufficient virtual address space (requested %zu)" , _v1(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "insufficient virtual address space (requested %zu)";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "insufficient virtual address space (requested %zu)" , _v1);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size)_,"insufficient virtual address space (requested %zu)" , _v1static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "insufficient virtual address space (requested %zu)";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "insufficient virtual address space (requested %zu)";)NUM_VA_ARGS_LESS_1("insufficient virtual address space (requested %zu)" , _v1)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "insufficient virtual address space (requested %zu)" , _v1))0, 0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size))( bool can_simple = LOG_MSG_SIMPLE_CHECK("insufficient virtual address space (requested %zu)" , _v1); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 1U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("insufficient virtual address space (requested %zu)" , _v1), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("insufficient virtual address space (requested %zu)" , _v1)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("insufficient virtual address space (requested %zu)" , _v1)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("insufficient virtual address space (requested %zu)" , _v1))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("insufficient virtual address space (requested %zu)" , _v1))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "insufficient virtual address space (requested %zu)", size)))("insufficient virtual address space (requested %zu)" , _v1)(COND_CODE_0(NUM_VA_ARGS_LESS_1("insufficient virtual address space (requested %zu)" , _v1), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "insufficient virtual address space (requested %zu)" , _v1))))(_fmt, GET_ARGS_LESS_N(1, "insufficient virtual address space (requested %zu)" , _v1))( LOG_MSG_SIMPLE_FUNC(_src, 1U, "insufficient virtual address space (requested %zu)" , _v1); )( z_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1); )(z_log_msg_simple_create_0(_src, 1U, GET_ARG_N(1, "insufficient virtual address space (requested %zu)" , _v1)))(z_log_msg_simple_create_0(_src, 1U, "insufficient virtual address space (requested %zu)"))(COND_CODE_1(1, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "insufficient virtual address space (requested %zu)" , _v1, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "insufficient virtual address space (requested %zu)" , _v1, dummy, dummy) ) ))(z_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 1U, "insufficient virtual address space (requested %zu)" , _v1, dummy) )( z_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 1U, "insufficient virtual address space (requested %zu)" , _v1, dummy, dummy) )( z_log_msg_simple_create_2(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)dummy) )"insufficient virtual address space (requested %zu)" , _v1, dummy"insufficient virtual address space (requested %zu)" , _v1, dummy, dummyz_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1)_ZZZZ1 (z_log_msg_simple_create_0(_src, 1U, "insufficient virtual address space (requested %zu)"))z_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 1U, "insufficient virtual address space (requested %zu)", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "insufficient virtual address space (requested %zu)" , _v1))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "insufficient virtual address space (requested %zu)" , _v1))REVERSE_ARGS("insufficient virtual address space (requested %zu)" , _v1)_v1 , "insufficient virtual address space (requested %zu)"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("insufficient virtual address space (requested %zu)") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("insufficient virtual address space (requested %zu)") + 0, long double : 1, default : 0) && !0)_Generic(("insufficient virtual address space (requested %zu)") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("insufficient virtual address space (requested %zu)") + 0))_Generic(("insufficient virtual address space (requested %zu)") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("insufficient virtual address space (requested %zu)") + 0))%c: insufficient virtual address space (requested %zu)
insufficient virtual address space (requested %zu)aligned_dest_addr + sizealigned_dest_addrZ_VIRT_REGION_START_ADDRvirt_region_freevaddr_u8(vaddr_u8 >= Z_VIRT_REGION_START_ADDR) && ((vaddr_u8 + size - 1) < Z_VIRT_REGION_END_ADDR)vaddr_u8, sizevirt_region_initPOINTER_TO_UINT(Z_VIRT_RAM_START)virt_to_bitmap_offsetvaddrPOINTER_TO_UINT(Z_VIRT_RAM_END)virt_from_bitmap_offsetcolumnPhysical memory from 0x%lx to 0x%lx
"Physical memory from 0x%lx to 0x%lx\n"
"\n"char[2]DEFAULTANSI_[0mpage_frame_dumpCYANMAGENTAYELLOWGREYRED[1;36mR"R"[1;35mB"B"[1;33mP"P"[1;90m."."M"M"[1;31m?"?"virt_to_page_framepaddrfree_page_frame_listvirt_region_initedvirt_region_bitmapCONFIG_KERNEL_VM_SIZE / CONFIG_MMU_PAGE_SIZE0x800000 / 0x1000DIV_ROUND_UP(0x800000 / 0x1000, 8)(((0x800000 / 0x1000) + (8) - 1) / (8))sizeof(uint32_t)uint32_t[64]unsigned int[64]_sys_bitarray_bundles_virt_region_bitmapz_mm_lockPF_ASSERT(pf,expr,fmt,__VA_ARGS__...)__ASSERT(expr, "page frame 0x%lx: " fmt, z_page_frame_to_phys(pf), ## __VA_ARGS__)Z_VIRT_REGION_END_ADDR(Z_VIRT_RAM_END - Z_VM_RESERVED)PHYS_FOREACH(_base,_size,_pos)for (_pos = _base; _pos < ((uintptr_t)_base + _size); _pos += CONFIG_MMU_PAGE_SIZE)VIRT_FOREACH(_base,_size,_pos)for (_pos = _base; _pos < ((uint8_t *)_base + _size); _pos += CONFIG_MMU_PAGE_SIZE)COLOR(x)printk(_CONCAT(ANSI_, x))ANSI_GREY"\x1B" "[1;90m"ANSI_CYAN"\x1B" "[1;36m"ANSI_MAGENTA"\x1B" "[1;35m"ANSI_BLUE"\x1B" "[1;34m"ANSI_YELLOW"\x1B" "[1;33m"ANSI_GREEN"\x1B" "[1;32m"ANSI_RED"\x1B" "[1;31m"ANSI_DEFAULT"\x1B" "[0m"COLOR_PAGE_FRAMESdefined(CONFIG_LINKER_USE_BOOT_SECTION) || defined(CONFIG_LINKER_USE_PINNED_SECTION)CONFIG_DEMAND_PAGING_STATS_USING_TIMING_FUNCTIONS/* CONFIG_DEMAND_PAGING_ALLOW_IRQ *//* Interrupts are now unlocked if they were not locked when we entered
	 * this function, and we may service ISRs. The scheduler is still
	 * locked.
	 *//* Need to evict a page frame *//* This if-block is to pin the page if it is
		 * already present in physical memory. There is
		 * no need to go through the following code to
		 * pull in the data pages. So skip to the end.
		 *//* It's a physical memory address *//* Return false to treat as a fatal error *//* We lock the scheduler so that other threads are never scheduled
	 * during the page-in/out operation.
	 *
	 * We do however re-enable interrupts during the page-in/page-out
	 * operation iff interrupts were enabled when the exception was taken;
	 * in this configuration page faults in an ISR are a bug; all their
	 * code/data must be pinned.
	 *
	 * If interrupts were disabled when the exception was taken, the
	 * arch code is responsible for keeping them that way when entering
	 * this function.
	 *
	 * If this is not enabled, then interrupts are always locked for the
	 * entire operation. This is far worse for system interrupt latency
	 * but requires less pinned pages and ISRs may also take page faults.
	 *
	 * Support for allowing k_mem_paging_backing_store_page_out() and
	 * k_mem_paging_backing_store_page_in() to also sleep and allow
	 * other threads to run (such as in the case where the transfer is
	 * async DMA) is not implemented. Even if limited to thread context,
	 * arbitrary memory access triggering exceptions that put a thread to
	 * sleep on a contended page fault operation will break scheduling
	 * assumptions of cooperative threads or threads that implement
	 * crticial sections with spinlocks or disabling IRQs.
	 *//*
	 * TODO: Add performance accounting:
	 * - k_mem_paging_eviction_select() metrics
	 *   * periodic timer execution time histogram (if implemented)
	 *//* CONFIG_DEMAND_PAGING_STATS_USING_TIMING_FUNCTIONS *//* CONFIG_DEMAND_PAGING_THREAD_STATS *//* Shouldn't ever happen *//* Nothing to do, free page *//* Implementation is similar to do_page_fault() except there is no
	 * data page to page-in, see comments in that function.
	 *//* Un-mapped or already evicted. Nothing to do *//* Update dirty parameter, since we set to true if it wasn't backed
	 * even if otherwise clean
	 *//* Mark as busy so that z_page_frame_is_evictable() returns false *//* Shouldn't happen unless this function is mis-used *//* If the backing store doesn't have a copy of the page, even if it
	 * wasn't modified, treat as dirty. This can happen for a few
	 * reasons:
	 * 1) Page has never been swapped out before, and the backing store
	 *    wasn't pre-populated with this data page.
	 * 2) Page was swapped out before, but the page contents were not
	 *    preserved after swapping back in.
	 * 3) Page contents were preserved when swapped back in, but were later
	 *    evicted from the backing store to make room for other evicted
	 *    pages.
	 *//*
 * Perform some preparatory steps before paging out. The provided page frame
 * must be evicted to the backing store immediately after this is called
 * with a call to k_mem_paging_backing_store_page_out() if it contains
 * a data page.
 *
 * - Map page frame to scratch area if requested. This always is true if we're
 *   doing a page fault, but is only set on manual evictions if the page is
 *   dirty.
 * - If mapped:
 *    - obtain backing store location and populate location parameter
 *    - Update page tables with location
 * - Mark page frame as busy
 *
 * Returns -ENOMEM if the backing store is full
 *//* Current implementation relies on interrupt locking to any prevent page table
 * access, which falls over if other CPUs are active. Addressing this is not
 * as simple as using spinlocks as regular memory reads/writes constitute
 * "access" in this sense.
 *
 * Current needs for demand paging are on uniprocessor systems.
 *//* At the end of boot process, unpin the boot sections
	 * as they don't need to be in memory all the time anymore.
	 *//* If BSS section is not present in memory at boot,
	 * it would not have been cleared. This needs to be
	 * done now since paging mechanism has been initialized
	 * and the BSS pages can be brought into physical
	 * memory to be cleared.
	 *//* Any remaining pages that aren't mapped, reserved, or pinned get
	 * added to the free pages list
	 *//* Pin the page frames correspondng to the pinned symbols *//* Pin the boot section to prevent it from being swapped out during
	 * boot process. Will be un-pinned once boot process completes.
	 *//* CONFIG_LINKER_GENERIC_SECTIONS_PRESENT_AT_BOOT *//* TODO: for now we pin the whole Zephyr image. Demand paging
		 * currently tested with anonymously-mapped pages which are not
		 * pinned.
		 *
		 * We will need to setup linker regions for a subset of kernel
		 * code/data pages which are pinned in memory and
		 * may not be evicted. This will contain critical CPU data
		 * structures, and any code used to perform page fault
		 * handling, page-ins, etc.
		 *//* All pages composing the Zephyr image are mapped at boot in a
	 * predictable way. This can change at runtime.
	 *//* If some page frames are unavailable for use as memory, arch
	 * code will mark Z_PAGE_FRAME_RESERVED in their flags
	 *//* CONFIG_LINKER_USE_BOOT_SECTION) || CONFIG_LINKER_USE_PINNED_SECTION *//* The actual mapped region must be page-aligned. Round down the
	 * physical address and pad the region size appropriately
	 *//*
 * Miscellaneous
 *//* May re-visit this in the future, but for now running out of
	 * virtual address space or failing the arch_mem_map() call is
	 * an unrecoverable situation.
	 *
	 * Other problems not related to resource exhaustion we leave as
	 * assertions since they are clearly programming mistakes.
	 *//* If this fails there's something amiss with virt_region_get *//* Obtain an appropriately sized chunk of virtual memory *//* Mark the region of virtual memory bitmap as used
		 * if the region overlaps the virtual memory space.
		 *
		 * Basically if either end of region is within
		 * virtual memory space, we need to mark the bits.
		 *//* This may be called from arch early boot code before z_cstart() is invoked.
 * Data will be copied and BSS zeroed, but this must not rely on any
 * initialization functions being called prior to work correctly.
 *//* Get the default virtual region alignment, here the default MMU page size
 *
 * @param[in] phys Physical address of region to be mapped, aligned to MMU_PAGE_SIZE
 * @param[in] size Size of region to be mapped, aligned to MMU_PAGE_SIZE
 *
 * @retval alignment to apply on the virtual address of this region
 *//* There are guard pages just before and after the mapped
	 * region. So we also need to free them from the bitmap.
	 *//* Put the page frame back into free list *//* Page frame is not marked mapped.
			 * This should not happen. Do not continue.
			 *//* Grab the corresponding page frame from physical address *//* Physical address has no corresponding page frame
			 * description in the page frame array.
			 * This should not happen. Do not continue.
			 *//* Found an address not mapped. Do not continue. *//* Check if both guard pages are unmapped.
	 * Bail if not, as this is probably a region not mapped
	 * using k_mem_map().
	 *//* Make sure address range is still valid after accounting
	 * for two guard pages.
	 *//* Need space for the "before" guard page *//* TODO: call k_mem_unmap(dst, pos - dst)  when
			 * implemented in #28990 and release any guard virtual
			 * page as well.
			 *//* Skip over the "before" guard page in returned address. *//* Unmap both guard pages to make sure accessing them
	 * will generate fault.
	 *//* Address space has no free region *//* Need extra for the guard pages (before and after) which we
	 * won't map.
	 *//* If we later implement mappings to a copy-on-write
		 * zero page, won't need this step
		 *//* Allocate a free page frame, and map it to a specified virtual address
 *
 * TODO: Add optional support for copy-on-write mappings to a zero page instead
 * of allocating, in which case page frames will be allocated lazily as
 * the mappings to the zero page get touched. This will avoid expensive
 * page-ins as memory is mapped and physical RAM or backing store storage will
 * not be used if the mapped memory is unused. The cost is an empty physical
 * page of zeroes.
 *//* Go through page frames to find the physical address mapped
 * by a virtual address.
 *
 * @param[in]  virt Virtual Address
 * @param[out] phys Physical address mapped to the input virtual address
 *                  if such mapping exists.
 *
 * @retval 0 if mapping is found and valid
 * @retval -EFAULT if virtual address is not mapped
 *//* We do allow multiple mappings for pinned page frames
	 * since we will never need to reverse map them.
	 * This is uncommon, use-cases are for things like the
	 * Zephyr equivalent of VSDOs
	 *//* Called after the frame is mapped in the arch layer, to update our
 * local ontology (and do some assertions while we're at it)
 *//*
 * Memory Mapping
 *//* The structure is packed, which ensures that this is true *//* Release a page frame back into the list of free pages *//* Get an unused page frame. don't care which one, or NULL if there are none *//* Number of unused and available free page frames *//* Linked list of unused and available page frames.
 *
 * TODO: This is very simple and treats all free page frames as being equal.
 * However, there are use-cases to consolidate free pages such that entire
 * SRAM banks can be switched off to save power, and so obtaining free pages
 * may require a more complex ontology which prefers page frames in RAM banks
 * which are still active.
 *
 * This implies in the future there may be multiple slists managing physical
 * pages. Each page frame will still just have one snode link.
 *//*
 * Free page frames management
 *
 * Call all of these functions with z_mm_lock held.
 *//* Need to make sure this does not step into kernel memory *//* Free the two unused regions *//* Here is the memory organization when trying to get an aligned
		 * virtual address:
		 *
		 * +--------------+ <- Z_VIRT_RAM_START
		 * | Undefined VM |
		 * +--------------+ <- Z_KERNEL_VIRT_START (often == Z_VIRT_RAM_START)
		 * | Mapping for  |
		 * | main kernel  |
		 * | image        |
		 * |		  |
		 * |		  |
		 * +--------------+ <- Z_FREE_VM_START
		 * | ...          |
		 * +==============+ <- dest_addr
		 * | Unused       |
		 * |..............| <- aligned_dest_addr
		 * |              |
		 * | Aligned      |
		 * | Mapping      |
		 * |              |
		 * |..............| <- aligned_dest_addr + size
		 * | Unused       |
		 * +==============+ <- offset from Z_VIRT_RAM_END == dest_addr + alloc_size
		 * | ...          |
		 * +--------------+
		 * | Mapping      |
		 * +--------------+
		 * | Reserved     |
		 * +--------------+ <- Z_VIRT_RAM_END
		 *//* Remember that bit #0 in bitmap corresponds to the highest
	 * virtual address. So here we need to go downwards (backwards?)
	 * to get the starting address of the allocated region.
	 *//* Possibly request more pages to ensure we can get an aligned virtual address *//* !CONFIG_KERNEL_DIRECT_MAP *//* With K_DIRECT_MAP, the region can be outside of the virtual
	 * memory space, wholly within it, or overlap partially.
	 * So additional processing is needed to make sure we only
	 * mark the pages within the bitmap.
	 *//* Without the need to support K_DIRECT_MAP, the region must be
	 * able to be represented in the bitmap. So this case is
	 * simple.
	 *//* Mark all bits up to Z_FREE_VM_START as allocated *//* Mark reserved region at end of virtual address space *//* There are regions where we should never map via
	 * k_mem_map() and z_phys_map(). Mark them as
	 * already allocated so they will never be used.
	 *//* Bitmap of virtual addresses where one bit corresponds to one page.
 * This is being used for virt_region_alloc() to figure out which
 * region of virtual addresses can be used for memory mapping.
 *
 * Note that bit #0 is the highest address so that allocation is
 * done in reverse from highest address.
 *//*
 * Virtual address space management
 *
 * Call all of these functions with z_mm_lock held.
 *
 * Overall virtual memory map: When the kernel starts, it resides in
 * virtual memory in the region Z_KERNEL_VIRT_START to
 * Z_KERNEL_VIRT_END. Unused virtual memory past this, up to the limit
 * noted by CONFIG_KERNEL_VM_SIZE may be used for runtime memory mappings.
 *
 * If CONFIG_ARCH_MAPS_ALL_RAM is set, we do not just map the kernel image,
 * but have a mapping for all RAM in place. This is for special architectural
 * purposes and does not otherwise affect page frame accounting or flags;
 * the only guarantee is that such RAM mapping outside of the Zephyr image
 * won't be disturbed by subsequent memory mapping calls.
 *
 * +--------------+ <- Z_VIRT_RAM_START
 * | Undefined VM | <- May contain ancillary regions like x86_64's locore
 * +--------------+ <- Z_KERNEL_VIRT_START (often == Z_VIRT_RAM_START)
 * | Mapping for  |
 * | main kernel  |
 * | image        |
 * |		  |
 * |		  |
 * +--------------+ <- Z_FREE_VM_START
 * |              |
 * | Unused,      |
 * | Available VM |
 * |              |
 * |..............| <- mapping_pos (grows downward as more mappings are made)
 * | Mapping      |
 * +--------------+
 * | Mapping      |
 * +--------------+
 * | ...          |
 * +--------------+
 * | Mapping      |
 * +--------------+ <- mappings start here
 * | Reserved     | <- special purpose virtual page(s) of size Z_VM_RESERVED
 * +--------------+ <- Z_VIRT_RAM_END
 *//* Indicator that z_page_frames has been initialized, many of these APIs do
 * not work before POST_KERNEL
 *//* Database of all RAM page frames *//*
 * General page frame management
 *//* Spinlock to protect any globals in this file and serialize page table
 * updates in arch code
 *//*
 * General terminology:
 * - A page frame is a page-sized physical memory region in RAM. It is a
 *   container where a data page may be placed. It is always referred to by
 *   physical address. We have a convention of using uintptr_t for physical
 *   addresses. We instantiate a struct z_page_frame to store metadata for
 *   every page frame.
 *
 * - A data page is a page-sized region of data. It may exist in a page frame,
 *   or be paged out to some backing store. Its location can always be looked
 *   up in the CPU's page tables (or equivalent) by virtual address.
 *   The data type will always be void * or in some cases uint8_t * when we
 *   want to do pointer arithmetic.
 *//*
 * Copyright (c) 2020 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *
 * Routines for managing virtual address spaces
 */alias/home/haojie/zephyrproject/zephyr/kernel/msg_q.cpurge4294967261bytes_to_endbyte_offsetstart_addr + byte_offsetmsgq->msg_sizepeekmsgq->read_ptrmsgq->write_ptr >= msgq->buffer_start && msgq->write_ptr < msgq->buffer_endmsgq->write_ptrpending_thread->base.swap_datatimeout, 0cleanupz_waitq_head(&msgq->wait_q) != NULLz_waitq_head(&msgq->wait_q) != ((void *)0)~K_MSGQ_FLAG_ALLOCalloc_init/* Initialize and link statically defined message queues *//* Initialize msgq object type *//* don't wait for a message to become available *//* wrap-around is required *//* Tweak the values in case *//* check item available in start/end of ring buffer *//* take first available message from queue *//* wait for get message success or timeout *//* wake up waiting thread *//* add thread's message to queue *//* handle first thread waiting to write (if any) *//* wait for put message success, failure, or timeout *//* don't wait for message space to become available *//* CONFIG_POLL *//* put message in queue *//* give message to waiting thread *//* message queue isn't full *//**
 * @file
 * @brief Message queues.
 *//home/haojie/zephyrproject/zephyr/kernel/mutex.cnew_owner"mutexes cannot be used inside ISRs"unlockmutex->owner == NULLmutex->owner == ((void *)0)-EPERMmutex->owner != _currentmutex->owner != _kernel.cpus[0].currentmutex->lock_count > 0U"mutex %p lock_count: %d", mutex, mutex->lock_count"mutex %p lock_count: %d"mutex, mutex->lock_countZ_LOG_STR(4U, "mutex %p lock_count: %d", mutex, mutex->lock_count)(Z_LOG_STR_WITH_PREFIX("mutex %p lock_count: %d", mutex, mutex->lock_count))("%s: " "mutex %p lock_count: %d", (const char *)__func__ , mutex, mutex->lock_count)("mutex %p lock_count: %d", mutex, mutex->lock_count)NUM_VA_ARGS_LESS_1(_,"mutex %p lock_count: %d", mutex, mutex->lock_count)(Z_LOG_STR_WITH_PREFIX2("mutex %p lock_count: %d", mutex, mutex->lock_count))_,"mutex %p lock_count: %d", mutex, mutex->lock_countmutex->lock_countNUM_VA_ARGS_LESS_1("mutex %p lock_count: %d", mutex, mutex->lock_count)(, GET_ARGS_LESS_N(1, "mutex %p lock_count: %d", mutex, mutex->lock_count))(, mutex, mutex->lock_count), mutex, mutex->lock_count"%s: " "mutex %p lock_count: %d", (const char *)__func__ , mutex, mutex->lock_count_XXXX0 ("%s: " "mutex %p lock_count: %d", (const char *)__func__ , mutex, mutex->lock_count)REVERSE_ARGS("mutex %p lock_count: %d", mutex, mutex->lock_count)mutex->lock_count , mutex , "mutex %p lock_count: %d"mutex , "mutex %p lock_count: %d"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "mutex %p lock_count: %d") = ("mutex %p lock_count: %d") + 0)(__auto_type "mutex %p lock_count: %d" = ("mutex %p lock_count: %d") + 0)("mutex %p lock_count: %d")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, mutex) = (mutex) + 0)(__auto_type _v1 = (mutex) + 0)(mutex)_ZZZZ1 (mutex)__auto_type _v1 = (mutex) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, mutex->lock_count) = (mutex->lock_count) + 0)(__auto_type _v2 = (mutex->lock_count) + 0)(mutex->lock_count)_ZZZZ2 (mutex->lock_count)__auto_type _v2 = (mutex->lock_count) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count)"mutex %p lock_count: %d" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "mutex %p lock_count: %d";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "mutex %p lock_count: %d" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count)_,"mutex %p lock_count: %d" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "mutex %p lock_count: %d";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "mutex %p lock_count: %d";)NUM_VA_ARGS_LESS_1("mutex %p lock_count: %d" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "mutex %p lock_count: %d" , _v1 , _v2))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count))( bool can_simple = LOG_MSG_SIMPLE_CHECK("mutex %p lock_count: %d" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("mutex %p lock_count: %d" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("mutex %p lock_count: %d" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("mutex %p lock_count: %d" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("mutex %p lock_count: %d" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("mutex %p lock_count: %d" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "mutex %p lock_count: %d", mutex, mutex->lock_count)))("mutex %p lock_count: %d" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("mutex %p lock_count: %d" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "mutex %p lock_count: %d" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "mutex %p lock_count: %d" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "mutex %p lock_count: %d" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "mutex %p lock_count: %d" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 4U, "mutex %p lock_count: %d"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "mutex %p lock_count: %d" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "mutex %p lock_count: %d" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "mutex %p lock_count: %d" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "mutex %p lock_count: %d" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"mutex %p lock_count: %d" , _v1 , _v2, dummy"mutex %p lock_count: %d" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 4U, "mutex %p lock_count: %d"))z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "mutex %p lock_count: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "mutex %p lock_count: %d" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "mutex %p lock_count: %d" , _v1 , _v2))REVERSE_ARGS("mutex %p lock_count: %d" , _v1 , _v2)_v2 , _v1 , "mutex %p lock_count: %d"_v1 , "mutex %p lock_count: %d"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("mutex %p lock_count: %d") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("mutex %p lock_count: %d") + 0, long double : 1, default : 0) && !0)_Generic(("mutex %p lock_count: %d") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("mutex %p lock_count: %d") + 0))_Generic(("mutex %p lock_count: %d") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("mutex %p lock_count: %d") + 0))%c: mutex %p lock_count: %d
mutex %p lock_count: %dk_mutex **"new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000"new owner of mutex %p: %p (prio: %d)"mutex, new_owner, new_owner ? new_owner->base.prio : -1000Z_LOG_STR(4U, "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)(Z_LOG_STR_WITH_PREFIX("new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))("%s: " "new owner of mutex %p: %p (prio: %d)", (const char *)__func__ , mutex, new_owner, new_owner ? new_owner->base.prio : -1000)("new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)NUM_VA_ARGS_LESS_1(_,"new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)(Z_LOG_STR_WITH_PREFIX2("new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))_,"new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000new_owner ? new_owner->base.prio : -1000NUM_VA_ARGS_LESS_1("new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)(, GET_ARGS_LESS_N(1, "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))(, mutex, new_owner, new_owner ? new_owner->base.prio : -1000), mutex, new_owner, new_owner ? new_owner->base.prio : -1000"%s: " "new owner of mutex %p: %p (prio: %d)", (const char *)__func__ , mutex, new_owner, new_owner ? new_owner->base.prio : -1000_XXXX0 ("%s: " "new owner of mutex %p: %p (prio: %d)", (const char *)__func__ , mutex, new_owner, new_owner ? new_owner->base.prio : -1000)REVERSE_ARGS("new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)new_owner ? new_owner->base.prio : -1000 , new_owner , mutex , "new owner of mutex %p: %p (prio: %d)"new_owner, new_owner ? new_owner->base.prio : -1000new_owner , mutex , "new owner of mutex %p: %p (prio: %d)"mutex , "new owner of mutex %p: %p (prio: %d)"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "new owner of mutex %p: %p (prio: %d)") = ("new owner of mutex %p: %p (prio: %d)") + 0)(__auto_type "new owner of mutex %p: %p (prio: %d)" = ("new owner of mutex %p: %p (prio: %d)") + 0)("new owner of mutex %p: %p (prio: %d)")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, new_owner) = (new_owner) + 0)(__auto_type _v2 = (new_owner) + 0)(new_owner)_ZZZZ2 (new_owner)__auto_type _v2 = (new_owner) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, new_owner ? new_owner->base.prio : -1000) = (new_owner ? new_owner->base.prio : -1000) + 0)(__auto_type _v3 = (new_owner ? new_owner->base.prio : -1000) + 0)(new_owner ? new_owner->base.prio : -1000)_ZZZZ3 (new_owner ? new_owner->base.prio : -1000)__auto_type _v3 = (new_owner ? new_owner->base.prio : -1000) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)"new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "new owner of mutex %p: %p (prio: %d)";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)_,"new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "new owner of mutex %p: %p (prio: %d)";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "new owner of mutex %p: %p (prio: %d)";)NUM_VA_ARGS_LESS_1("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))( bool can_simple = LOG_MSG_SIMPLE_CHECK("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "new owner of mutex %p: %p (prio: %d)", mutex, new_owner, new_owner ? new_owner->base.prio : -1000)))("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3)(COND_CODE_0(NUM_VA_ARGS_LESS_1("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))))(_fmt, GET_ARGS_LESS_N(1, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3); )( z_log_msg_simple_create_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3)))(z_log_msg_simple_create_0(_src, 4U, "new owner of mutex %p: %p (prio: %d)"))(COND_CODE_1(3, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3, dummy) )( z_log_msg_simple_create_1(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3, dummy"new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3, dummy, dummy_XXXX3 ( z_log_msg_simple_create_1(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ3 (z_log_msg_simple_create_0(_src, 4U, "new owner of mutex %p: %p (prio: %d)"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "new owner of mutex %p: %p (prio: %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3))REVERSE_ARGS("new owner of mutex %p: %p (prio: %d)" , _v1 , _v2 , _v3)_v3 , _v2 , _v1 , "new owner of mutex %p: %p (prio: %d)"_v2 , _v1 , "new owner of mutex %p: %p (prio: %d)"_v1 , "new owner of mutex %p: %p (prio: %d)"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("new owner of mutex %p: %p (prio: %d)") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("new owner of mutex %p: %p (prio: %d)") + 0, long double : 1, default : 0) && !0)_Generic(("new owner of mutex %p: %p (prio: %d)") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("new owner of mutex %p: %p (prio: %d)") + 0))_Generic(("new owner of mutex %p: %p (prio: %d)") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("new owner of mutex %p: %p (prio: %d)") + 0))%c: new owner of mutex %p: %p (prio: %d)
-1000new owner of mutex %p: %p (prio: %d)k_mutex_unlock_returnnew_prioresched(mutex->lock_count == 0U) || (mutex->owner == _current)(mutex->lock_count == 0U) || (mutex->owner == _kernel.cpus[0].current)"%p took mutex %p, count: %d, orig prio: %d", _current, mutex, mutex->lock_count, mutex->owner_orig_prio"%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio"%p took mutex %p, count: %d, orig prio: %d"_kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prioZ_LOG_STR(4U, "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)(Z_LOG_STR_WITH_PREFIX("%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))("%s: " "%p took mutex %p, count: %d, orig prio: %d", (const char *)__func__ , _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)("%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)NUM_VA_ARGS_LESS_1(_,"%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)(Z_LOG_STR_WITH_PREFIX2("%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))_,"%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_priomutex->owner_orig_prioNUM_VA_ARGS_LESS_1("%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)(, GET_ARGS_LESS_N(1, "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))(, _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio), _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio_ZZZZ5 ("%s", (const char *)__func__)"%s: " "%p took mutex %p, count: %d, orig prio: %d", (const char *)__func__ , _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio_XXXX0 ("%s: " "%p took mutex %p, count: %d, orig prio: %d", (const char *)__func__ , _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)REVERSE_ARGS("%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)mutex->owner_orig_prio , mutex->lock_count , mutex , _kernel.cpus[0].current , "%p took mutex %p, count: %d, orig prio: %d"mutex, mutex->lock_count, mutex->owner_orig_priomutex->lock_count, mutex->owner_orig_priomutex->lock_count , mutex , _kernel.cpus[0].current , "%p took mutex %p, count: %d, orig prio: %d"mutex , _kernel.cpus[0].current , "%p took mutex %p, count: %d, orig prio: %d"_kernel.cpus[0].current , "%p took mutex %p, count: %d, orig prio: %d"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "%p took mutex %p, count: %d, orig prio: %d") = ("%p took mutex %p, count: %d, orig prio: %d") + 0)(__auto_type "%p took mutex %p, count: %d, orig prio: %d" = ("%p took mutex %p, count: %d, orig prio: %d") + 0)("%p took mutex %p, count: %d, orig prio: %d")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, _kernel.cpus[0].current) = (_kernel.cpus[0].current) + 0)(__auto_type _v1 = (_kernel.cpus[0].current) + 0)(_kernel.cpus[0].current)_ZZZZ1 (_kernel.cpus[0].current)__auto_type _v1 = (_kernel.cpus[0].current) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, mutex) = (mutex) + 0)(__auto_type _v2 = (mutex) + 0)_ZZZZ2 (mutex)__auto_type _v2 = (mutex) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, mutex->lock_count) = (mutex->lock_count) + 0)(__auto_type _v3 = (mutex->lock_count) + 0)_ZZZZ3 (mutex->lock_count)__auto_type _v3 = (mutex->lock_count) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(4, mutex->owner_orig_prio) = (mutex->owner_orig_prio) + 0)(__auto_type _v4 = (mutex->owner_orig_prio) + 0)(mutex->owner_orig_prio)_ZZZZ4 (mutex->owner_orig_prio)__auto_type _v4 = (mutex->owner_orig_prio) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)"%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p took mutex %p, count: %d, orig prio: %d";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)_,"%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4_v1 , _v2 , _v3 , _v4_ZZZZ5 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p took mutex %p, count: %d, orig prio: %d";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p took mutex %p, count: %d, orig prio: %d";)NUM_VA_ARGS_LESS_1("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS(_v1 , _v2 , _v3 , _v4)_v2 , _v3 , _v4_v3 , _v4_ZZZZ4 (0)((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))( bool can_simple = LOG_MSG_SIMPLE_CHECK("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_4("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))_LOG_MSG_SIMPLE_XXXX4_XXXX_LOG_MSG_SIMPLE_XXXX4_XXXX_LOG_MSG_SIMPLE_XXXX4 (1)_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_4("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p took mutex %p, count: %d, orig prio: %d", _kernel.cpus[0].current, mutex, mutex->lock_count, mutex->owner_orig_prio)))("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4)(COND_CODE_0(NUM_VA_ARGS_LESS_1("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))))(_fmt, _v1 , _v2 , _v3 , _v4)(_fmt, GET_ARGS_LESS_N(1, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))_ZZZZ4 (_fmt)_fmt, _v1 , _v2 , _v3 , _v4_XXXXCONFIG_LOG_FMT_SECTION (_fmt, _v1 , _v2 , _v3 , _v4)_ZZZZ5 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4); )( z_log_msg_simple_create_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4)))(z_log_msg_simple_create_0(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d"))(COND_CODE_1(4, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4, dummy) )( z_log_msg_simple_create_1(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4, dummy_v1 , _v2 , _v3 , _v4, dummy_v2 , _v3 , _v4, dummy"%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4, dummy, dummy_v1 , _v2 , _v3 , _v4, dummy, dummy_v2 , _v3 , _v4, dummy, dummy_v3 , _v4, dummy, dummy_XXXX4_XXXX4 ( z_log_msg_simple_create_1(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ4 (z_log_msg_simple_create_0(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "%p took mutex %p, count: %d, orig prio: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))REVERSE_ARGS("%p took mutex %p, count: %d, orig prio: %d" , _v1 , _v2 , _v3 , _v4)_v4 , _v3 , _v2 , _v1 , "%p took mutex %p, count: %d, orig prio: %d"_v3 , _v2 , _v1 , "%p took mutex %p, count: %d, orig prio: %d"_v2 , _v1 , "%p took mutex %p, count: %d, orig prio: %d"_v1 , "%p took mutex %p, count: %d, orig prio: %d"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("%p took mutex %p, count: %d, orig prio: %d") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("%p took mutex %p, count: %d, orig prio: %d") + 0, long double : 1, default : 0) && !0)_Generic(("%p took mutex %p, count: %d, orig prio: %d") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("%p took mutex %p, count: %d, orig prio: %d") + 0))_Generic(("%p took mutex %p, count: %d, orig prio: %d") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("%p took mutex %p, count: %d, orig prio: %d") + 0))%c: %p took mutex %p, count: %d, orig prio: %d
char[48]%p took mutex %p, count: %d, orig prio: %dK_TIMEOUT_EQ(timeout, K_NO_WAIT)((timeout).ticks == (((k_timeout_t) {0})).ticks)timeout, -EBUSY"adjusting prio up on mutex %p", mutex"adjusting prio up on mutex %p"Z_LOG_STR(4U, "adjusting prio up on mutex %p", mutex)(Z_LOG_STR_WITH_PREFIX("adjusting prio up on mutex %p", mutex))("%s: " "adjusting prio up on mutex %p", (const char *)__func__ , mutex)("adjusting prio up on mutex %p", mutex)NUM_VA_ARGS_LESS_1(_,"adjusting prio up on mutex %p", mutex)(Z_LOG_STR_WITH_PREFIX2("adjusting prio up on mutex %p", mutex))_,"adjusting prio up on mutex %p", mutexNUM_VA_ARGS_LESS_1("adjusting prio up on mutex %p", mutex)(, GET_ARGS_LESS_N(1, "adjusting prio up on mutex %p", mutex))(, mutex), mutex"%s: " "adjusting prio up on mutex %p", (const char *)__func__ , mutex_XXXX0 ("%s: " "adjusting prio up on mutex %p", (const char *)__func__ , mutex)REVERSE_ARGS("adjusting prio up on mutex %p", mutex)mutex , "adjusting prio up on mutex %p"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "adjusting prio up on mutex %p") = ("adjusting prio up on mutex %p") + 0)(__auto_type "adjusting prio up on mutex %p" = ("adjusting prio up on mutex %p") + 0)("adjusting prio up on mutex %p")FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex)"adjusting prio up on mutex %p" , _v1(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "adjusting prio up on mutex %p";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "adjusting prio up on mutex %p" , _v1);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex)_,"adjusting prio up on mutex %p" , _v1static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "adjusting prio up on mutex %p";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "adjusting prio up on mutex %p";)NUM_VA_ARGS_LESS_1("adjusting prio up on mutex %p" , _v1)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "adjusting prio up on mutex %p" , _v1))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex))( bool can_simple = LOG_MSG_SIMPLE_CHECK("adjusting prio up on mutex %p" , _v1); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("adjusting prio up on mutex %p" , _v1), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("adjusting prio up on mutex %p" , _v1)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("adjusting prio up on mutex %p" , _v1)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("adjusting prio up on mutex %p" , _v1))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("adjusting prio up on mutex %p" , _v1))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio up on mutex %p", mutex)))("adjusting prio up on mutex %p" , _v1)(COND_CODE_0(NUM_VA_ARGS_LESS_1("adjusting prio up on mutex %p" , _v1), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "adjusting prio up on mutex %p" , _v1))))(_fmt, GET_ARGS_LESS_N(1, "adjusting prio up on mutex %p" , _v1))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "adjusting prio up on mutex %p" , _v1); )( z_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "adjusting prio up on mutex %p" , _v1)))(z_log_msg_simple_create_0(_src, 4U, "adjusting prio up on mutex %p"))(COND_CODE_1(1, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "adjusting prio up on mutex %p" , _v1, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "adjusting prio up on mutex %p" , _v1, dummy, dummy) ) ))(z_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "adjusting prio up on mutex %p" , _v1, dummy) )( z_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "adjusting prio up on mutex %p" , _v1, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)dummy) )"adjusting prio up on mutex %p" , _v1, dummy"adjusting prio up on mutex %p" , _v1, dummy, dummyz_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1)_ZZZZ1 (z_log_msg_simple_create_0(_src, 4U, "adjusting prio up on mutex %p"))z_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 4U, "adjusting prio up on mutex %p", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "adjusting prio up on mutex %p" , _v1))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "adjusting prio up on mutex %p" , _v1))REVERSE_ARGS("adjusting prio up on mutex %p" , _v1)_v1 , "adjusting prio up on mutex %p"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("adjusting prio up on mutex %p") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("adjusting prio up on mutex %p") + 0, long double : 1, default : 0) && !0)_Generic(("adjusting prio up on mutex %p") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("adjusting prio up on mutex %p") + 0))_Generic(("adjusting prio up on mutex %p") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("adjusting prio up on mutex %p") + 0))%c: adjusting prio up on mutex %p
char[35]adjusting prio up on mutex %pgot_mutex"on mutex %p got_mutex value: %d", mutex, got_mutex"on mutex %p got_mutex value: %d"mutex, got_mutexZ_LOG_STR(4U, "on mutex %p got_mutex value: %d", mutex, got_mutex)(Z_LOG_STR_WITH_PREFIX("on mutex %p got_mutex value: %d", mutex, got_mutex))("%s: " "on mutex %p got_mutex value: %d", (const char *)__func__ , mutex, got_mutex)("on mutex %p got_mutex value: %d", mutex, got_mutex)NUM_VA_ARGS_LESS_1(_,"on mutex %p got_mutex value: %d", mutex, got_mutex)(Z_LOG_STR_WITH_PREFIX2("on mutex %p got_mutex value: %d", mutex, got_mutex))_,"on mutex %p got_mutex value: %d", mutex, got_mutexNUM_VA_ARGS_LESS_1("on mutex %p got_mutex value: %d", mutex, got_mutex)(, GET_ARGS_LESS_N(1, "on mutex %p got_mutex value: %d", mutex, got_mutex))(, mutex, got_mutex), mutex, got_mutex"%s: " "on mutex %p got_mutex value: %d", (const char *)__func__ , mutex, got_mutex_XXXX0 ("%s: " "on mutex %p got_mutex value: %d", (const char *)__func__ , mutex, got_mutex)REVERSE_ARGS("on mutex %p got_mutex value: %d", mutex, got_mutex)got_mutex , mutex , "on mutex %p got_mutex value: %d"mutex , "on mutex %p got_mutex value: %d"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "on mutex %p got_mutex value: %d") = ("on mutex %p got_mutex value: %d") + 0)(__auto_type "on mutex %p got_mutex value: %d" = ("on mutex %p got_mutex value: %d") + 0)("on mutex %p got_mutex value: %d")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, got_mutex) = (got_mutex) + 0)(__auto_type _v2 = (got_mutex) + 0)(got_mutex)_ZZZZ2 (got_mutex)__auto_type _v2 = (got_mutex) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex)"on mutex %p got_mutex value: %d" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "on mutex %p got_mutex value: %d";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "on mutex %p got_mutex value: %d" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex)_,"on mutex %p got_mutex value: %d" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "on mutex %p got_mutex value: %d";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "on mutex %p got_mutex value: %d";)NUM_VA_ARGS_LESS_1("on mutex %p got_mutex value: %d" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "on mutex %p got_mutex value: %d" , _v1 , _v2))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex))( bool can_simple = LOG_MSG_SIMPLE_CHECK("on mutex %p got_mutex value: %d" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("on mutex %p got_mutex value: %d" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("on mutex %p got_mutex value: %d" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("on mutex %p got_mutex value: %d" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("on mutex %p got_mutex value: %d" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("on mutex %p got_mutex value: %d" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "on mutex %p got_mutex value: %d", mutex, got_mutex)))("on mutex %p got_mutex value: %d" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("on mutex %p got_mutex value: %d" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "on mutex %p got_mutex value: %d" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "on mutex %p got_mutex value: %d" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "on mutex %p got_mutex value: %d" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "on mutex %p got_mutex value: %d" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 4U, "on mutex %p got_mutex value: %d"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "on mutex %p got_mutex value: %d" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "on mutex %p got_mutex value: %d" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "on mutex %p got_mutex value: %d" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "on mutex %p got_mutex value: %d" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"on mutex %p got_mutex value: %d" , _v1 , _v2, dummy"on mutex %p got_mutex value: %d" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 4U, "on mutex %p got_mutex value: %d"))z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "on mutex %p got_mutex value: %d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "on mutex %p got_mutex value: %d" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "on mutex %p got_mutex value: %d" , _v1 , _v2))REVERSE_ARGS("on mutex %p got_mutex value: %d" , _v1 , _v2)_v2 , _v1 , "on mutex %p got_mutex value: %d"_v1 , "on mutex %p got_mutex value: %d"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("on mutex %p got_mutex value: %d") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("on mutex %p got_mutex value: %d") + 0, long double : 1, default : 0) && !0)_Generic(("on mutex %p got_mutex value: %d") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("on mutex %p got_mutex value: %d") + 0))_Generic(("on mutex %p got_mutex value: %d") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("on mutex %p got_mutex value: %d") + 0))%c: on mutex %p got_mutex value: %d
on mutex %p got_mutex value: %d"%p got mutex %p (y/n): %c", _current, mutex, got_mutex ? 'y' : 'n'"%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'"%p got mutex %p (y/n): %c"_kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'Z_LOG_STR(4U, "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')(Z_LOG_STR_WITH_PREFIX("%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))("%s: " "%p got mutex %p (y/n): %c", (const char *)__func__ , _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')("%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')NUM_VA_ARGS_LESS_1(_,"%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')(Z_LOG_STR_WITH_PREFIX2("%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))_,"%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'got_mutex ? 'y' : 'n'NUM_VA_ARGS_LESS_1("%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')(, GET_ARGS_LESS_N(1, "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))(, _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'), _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'"%s: " "%p got mutex %p (y/n): %c", (const char *)__func__ , _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'_XXXX0 ("%s: " "%p got mutex %p (y/n): %c", (const char *)__func__ , _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')REVERSE_ARGS("%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')got_mutex ? 'y' : 'n' , mutex , _kernel.cpus[0].current , "%p got mutex %p (y/n): %c"mutex, got_mutex ? 'y' : 'n'mutex , _kernel.cpus[0].current , "%p got mutex %p (y/n): %c"_kernel.cpus[0].current , "%p got mutex %p (y/n): %c"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "%p got mutex %p (y/n): %c") = ("%p got mutex %p (y/n): %c") + 0)(__auto_type "%p got mutex %p (y/n): %c" = ("%p got mutex %p (y/n): %c") + 0)("%p got mutex %p (y/n): %c")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, got_mutex ? 'y' : 'n') = (got_mutex ? 'y' : 'n') + 0)(__auto_type _v3 = (got_mutex ? 'y' : 'n') + 0)(got_mutex ? 'y' : 'n')_ZZZZ3 (got_mutex ? 'y' : 'n')__auto_type _v3 = (got_mutex ? 'y' : 'n') + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')"%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p got mutex %p (y/n): %c";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')_,"%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p got mutex %p (y/n): %c";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p got mutex %p (y/n): %c";)NUM_VA_ARGS_LESS_1("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))( bool can_simple = LOG_MSG_SIMPLE_CHECK("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_3("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n'))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p got mutex %p (y/n): %c", _kernel.cpus[0].current, mutex, got_mutex ? 'y' : 'n')))("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3)(COND_CODE_0(NUM_VA_ARGS_LESS_1("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))))(_fmt, GET_ARGS_LESS_N(1, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3); )( z_log_msg_simple_create_2(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3)))(z_log_msg_simple_create_0(_src, 4U, "%p got mutex %p (y/n): %c"))(COND_CODE_1(3, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3, dummy) )( z_log_msg_simple_create_1(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3, dummy"%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3, dummy, dummy_XXXX3 ( z_log_msg_simple_create_1(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ3 (z_log_msg_simple_create_0(_src, 4U, "%p got mutex %p (y/n): %c"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "%p got mutex %p (y/n): %c", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3))REVERSE_ARGS("%p got mutex %p (y/n): %c" , _v1 , _v2 , _v3)_v3 , _v2 , _v1 , "%p got mutex %p (y/n): %c"_v2 , _v1 , "%p got mutex %p (y/n): %c"_v1 , "%p got mutex %p (y/n): %c"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("%p got mutex %p (y/n): %c") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("%p got mutex %p (y/n): %c") + 0, long double : 1, default : 0) && !0)_Generic(("%p got mutex %p (y/n): %c") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("%p got mutex %p (y/n): %c") + 0))_Generic(("%p got mutex %p (y/n): %c") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("%p got mutex %p (y/n): %c") + 0))%c: %p got mutex %p (y/n): %c
char[31]%p got mutex %p (y/n): %c"%p timeout on mutex %p", _current, mutex"%p timeout on mutex %p", _kernel.cpus[0].current, mutex"%p timeout on mutex %p"_kernel.cpus[0].current, mutexZ_LOG_STR(4U, "%p timeout on mutex %p", _kernel.cpus[0].current, mutex)(Z_LOG_STR_WITH_PREFIX("%p timeout on mutex %p", _kernel.cpus[0].current, mutex))("%s: " "%p timeout on mutex %p", (const char *)__func__ , _kernel.cpus[0].current, mutex)("%p timeout on mutex %p", _kernel.cpus[0].current, mutex)NUM_VA_ARGS_LESS_1(_,"%p timeout on mutex %p", _kernel.cpus[0].current, mutex)(Z_LOG_STR_WITH_PREFIX2("%p timeout on mutex %p", _kernel.cpus[0].current, mutex))_,"%p timeout on mutex %p", _kernel.cpus[0].current, mutexNUM_VA_ARGS_LESS_1("%p timeout on mutex %p", _kernel.cpus[0].current, mutex)(, GET_ARGS_LESS_N(1, "%p timeout on mutex %p", _kernel.cpus[0].current, mutex))(, _kernel.cpus[0].current, mutex), _kernel.cpus[0].current, mutex"%s: " "%p timeout on mutex %p", (const char *)__func__ , _kernel.cpus[0].current, mutex_XXXX0 ("%s: " "%p timeout on mutex %p", (const char *)__func__ , _kernel.cpus[0].current, mutex)REVERSE_ARGS("%p timeout on mutex %p", _kernel.cpus[0].current, mutex)mutex , _kernel.cpus[0].current , "%p timeout on mutex %p"_kernel.cpus[0].current , "%p timeout on mutex %p"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "%p timeout on mutex %p") = ("%p timeout on mutex %p") + 0)(__auto_type "%p timeout on mutex %p" = ("%p timeout on mutex %p") + 0)("%p timeout on mutex %p")FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex)"%p timeout on mutex %p" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p timeout on mutex %p";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "%p timeout on mutex %p" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex)_,"%p timeout on mutex %p" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p timeout on mutex %p";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p timeout on mutex %p";)NUM_VA_ARGS_LESS_1("%p timeout on mutex %p" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "%p timeout on mutex %p" , _v1 , _v2))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex))( bool can_simple = LOG_MSG_SIMPLE_CHECK("%p timeout on mutex %p" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p timeout on mutex %p" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p timeout on mutex %p" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p timeout on mutex %p" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p timeout on mutex %p" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("%p timeout on mutex %p" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p timeout on mutex %p", _kernel.cpus[0].current, mutex)))("%p timeout on mutex %p" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("%p timeout on mutex %p" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "%p timeout on mutex %p" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "%p timeout on mutex %p" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "%p timeout on mutex %p" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "%p timeout on mutex %p" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 4U, "%p timeout on mutex %p"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p timeout on mutex %p" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p timeout on mutex %p" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p timeout on mutex %p" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p timeout on mutex %p" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"%p timeout on mutex %p" , _v1 , _v2, dummy"%p timeout on mutex %p" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 4U, "%p timeout on mutex %p"))z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "%p timeout on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "%p timeout on mutex %p" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "%p timeout on mutex %p" , _v1 , _v2))REVERSE_ARGS("%p timeout on mutex %p" , _v1 , _v2)_v2 , _v1 , "%p timeout on mutex %p"_v1 , "%p timeout on mutex %p"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("%p timeout on mutex %p") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("%p timeout on mutex %p") + 0, long double : 1, default : 0) && !0)_Generic(("%p timeout on mutex %p") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("%p timeout on mutex %p") + 0))_Generic(("%p timeout on mutex %p") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("%p timeout on mutex %p") + 0))%c: %p timeout on mutex %p
%p timeout on mutex %pmutex->owner != NULLmutex->owner != ((void *)0)"adjusting prio down on mutex %p", mutex"adjusting prio down on mutex %p"Z_LOG_STR(4U, "adjusting prio down on mutex %p", mutex)(Z_LOG_STR_WITH_PREFIX("adjusting prio down on mutex %p", mutex))("%s: " "adjusting prio down on mutex %p", (const char *)__func__ , mutex)("adjusting prio down on mutex %p", mutex)NUM_VA_ARGS_LESS_1(_,"adjusting prio down on mutex %p", mutex)(Z_LOG_STR_WITH_PREFIX2("adjusting prio down on mutex %p", mutex))_,"adjusting prio down on mutex %p", mutexNUM_VA_ARGS_LESS_1("adjusting prio down on mutex %p", mutex)(, GET_ARGS_LESS_N(1, "adjusting prio down on mutex %p", mutex))"%s: " "adjusting prio down on mutex %p", (const char *)__func__ , mutex_XXXX0 ("%s: " "adjusting prio down on mutex %p", (const char *)__func__ , mutex)REVERSE_ARGS("adjusting prio down on mutex %p", mutex)mutex , "adjusting prio down on mutex %p"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "adjusting prio down on mutex %p") = ("adjusting prio down on mutex %p") + 0)(__auto_type "adjusting prio down on mutex %p" = ("adjusting prio down on mutex %p") + 0)("adjusting prio down on mutex %p")FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex)"adjusting prio down on mutex %p" , _v1(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "adjusting prio down on mutex %p";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "adjusting prio down on mutex %p" , _v1);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex)_,"adjusting prio down on mutex %p" , _v1static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "adjusting prio down on mutex %p";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "adjusting prio down on mutex %p";)NUM_VA_ARGS_LESS_1("adjusting prio down on mutex %p" , _v1)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "adjusting prio down on mutex %p" , _v1))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex))( bool can_simple = LOG_MSG_SIMPLE_CHECK("adjusting prio down on mutex %p" , _v1); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("adjusting prio down on mutex %p" , _v1), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("adjusting prio down on mutex %p" , _v1)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("adjusting prio down on mutex %p" , _v1)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("adjusting prio down on mutex %p" , _v1))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("adjusting prio down on mutex %p" , _v1))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "adjusting prio down on mutex %p", mutex)))("adjusting prio down on mutex %p" , _v1)(COND_CODE_0(NUM_VA_ARGS_LESS_1("adjusting prio down on mutex %p" , _v1), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "adjusting prio down on mutex %p" , _v1))))(_fmt, GET_ARGS_LESS_N(1, "adjusting prio down on mutex %p" , _v1))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "adjusting prio down on mutex %p" , _v1); )( z_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "adjusting prio down on mutex %p" , _v1)))(z_log_msg_simple_create_0(_src, 4U, "adjusting prio down on mutex %p"))(COND_CODE_1(1, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "adjusting prio down on mutex %p" , _v1, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "adjusting prio down on mutex %p" , _v1, dummy, dummy) ) ))(z_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "adjusting prio down on mutex %p" , _v1, dummy) )( z_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "adjusting prio down on mutex %p" , _v1, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)dummy) )"adjusting prio down on mutex %p" , _v1, dummy"adjusting prio down on mutex %p" , _v1, dummy, dummyz_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1)_ZZZZ1 (z_log_msg_simple_create_0(_src, 4U, "adjusting prio down on mutex %p"))z_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_1(_src, 4U, "adjusting prio down on mutex %p", (uint32_t)(uintptr_t)_v1);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "adjusting prio down on mutex %p" , _v1))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "adjusting prio down on mutex %p" , _v1))REVERSE_ARGS("adjusting prio down on mutex %p" , _v1)_v1 , "adjusting prio down on mutex %p"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("adjusting prio down on mutex %p") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("adjusting prio down on mutex %p") + 0, long double : 1, default : 0) && !0)_Generic(("adjusting prio down on mutex %p") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("adjusting prio down on mutex %p") + 0))_Generic(("adjusting prio down on mutex %p") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("adjusting prio down on mutex %p") + 0))waiter%c: adjusting prio down on mutex %p
adjusting prio down on mutex %ptimeout, -EAGAINadjust_owner_prio"%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio"%p (ready (y/n): %c) prio changed to %d (was %d)"mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prioZ_LOG_STR(4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)(Z_LOG_STR_WITH_PREFIX("%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))("%s: " "%p (ready (y/n): %c) prio changed to %d (was %d)", (const char *)__func__ , mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)("%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)NUM_VA_ARGS_LESS_1(_,"%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)(Z_LOG_STR_WITH_PREFIX2("%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))_,"%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.priomutex->ownerz_is_thread_ready(mutex->owner) ? 'y' : 'n'mutex->owner->base.prioNUM_VA_ARGS_LESS_1("%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)(, GET_ARGS_LESS_N(1, "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))(, mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio), mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio"%s: " "%p (ready (y/n): %c) prio changed to %d (was %d)", (const char *)__func__ , mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio_XXXX0 ("%s: " "%p (ready (y/n): %c) prio changed to %d (was %d)", (const char *)__func__ , mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)REVERSE_ARGS("%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)mutex->owner->base.prio , new_prio , z_is_thread_ready(mutex->owner) ? 'y' : 'n' , mutex->owner , "%p (ready (y/n): %c) prio changed to %d (was %d)"z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prionew_prio, mutex->owner->base.prionew_prio , z_is_thread_ready(mutex->owner) ? 'y' : 'n' , mutex->owner , "%p (ready (y/n): %c) prio changed to %d (was %d)"z_is_thread_ready(mutex->owner) ? 'y' : 'n' , mutex->owner , "%p (ready (y/n): %c) prio changed to %d (was %d)"mutex->owner , "%p (ready (y/n): %c) prio changed to %d (was %d)"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "%p (ready (y/n): %c) prio changed to %d (was %d)") = ("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0)(__auto_type "%p (ready (y/n): %c) prio changed to %d (was %d)" = ("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0)("%p (ready (y/n): %c) prio changed to %d (was %d)")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, mutex->owner) = (mutex->owner) + 0)(__auto_type _v1 = (mutex->owner) + 0)(mutex->owner)_ZZZZ1 (mutex->owner)__auto_type _v1 = (mutex->owner) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, z_is_thread_ready(mutex->owner) ? 'y' : 'n') = (z_is_thread_ready(mutex->owner) ? 'y' : 'n') + 0)(__auto_type _v2 = (z_is_thread_ready(mutex->owner) ? 'y' : 'n') + 0)(z_is_thread_ready(mutex->owner) ? 'y' : 'n')_ZZZZ2 (z_is_thread_ready(mutex->owner) ? 'y' : 'n')__auto_type _v2 = (z_is_thread_ready(mutex->owner) ? 'y' : 'n') + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, new_prio) = (new_prio) + 0)(__auto_type _v3 = (new_prio) + 0)(new_prio)_ZZZZ3 (new_prio)__auto_type _v3 = (new_prio) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(4, mutex->owner->base.prio) = (mutex->owner->base.prio) + 0)(__auto_type _v4 = (mutex->owner->base.prio) + 0)(mutex->owner->base.prio)_ZZZZ4 (mutex->owner->base.prio)__auto_type _v4 = (mutex->owner->base.prio) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)"%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p (ready (y/n): %c) prio changed to %d (was %d)";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)_,"%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p (ready (y/n): %c) prio changed to %d (was %d)";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "%p (ready (y/n): %c) prio changed to %d (was %d)";)NUM_VA_ARGS_LESS_1("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))( bool can_simple = LOG_MSG_SIMPLE_CHECK("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_4("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_4("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "%p (ready (y/n): %c) prio changed to %d (was %d)", mutex->owner, z_is_thread_ready(mutex->owner) ? 'y' : 'n', new_prio, mutex->owner->base.prio)))("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4)(COND_CODE_0(NUM_VA_ARGS_LESS_1("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))))(_fmt, GET_ARGS_LESS_N(1, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4); )( z_log_msg_simple_create_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4)))(z_log_msg_simple_create_0(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)"))(COND_CODE_1(4, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4, dummy) )( z_log_msg_simple_create_1(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4, dummy"%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4, dummy, dummy_XXXX4 ( z_log_msg_simple_create_1(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ4 (z_log_msg_simple_create_0(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "%p (ready (y/n): %c) prio changed to %d (was %d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4))REVERSE_ARGS("%p (ready (y/n): %c) prio changed to %d (was %d)" , _v1 , _v2 , _v3 , _v4)_v4 , _v3 , _v2 , _v1 , "%p (ready (y/n): %c) prio changed to %d (was %d)"_v3 , _v2 , _v1 , "%p (ready (y/n): %c) prio changed to %d (was %d)"_v2 , _v1 , "%p (ready (y/n): %c) prio changed to %d (was %d)"_v1 , "%p (ready (y/n): %c) prio changed to %d (was %d)"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("%p (ready (y/n): %c) prio changed to %d (was %d)") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0, long double : 1, default : 0) && !0)_Generic(("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0))_Generic(("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("%p (ready (y/n): %c) prio changed to %d (was %d)") + 0))%c: %p (ready (y/n): %c) prio changed to %d (was %d)
char[54]%p (ready (y/n): %c) prio changed to %d (was %d)new_prio_for_inheritance/* Initialize and link statically defined mutexs *//* Initialize mutex object type *//*
		 * new owner is already of higher or equal prio than first
		 * waiter since the wait queue is priority-based: no need to
		 * adjust its priority
		 *//* Get the new owner, if any *//*
	 * If we are the owner and count is greater than 1, then decrement
	 * the count and return and keep current thread as the owner.
	 *//*
	 * Attempt to unlock a mutex which is unlocked. mutex->lock_count
	 * cannot be zero if the current thread is equal to mutex->owner,
	 * therefore no underflow check is required. Use assert to catch
	 * undefined behavior.
	 *//*
	 * The current thread does not own the mutex.
	 *//*
	 * Check if mutex was unlocked after this thread was unpended.
	 * If so, skip adjusting owner's priority down.
	 *//* timed out *//* We use a global spinlock here because some of the synchronization
 * is protecting things like owner thread priorities which aren't
 * "part of" a single k_mutex.  Should move those bits of the API
 * under the scheduler lock so we can break this up.
 *//**
 * @file @brief mutex kernel services
 *
 * This module contains routines for handling mutex locking and unlocking.
 *
 * Mutexes implement a priority inheritance algorithm that boosts the priority
 * level of the owning thread to match the priority level of the highest
 * priority thread waiting on the mutex.
 *
 * Each mutex that contributes to priority inheritance must be released in the
 * reverse order in which it was acquired.  Furthermore each subsequent mutex
 * that contributes to raising the owning thread's priority level must be
 * acquired at a point after the most recent "bumping" of the priority level.
 *
 * For example, if thread A has two mutexes contributing to the raising of its
 * priority level, the second mutex M2 must be acquired by thread A after
 * thread A's priority level was bumped due to owning the first mutex M1.
 * When releasing the mutex, thread A must release M2 before it releases M1.
 * Failure to follow this nested model may result in threads running at
 * unexpected priority levels (too high, or too low).
 *//home/haojie/zephyrproject/zephyr/kernel/queue.cpeek_tailpeek_headunique_append&queue->data_q!sys_sflist_is_empty(&queue->data_q)timeout, datatimeout, NULLtimeout, (ret != 0) ? NULL : _current->base.swap_datamerge_slistsys_slist_is_empty(list)ret != 0append_listhead == NULL || tail == NULLhead == ((void *)0) || tail == ((void *)0)alloc_prependalloc_appendprependappendinsertqueue_insertfirst_pending_threadalloc, K_FOREVERalloc, 0alloc, -ENOMEMalloc_node *anodesizeof(*anode)cancel_waithandle_poll_eventsprepare_thread_to_runis_appendz_queue_node_peekstruct alloc_nodeSAME_TYPE(*(node), ((struct alloc_node *)0)->node) || SAME_TYPE(*(node), void)__builtin_types_compatible_p(__typeof__(*(node)), __typeof__(((struct alloc_node *)0)->node)) || __builtin_types_compatible_p(__typeof__(*(node)), __typeof__(void))((struct alloc_node *)0)->node(uint8_t)0alloc_node/* Initialize and link statically defined lifo *//* Initialize lifo object type *//* Initialize and link statically defined fifos *//* Initialize fifo object type *//*
	 * note: this works as long as:
	 * - the slist implementation keeps the next pointer as the first
	 *   field of the node object type
	 * - list->tail->next = NULL.
	 * - sflist implementation only differs from slist by stuffing
	 *   flag bytes in the lower order bits of the data pointer
	 * - source list is really an slist and not an sflist with flags set
	 *//* list must not be empty *//* invalid head or tail of list *//* Only need to actually allocate if no threads are pending *//* Data was directly placed in the queue, the first word
		 * reserved for the linked list. User mode isn't allowed to
		 * do this, although it can get data sent this way.
		 *//* If the flag is set, then the enqueue operation for this item
		 * did a behind-the scenes memory allocation of an alloc_node
		 * struct, which is what got put in the queue. Free it and pass
		 * back the data pointer.
		 *//**
 * @file
 *
 * @brief dynamic-size QUEUE object.
 *//*
 * Copyright (c) 2010-2016 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */needs_free/home/haojie/zephyrproject/zephyr/kernel/sched.c__i&sched_spinlock__key&(wait_q)->waitq.tree__typeof__(*(thread))SAME_TYPE(*(n), ((__typeof__(*(thread)) *)0)->base.qnode_rb) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((__typeof__(*(thread)) *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))((__typeof__(*(thread)) *)0)->base.qnode_rbjoin"cannot join in ISR"-45-EDEADLK"aborting essential thread %p"halt_threadsched_abortunpend_allwakeupusleepCONFIG_SYS_CLOCK_MAX_TIMEOUT_DAYS * 24ULL * 3600ULL * 1000000365 * 24ULL * 3600ULL * 10000009999new_state3153600000000031540294967295315402949672947343734300500000999999us, k_ticks_to_us_floor64(ticks)sleep((k_timeout_t) { .ticks = (((k_ticks_t) -1)) })timeout, (int32_t) K_TICKS_FOREVER(int32_t) K_TICKS_FOREVERz_tick_sleepexpected_wakeup_ticks"thread %p for %lu ticks", _current, (unsigned long)ticks"thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks"thread %p for %lu ticks"_kernel.cpus[0].current, (unsigned long)ticksZ_LOG_STR(4U, "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)(Z_LOG_STR_WITH_PREFIX("thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))("%s: " "thread %p for %lu ticks", (const char *)__func__ , _kernel.cpus[0].current, (unsigned long)ticks)("thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)NUM_VA_ARGS_LESS_1(_,"thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)(Z_LOG_STR_WITH_PREFIX2("thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))_,"thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks(unsigned long)ticksNUM_VA_ARGS_LESS_1("thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)(, GET_ARGS_LESS_N(1, "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))(, _kernel.cpus[0].current, (unsigned long)ticks), _kernel.cpus[0].current, (unsigned long)ticks"%s: " "thread %p for %lu ticks", (const char *)__func__ , _kernel.cpus[0].current, (unsigned long)ticks_XXXX0 ("%s: " "thread %p for %lu ticks", (const char *)__func__ , _kernel.cpus[0].current, (unsigned long)ticks)REVERSE_ARGS("thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)(unsigned long)ticks , _kernel.cpus[0].current , "thread %p for %lu ticks"_kernel.cpus[0].current , "thread %p for %lu ticks"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "thread %p for %lu ticks") = ("thread %p for %lu ticks") + 0)(__auto_type "thread %p for %lu ticks" = ("thread %p for %lu ticks") + 0)("thread %p for %lu ticks")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, (unsigned long)ticks) = ((unsigned long)ticks) + 0)(__auto_type _v2 = ((unsigned long)ticks) + 0)((unsigned long)ticks)_ZZZZ2 ((unsigned long)ticks)__auto_type _v2 = ((unsigned long)ticks) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)"thread %p for %lu ticks" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "thread %p for %lu ticks";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "thread %p for %lu ticks" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)_,"thread %p for %lu ticks" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "thread %p for %lu ticks";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "thread %p for %lu ticks";)NUM_VA_ARGS_LESS_1("thread %p for %lu ticks" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "thread %p for %lu ticks" , _v1 , _v2))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))( bool can_simple = LOG_MSG_SIMPLE_CHECK("thread %p for %lu ticks" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("thread %p for %lu ticks" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("thread %p for %lu ticks" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("thread %p for %lu ticks" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("thread %p for %lu ticks" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("thread %p for %lu ticks" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "thread %p for %lu ticks", _kernel.cpus[0].current, (unsigned long)ticks)))("thread %p for %lu ticks" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("thread %p for %lu ticks" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "thread %p for %lu ticks" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "thread %p for %lu ticks" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "thread %p for %lu ticks" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "thread %p for %lu ticks" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 4U, "thread %p for %lu ticks"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "thread %p for %lu ticks" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "thread %p for %lu ticks" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "thread %p for %lu ticks" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "thread %p for %lu ticks" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"thread %p for %lu ticks" , _v1 , _v2, dummy"thread %p for %lu ticks" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 4U, "thread %p for %lu ticks"))z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "thread %p for %lu ticks", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "thread %p for %lu ticks" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "thread %p for %lu ticks" , _v1 , _v2))REVERSE_ARGS("thread %p for %lu ticks" , _v1 , _v2)_v2 , _v1 , "thread %p for %lu ticks"_v1 , "thread %p for %lu ticks"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("thread %p for %lu ticks") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("thread %p for %lu ticks") + 0, long double : 1, default : 0) && !0)_Generic(("thread %p for %lu ticks") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("thread %p for %lu ticks") + 0))_Generic(("thread %p for %lu ticks") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("thread %p for %lu ticks") + 0))%c: thread %p for %lu ticks
thread %p for %lu ticks!z_is_thread_state_set(_current, _THREAD_SUSPENDED)yieldZ_VALID_PRIO((prio), (((void *)0)))"invalid priority (%d); allowed range: %d to %d"(prio), K_LOWEST_APPLICATION_THREAD_PRIO, K_HIGHEST_APPLICATION_THREAD_PRIOinit_ready_qneed_sched__builtin_ctzstruct k_threadbase.qnode_dlistSAME_TYPE(*(n), ((struct k_thread *)0)->base.qnode_dlist) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((struct k_thread *)0)->base.qnode_dlist)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))((struct k_thread *)0)->base.qnode_dlistSAME_TYPE(*(n), ((struct k_thread *)0)->base.qnode_rb) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((struct k_thread *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))((struct k_thread *)0)->base.qnode_rb!z_is_idle_thread_object(thread)&pq->tree__typeof__(*(t))SAME_TYPE(*(n), ((__typeof__(*(t)) *)0)->base.qnode_rb) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((__typeof__(*(t)) *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))((__typeof__(*(t)) *)0)->base.qnode_rbthread_athread_bcmpSAME_TYPE(*(a), ((struct k_thread *)0)->base.qnode_rb) || SAME_TYPE(*(a), void)__builtin_types_compatible_p(__typeof__(*(a)), __typeof__(((struct k_thread *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(a)), __typeof__(void))*(a)SAME_TYPE(*(b), ((struct k_thread *)0)->base.qnode_rb) || SAME_TYPE(*(b), void)__builtin_types_compatible_p(__typeof__(*(b)), __typeof__(((struct k_thread *)0)->base.qnode_rb)) || __builtin_types_compatible_p(__typeof__(*(b)), __typeof__(void))*(b)rq"scheduler unlocked (%p:%d)", _current, _current->base.sched_locked"scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked"scheduler unlocked (%p:%d)"_kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_lockedZ_LOG_STR(4U, "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)(Z_LOG_STR_WITH_PREFIX("scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))("%s: " "scheduler unlocked (%p:%d)", (const char *)__func__ , _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)("scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)NUM_VA_ARGS_LESS_1(_,"scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)(Z_LOG_STR_WITH_PREFIX2("scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))_,"scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked_kernel.cpus[0].current->base.sched_lockedNUM_VA_ARGS_LESS_1("scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)(, GET_ARGS_LESS_N(1, "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))(, _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked), _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked"%s: " "scheduler unlocked (%p:%d)", (const char *)__func__ , _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked_XXXX0 ("%s: " "scheduler unlocked (%p:%d)", (const char *)__func__ , _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)REVERSE_ARGS("scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)_kernel.cpus[0].current->base.sched_locked , _kernel.cpus[0].current , "scheduler unlocked (%p:%d)"_kernel.cpus[0].current , "scheduler unlocked (%p:%d)"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "scheduler unlocked (%p:%d)") = ("scheduler unlocked (%p:%d)") + 0)(__auto_type "scheduler unlocked (%p:%d)" = ("scheduler unlocked (%p:%d)") + 0)("scheduler unlocked (%p:%d)")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, _kernel.cpus[0].current->base.sched_locked) = (_kernel.cpus[0].current->base.sched_locked) + 0)(__auto_type _v2 = (_kernel.cpus[0].current->base.sched_locked) + 0)(_kernel.cpus[0].current->base.sched_locked)_ZZZZ2 (_kernel.cpus[0].current->base.sched_locked)__auto_type _v2 = (_kernel.cpus[0].current->base.sched_locked) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)"scheduler unlocked (%p:%d)" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "scheduler unlocked (%p:%d)";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "scheduler unlocked (%p:%d)" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)_,"scheduler unlocked (%p:%d)" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "scheduler unlocked (%p:%d)";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "scheduler unlocked (%p:%d)";)NUM_VA_ARGS_LESS_1("scheduler unlocked (%p:%d)" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "scheduler unlocked (%p:%d)" , _v1 , _v2))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))( bool can_simple = LOG_MSG_SIMPLE_CHECK("scheduler unlocked (%p:%d)" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("scheduler unlocked (%p:%d)" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("scheduler unlocked (%p:%d)" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("scheduler unlocked (%p:%d)" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("scheduler unlocked (%p:%d)" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("scheduler unlocked (%p:%d)" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "scheduler unlocked (%p:%d)", _kernel.cpus[0].current, _kernel.cpus[0].current->base.sched_locked)))("scheduler unlocked (%p:%d)" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("scheduler unlocked (%p:%d)" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "scheduler unlocked (%p:%d)" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "scheduler unlocked (%p:%d)" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "scheduler unlocked (%p:%d)" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "scheduler unlocked (%p:%d)" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 4U, "scheduler unlocked (%p:%d)"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "scheduler unlocked (%p:%d)" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "scheduler unlocked (%p:%d)" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "scheduler unlocked (%p:%d)" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "scheduler unlocked (%p:%d)" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"scheduler unlocked (%p:%d)" , _v1 , _v2, dummy"scheduler unlocked (%p:%d)" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 4U, "scheduler unlocked (%p:%d)"))z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 4U, "scheduler unlocked (%p:%d)", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "scheduler unlocked (%p:%d)" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "scheduler unlocked (%p:%d)" , _v1 , _v2))REVERSE_ARGS("scheduler unlocked (%p:%d)" , _v1 , _v2)_v2 , _v1 , "scheduler unlocked (%p:%d)"_v1 , "scheduler unlocked (%p:%d)"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("scheduler unlocked (%p:%d)") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("scheduler unlocked (%p:%d)") + 0, long double : 1, default : 0) && !0)_Generic(("scheduler unlocked (%p:%d)") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("scheduler unlocked (%p:%d)") + 0))_Generic(("scheduler unlocked (%p:%d)") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("scheduler unlocked (%p:%d)") + 0))%c: scheduler unlocked (%p:%d)
scheduler unlocked (%p:%d)sched_unlocksched_lockneed_swapsched_priority_setsizeof(sched_spinlock) == 0 || lock != &sched_spinlockbase.timeoutSAME_TYPE(*(timeout), ((struct k_thread *)0)->base.timeout) || SAME_TYPE(*(timeout), void)__builtin_types_compatible_p(__typeof__(*(timeout)), __typeof__(((struct k_thread *)0)->base.timeout)) || __builtin_types_compatible_p(__typeof__(*(timeout)), __typeof__(void))*(timeout)((struct k_thread *)0)->base.timeoutkilled(_THREAD_DEAD | _THREAD_ABORTING)unpend_thread_no_timeoutthread == _current || is_thread_dummy(thread)pend_lockedadd_thread_timeoutadd_to_waitq_lockedsched_pendunready_threadpended_on_threadthread->base.pended_onresumesuspendz_thread_halt!terminate"aborted _current back from dead"ready_threadsched_readyterminatethread_active_elsewhereupdate_cacheupdate_metairq_preemptbool[1]4294967286_timeout[1]slice_time(curr) - 1slice_timeoutslice_timeoutsIS_ARRAY_ELEMENT(slice_timeouts, t)sliceableslice_timeflag_ipimove_thread_to_end_of_prio_qnext_upclear_halting(_THREAD_ABORTING | _THREAD_SUSPENDING)4294967199~(_THREAD_ABORTING | _THREAD_SUSPENDING)signal_pending_ipidequeue_thread4294967167~_THREAD_QUEUEDqueue_threadshould_queue_threadrunq_bestrunq_removerunq_addcurr_cpu_runqthread_runqshould_preempt_current != NULLCONFIG_SWAP_NONATOMIC_XXXXCONFIG_SWAP_NONATOMIC_XXXXCONFIG_SWAP_NONATOMIC 1preempt_okb1b2is_metairqis_preemptslice_expiredslice_max_prioCONFIG_TIMESLICE_SIZE * Z_HZ_ticks0 * 100DIV_ROUND_UP(CONFIG_TIMESLICE_SIZE * Z_HZ_ticks, Z_HZ_ms)CONFIG_NUM_COOP_PRIORITIES >= CONFIG_NUM_METAIRQ_PRIORITIES16 >= 0"You need to provide at least as many CONFIG_NUM_COOP_PRIORITIES as " "CONFIG_NUM_METAIRQ_PRIORITIES as Meta IRQs are just a special class of cooperative " "threads."_priq_wait_best_priq_wait_removez_priq_wait_add_priq_run_best_priq_run_remove_priq_run_adddefined(CONFIG_SCHED_CPU_MASK)defined(CONFIG_WAITQ_SCALABLE)defined(CONFIG_WAITQ_DUMB)CONFIG_NUM_METAIRQ_PRIORITIES > 0defined(CONFIG_SCHED_DUMB) || defined(CONFIG_WAITQ_DUMB)defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)CONFIG_SCHED_MULTIQ(K_LOWEST_THREAD_PRIO - K_HIGHEST_THREAD_PRIO) > 31CONFIG_TRACE_SCHED_IPIdefined(CONFIG_ASSERT) && defined(CONFIG_SCHED_CPU_MASK_PIN_ONLY)CONFIG_CMSIS_RTOS_V1!defined(CONFIG_ARCH_HAS_THREAD_ABORT)/*
			 * Invoke the callback function on each waiting thread
			 * for as long as there are both waiting threads AND
			 * it returns 0.
			 *//*
 * future scheduler.h API implementations
 *//* Special case: don't oops if the thread is uninitialized.  This is because
 * the initialization bit does double-duty for thread objects; if false, means
 * the thread object is truly uninitialized, or the thread ran and exited for
 * some reason.
 *
 * Return true in this case indicating we should just do nothing and return
 * success to the caller.
 *//* We hold the lock, and the thread is known not to be running
	 * anywhere.
	 *//**
 * @brief Dequeues the specified thread
 *
 * Dequeues the specified thread and move it into the specified new state.
 *
 * @param thread Identify the thread to halt
 * @param new_state New thread state (_THREAD_DEAD or _THREAD_SUSPENDED)
 *//* Right now we use a two byte for this mask *//* In SMP, _current is a field read from _current_cpu, which
	 * can race with preemption before it is read.  We must lock
	 * local interrupts when reading it.
	 *//* NOTE: When adding code to this, make sure this is called
	 * at appropriate location when !CONFIG_SCHED_IPI_SUPPORTED.
	 *//* Might have just been sleeping forever *//* in case of K_FOREVER, we suspend *//* wait of 0 ms is treated as a 'yield' *//*
	 * Use NULL, since we cannot know what the entry point is (we do not
	 * keep track of it) and idle cannot change its priority.
	 *//* Renumber at wraparound.  This is tiny code, and in practice
	 * will almost never be hit on real systems.  BUT on very
	 * long-running systems where a priq never completely empties
	 * AND that contains very large numbers of threads, it can be
	 * a latency glitch to loop over all the threads like this.
	 *//* Active threads MUST have a null here *//* A queued (runnable) old/current thread
			 * needs to be added back to the run queue
			 * here, and atomically with its switch handle
			 * being set below.  This is safe now, as we
			 * will not return into it.
			 *//* Changed _current!  Update the spinlock
			 * bookkeeping so the validation doesn't get
			 * confused when the "wrong" thread tries to
			 * release the lock.
			 *//**
 * @brief Determine next thread to execute upon completion of an interrupt
 *
 * Thread preemption is performed by context switching after the completion
 * of a non-recursed interrupt. This function determines which thread to
 * switch to if any. This function accepts as @p interrupted either:
 *
 * - The handle for the interrupted thread in which case the thread's context
 *   must already be fully saved and ready to be picked up by a different CPU.
 *
 * - NULL if more work is required to fully save the thread's state after
 *   it is known that a new thread is to be scheduled. It is up to the caller
 *   to store the handle resulting from the thread that is being switched out
 *   in that thread's "switch_handle" field after its
 *   context has fully been saved, following the same requirements as with
 *   the @ref arch_switch() function.
 *
 * If a new thread needs to be scheduled then its handle is returned.
 * Otherwise the same value provided as @p interrupted is returned back.
 * Those handles are the same opaque types used by the @ref arch_switch()
 * function.
 *
 * @warning
 * The @ref _current value may have changed after this call and not refer
 * to the interrupted thread anymore. It might be necessary to make a local
 * copy before calling this function.
 *
 * @param interrupted Handle for the thread that was interrupted or NULL.
 * @retval Handle for the next thread to execute, or @p interrupted when
 *         no new thread is to be scheduled.
 *//* Just a wrapper around _current = xxx with tracing *//* When not swapping, have to signal IPIs here.  In
		 * the context switch case it must happen later, after
		 * _current gets requeued.
		 *//* Check if the next ready thread is the same as the current thread *//* the SMP case will be handled in C based z_swap() *//*
 * Check if the next ready thread is the same as the current thread
 * and save the trip if true.
 *//* Don't requeue on SMP if it's the running thread *//* Priority set utility that does no rescheduling, it just changes the
 * run queue state, returning true if a reschedule is needed later.
 *//* We do a "lock swap" prior to calling z_swap(), such that
	 * the caller's lock gets released as desired.  But we ensure
	 * that we hold the scheduler lock and leave local interrupts
	 * masked until we reach the context swich.  z_swap() itself
	 * has similar code; the duplication is because it's a legacy
	 * API that doesn't expect to be called with scheduler lock
	 * held.
	 *//* This is a legacy API for pre-switch architectures and isn't
	 * correctly synchronized for multi-cpu use
	 *//* Timeout handler for *_thread_timeout() APIs *//* The thread is not being killed *//* sched_spinlock must be held *//* Do not try to resume a thread that was not suspended *//* The target thread is already suspended. Nothing to do. *//* lock has been released *//* Threads can wait on a queue *//* Now we know it's halting, but not necessarily
			 * halted (suspended or aborted). Wait for the switch
			 * to happen!
			 *//* ISRs can only spin waiting another CPU *//* We might spin to wait, so a true synchronous IPI is needed
		 * here, not deferred!
		 *//* It's running somewhere else, flag and poke *//* Another CPU (in an ISR) or thread is waiting for the
		 * current thread to halt. Halt it now to help avoid a
		 * potential deadlock.
		 *//**
 * @brief Halt a thread
 *
 * If the target thread is running on another CPU, flag it as needing to
 * abort and send an IPI (if supported) to force a schedule point and wait
 * until the target thread is switched out (ISRs will spin to wait and threads
 * will block to wait). If the target thread is not running on another CPU,
 * then it is safe to act immediately.
 *
 * Upon entry to this routine, the scheduler lock is already held. It is
 * released before this routine returns.
 *
 * @param thread Thread to suspend or abort
 * @param key Current key for sched_spinlock
 * @param terminate True if aborting thread, false if suspending thread
 *//* If thread is queued already, do not try and added it to the
	 * run queue again
	 *//* True if the thread is currently running on another CPU.
	 * There are more scalable designs to answer this question in
	 * constant time, but this is fine for now.
	 *//* The way this works is that the CPU record keeps its
	 * "cooperative swapping is OK" flag until the next reschedule
	 * call or context switch.  It doesn't need to be tracked per
	 * thread because if the thread gets preempted for whatever
	 * reason the scheduler will make the same decision anyway.
	 *//* Returning from existing preemption *//* Record new preemption *//* Track cooperative threads preempted by metairqs so we can return to
 * them specifically.  Called at the moment a new thread has been
 * selected to run.
 *//* Called out of each timer interrupt *//* We need an IPI if we just handled a timeslice expiration
	 * for a different CPU.  Ideally this would be able to target
	 * the specific core, but that's not part of the API yet.
	 *//* If z_swap() isn't atomic, then it's possible for a timer interrupt
 * to try to timeslice away _current after it has already pended
 * itself but before the corresponding context switch.  Treat that as
 * a noop condition in z_time_slice().
 *//* Take the new _current out of the queue *//* Put _current back into the queue *//* Ties only switch if state says we yielded *//* Under SMP, the "cache" mechanism for selecting the next
	 * thread doesn't work, so we have more work to do to test
	 * _current against the best choice from the queue.  Here, the
	 * thread selected above represents "the best thread that is
	 * not current".
	 *
	 * Subtle note on "queued": in SMP mode, _current does not
	 * live in the queue, so this isn't exactly the same thing as
	 * "ready", it means "is _current already added back to the
	 * queue such that we don't want to re-add it".
	 *//* In uniprocessor mode, we can leave the current thread in
	 * the queue (actually we have to, otherwise the assembly
	 * context switch code for all architectures would be
	 * responsible for putting it back in z_swap and ISR return!),
	 * which makes this choice simple.
	 *//* MetaIRQs must always attempt to return back to a
	 * cooperative thread they preempted and not whatever happens
	 * to be highest priority now. The cooperative thread was
	 * promised it wouldn't be preempted (by non-metairq threads)!
	 *//* Clear the halting bits (_THREAD_ABORTING and _THREAD_SUSPENDING) *//* Return true if the thread is aborting or suspending, else false *//* Return true if the thread is aborting, else false *//* Called out of z_swap() when CONFIG_SMP.  The current thread can
 * never live in the run queue until we are inexorably on the context
 * switch path on SMP, otherwise there is a deadlock condition where a
 * set of CPUs pick a cycle of threads to run and wait for them all to
 * context switch forever.
 *//* Synchronization note: you might think we need to lock these
	 * two steps, but an IPI is idempotent.  It's OK if we do it
	 * twice.  All we require is that if a CPU sees the flag true,
	 * it is guaranteed to send the IPI, and if a core sets
	 * pending_ipi, the IPI will be sent the next time through
	 * this code.
	 *//* add current to end of queue means "yield" *//* _current is never in the run queue until context switch on
 * SMP configurations, see z_requeue_current()
 *//* Edge case: it's legal per the API to "make runnable" a
	 * thread with all CPUs masked off (i.e. one that isn't
	 * actually runnable!).  Sort of a wart in the API and maybe
	 * we should address this in docs/assertions instead to avoid
	 * the extra test.
	 *//* With masks enabled we need to be prepared to walk the list
	 * looking for one we can run
	 *//* Otherwise we have to be running a preemptible thread or
	 * switching to a metairq
	 *//* Edge case on ARM where a thread can be pended out of an
	 * interrupt handler before the "synchronous" swap starts
	 * context switching.  Platforms with atomic swap can never
	 * hit this.
	 *//* Or if we're pended/suspended/dummy (duh) *//* Preemption is OK if it's being explicitly allowed by
	 * software state (e.g. the thread called k_yield())
	 *//* Sooner deadline means higher effective priority.
		 * Doing the calculation with unsigned types and casting
		 * to signed isn't perfect, but at least reduces this
		 * from UB on overflow to impdef.
		 *//* If we assume all deadlines live within the same "half" of
	 * the 32 bit modulus space (this is a documented API rule),
	 * then the latest deadline in the queue minus the earliest is
	 * guaranteed to be (2's complement) non-negative.  We can
	 * leverage that to compare the values without having to check
	 * the current time.
	 *//* `prio` is <32b, so the below cannot overflow. *//*
 * Return value same as e.g. memcmp
 * > 0 -> thread 1 priority  > thread 2 priority
 * = 0 -> thread 1 priority == thread 2 priority
 * < 0 -> thread 1 priority  < thread 2 priority
 * Do not rely on the actual value returned aside from the above.
 * (Again, like memcmp.)
 *//* explanation in kernel_struct.h */You need to provide at least as many CONFIG_NUM_COOP_PRIORITIES as CONFIG_NUM_METAIRQ_PRIORITIES as Meta IRQs are just a special class of cooperative threads./home/haojie/zephyrproject/zephyr/kernel/sem.c4294967285((arch_is_in_isr() == false) || K_TIMEOUT_EQ(timeout, K_NO_WAIT))takesem->count > 0Ugivelimit == 0U || limit > K_SEM_MAX_LIMIT || initial_count > limitlimit == 0U || limit > (0x7fffffff * 2U + 1U) || initial_count > limit/* Initialize and link statically defined semaphores *//* Initialize semaphore object type *//*
	 * Limit cannot be zero and count cannot be greater than limit
	 *//* We use a system-wide lock to synchronize semaphores, which has
 * unfortunate performance impact vs. using a per-object lock
 * (semaphores are *very* widely used).  But per-object locks require
 * significant extra RAM.  A properly spin-aware semaphore
 * implementation would spin on atomic access to the count variable,
 * and not a spinlock per se.  Useful optimization for the future...
 *//**
 * @file
 *
 * @brief Kernel semaphore object.
 *
 * The semaphores are of the 'counting' type, i.e. each 'give' operation will
 * increment the internal count by 1, if no thread is pending on it. The 'init'
 * call initializes the count to 'initial_count'. Following multiple 'give'
 * operations, the same number of 'take' operations can be performed without
 * the calling thread having to pend on the semaphore, or the calling task
 * having to poll.
 *//home/haojie/zephyrproject/zephyr/kernel/stack.cpopstack->next > stack->basepushstack->next == stack->topz_waitq_head(&stack->wait_q) != NULLz_waitq_head(&stack->wait_q) != ((void *)0)~K_STACK_FLAG_ALLOCsizeof(stack_data_t)(int32_t)0/* Initialize and link statically defined stacks *//* Initialize stack object type *//**
 * @brief fixed-size stack object
 *//home/haojie/zephyrproject/zephyr/kernel/system_work_q.ck_sys_work_q_initCONFIG_SYSTEM_WORKQUEUE_NO_YIELD_XXXXCONFIG_SYSTEM_WORKQUEUE_NO_YIELD_XXXXCONFIG_SYSTEM_WORKQUEUE_NO_YIELD 1sysworkq"sysworkq"sys_work_q_stack__attribute__((section("." "noinit" "." "\"/home/haojie/zephyrproject/zephyr/kernel/system_work_q.c\"" "." "0")))K_KERNEL_STACK_SIZEOF(sys_work_q_stack)__init_k_sys_work_q_initPOST_KERNEL.z_init_POST_KERNEL40_0_.noinit."/home/haojie/zephyrproject/zephyr/kernel/system_work_q.c".0"/home/haojie/zephyrproject/zephyr/kernel/system_work_q.c"char[69]/**
 * @file
 *
 * System workqueue.
 *//*
 * Copyright (c) 2016 Wind River Systems, Inc.
 * Copyright (c) 2016 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/kernel/thread.cuser_mode_enterthread_datastruct _static_thread_data__static_thread_data_static_thread_data *_static_thread_data[]thread_data <= TYPE_SECTION_END(_static_thread_data)(thread_data)->init_delay_ms((thread_data)->init_delay_ms) == SYS_FOREVER_MS ? K_TICKS_FOREVER : Z_TIMEOUT_MS_TICKS((thread_data)->init_delay_ms)((thread_data)->init_delay_ms) == (-1) ? ((k_ticks_t) -1) : ((k_ticks_t)((1) ? ( ((100) == (1000)) ? (uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))) : ((1000) > (100) && (1000) % (100) == 0U) ? (((uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))) + ((0) ? ((1000) / (100)) / 2 : (1) ? ((1000) / (100)) - 1 : 0)) / ((1000) / (100))) : ((100) > (1000) && (100) % (1000) == 0U) ? (uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0)))*((100) / (1000)) : ((((((365 * 24ULL * 3600ULL * 1000) + ((0xffffffffUL)) - 1) / ((0xffffffffUL))) * 100) <= (0xffffffffUL)) ? (((uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0)))*(100) + ((0) ? (1000) / 2 : (1) ? (1000) - 1 : 0)) / (1000)) : (((uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))) / (1000))*(100) + (((uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))) % (1000))*(100) + ((0) ? (1000) / 2 : (1) ? (1000) - 1 : 0)) / (1000))) ) : (((uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))) / (1000))*(100) + (((uint64_t) (((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))) % (1000))*(100) + ((0) ? (1000) / 2 : (1) ? (1000) - 1 : 0)) / (1000)) ))MAX((thread_data)->init_delay_ms, 0)((((thread_data)->init_delay_ms) > (0)) ? ((thread_data)->init_delay_ms) : (0))init_delay"Threads may not be created in ISRs"Z_VALID_PRIO((prio), (entry))createsetup_thread_stackstack_obj_sizestack_buf_sizestack_buf_start"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptrZ_LOG_STR(4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)(Z_LOG_STR_WITH_PREFIX("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))("%s: " "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (const char *)__func__ , stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)NUM_VA_ARGS_LESS_1(_,"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)(Z_LOG_STR_WITH_PREFIX2("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))_,"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr(void *)stack_buf_start(void *)stack_ptrNUM_VA_ARGS_LESS_1("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)(, GET_ARGS_LESS_N(1, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))(, stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr), stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr_ZZZZ7 ("%s", (const char *)__func__)"%s: " "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (const char *)__func__ , stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr_XXXX0 ("%s: " "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (const char *)__func__ , stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)REVERSE_ARGS("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)(void *)stack_ptr , stack_buf_size , (void *)stack_buf_start , stack_obj_size , new_thread , stack , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptrstack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr(void *)stack_buf_start, stack_buf_size, (void *)stack_ptrstack_buf_size, (void *)stack_ptrstack_buf_size , (void *)stack_buf_start , stack_obj_size , new_thread , stack , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"(void *)stack_buf_start , stack_obj_size , new_thread , stack , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"stack_obj_size , new_thread , stack , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"new_thread , stack , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"stack , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") = ("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0)(__auto_type "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" = ("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0)("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, stack) = (stack) + 0)(__auto_type _v1 = (stack) + 0)(stack)_ZZZZ1 (stack)__auto_type _v1 = (stack) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, new_thread) = (new_thread) + 0)(__auto_type _v2 = (new_thread) + 0)(new_thread)_ZZZZ2 (new_thread)__auto_type _v2 = (new_thread) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(3, stack_obj_size) = (stack_obj_size) + 0)(__auto_type _v3 = (stack_obj_size) + 0)(stack_obj_size)_ZZZZ3 (stack_obj_size)__auto_type _v3 = (stack_obj_size) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(4, (void *)stack_buf_start) = ((void *)stack_buf_start) + 0)(__auto_type _v4 = ((void *)stack_buf_start) + 0)((void *)stack_buf_start)_ZZZZ4 ((void *)stack_buf_start)__auto_type _v4 = ((void *)stack_buf_start) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(5, stack_buf_size) = (stack_buf_size) + 0)(__auto_type _v5 = (stack_buf_size) + 0)(stack_buf_size)_ZZZZ5 (stack_buf_size)__auto_type _v5 = (stack_buf_size) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(6, (void *)stack_ptr) = ((void *)stack_ptr) + 0)(__auto_type _v6 = ((void *)stack_ptr) + 0)((void *)stack_ptr)_ZZZZ6 ((void *)stack_ptr)__auto_type _v6 = ((void *)stack_ptr) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)_,"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6_v1 , _v2 , _v3 , _v4 , _v5 , _v6_ZZZZ7 ( )static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p";)NUM_VA_ARGS_LESS_1("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))(((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))REVERSE_ARGS(_v1 , _v2 , _v3 , _v4 , _v5 , _v6)_v2 , _v3 , _v4 , _v5 , _v6_v3 , _v4 , _v5 , _v6_v4 , _v5 , _v6_v5 , _v6_ZZZZ6 (0)((0 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0))) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))0, 0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))( bool can_simple = LOG_MSG_SIMPLE_CHECK("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 4U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_6("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))_LOG_MSG_SIMPLE_XXXX6_XXXX_LOG_MSG_SIMPLE_XXXX6_XXXX_LOG_MSG_SIMPLE_XXXX6 (1)_XXXX0 ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK_6("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", stack, new_thread, stack_obj_size, (void *)stack_buf_start, stack_buf_size, (void *)stack_ptr)))("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6)(COND_CODE_0(NUM_VA_ARGS_LESS_1("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))))(_fmt, _v1 , _v2 , _v3 , _v4 , _v5 , _v6)(_fmt, GET_ARGS_LESS_N(1, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))_ZZZZ6 (_fmt)_fmt, _v1 , _v2 , _v3 , _v4 , _v5 , _v6_XXXXCONFIG_LOG_FMT_SECTION (_fmt, _v1 , _v2 , _v3 , _v4 , _v5 , _v6)_ZZZZ7 (((void *)0))( LOG_MSG_SIMPLE_FUNC(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6); )( z_log_msg_simple_create_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 4U, GET_ARG_N(1, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6)))(z_log_msg_simple_create_0(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"))(COND_CODE_1(6, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy) )( z_log_msg_simple_create_1(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy, dummy) )( z_log_msg_simple_create_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy_v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy_v2 , _v3 , _v4 , _v5 , _v6, dummy"stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy, dummy_v1 , _v2 , _v3 , _v4 , _v5 , _v6, dummy, dummy_v2 , _v3 , _v4 , _v5 , _v6, dummy, dummy_v3 , _v4 , _v5 , _v6, dummy, dummy_XXXX6_XXXX6 ( z_log_msg_simple_create_1(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ6 (z_log_msg_simple_create_0(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"))_XXXX0 ( z_log_msg_simple_create_2(_src, 4U, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))(((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((0) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((0) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((0) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((0) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6))(((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0))))((0 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v1) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (1 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v2) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (2 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v3) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (3 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v4) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (4 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v5) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)) + (5 < (((_flags) >> 3) & ((1UL << (3)) - 1UL)) ? 0 : _Generic((_v6) + 0, char * : 1, const char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((_flags) & (1UL << (0))) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)))REVERSE_ARGS("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p" , _v1 , _v2 , _v3 , _v4 , _v5 , _v6)_v6 , _v5 , _v4 , _v3 , _v2 , _v1 , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"_v5 , _v4 , _v3 , _v2 , _v1 , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"_v4 , _v3 , _v2 , _v1 , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"_v3 , _v2 , _v1 , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"_v2 , _v1 , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"_v1 , "stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0, long double : 1, default : 0) && !0)_Generic(("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0))_Generic(("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("stack %p for thread %p: obj_size=%zu buf_start=%p " " buf_size %zu stack_ptr=%p") + 0))%c: stack %p for thread %p: obj_size=%zu buf_start=%p  buf_size %zu stack_ptr=%p
char[82]stack %p for thread %p: obj_size=%zu buf_start=%p  buf_size %zu stack_ptr=%pchar[77]k_thread_stack_t **z_thread_stack_element **schedule_new_threadconst struct <unnamed>const struct <unnamed>[]struct <unnamed>[]state_stringconst struct <unnamed>[8]struct <unnamed>[8]const struct <unnamed> *"+"Z_STATE_STR_DUMMYchar[6]sizeof(Z_STATE_STR_DUMMY)sizeof(Z_STATE_STR_DUMMY) - 1Z_STATE_STR_PENDINGsizeof(Z_STATE_STR_PENDING)sizeof(Z_STATE_STR_PENDING) - 1prestartZ_STATE_STR_PRESTARTsizeof(Z_STATE_STR_PRESTART)sizeof(Z_STATE_STR_PRESTART) - 1deadZ_STATE_STR_DEADsizeof(Z_STATE_STR_DEAD)sizeof(Z_STATE_STR_DEAD) - 1suspendedZ_STATE_STR_SUSPENDEDsizeof(Z_STATE_STR_SUSPENDED)sizeof(Z_STATE_STR_SUSPENDED) - 1abortingZ_STATE_STR_ABORTINGsizeof(Z_STATE_STR_ABORTING)sizeof(Z_STATE_STR_ABORTING) - 1suspendingZ_STATE_STR_SUSPENDINGsizeof(Z_STATE_STR_SUSPENDING)sizeof(Z_STATE_STR_SUSPENDING) - 1queuedZ_STATE_STR_QUEUEDchar[7]sizeof(Z_STATE_STR_QUEUED)sizeof(Z_STATE_STR_QUEUED) - 1copy_bytesbytes_to_copydest_sizesrc_sizename_set__static_thread_data_list_end__static_thread_data_list_start"queued""suspending""aborting""suspended""dead""prestart""pending""dummy"_FOREACH_STATIC_THREAD(thread_data)STRUCT_SECTION_FOREACH(_static_thread_data, thread_data)defined(CONFIG_STACK_GROWS_UP)CONFIG_INIT_STACKSCONFIG_IRQ_OFFLOAD_NESTEDCONFIG_STACK_GROWS_UPdefined(CONFIG_SCHED_THREAD_USAGE) && !defined(CONFIG_USE_SWITCH)CONFIG_TRACING/* Retrieve the usage stats for each core and amalgamate them. *//* Dummy thread won't have TLS set up to run arbitrary code *//* CONFIG_INIT_STACKS && CONFIG_THREAD_STACK_INFO *//* First 4 bytes of the stack buffer reserved for the
		 * sentinel value, it won't be 0xAAAAAAAA for thread
		 * stacks.
		 *
		 * FIXME: thread->stack_info.start ought to reflect
		 * this!
		 *//* TODO: We could add an arch_ API call to temporarily
		 * disable the stack checking in the CPU, but this would
		 * need to be properly managed wrt context switches/interrupts
		 *//* If we are currently running on the stack being analyzed, some
	 * memory management hardware will generate an exception if we
	 * read unused stack memory.
	 *
	 * This never happens when invoked from user mode, as user mode
	 * will always run this function on the privilege elevation stack.
	 *//* Take the address of any local variable as a shallow bound for the
	 * stack pointer.  Addresses above it are guaranteed to be
	 * accessible.
	 *//* Make offload_sem visible outside under testing, in order to release
 * it outside when error happened.
 *//* These spinlock assertion predicates are defined here because having
 * them in spinlock.h is a giant header ordering headache.
 *//* XXX In this case we do not reset the stack *//* swap_data does not need to be initialized *//* k_q_node is initialized upon first insertion in a list *//*
	 * Non-legacy static threads may be started immediately or
	 * after a previously specified delay. Even though the
	 * scheduler is locked, ticks can still be delivered and
	 * processed. Take a sched lock to prevent them from running
	 * until they are all started.
	 *
	 * Note that static threads defined using the legacy API have a
	 * delay of K_FOREVER.
	 *//* Check validity of prio argument; must be the same or worse priority
	 * than the caller
	 *//* User threads may only create other user threads and they can't
	 * be marked as essential
	 *//* Testing less-than-or-equal since additional room may have been
	 * allocated for alignment constraints
	 *//* Verify that the stack size passed in is OK by computing the total
	 * size and comparing it with the size value in the object metadata
	 *//* No need to check z_stack_is_user_capable(), it won't be in the
	 * object table if it isn't
	 *//* The thread and stack objects *must* be in an uninitialized state *//* _current may be null if the dummy thread is not used *//* allow all cpus *//* must specify only one cpu *//* Ensure NULL termination, truncate if longer *//* Initialize custom data field (value is opaque to kernel) *//* switch_handle must be non-null except when inside z_swap()
	 * for synchronization reasons.  Historically some notional
	 * USE_SWITCH architectures have actually ignored the field
	 *//* static threads overwrite it afterwards with real value *//* Check that the thread object is safe, but that the stack is
	 * still cached!
	 *//* Initialize various struct k_thread members *//* Any given thread has access to itself *//*
 * The provided stack_size value is presumed to be either the result of
 * K_THREAD_STACK_SIZEOF(stack), or the size value passed to the instance
 * of K_THREAD_STACK_DEFINE() which defined 'stack'.
 *//* Initial values. Arches which implement MPU guards that "borrow"
	 * memory from the stack buffer (not tracked in K_THREAD_STACK_RESERVED)
	 * will need to appropriately update this.
	 *
	 * The bounds tracked here correspond to the area of the stack object
	 * that the thread can access, which includes TLS.
	 *//* reserve space on highest memory of stack buffer for local data *//* TLS is always last within the stack buffer *//* Put the stack sentinel at the lowest 4 bytes of the stack area.
	 * We periodically check that it's still present and kill the thread
	 * if it isn't.
	 *//* Initial stack pointer at the high end of the stack object, may
	 * be reduced later in this function by TLS or random offset
	 *//* Object cannot host a user mode thread *//* CONFIG_STACK_POINTER_RANDOM *//* CONFIG_STACK_GROWS_UP *//* This is so rare not bothering for now *//* Don't need to worry about alignment of the size here,
	 * arch_new_thread() is required to do it.
	 *
	 * FIXME: Not the best way to get a random number in a range.
	 * See #6493
	 *//* Restore it so further checks don't trigger this same error *//* Check that the stack sentinel is still present
 *
 * The stack sentinel feature writes a magic value to the lowest 4 bytes of
 * the thread's stack when the thread is initialized. This value gets checked
 * in a few places:
 *
 * 1) In k_yield() if the current thread is not swapped out
 * 2) After servicing a non-nested interrupt
 * 3) In z_swap(), check the sentinel in the outgoing thread
 *
 * Item 2 requires support in arch/ code.
 *
 * If the check fails, the thread will be terminated appropriately through
 * the system fatal error handler.
 *//* Special case: we allow reading the names of initialized threads
	 * even if we don't have permission on them
	 *//*
	 * Loop through each bit in the thread_state. Stop once all have
	 * been processed. If more than one thread_state bit is set, then
	 * separate the descriptive strings with a '+'.
	 *//* Reserve 1 byte for end-of-string character *//* In theory we could copy directly into thread->name, but
	 * the current z_vrfy / z_impl split does not provide a
	 * means of doing so.
	 *//*
 * Remove a thread from the kernel's list of active threads.
 *//* CONFIG_THREAD_CUSTOM_DATA *//*
 * This routine indicates if the current thread is an essential system thread.
 *
 * Returns true if current thread is essential, false if it is not.
 *//*
 * This function tags the current thread as not essential to system operation.
 * Exceptions raised by this thread may be recoverable.
 * (This is the default tag for a thread.)
 *//*
 * This function tags the current thread as essential to system operation.
 * Exceptions raised by this thread will be treated as a fatal system error.
 *//*
	 * Lock is needed to make sure that the _kernel.threads is not being
	 * modified by the user_cb either directly or indirectly.
	 * The indirect ways are through calling k_thread_create and
	 * k_thread_abort from user_cb.
	 *//* This lock protects the linked list of active threads; i.e. the
 * initial _kernel.threads pointer and the linked list made up of
 * thread->next_thread (until NULL)
 *//**
 * @file
 * @brief Kernel thread support
 *
 * This module provides general purpose thread support.
 *//home/haojie/zephyrproject/zephyr/kernel/timeout.cremainingdt&timeout_locktimeout_rem!sys_dnode_is_linked(&to->node)timeout.ticksnext_timeoutticks_elapsedCONFIG_SYSTEM_CLOCK_SLOPPY_IDLE_XXXXCONFIG_SYSTEM_CLOCK_SLOPPY_IDLE_XXXXCONFIG_SYSTEM_CLOCK_SLOPPY_IDLE 1to->dticks - ticks_elapsed(int64_t)INT_MAXMAX_WAITelapsedremove_timeoutstruct _timeoutSAME_TYPE(*(n), ((struct _timeout *)0)->node) || SAME_TYPE(*(n), void)__builtin_types_compatible_p(__typeof__(*(n)), __typeof__(((struct _timeout *)0)->node)) || __builtin_types_compatible_p(__typeof__(*(n)), __typeof__(void))((struct _timeout *)0)->nodefirstSAME_TYPE(*(t), ((struct _timeout *)0)->node) || SAME_TYPE(*(t), void)__builtin_types_compatible_p(__typeof__(*(t)), __typeof__(((struct _timeout *)0)->node)) || __builtin_types_compatible_p(__typeof__(*(t)), __typeof__(void))*(t)announce_remainingtimeout_locktimeout_list&timeout_listcurr_tick(IS_ENABLED(CONFIG_SYSTEM_CLOCK_SLOPPY_IDLE) ? K_TICKS_FOREVER : INT_MAX)__UINT64_MAX__/* We release the lock around the callbacks below, so on SMP
	 * systems someone might be already running the loop.  Don't
	 * race (which will cause paralllel execution of "sequential"
	 * timeouts and confuse apps), just increment the tick count
	 * and return.
	 *//* must be locked *//* While sys_clock_announce() is executing, new relative timeouts will be
	 * scheduled relatively to the currently firing timeout's original tick
	 * value (=curr_tick) rather than relative to the current
	 * sys_clock_elapsed().
	 *
	 * This means that timeouts being scheduled from within timeout callbacks
	 * will be scheduled at well-defined offsets from the currently firing
	 * timeout.
	 *
	 * As a side effect, the same will happen if an ISR with higher priority
	 * preempts a timeout callback and schedules a timeout.
	 *
	 * The distinction is implemented by looking at announce_remaining which
	 * will be non-zero while sys_clock_announce() is executing and zero
	 * otherwise.
	 *//* Ticks left to process in the currently-executing sys_clock_announce() *//home/haojie/zephyrproject/zephyr/kernel/timer.cstatus_syncstopinactiveduration, periodduration.ticksduration.ticks - 1struct k_timerSAME_TYPE(*(t), ((struct k_timer *)0)->timeout) || SAME_TYPE(*(t), void)__builtin_types_compatible_p(__typeof__(*(t)), __typeof__(((struct k_timer *)0)->timeout)) || __builtin_types_compatible_p(__typeof__(*(t)), __typeof__(void))((struct k_timer *)0)->timeouttimer->periodnext.ticks - 1k_uptime_ticks() + 1 + next.ticksZ_TICK_ABS((k_ticks_t)MAX(k_uptime_ticks() + 1 + next.ticks, 0))(((k_ticks_t) -1) - 1 - ((k_ticks_t)(((k_uptime_ticks() + 1 + next.ticks) > (0)) ? (k_uptime_ticks() + 1 + next.ticks) : (0))))(k_ticks_t)MAX(k_uptime_ticks() + 1 + next.ticks, 0)(k_ticks_t)(((k_uptime_ticks() + 1 + next.ticks) > (0)) ? (k_uptime_ticks() + 1 + next.ticks) : (0))/* Initialize and link statically defined timers *//* Initialize timer object type *//**
	 * @note	New tracing hook
	 *//* timer has already expired at least once *//* timer is already stopped *//* get updated timer status *//* wait for timer to expire or stop *//* z_add_timeout() always adds one to the incoming tick count
	 * to round up to the next tick (by convention it waits for
	 * "at least as long as the specified timeout"), but the
	 * period interval is always guaranteed to be reset from
	 * within the timer ISR, so no round up is desired and 1 is
	 * subtracted in there.
	 *
	 * Note that the duration (!) value gets the same treatment
	 * for backwards compatibility.  This is unfortunate
	 * (i.e. k_timer_start() doesn't treat its initial sleep
	 * argument the same way k_sleep() does), but historical.  The
	 * timer_api test relies on this behavior.
	 *//* Acquire spinlock to ensure safety during concurrent calls to
	 * k_timer_start for scheduling or rescheduling. This is necessary
	 * since k_timer_start can be preempted, especially for the same
	 * timer instance.
	 *//* Unlock for user handler. *//* invoke timer expiry function *//* update timer's status *//* Exploit the fact that uptime during a kernel
		 * timeout handler reflects the time of the scheduled
		 * event and not real time to get some inexpensive
		 * protection against late interrupts.  If we're
		 * delayed for any reason, we still end up calculating
		 * the next expiration as a regular stride from where
		 * we "should" have run.  Requires absolute timeouts.
		 * (Note offset by one: we're nominally at the
		 * beginning of a tick, so need to defeat the "round
		 * down" behavior on timeout addition).
		 *//* see note about z_add_timeout() in z_impl_k_timer_start() *//*
	 * if the timer is periodic, start it again; don't add _TICK_ALIGN
	 * since we're already aligned to a tick boundary
	 *//* In sys_clock_announce(), when a timeout expires, it is first removed
	 * from the timeout list, then its expiration handler is called (with
	 * unlocked interrupts). For kernel timers, the expiration handler is
	 * this function. Usually, the timeout structure related to the timer
	 * that is handled here will not be linked to the timeout list at this
	 * point. But it may happen that before this function is executed and
	 * interrupts are locked again, a given timer gets restarted from an
	 * interrupt context that has a priority higher than the system timer
	 * interrupt. Then, the timeout structure for this timer will turn out
	 * to be linked to the timeout list. And in such case, since the timer
	 * was restarted, its expiration handler should not be executed then,
	 * so the function exits immediately.
	 *//**
 * @brief Handle expiration of a kernel timer object.
 *
 * @param t  Timeout used by the timer.
 *//*
 * Copyright (c) 1997-2016 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */KERNEL_VERSION_STRING"3.5.99"KERNEL_PATCHLEVELKERNEL_VERSION_MINORKERNEL_VERSION_MAJORKERNEL_VERSION_NUMBER0x30563KERNELVERSION0x3056300ZEPHYR_VERSION(a,b,c)(((a) << 16) + ((b) << 8) + (c))ZEPHYR_VERSION_CODE197987_KERNEL_VERSION_H_/* _KERNEL_VERSION_H_ *//*  values come from cmake/version.cmake
 * BUILD_VERSION related  values will be 'git describe',
 * alternatively user defined BUILD_VERSION.
 *//home/haojie/zephyrproject/zephyr/kernel/version.c"version.h"50684672/* generated by MAKE, at compile time *//*
 * Copyright (c) 1997-2010, 2012-2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/kernel/work.cdwork != NULLsync != NULL!k_is_in_isr()flush_delayablez_work_flusher *sync, falsek_work_q **need_flushsync, need_flushcancel_delayable_syncz_work_canceller *need_waitsync, pendingcancel_delayablerescheduledelay, retreschedule_for_queuedwork, delaydwork, delay, retscheduleschedule_for_queue~K_WORK_RUNNINGcancel_delayable_async_lockedunschedule_lockedschedule_for_queue_locked 1work_delayable_busy_get_lockedhandler != NULLwork_timeoutSAME_TYPE(*(to), ((struct k_work_delayable *)0)->timeout) || SAME_TYPE(*(to), void)__builtin_types_compatible_p(__typeof__(*(to)), __typeof__(((struct k_work_delayable *)0)->timeout)) || __builtin_types_compatible_p(__typeof__(*(to)), __typeof__(void))*(to)((struct k_work_delayable *)0)->timeoutdwwpk_work_queueunplug-120-EALREADYdrainK_WORK_QUEUE_BUSY | K_WORK_QUEUE_DRAIN(K_WORK_QUEUE_BUSY | K_WORK_QUEUE_DRAIN)!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)queue != NULLwork_queue_mainstruct k_workSAME_TYPE(*(node), ((struct k_work *)0)->node) || SAME_TYPE(*(node), void)__builtin_types_compatible_p(__typeof__(*(node)), __typeof__(((struct k_work *)0)->node)) || __builtin_types_compatible_p(__typeof__(*(node)), __typeof__(void))((struct k_work *)0)->nodequeuepworkq_ptrwork != NULL!flag_test(&work->flags, K_WORK_DELAYABLE_BIT)cancel_synccancelcancel_sync_lockedcancel_async_lockedwork_flush_lockedK_WORK_QUEUED | K_WORK_RUNNING(K_WORK_QUEUED | K_WORK_RUNNING)submitsubmit_to_queuework, retz_work_submit_to_queuework->handler != NULLsubmit_to_queue_lockedwork->queue != NULLqueue_submit_lockedchaineddrainingpluggednotify_queue_lockedqueue_remove_lockedqueue_flusher_lockedin_listwn&queue->pendingsys_slist_peek_head(&queue->pending)(sys_slist_peek_head(&queue->pending))__typeof__(*(wn))SAME_TYPE(*((sys_slist_peek_head(&queue->pending))), ((__typeof__(*(wn)) *)0)->node) || SAME_TYPE(*((sys_slist_peek_head(&queue->pending))), void)__builtin_types_compatible_p(__typeof__(*((sys_slist_peek_head(&queue->pending)))), __typeof__(((__typeof__(*(wn)) *)0)->node)) || __builtin_types_compatible_p(__typeof__(*((sys_slist_peek_head(&queue->pending)))), __typeof__(void))*((sys_slist_peek_head(&queue->pending)))((__typeof__(*(wn)) *)0)->nodesys_slist_peek_next(&((wn)->node))(sys_slist_peek_next(&((wn)->node)))SAME_TYPE(*((sys_slist_peek_next(&((wn)->node)))), ((__typeof__(*(wn)) *)0)->node) || SAME_TYPE(*((sys_slist_peek_next(&((wn)->node)))), void)__builtin_types_compatible_p(__typeof__(*((sys_slist_peek_next(&((wn)->node))))), __typeof__(((__typeof__(*(wn)) *)0)->node)) || __builtin_types_compatible_p(__typeof__(*((sys_slist_peek_next(&((wn)->node))))), __typeof__(void))*((sys_slist_peek_next(&((wn)->node))))work_busy_get_lockedfinalize_cancel_lockedwctmp&pending_cancelssys_slist_peek_head(&pending_cancels)(sys_slist_peek_head(&pending_cancels))__typeof__(*(wc))SAME_TYPE(*((sys_slist_peek_head(&pending_cancels))), ((__typeof__(*(wc)) *)0)->node) || SAME_TYPE(*((sys_slist_peek_head(&pending_cancels))), void)__builtin_types_compatible_p(__typeof__(*((sys_slist_peek_head(&pending_cancels)))), __typeof__(((__typeof__(*(wc)) *)0)->node)) || __builtin_types_compatible_p(__typeof__(*((sys_slist_peek_head(&pending_cancels)))), __typeof__(void))*((sys_slist_peek_head(&pending_cancels)))((__typeof__(*(wc)) *)0)->nodesys_slist_peek_next(&((wc)->node))(sys_slist_peek_next(&((wc)->node)))SAME_TYPE(*((sys_slist_peek_next(&((wc)->node)))), ((__typeof__(*(wc)) *)0)->node) || SAME_TYPE(*((sys_slist_peek_next(&((wc)->node)))), void)__builtin_types_compatible_p(__typeof__(*((sys_slist_peek_next(&((wc)->node))))), __typeof__(((__typeof__(*(wc)) *)0)->node)) || __builtin_types_compatible_p(__typeof__(*((sys_slist_peek_next(&((wc)->node))))), __typeof__(void))*((sys_slist_peek_next(&((wc)->node))))init_work_cancelinit_flusherhandle_flushstruct z_work_flusherSAME_TYPE(*(work), ((struct z_work_flusher *)0)->work) || SAME_TYPE(*(work), void)__builtin_types_compatible_p(__typeof__(*(work)), __typeof__(((struct z_work_flusher *)0)->work)) || __builtin_types_compatible_p(__typeof__(*(work)), __typeof__(void))((struct z_work_flusher *)0)->workflags_getflags_setflag_test_and_clearflag_testflag_setflag_clearpending_cancels/* If necessary wait until the flusher item completes *//* Wait for it to finish *//* If unscheduling did something then submit it.  Ignore a
	 * failed submission (e.g. when cancelling).
	 *//* If it's idle release the lock and return immediately. *//* Schedule the work item with the new parameters. *//* Remove any active scheduling. *//* Schedule the work item if it's idle or running. *//* Full cancellation of a delayable work item.
 *
 * Unschedules the delayed part then delegates to standard work
 * cancellation.
 *
 * Invoked with work lock held.
 *
 * @param dwork delayable work item
 *
 * @return k_work_busy_get() flags
 *//* If scheduled, try to cancel.  If it fails, that means the
	 * callback has been dequeued and will inevitably run (or has
	 * already run), so treat that as "undelayed" and return
	 * false.
	 *//* Unschedule delayable work.
 *
 * If the work is delayed, cancel the timeout and clear the delayed
 * flag.
 *
 * Invoked with work lock held.
 *
 * @param dwork pointer to delayable work structure.
 *
 * @return true if and only if work had been delayed so the timeout
 * was cancelled.
 *//* Add timeout *//* Attempt to schedule a work item for future (maybe immediate)
 * submission.
 *
 * Invoked with work lock held.
 *
 * See also submit_to_queue_locked(), which implements this for a no-wait
 * delay.
 *
 * Invoked with work lock held.
 *
 * @param queuep pointer to a pointer to a queue.  On input this
 * should dereference to the proposed queue (which may be null); after
 * completion it will be null if the work was not submitted or if
 * submitted will reference the queue it was submitted to.  That may
 * or may not be the queue provided on input.
 *
 * @param dwork the delayed work structure
 *
 * @param delay the delay to use before scheduling.
 *
 * @retval from submit_to_queue_locked() if delay is K_NO_WAIT; otherwise
 * @retval 1 to indicate successfully scheduled.
 *//* If the work is still marked delayed (should be) then clear that
	 * state and submit it to the queue.  If successful the queue will be
	 * notified of new work at the next reschedule point.
	 *
	 * If not successful there is no notification that the work has been
	 * abandoned.  Sorry.
	 *//* Timeout handler for delayable work.
 *
 * Invoked by timeout infrastructure.
 * Takes and releases work lock.
 * Conditionally reschedules.
 *//* It hasn't actually been started yet, but all the state is in place
	 * so we can submit things and once the thread gets control it's ready
	 * to roll.
	 *//* Optionally yield to prevent the work queue from
		 * starving other threads.
		 *//* Mark the work item as no longer running and deal
		 * with any cancellation issued while it was running.
		 * Clear the BUSY flag and optionally yield to prevent
		 * starving other threads.
		 *//* Nothing's had a chance to add work since we took
			 * the lock, and we didn't find work nor got asked to
			 * stop.  Just go to sleep: when something happens the
			 * work thread will be woken and we can check again.
			 *//* No work is available and no queue state requires
			 * special handling.
			 *//* Not busy and draining: move threads waiting for
			 * drain to ready state.  The held spinlock inhibits
			 * immediate reschedule; released threads get their
			 * chance when this invokes z_sched_wait() below.
			 *
			 * We don't touch K_WORK_QUEUE_PLUGGABLE, so getting
			 * here doesn't mean that the queue will allow new
			 * submissions.
			 *//* Static code analysis tool can raise a false-positive violation
			 * in the line below that 'work' is checked for null after being
			 * dereferenced.
			 *
			 * The work is figured out by CONTAINER_OF, as a container
			 * of type struct k_work that contains the node.
			 * The only way for it to be NULL is if node would be a member
			 * of struct k_work object that has been placed at address NULL,
			 * which should never happen, even line 'if (work != NULL)'
			 * ensures that.
			 * This means that if node is not NULL, then work will not be NULL.
			 *//* Mark that there's some work active that's
			 * not on the pending list.
			 *//* Check for and prepare any new work. *//* Loop executed by a work queue thread.
 *
 * @param workq_ptr pointer to the work queue structure
 *//* If something's still running then we have to wait for
	 * completion, which is indicated when finish_cancel() gets
	 * invoked.
	 *//* Complete cancellation necessary, release work lock, and wait if
 * necessary.
 *
 * Invoked with work lock held by key.
 * Sleeps.
 *
 * @param work work that is being canceled
 * @param canceller state used to synchronize the cancellation
 * @param key used by work lock
 *
 * @retval true if and only if the work was still active on entry.  The caller
 * must wait on the canceller semaphore after releasing the lock.
 *
 * @retval false if work was idle on entry.  The caller need not wait.
 *//* If it's still busy after it's been dequeued, then flag it
	 * as canceling.
	 *//* Remove it from the queue, if it's queued. *//* If we haven't already started canceling, do it now. *//* Execute the non-waiting steps necessary to cancel a work item.
 *
 * Invoked with work lock held.
 *
 * @param work the work item to be canceled.
 *
 * @retval true if we need to wait for the work item to finish canceling
 * @retval false if the work item is idle
 *
 * @return k_busy_wait() captured under lock
 *//* Flush the work item if necessary.
 *
 * Flushing is necessary only if the work is either queued or running.
 *
 * Invoked with work lock held by key.
 * Sleeps.
 *
 * @param work the work item that is to be flushed
 * @param flusher state used to synchronize the flush
 *
 * @retval true if work is queued or running.  If this happens the
 * caller must take the flusher semaphore after releasing the lock.
 *
 * @retval false otherwise.  No wait required.
 *//* submit_to_queue_locked() won't reschedule on its own
	 * (really it should, otherwise this process will result in
	 * spurious calls to z_swap() due to the race), so do it here
	 * if the queue state changed.
	 *//* Submit work to a queue but do not yield the current thread.
 *
 * Intended for internal use.
 *
 * See also submit_to_queue_locked().
 *
 * @param queuep pointer to a queue reference.
 * @param work the work structure to be submitted
 *
 * @retval see submit_to_queue_locked()
 *//* Already queued, do nothing. *//* If the work is currently running we have to use the
		 * queue it's running on to prevent handler
		 * re-entrancy.
		 *//* If no queue specified resubmit to last queue.
		 *//* Not currently queued *//* Disallowed *//* Attempt to submit work to a queue.
 *
 * The submission can fail if:
 * * the work is cancelling,
 * * no candidate queue can be identified;
 * * the candidate queue rejects the submission.
 *
 * Invoked with work lock held.
 * Conditionally notifies queue.
 *
 * @param work the work structure to be submitted

 * @param queuep pointer to a queue reference.  On input this should
 * dereference to the proposed queue (which may be null); after completion it
 * will be null if the work was not submitted or if submitted will reference
 * the queue it was submitted to.  That may or may not be the queue provided
 * on input.
 *
 * @retval 0 if work was already submitted to a queue
 * @retval 1 if work was not submitted and has been queued to @p queue
 * @retval 2 if work was running and has been queued to the queue that was
 * running it
 * @retval -EBUSY if canceling or submission was rejected by queue
 * @retval -EINVAL if no queue is provided
 * @retval -ENODEV if the queue is not started
 *//* Test for acceptability, in priority order:
	 *
	 * * -ENODEV if the queue isn't running.
	 * * -EBUSY if draining and not chained
	 * * -EBUSY if plugged and not draining
	 * * otherwise OK
	 *//* Submit an work item to a queue if queue state allows new work.
 *
 * Submission is rejected if no queue is provided, or if the queue is
 * draining and the work isn't being submitted from the queue's
 * thread (chained submission).
 *
 * Invoked with work lock held.
 * Conditionally notifies queue.
 *
 * @param queue the queue to which work should be submitted.  This may
 * be null, in which case the submission will fail.
 *
 * @param work to be submitted
 *
 * @retval 1 if successfully queued
 * @retval -EINVAL if no queue is provided
 * @retval -ENODEV if the queue is not started
 * @retval -EBUSY if the submission was rejected (draining, plugged)
 *//* Potentially notify a queue that it needs to look for pending work.
 *
 * This may make the work queue thread ready, but as the lock is held it
 * will not be a reschedule point.  Callers should yield after the lock is
 * released where appropriate (generally if this returns true).
 *
 * @param queue to be notified.  If this is null no notification is required.
 *
 * @return true if and only if the queue was notified and woken, i.e. a
 * reschedule is pending.
 *//* Try to remove a work item from the given queue.
 *
 * Invoked with work lock held.
 *
 * @param queue the queue from which the work should be removed
 * @param work work that may be on the queue
 *//* Determine whether the work item is still queued. *//* Add a flusher work item to the queue.
 *
 * Invoked with work lock held.
 *
 * Caller must notify queue of pending work.
 *
 * @param queue queue on which a work item may appear.
 * @param work the work item that is either queued or running on @p
 * queue
 * @param flusher an uninitialized/unused flusher object
 *//* Search for and remove the matching container, and release
	 * what's waiting for the completion.  The same work item can
	 * appear multiple times in the list if multiple threads
	 * attempt to cancel it.
	 *//* Clear this first, so released high-priority threads don't
	 * see it when doing things.
	 *//* Complete cancellation of a work item and unlock held lock.
 *
 * Invoked with work lock held.
 *
 * Invoked from a work queue thread.
 *
 * Reschedules.
 *
 * @param work the work structure that has completed cancellation
 *//* Initialize a canceler record and add it to the list of pending
 * cancels.
 *
 * Invoked with work lock held.
 *
 * @param canceler the structure used to notify a waiting process.
 * @param work the work structure that is to be canceled
 *//* List of pending cancellations. *//* Invoked by work thread *//* Lock to protect the internal state of all work items, work queues,
 * and pending_cancels.
 *//**
 * @file
 *
 * Second generation work queue implementation
 *//*
 * Copyright (c) 2020 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 */cancelerflagp/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/machine/stdlib.h_MACHSTDLIB_H_/* _MACHSTDLIB_H_ *//* place holder so platforms may add stdlib.h extensions *//home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/ssp/stdlib.hwctomb(char *__buf, wchar_t __wc)MB_CUR_MAX__locale_mb_cur_max()__ssp_bos__ssp_real_wctombwcstombs(char *__buf, const wchar_t *__src, size_t __len)(__buf, __src, __len)__buf != NULL__buf != ((void *)0)__len__ssp_real_wcstombsmbstowcs(wchar_t *__buf, const char *__src, size_t __n)__n * sizeof(wchar_t)__ssp_real_mbstowcs_SSP_STDLIB_H_"wctomb""wcstombs""mbstowcs"/* _SSP_STDLIB_H_ *//* Copyright (c) 2017 Yaakov Selkowitz <yselkowi@redhat.com> */__wc__src/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/stdlib.h<ssp/stdlib.h><machine/stdlib.h>quick_exitat_quick_exit__eprintf__ldtoa__dtoaposix_memalignunsetenvstrtoullstrtolllldivllabsatollrand_r__utoa__itoasetenv_Exitsystemstrtoulstrtolstrfromlstrfromfstrtoldstrtofstrfromdstrtodsrandreallocrandqsortmkstempmkdtempmbtowcwchar_t *__restrict__mblenvallocldivlabsgetsuboptchar *constchar *const *_findenvgetenvexitdivcallocbsearchatolatoiatofatexitabs__locale_mb_cur_max__compar_fn_tlldiv_tldiv_tdiv_tsuboptargATEXIT_MAXRAND_MAXEXIT_SUCCESSEXIT_FAILURE__compar_fn_t_defined_STDLIB_H___BSD_VISIBLE || __POSIX_VISIBLE >= 200809__MISC_VISIBLE || __POSIX_VISIBLE >= 200112 || __XSI_VISIBLE >= 4__BSD_VISIBLE || (__XSI_VISIBLE >= 4 && __POSIX_VISIBLE < 200112)__BSD_VISIBLE || __XSI_VISIBLE >= 4strtodf__SVID_VISIBLE || __XSI_VISIBLE >= 4__SVID_VISIBLE || __XSI_VISIBLE__BSD_VISIBLE || __POSIX_VISIBLE >= 200112__SVID_VISIBLE || __XSI_VISIBLE >= 4 || __BSD_VISIBLE__ISO_C_VISIBLE >= 2011(__noreturn__)/* _STDLIB_H_ *//* __ISO_C_VISIBLE >= 2011 *//*
 * If we're in a mode greater than C99, expose C11 functions.
 *//* _HAVE_LONG_DOUBLE *//* On platforms where long double equals double.  *//* There are two common qsort_r variants.  If you request
   _BSD_SOURCE, you get the BSD version; otherwise you get the GNU
   version.  We want that #undef qsort_r will still let you
   invoke the underlying function, but that requires gcc support. *//* !__CYGWIN__ *//* __SVID_VISIBLE || __XSI_VISIBLE *//* the following strtodf interface is deprecated...use strtof instead *//* getsubopt(3) external variable *//* remainder *//* quotient *//*
 * stdlib.h
 *
 * Definitions for common types, variables, and functions.
 */alloc_align__string__end_PTR__base__denom__nptr__seed__overwrite__statusfp_compar__func/home/haojie/zephyrproject/zephyr/lib/libc/common/source/stdlib/abort.c<stdlib.h>abort()
"abort()\n"/*
 * Copyright (c) 2020 Linaro Limited
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/lib/libc/common/source/stdlib/home/haojie/zephyrproject/zephyr/lib/libc/common/source/home/haojie/zephyrproject/zephyr/lib/libc/common/home/haojie/zephyrproject/zephyr/lib/libc/home/haojie/zephyrproject/zephyr/libu64_count_trailing_zeros__builtin_ctzllu32_count_trailing_zerosu64_count_leading_zeros__builtin_clzllu32_count_leading_zerossize_mul_overflow__builtin_mul_overflowu64_mul_overflowuint64_t *u32_mul_overflowu16_mul_overflowsize_add_overflow__builtin_add_overflowu64_add_overflowu32_add_overflowu16_add_overflowuse_builtinuse_builtin(x)ZEPHYR_INCLUDE_SYS_MATH_EXTRAS_H_PORTABLE_MISC_MATH_EXTRASuse_builtin(__builtin_add_overflow)use_builtin(__builtin_mul_overflow)use_builtin(__builtin_clz)use_builtin(__builtin_clzll)use_builtin(__builtin_ctz)use_builtin(__builtin_ctzll)/* use_builtin(__builtin_ctzll) *//* !use_builtin(__builtin_ctzll) *//* use_builtin(__builtin_ctz) *//* !use_builtin(__builtin_ctz) *//* use_builtin(__builtin_clzll) *//* !use_builtin(__builtin_clzll) *//* use_builtin(__builtin_clz) *//* !use_builtin(__builtin_clz) *//*
 * The GCC builtins __builtin_clz(), __builtin_ctz(), and 64-bit
 * variants are described by the GCC documentation as having undefined
 * behavior when the argument is zero. See
 * https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html.
 *
 * The undefined behavior applies to all architectures, regardless of
 * the behavior of the instruction used to implement the builtin.
 *
 * We don't want to expose users of this API to the undefined behavior,
 * so we use a conditional to explicitly provide the correct result when
 * x=0.
 *
 * Most instruction set architectures have a CLZ instruction or similar
 * that already computes the correct result for x=0. Both GCC and Clang
 * know this and simply generate a CLZ instruction, optimizing away the
 * conditional.
 *
 * For x86, and for compilers that fail to eliminate the conditional,
 * there is often another opportunity for optimization since code using
 * these functions tends to contain a zero check already. For example,
 * from kernel/sched.c:
 *
 *	struct k_thread *z_priq_mq_best(struct _priq_mq *pq)
 *	{
 *		if (!pq->bitmask) {
 *			return NULL;
 *		}
 *
 *		struct k_thread *thread = NULL;
 *		sys_dlist_t *l =
 *			&pq->queues[u32_count_trailing_zeros(pq->bitmask)];
 *
 *		...
 *
 * The compiler will often be able to eliminate the redundant x == 0
 * check after inlining the call to u32_count_trailing_zeros().
 *//* use_builtin(__builtin_mul_overflow) *//* !use_builtin(__builtin_mul_overflow) *//* use_builtin(__builtin_add_overflow) *//* !use_builtin(__builtin_add_overflow) *//*
 * Force the use of portable C code (no builtins) by defining
 * PORTABLE_MISC_MATH_EXTRAS before including <misc/math_extras.h>.
 * This is primarily for use by tests.
 *
 * We'll #undef use_builtin again at the end of the file.
 *//**
 * @file
 * @brief Inline implementation of functions declared in math_extras.h.
 *//*
 * Copyright (c) 2019 Facebook.
 *
 * SPDX-License-Identifier: Apache-2.0
 */<zephyr/sys/math_extras_impl.h>/* ZEPHYR_INCLUDE_SYS_MATH_EXTRAS_H_ *//**@}*//**
 * @brief Count the number of trailing zero bits in a 64-bit integer.
 * @param x Integer to count trailing zeros in.
 * @return Number of trailing zero bits in `x`.
 *//**
 * @brief Count the number of trailing zero bits in a 32-bit integer.
 * @param x Integer to count trailing zeros in.
 * @return Number of trailing zero bits in `x`.
 *//**@{*//**
 * @name Count trailing zeros.
 *
 * Count the number of trailing zero bits in the bitwise representation of `x`.
 * When `x = 0`, this is the size of `x` in bits.
 *//**
 * @brief Count the number of leading zero bits in a 64-bit integer.
 * @param x Integer to count leading zeros in.
 * @return Number of leading zero bits in `x`.
 *//**
 * @brief Count the number of leading zero bits in a 32-bit integer.
 * @param x Integer to count leading zeros in.
 * @return Number of leading zero bits in `x`.
 *//**
 * @name Count leading zeros.
 *
 * Count the number of leading zero bits in the bitwise representation of `x`.
 * When `x = 0`, this is the size of `x` in bits.
 *//**
 * @brief Multiply two size_t integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @brief Multiply two unsigned 64-bit integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @brief Multiply two unsigned 32-bit integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @brief Multiply two unsigned 16-bit integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @name Unsigned integer multiplication with overflow detection.
 *
 * These functions compute `a * b` and store the result in `*result`, returning
 * true if the operation overflowed.
 *//**
 * @brief Add two size_t integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @brief Add two unsigned 64-bit integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @brief Add two unsigned 32-bit integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @brief Add two unsigned 16-bit integers.
 * @param a First operand.
 * @param b Second operand.
 * @param result Pointer to the result.
 * @return true if the operation overflowed.
 *//**
 * @name Unsigned integer addition with overflow detection.
 *
 * These functions compute `a + b` and store the result in `*result`, returning
 * true if the operation overflowed.
 *//**
 * @brief Extra arithmetic and bit manipulation functions.
 * @defgroup math_extras Math extras
 * @ingroup utilities
 *
 * Portable wrapper functions for a number of arithmetic and bit-counting functions that are often
 * provided by compiler builtins. If the compiler does not have an appropriate builtin, a portable C
 * implementation is used instead.
 *
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/sys/mutex.hsys_mutex_unlocksys_mutex *sys_mutex_locksys_mutex_initsys_mutexkernel_mutexSYS_MUTEX_DEFINE(name)struct sys_mutex name = { .kernel_mutex = Z_MUTEX_INITIALIZER(name.kernel_mutex) }ZEPHYR_INCLUDE_SYS_MUTEX_H_/* ZEPHYR_INCLUDE_SYS_MUTEX_H_ *//* For now, make the syscall unconditionally *//**
 * @brief Unlock a mutex.
 *
 * This routine unlocks @a mutex. The mutex must already be locked by the
 * calling thread.
 *
 * The mutex cannot be claimed by another thread until it has been unlocked by
 * the calling thread as many times as it was previously locked by that
 * thread.
 *
 * @param mutex Address of the mutex, which may reside in user memory
 * @retval 0 Mutex unlocked
 * @retval -EACCES Caller has no access to provided mutex address
 * @retval -EINVAL Provided mutex not recognized by the kernel or mutex wasn't
 *                 locked
 * @retval -EPERM Caller does not own the mutex
 *//**
 * @brief Lock a mutex.
 *
 * This routine locks @a mutex. If the mutex is locked by another thread,
 * the calling thread waits until the mutex becomes available or until
 * a timeout occurs.
 *
 * A thread is permitted to lock a mutex it has already locked. The operation
 * completes immediately and the lock count is increased by 1.
 *
 * @param mutex Address of the mutex, which may reside in user memory
 * @param timeout Waiting period to lock the mutex,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 Mutex locked.
 * @retval -EBUSY Returned without waiting.
 * @retval -EAGAIN Waiting period timed out.
 * @retval -EACCES Caller has no access to provided mutex address
 * @retval -EINVAL Provided mutex not recognized by the kernel
 *//* Nothing to do, kernel-side data structures are initialized at
	 * boot
	 *//**
 * @brief Initialize a mutex.
 *
 * This routine initializes a mutex object, prior to its first use.
 *
 * Upon completion, the mutex is available and does not have an owner.
 *
 * This routine is only necessary to call when userspace is disabled
 * and the mutex was not created with SYS_MUTEX_DEFINE().
 *
 * @param mutex Address of the mutex.
 *//**
 * @brief Statically define and initialize a sys_mutex
 *
 * The mutex can be accessed outside the module where it is defined using:
 *
 * @code extern struct sys_mutex <name>; @endcode
 *
 * Route this to memory domains using K_APP_DMEM().
 *
 * @param name Name of the mutex.
 *//**
 * @defgroup user_mutex_apis User mode mutex APIs
 * @ingroup kernel_apis
 * @{
 *//* Currently unused, but will be used to store state for fast mutexes
	 * that can be locked/unlocked with atomic ops if there is no
	 * contention
	 *//*
 * sys_mutex behaves almost exactly like k_mutex, with the added advantage
 * that a sys_mutex instance can reside in user memory.
 *
 * Further enhancements will support locking/unlocking uncontended sys_mutexes
 * with simple atomic ops instead of syscalls, similar to Linux's
 * FUTEX_LOCK_PI and FUTEX_UNLOCK_PI
 *//home/haojie/zephyrproject/zephyr/include/zephyr/app_memory/app_memdomain.h/home/haojie/zephyrproject/zephyr/include/zephyr/sys/libc-hooks.h/home/haojie/zephyrproject/zephyr/build/zephyr/include/generated/syscalls/libc-hooks.h/home/haojie/zephyrproject/zephyr/lib/libc/common/source/stdlib/malloc.c<zephyr/sys/libc-hooks.h><zephyr/sys/mutex.h><zephyr/app_memory/app_memdomain.h>reallocarray__alignof__(z_max_align_t)malloc_prepareheap_baseheap_sizeHEAP_BASE((uintptr_t) (malloc_arena))malloc_arenaunsigned char[16384]HEAP_ALIGN16391malloc_unlockmalloc_locklock_retlock_ret == 0__init_malloc_preparez_malloc_heap_mutexz_malloc_heap_mutex.kernel_mutex&z_malloc_heap_mutex.kernel_mutex.wait_qz_malloc_heap.noinit."/home/haojie/zephyrproject/zephyr/lib/libc/common/source/stdlib/malloc.c".0"/home/haojie/zephyrproject/zephyr/lib/libc/common/source/stdlib/malloc.c"char[85]POINTER_TO_UINT(malloc_arena)HEAP_SIZEROUND_UP(CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE, HEAP_ALIGN)HEAP_STATICPOOL_SECTIONLOG_LEVEL(CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE != 0)Z_MALLOC_PARTITION_EXISTSdefined(CONFIG_MMU) && CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE < 0ALLOCATE_HEAP_AT_STARTUPdefined(CONFIG_MPU)defined(CONFIG_MPU_REQUIRES_POWER_OF_TWO_ALIGNMENT) && \(CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE & (CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE - 1)) != 0CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE > 0defined(CONFIG_XTENSA) && (defined(CONFIG_SOC_FAMILY_INTEL_ADSP) \CONFIG_GLIBCXX_LIBCPPdefined(Z_MALLOC_PARTITION_EXISTS) && \Z_MALLOC_PARTITION_EXISTS && !defined(HEAP_STATIC)z_libc_partition/* CONFIG_COMMON_LIBC_REALLOCARRAY *//* CONFIG_COMMON_LIBC_CALLOC *//* CONFIG_COMMON_LIBC_MALLOC *//* else no malloc arena *//* No malloc arena *//* Search for an aligned heap that fits within the available space *//* Align size to power of two *//*
 * GCC's libstdc++ may use this function instead of aligned_alloc due to a
 * bug in the configuration for "newlib" environments (which includes picolibc).
 * When toolchains including that bug fix can become a dependency for Zephyr,
 * this work-around can be removed.
 *
 * Note that aligned_alloc isn't defined to work as a replacement for
 * memalign as it requires that the size be a multiple of the alignment,
 * while memalign does not. However, the aligned_alloc implementation here
 * is just a wrapper around sys_heap_aligned_alloc which doesn't have that
 * requirement and so can be used by memalign.
 *//* else ALLOCATE_HEAP_AT_STARTUP *//* else CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE > 0 *//* else CONFIG_XTENSA *//*
 * No partition, heap can just start wherever _end is, with
 * suitable alignment
 *//*
 * Heap base and size are determined based on the available unused SRAM, in the
 * interval from a properly aligned address after the linker symbol `_end`, to
 * the end of SRAM
 *//* CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE > 0 *//* Static allocation of heap in BSS *//* else Z_MALLOC_PARTITION_EXISTS *//* elif CONFIG_MPU *//* CONFIG_<arch> *//* Default to 64-bytes; we'll get a run-time error if this doesn't work. *//* Figure out alignment requirement *//* Figure out where the malloc variables live */requested_sizealignment/home/haojie/zephyrproject/zephyr/include/zephyr/posix/sys/stat.h<sys/_timespec.h><time.h>futimensconst timespecconst timespec[2]timespec[2]utimensatmknodatmkfifoatmkdiratfstatatstat *stat *__restrict__fchmodatumaskstatmkfifomkdirfstatfchmodchmodlong[2]st_spare4st_blocksst_blksizest_ctimst_mtimst_atimst_sizest_rdevst_gidst_uidst_nlinkst_modest_inost_devS_ISSOCK(m)(((m)&_IFMT) == _IFSOCK)S_ISLNK(m)(((m)&_IFMT) == _IFLNK)S_ISREG(m)(((m)&_IFMT) == _IFREG)S_ISFIFO(m)(((m)&_IFMT) == _IFIFO)S_ISDIR(m)(((m)&_IFMT) == _IFDIR)S_ISCHR(m)(((m)&_IFMT) == _IFCHR)S_ISBLK(m)(((m)&_IFMT) == _IFBLK)S_IXOTH0000001S_IWOTH0000002S_IROTH0000004S_IRWXO(S_IROTH | S_IWOTH | S_IXOTH)S_IXGRP0000010S_IWGRP0000020S_IRGRP0000040S_IRWXG(S_IRGRP | S_IWGRP | S_IXGRP)S_IXUSR0000100S_IWUSR0000200S_IRUSR0000400S_IRWXU(S_IRUSR | S_IWUSR | S_IXUSR)S_IFIFO_IFIFOS_IFSOCK_IFSOCKS_IFLNK_IFLNKS_IFREG_IFREGS_IFBLK_IFBLKS_IFCHR_IFCHRS_IFDIR_IFDIRS_IFMT_IFMTS_ISVTX0001000S_ISGID0002000S_ISUID0004000S_BLKSIZE00100000140000012000001000000060000002000000400000170000st_mtimest_mtim.tv_secst_ctimest_ctim.tv_secst_atimest_atim.tv_secZEPHYR_POSIX_SYS_STAT_H__STAT_H__LIBCdefined(__linux) && defined(__x86_64__)defined(__linux) && !defined(__x86_64__)defined(__linux)defined(__svr4__) && !defined(__PPC__) && !defined(__sun__)!defined(__rtems__)!(defined(__svr4__) && !defined(__PPC__) && !defined(__sun__))defined(__CYGWIN__) || defined(__rtems__)defined(__SPU__) || defined(__rtems__) || defined(__CYGWIN__) && !defined(__INSIDE_CYGWIN__)__ATFILE_VISIBLE && !defined(__INSIDE_CYGWIN__)__POSIX_VISIBLE >= 200809 && !defined(__INSIDE_CYGWIN__)/* ZEPHYR_POSIX_SYS_STAT_H_ *//* !_STAT_H_ *//*
 * Provide prototypes for most of the _<systemcall> names that are
 * provided in newlib for some compilers.
 *//* Special tv_nsec values for futimens(2) and utimensat(2). *//* 0666 *//* 07777 *//* 0777 *//* execute/search permission, other *//* write permission, other *//* read permission, other *//* execute/search permission, group *//* write permission, grougroup *//* read permission, group *//* execute/search permission, owner *//* write permission, owner *//* read permission, owner *//*
 * The Windows header files define _S_ forms of these, so we do too
 * for easier portability.
 *//* !_BSD_VISIBLE *//* enforcement-mode locking *//* save swapped text even after use *//* set group id on execution *//* set user id on execution *//* size of a block *//* fifo *//* socket *//* symbolic link *//* regular *//* block special *//* character special *//* directory *//* type of file *//* SysV/sco doesn't have the rest... But Solaris, eabi does.  *//* Backward compatibility *//*
 * It is intended that the layout of this structure not change when the
 * sizes of any of the basic types change (short, int, long) [via a compile
 * time option].
 *//* dj's stat defines _STAT_H_ *//*
 * Copyright (c) 1982, 1986, 1993
 * The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 * notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 * notice, this list of conditions and the following disclaimer in the
 * documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 * may be used to endorse or promote products derived from this software
 * without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *//* SPDX-License-Identifier: BSD-3-Clause *//home/haojie/zephyrproject/zephyr/include/zephyr/posix/sys/home/haojie/zephyrproject/zephyr/include/zephyr/posix__fd__times__path__flag__mode__dev__mask__sbuf_path/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/sys/_timeval.htimevaltv_usectv_sec_TIMEVAL_DEFINED_SYS__TIMEVAL_H_/* !_SYS__TIMEVAL_H_ *//* _TIMEVAL_DEFINED *//* and microseconds *//* seconds *//*
 * Structure returned by gettimeofday(2) system call, and used in other calls.
 *//* This define is also used outside of Newlib, e.g. in MinGW-w64 *//*-
 * SPDX-License-Identifier: BSD-2-Clause-FreeBSD
 *
 * Copyright (c) 2002 Mike Barcroft <mike@FreeBSD.org>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * $FreeBSD: head/sys/sys/_timeval.h 326256 2017-11-27 15:01:59Z pfg $
 *//home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/sys/_sigset.h__sigset_t_SYS__SIGSET_H_/* !_SYS__SIGSET_H_ *//*-
 * Copyright (c) 1982, 1986, 1989, 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 * (c) UNIX System Laboratories, Inc.
 * All or some portions of this file are derived from material licensed
 * to the University of California by American Telephone and Telegraph
 * Co. or Unix System Laboratories, Inc. and are reproduced herein with
 * the permission of UNIX System Laboratories, Inc.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@(#)signal.h	8.4 (Berkeley) 5/4/95
 * $FreeBSD$
 *//home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/sys/select.h<sys/timespec.h><sys/_timeval.h><sys/_sigset.h>pselectfd_set *const timespec *timespec *const sigset_tconst sigset_t *selecttimeval *fd_set__fd_masksigset_t__fd_mask[2]unsigned long[2]FD_SETSIZE_NFDBITS((int)sizeof(__fd_mask) * 8)_howmany(FD_SETSIZE, _NFDBITS)__fds_bitsFD_ZERO(p)do { fd_set *_p; __size_t _n; _p = (p); _n = _howmany(FD_SETSIZE, _NFDBITS); while (_n > 0) _p->__fds_bits[--_n] = 0; } while (0)FD_SET(n,p)((p)->__fds_bits[(n)/_NFDBITS] |= __fdset_mask(n))FD_ISSET(n,p)(((p)->__fds_bits[(n)/_NFDBITS] & __fdset_mask(n)) != 0)FD_CLR(n,p)((p)->__fds_bits[(n)/_NFDBITS] &= ~__fdset_mask(n))__fdset_mask(n)((__fd_mask)1 << ((n) % _NFDBITS))_howmany(x,y)(((x) + ((y) - 1)) / (y))_SYS_TYPES_FD_SET_SIGSET_T_DECLARED_SYS_SELECT_H!(defined (_WINSOCK_H) || defined (_WINSOCKAPI_) || defined (__USE_W32_SOCKETS))!defined(_SIGSET_T_DECLARED)_howmany!defined (__INSIDE_CYGWIN_NET__)(int __n, fd_set *__readfds, fd_set *__writefds, fd_set *__exceptfds, const struct timespec *__timeout, const sigset_t *__set)(int __n, fd_set *__readfds, fd_set *__writefds, fd_set *__exceptfds, struct timeval *__timeout)/* sys/select.h *//* !(_WINSOCK_H || _WINSOCKAPI_ || __USE_W32_SOCKETS) *//* !__INSIDE_CYGWIN_NET__ *//* bits per mask *//*
 * Select uses bit masks of file descriptors in longs.
 * These macros manipulate such bit fields (the filesystem macros use chars).
 * FD_SETSIZE may be defined by the user, but the default here
 * should be enough for most uses.
 *//* We don't define fd_set and friends if we are compiling POSIX
   source, or if we have included (or may include as indicated
   by __USE_W32_SOCKETS) the W32api winsock[2].h header which
   defines Windows versions of them.   Note that a program which
   includes the W32api winsock[2].h header must know what it is doing;
   it must not call the Cygwin select function.
*/__readfds__writefds__exceptfds__timeout__set/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/machine/_time.h_SYS_TIME_H_/* !_SYS_TIME_H_ *//* Copyright (c) 2016 Sebastian Huber <sebastian.huber@embedded-brains.de> *//home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/sys/time.h<machine/_time.h><sys/select.h>gettimeofdaytimeval *__restrict__utimesconst timevalconst timeval[2]timeval[2]itimervaltimezoneit_valueit_intervaltz_dsttimetz_minuteswestITIMER_PROFITIMER_VIRTUALITIMER_REALDST_CANDST_EETDST_METDST_WETDST_AUSTDST_USADST_NONE__BSD_VISIBLE || __POSIX_VISIBLE >= 200112 || __XSI_VISIBLE/* !_KERNEL *//* current value *//* timer interval *//*
 * Names of the interval timers, and structure
 * defining a timer setting.
 *//* NetBSD/OpenBSD compatible interfaces *//* Operations on timespecs *//* 18446744073709 = int(2^64 / 1000000) *//* 18446744073 = int(2^64 / 1000000000) *//*-
 * Background information:
 *
 * When converting between timestamps on parallel timescales of differing
 * resolutions it is historical and scientific practice to round down rather
 * than doing 4/5 rounding.
 *
 *   The date changes at midnight, not at noon.
 *
 *   Even at 15:59:59.999999999 it's not four'o'clock.
 *
 *   time_second ticks after N.999999999 not after N.4999999999
 *//* 9223372036854776 = ceil(2^63 / 1000) *//* 9223372036855 = ceil(2^63 / 1000000) *//* 9223372037 = ceil(2^63 / 1000000000) *//*
 * Decimal<->sbt conversions.  Multiplying or dividing by SBT_1NS results in
 * large roundoff errors which sbttons() and nstosbt() avoid.  Millisecond and
 * microsecond functions are also provided for completeness.
 *
 * These functions return the smallest sbt larger or equal to the
 * number of seconds requested so that sbttoX(Xtosbt(y)) == y.  Unlike
 * top of second computations below, which require that we tick at the
 * top of second, these need to be rounded up so we do whatever for at
 * least as long as requested.
 *
 * The naive computation we'd do is this
 *	((unit * 2^64 / SIFACTOR) + 2^32-1) >> 32
 * However, that overflows. Instead, we compute
 *	((unit * 2^63 / SIFACTOR) + 2^31-1) >> 32
 * and use pre-computed constants that are the ceil of the 2^63 / SIFACTOR
 * term to ensure we are using exactly the right constant. We use the lesser
 * evil of ull rather than a uint64_t cast to ensure we have well defined
 * right shift semantics. With these changes, we get all the ns, us and ms
 * conversions back and forth right.
 *//* beware rounding, see nstosbt() *//* Canada *//* Eastern European dst *//* Middle European dst *//* Western European dst *//* Australian style dst *//* USA style dst *//* not on dst *//* type of dst correction *//* minutes west of Greenwich *//*-
 * SPDX-License-Identifier: BSD-3-Clause
 *
 * Copyright (c) 1982, 1986, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@(#)time.h	8.5 (Berkeley) 5/4/95
 * $FreeBSD: head/sys/sys/time.h 346176 2019-04-13 04:46:35Z imp $
 *//* time.h -- An implementation of the standard Unix <sys/time.h> file.
   Written by Geoffrey Noer <noer@cygnus.com>
   Public domain; no rights reserved. */__p__tz/home/haojie/zephyrproject/zephyr/include/zephyr/sys/errno_private.hz_errnoZEPHYR_INCLUDE_SYS_ERRNO_PRIVATE_H_!defined(CONFIG_ERRNO_IN_TLS) && !defined(CONFIG_LIBC_ERRNO)/* ZEPHYR_INCLUDE_SYS_ERRNO_PRIVATE_H_ *//**
 * return a pointer to a memory location containing errno
 *
 * errno is thread-specific, and can't just be a global. This pointer
 * is guaranteed to be read/writable from user mode.
 *
 * @return Memory location of errno data for current thread
 *//* NOTE: located here to avoid include dependency loops between errno.h
 * and kernel.h
 */K_APPMEM_PARTITION_DEFINE(name)K_APP_BMEM_SECTION(ptn).bssK_APP_DMEM_SECTION(ptn).dataK_APP_DMEM(ptn)K_APP_BMEM(ptn)ZEPHYR_INCLUDE_APP_MEMORY_APP_MEMDOMAIN_H_defined(CONFIG_ARC) && defined(__CCAC__)/* ZEPHYR_INCLUDE_APP_MEMORY_APP_MEMDOMAIN_H_ *//**
 * @brief Define an application memory partition with linker support
 *
 * Defines a k_mem_paritition with the provided name.
 * This name may be used with the K_APP_DMEM and K_APP_BMEM macros to
 * place globals automatically in this partition.
 *
 * NOTE: placeholder char variable is defined here to prevent build errors
 * if a partition is defined but nothing ever placed in it.
 *
 * @param name Name of the k_mem_partition to declare
 *//* ARC MWDT assembler has slightly different pushsection/popsection directives
 * names.
 *//* ARM has a quirk in that '@' denotes a comment, so we have to send
 * %progbits to the assembler instead.
 *//* If a partition is declared with K_APPMEM_PARTITION, but never has any
 * data assigned to its contents, then no symbols with its prefix will end
 * up in the symbol table. This prevents gen_app_partitions.py from detecting
 * that the partition exists, and the linker symbols which specify partition
 * bounds will not be generated, resulting in build errors.
 *
 * What this inline assembly code does is define a symbol with no data.
 * This should work for all arches that produce ELF binaries, see
 * https://sourceware.org/binutils/docs/as/Section.html
 *
 * We don't know what active flags/type of the pushed section were, so we are
 * specific: "aw" indicates section is allocatable and writable,
 * and "@progbits" indicates the section has data.
 *//**
 * @brief Place data in a partition's bss section
 *
 * Globals tagged with this will end up in the bss section for the
 * specified memory partition. This data will be zeroed at boot.
 *
 * @param id Name of the memory partition to associate this data
 *//**
 * @brief Place data in a partition's data section
 *
 * Globals tagged with this will end up in the data section for the
 * specified memory partition. This data should be initialized to some
 * desired value.
 *
 * @param id Name of the memory partition to associate this data
 *//**
 * @brief Name of the bss section for a particular partition
 *
 * Useful for defining memory pools, or any other macro that takes a
 * section name as a parameter.
 *
 * @param id Partition name
 *//**
 * @brief Name of the data section for a particular partition
 *
 * Useful for defining memory pools, or any other macro that takes a
 * section name as a parameter.
 *
 * @param id Partition name
 *//**
 * @brief Application memory domain APIs
 * @defgroup mem_domain_apis_app Application memory domain APIs
 * @ingroup mem_domain_apis
 * @{
 */zephyr_fwritez_impl_zephyr_fwritezephyr_fputczephyr_write_stdoutz_impl_zephyr_write_stdoutzephyr_read_stdinz_impl_zephyr_read_stdinZ_INCLUDE_SYSCALLS_LIBC_HOOKS_Hz_impl_zephyr_fputcnitemsnbytes<syscalls/libc-hooks.h>Z_LIBC_DATAK_APP_DMEM(z_libc_partition)ZEPHYR_INCLUDE_SYS_LIBC_HOOKS_H_defined(CONFIG_NEWLIB_LIBC) || defined(CONFIG_ARCMWDT_LIBC)CONFIG_MINIMAL_LIBCdefined(CONFIG_MINIMAL_LIBC) && (CONFIG_MINIMAL_LIBC_MALLOC_ARENA_SIZE != -2)defined(CONFIG_PICOLIBC) && (CONFIG_PICOLIBC_HEAP_SIZE != -2)CONFIG_COMMON_LIBC_MALLOC_ARENA_SIZE != 0 && \defined(CONFIG_NEWLIB_LIBC)(!defined(CONFIG_MPU_REQUIRES_POWER_OF_TWO_ALIGNMENT) || \/* ZEPHYR_INCLUDE_SYS_LIBC_HOOKS_H_ *//* C library memory partitions *//* C library globals, except the malloc arena *//* - All newlib globals will be placed into z_libc_partition.
 * - Minimal C library globals, if any, will be placed into
 *   z_libc_partition.
 * - Stack canary globals will be placed into z_libc_partition since
 *   it is not worth placing in its own partition.
 * - Some architectures may place the global pointer to the thread local
 *   storage in z_libc_partition since it is not worth placing in its
 *   own partition.
 *//* Memory partition containing the libc malloc arena. Configuration controls
 * whether this is available, and an arena size may need to be set.
 *//* CONFIG_NEWLIB_LIBC *//* If we are using newlib, the heap arena is in one of two areas:
 *  - If we have an MPU that requires power of two alignment, the heap bounds
 *    must be specified in Kconfig via CONFIG_NEWLIB_LIBC_ALIGNED_HEAP_SIZE.
 *  - Otherwise, the heap arena on most arches starts at a suitably
 *    aligned base addreess after the `_end` linker symbol, through to the end
 *    of system RAM.
 *//* When using the common malloc implementation with CONFIG_USERSPACE, the
 * heap will be in a separate partition when there's an MPU or MMU
 * available.
 *//* Handle deprecated malloc arena size configuration values *//* Minimal libc only *//* Minimal libc and picolibc *//* syscall generation ignores preprocessor, ensure this is defined to ensure
 * we don't have compile errors
 *//*
 * Private header for specifying accessory functions to the C library internals
 * that need to call into the kernel as system calls
 *//*
 * Copyright (c) 2018, Intel Corporation.
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/time.h/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/machine/time.h/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/sys/timespec.h/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/picolibc/include/sys/_timespec.h/home/haojie/zephyrproject/zephyr/include/zephyr/sys/sem.h/home/haojie/zephyrproject/zephyr/lib/libc/picolibc/libc-hooks.c<zephyr/sys/cbprintf.h><zephyr/sys/sem.h><zephyr/sys/errno_private.h><sys/time.h><zephyr/posix/sys/stat.h>* buffer overflow detected *
"* buffer overflow detected *\n"__retarget_lock_release__retarget_lock_release_recursivelock != NULL__retarget_lock_try_acquire__retarget_lock_try_acquire_recursive__retarget_lock_acquire__retarget_lock_acquire_recursive__retarget_lock_close__retarget_lock_close_recursive__retarget_lock_init__retarget_lock_init_recursivesizeof(struct k_mutex)*lock != NULL"recursive lock allocation failed"_exitexit
"exit\n"cbvprintfcbputccb_bits *__stdin_hook_installpicolibc_putcb_bits__lock___libc_recursive_mutex._k_mutex.static.__lock___libc_recursive_mutex_struct k_mutex_k_mutex_CONCAT(__lock___libc_recursive_mutex, _)__lock___libc_recursive_mutex_&__lock___libc_recursive_mutex.wait_q__stdin__stdout_stdout_hook_LOCK_TSTDIO_ALIAS(x)__strong_reference(stdout, x);LIBC_DATALIBC_BSSK_APP_BMEM(z_libc_partition)__strong_reference__alignof(struct k_mutex)/*
 * Picolibc needs to be able to declare this itself so that the library
 * doesn't end up needing zephyr header files. That means using a regular
 * function instead of an inline.
 *//* This function gets called if static buffer overflow detection is enabled on
 * stdlib side (Picolibc here), in case such an overflow is detected. Picolibc
 * provides an implementation not suitable for us, so we override it here.
 *//* Release non-recursive lock *//* Release recursive lock *//* Try acquiring non-recursive lock *//* Try acquiring recursive lock *//* Acquiure non-recursive lock *//* Acquiure recursive lock *//* Close dynamic non-recursive lock *//* Close dynamic recursive lock *//* Create a new dynamic non-recursive lock *//* Allocate mutex object *//* Create a new dynamic recursive lock *//* Initialise recursive locks *//* Grant public access to picolibc lock after boot *//*
 * Copyright  2021, Keith Packard <keithp@keithp.com>
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/lib/libc/picolibc_s/home/haojie/zephyrproject/zephyr/lib/os/assert.cassert_post_action/* User threads aren't allowed to induce kernel panics; generate
	 * an oops instead.
	 *//**
 * @brief Assert Action Handler
 *
 * This routine implements the action to be taken when an assertion fails.
 *
 * System designers may wish to substitute this implementation to take other
 * actions, such as logging program counter, line number, debug information
 * to a persistent repository and/or rebooting the system.
 *
 * @param N/A
 *//*
 * Copyright (c) 2019 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/lib/ossys_bitarray_tsys_bitarraybundlesnum_bundlesSYS_BITARRAY_DEFINE_STATIC(name,total_bits)_SYS_BITARRAY_DEFINE(name, total_bits, static)SYS_BITARRAY_DEFINE(name,total_bits)_SYS_BITARRAY_DEFINE(name, total_bits,)_SYS_BITARRAY_DEFINE(name,total_bits,sba_mod)sba_mod uint32_t _sys_bitarray_bundles_ ## name [DIV_ROUND_UP(DIV_ROUND_UP(total_bits, 8), sizeof(uint32_t))] = {0}; sba_mod sys_bitarray_t name = { .num_bits = total_bits, .num_bundles = DIV_ROUND_UP( DIV_ROUND_UP(total_bits, 8), sizeof(uint32_t)), .bundles = _sys_bitarray_bundles_ ## name, }ZEPHYR_INCLUDE_SYS_BITARRAY_H_sys_bitarray_clear_regionsys_bitarray_test_and_set_regionsys_bitarray_set_regionsys_bitarray_is_region_clearedsys_bitarray_is_region_setsys_bitarray_freesys_bitarray_allocsys_bitarray_test_and_clear_bitsys_bitarray_test_and_set_bitsys_bitarray_test_bitsys_bitarray_clear_bitsys_bitarray_set_bit/* ZEPHYR_INCLUDE_SYS_BITARRAY_H_ *//**
 * Clear all bits in a region.
 *
 * This clears the number of bits (@p num_bits) in region starting
 * from @p offset.
 *
 * @param bitarray Bitarray struct
 * @param num_bits Number of bits to test
 * @param offset   Starting bit position to test
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to set exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * Test if all bits in a region are cleared/set and set/clear them
 * in a single atomic operation
 *
 * This checks if all the bits (@p num_bits) in region starting
 * from @p offset are in required state. If even one bit is not,
 * -EEXIST is returned.  If the whole region is set/cleared
 * it is set to opposite state. The check and set is performed as a single
 * atomic operation.
 *
 * @param bitarray Bitarray struct
 * @param num_bits Number of bits to test and set
 * @param offset   Starting bit position to test and set
 * @param to_set   if true the region will be set if all bits are cleared
 *		   if false the region will be cleard if all bits are set
 *
 * @retval 0	   Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to set exceeds
 *		   the number of bits in bit array, etc.)
 * @retval -EEXIST at least one bit in the region is set/cleared,
 *		   operation cancelled
 *//**
 * Set all bits in a region.
 *
 * This sets the number of bits (@p num_bits) in region starting
 * from @p offset.
 *
 * @param bitarray Bitarray struct
 * @param num_bits Number of bits to test
 * @param offset   Starting bit position to test
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to set exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * Test if bits in a region is all cleared.
 *
 * This tests if the number of bits (@p num_bits) in region starting
 * from @p offset are all cleared.
 *
 * @param bitarray Bitarray struct
 * @param num_bits Number of bits to test
 * @param offset   Starting bit position to test
 *
 * @retval true    All bits are cleared.
 * @retval false   Not all bits are cleared.
 *//**
 * Test if bits in a region is all set.
 *
 * This tests if the number of bits (@p num_bits) in region starting
 * from @p offset are all set.
 *
 * @param bitarray Bitarray struct
 * @param num_bits Number of bits to test
 * @param offset   Starting bit position to test
 *
 * @retval true    All bits are set.
 * @retval false   Not all bits are set.
 *//**
 * Free bits in a bit array
 *
 * This marks the number of bits (@p num_bits) starting from @p offset
 * as no longer allocated.
 *
 * @param bitarray Bitarray struct
 * @param num_bits Number of bits to free
 * @param offset   Starting bit position to free
 *
 * @retval 0       Free is successful
 * @retval -EINVAL Invalid argument (e.g. try to free more bits than
 *                 the bitarray has, trying to free 0 bits, etc.)
 * @retval -EFAULT The bits in the indicated region are not all allocated.
 *//**
 * Allocate bits in a bit array
 *
 * This finds a number of bits (@p num_bits) in a contiguous of
 * previously unallocated region. If such a region exists, the bits are
 * marked as allocated and the offset to the start of this region is
 * returned via @p offset.
 *
 * @param[in]  bitarray Bitarray struct
 * @param[in]  num_bits Number of bits to allocate
 * @param[out] offset   Offset to the start of allocated region if
 *                      successful
 *
 * @retval 0       Allocation successful
 * @retval -EINVAL Invalid argument (e.g. allocating more bits than
 *                 the bitarray has, trying to allocate 0 bits, etc.)
 * @retval -ENOSPC No contiguous region big enough to accommodate
 *                 the allocation
 *//**
 * Test the bit and clear it
 *
 * @param[in]  bitarray Bitarray struct
 * @param[in]  bit      The bit to be tested and cleared
 * @param[out] prev_val Previous value of the bit (0 or 1)
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to test exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * Test the bit and set it
 *
 * @param[in]  bitarray Bitarray struct
 * @param[in]  bit      The bit to be tested and set
 * @param[out] prev_val Previous value of the bit (0 or 1)
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to test exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * Test whether a bit is set or not
 *
 * @param[in]  bitarray Bitarray struct
 * @param[in]  bit      The bit to be tested
 * @param[out] val      The value of the bit (0 or 1)
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to test exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * Clear a bit in a bit array
 *
 * @param[in] bitarray Bitarray struct
 * @param[in] bit      The bit to be cleared
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to clear exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * Set a bit in a bit array
 *
 * @param[in] bitarray Bitarray struct
 * @param[in] bit      The bit to be set
 *
 * @retval 0       Operation successful
 * @retval -EINVAL Invalid argument (e.g. bit to set exceeds
 *                 the number of bits in bit array, etc.)
 *//**
 * @brief Create a static bitarray object.
 *
 * @param name Name of the bitarray object.
 * @param total_bits Total number of bits in this bitarray object.
 *//**
 * @brief Create a bitarray object.
 *
 * @param name Name of the bitarray object.
 * @param total_bits Total number of bits in this bitarray object.
 *//**
 * @brief Create a bitarray object.
 *
 * @param name Name of the bitarray object.
 * @param total_bits Total number of bits in this bitarray object.
 * @param sba_mod Modifier to the bitarray variables.
 *//** Bitarray structure *//* Spinlock guarding access to this bit array *//* Bundle of bits *//* Number of bundles *//* Number of bits *//**
 * @file
 *
 * @defgroup bitarray_apis Bit array
 * @ingroup datastructure_apis
 *
 * @brief Store and manipulate bits in a bit array.
 *
 * @{
 */bitarrayto_setprev_val/home/haojie/zephyrproject/zephyr/lib/os/bitarray.cregion_clearbdbitarray != NULLbitarray->num_bits > 0off_endbundle_data *-17-EEXISTset_clear_regionis_region_set_clearbit_idxoff_startmismatchoffset == NULLoffset == ((void *)0)bundle_bitness(bitarray)-ENOSPCprev_val == NULLprev_val == ((void *)0)val == NULLval == ((void *)0)set_regionbdata~0Umatch_regionbundlemismatch_bundlemismatch_bundle_idxmismatch_bit_offmismatch_bundle != 0setup_bundle_databd->soffbd->eoffbundle_dataemasksmaskeoffsoffeidxsidxbundle_bitness(ba)(sizeof(ba->bundles[0]) * 8)/* Note that we need to make sure the bits in specified region
	 * (offset to offset + num_bits) are all allocated before we clear
	 * them.
	 *//* Fast-forward to the bit just after
		 * the mismatched bit.
		 *//* Find the first free bit in bundle if not all free *//* bundle is all 1s => all allocated, skip *//* Find the first non-allocated bit by looking at bundles
	 * instead of individual bits.
	 *
	 * On RISC-V 64-bit, it complains about undefined reference to `ffs`.
	 * So don't use this on RISCV64.
	 *//* Start/end at different bundle.
		 * So set/clear the bits in start and end bundles
		 * separately. For in-between bundles,
		 * set/clear all bits.
		 *//* Start/end at same bundle *//*
 * Set or clear a region of bits.
 *
 * @param bitarray Bitarray struct
 * @param offset   Starting bit location
 * @param num_bits Number of bits in the region
 * @param to_set   True if to set all bits.
 *                 False if to clear all bits.
 * @param bd       Bundle data. Can reuse the output from
 *                 match_region(). NULL if there is no
 *                 prior call to match_region().
 *//* Must have at least 1 bit set to indicate
		 * where the mismatch is.
		 *//* All bits in region matched. *//* Bits in "between bundles" do not match *//* Note that this is opposite from above so that
		 * we are simply checking if bundle == 0.
		 *//* In-between bundles *//* End bundle not matching to mask. *//* End of bundles *//* Start bundle not matching to mask. *//* Start of bundles *//* Region lies in a number of bundles. Need to loop through them. *//* Matching to mask. *//* Not matching to mask. *//*
 * Find out if the bits in a region is all set or all clear.
 *
 * @param[in]  bitarray  Bitarray struct
 * @param[in]  offset    Starting bit location
 * @param[in]  num_bits  Number of bits in the region
 * @param[in]  match_set True if matching all set bits,
 *                       False if matching all cleared bits
 * @param[out] bd        Data related to matching which can be
 *                       used later to find out where the region
 *                       lies in the bitarray bundles.
 * @param[out] mismatch  Offset to the mismatched bit.
 *                       Can be NULL.
 *
 * @retval     true      If all bits are set or cleared
 * @retval     false     Not all bits are set or cleared
 *//* The region lies within the same bundle. So combine the masks. *//* Masks for start/end bundles *//* Offset inside start and end bundles *//* Start and end index of bundles *//* Number of bits represented by one bundle */match_set/home/haojie/zephyrproject/zephyr/lib/os/cbprintf_complete.cz_cbvprintf_implsintconst booltagged_ap*fp++CONFIG_CBPRINTF_PACKAGE_SUPPORT_TAGGED_ARGUMENTS_XXXXCONFIG_CBPRINTF_PACKAGE_SUPPORT_TAGGED_ARGUMENTS_XXXXCONFIG_CBPRINTF_PACKAGE_SUPPORT_TAGGED_ARGUMENTS 1CONFIG_CBPRINTF_FP_SUPPORT_XXXXCONFIG_CBPRINTF_FP_SUPPORT_XXXXCONFIG_CBPRINTF_FP_SUPPORT 1FRACTION_BITSWINT_TYPEsp'%'signpad*cp++(unsigned char)*cp'0'cpbpeconv->specifierbpsconversion *conversion *constconvargument_value *argument_value *constwidthprecisionsizeof(buf)specifier_catlength_modnj_lenpad_lenSPECIFIER_FPSPECIFIER_SINTLENGTH_NONELENGTH_HHLENGTH_HLENGTH_L-2147483647-2147483648WCHAR_IS_SIGNEDLENGTH_LLLENGTH_JLENGTH_ZLENGTH_TSPECIFIER_UINT!WCHAR_IS_SIGNED(!WCHAR_IS_SIGNED)LENGTH_UPPER_LSPECIFIER_PTR-128CHAR_IS_SIGNED'd''+''-''u''x''X'prec_int_pad0(nil)"(nil)"const conversionconst conversion *outsstore_countsigned char *short *intmax_t *ptrdiff_t *encode_floatprune_zeroEXPONENT_BITSexpoBIT_MASK(EXPONENT_BITS)fract45035996273704964503599627370495BIT64_MASK(FRACTION_BITS)is_subnormal(unsigned char)c'f''A''a'CONFIG_CBPRINTF_FP_A_SUPPORT_XXXXCONFIG_CBPRINTF_FP_A_SUPPORT_XXXXCONFIG_CBPRINTF_FP_A_SUPPORT 1CONFIG_CBPRINTF_FP_ALWAYS_A_XXXXCONFIG_CBPRINTF_FP_ALWAYS_A_XXXXCONFIG_CBPRINTF_FP_ALWAYS_A 1require_dpaconvspeepdp'1'9223372036854775807~SIGN_MASK1023 - 1(1023 - 1)decexp858993459(UINT32_MAX / 5U)'g''G'-4-3-4 + 1(-4 + 1)'e' - 'g'decimalsdigit_count 16round576460752303423488BIT64(59)1152921504606846976BIT64(60)'E'encode_uint(int)conv->specifierupcaseconst unsigned intradixbplsvconversion_radix_get_digitrvalspecifierfr1152921504606846975(BIT64(60) - 1U)_ldiv10_ldiv5v_lov_him0x33333333extract_conversionextract_specifierunsupportedint_conv!IS_ENABLED(CONFIG_CBPRINTF_FULL_INTEGRAL)sizeof(long)sizeof(long) > 4sizeof(long long) > 4sizeof(uintmax_t)sizeof(uintmax_t) > 4sizeof(size_t)sizeof(size_t) > 4sizeof(ptrdiff_t)sizeof(ptrdiff_t) > 4!IS_ENABLED(CONFIG_CBPRINTF_FP_SUPPORT)!IS_ENABLED(CONFIG_CBPRINTF_FP_A_SUPPORT)extract_length'h''j''z''t''L'extract_prec'*'precextract_widthextract_flagsloop'#'extract_decimal(int)(unsigned char)*spconversionargument_valuespecifier_cat_enumSPECIFIER_INVALIDlength_mod_enumuint_value_typesint_value_typedblu64pad_fppad_postdpaltform_0caltform_0specifier_aprec_starprec_presentwidth_starwidth_presentflag_zeroflag_hashflag_spaceflag_plusflag_dashinvalidpad0_pre_expprec_valuepad0_valuewidth_valueldbluintOUTCOUTSOUTS(_sp,_ep)do { int rc = outs(out, ctx, _sp, _ep); if (rc < 0) { return rc; } count += rc; } while (false)OUTC(c)do { int rc = (*out)((int)(c), ctx); if (rc < 0) { return rc; } ++count; } while (false)BIT_63SIGN_MASKFRACTION_HEXDIV_ROUND_UP(FRACTION_BITS, 4)PTR_CONV_CASES'n': case 'p': case 's'FP_CONV_CASES'a': case 'A': case 'e': case 'E': case 'f': case 'F': case 'g': case 'G'UINT_CONV_CASES'o': CASE_UINT_CHAR case 'u': case 'x': case 'X'SINT_CONV_CASES'd': CASE_SINT_CHAR case 'i'((WCHAR_MIN - 0) != 0)CASE_UINT_CHARCASE_SINT_CHARcase 'c':(CHAR_MIN != 0)CONVERTED_BUFLENCONVERTED_INT_BUFLENCONVERTED_FP_BUFLEN25U((CHAR_BIT * sizeof(uint_value_type) + 2) / 3)WCHAR_MAX < INT_MAX/* Finish left justification *//* Remaining padding is
					 * post-dp.
					 *//* Only padding is pre_exp *//* If we have a sign that hasn't been emitted, now's the
		 * time....
		 *//* If we're zero-padding we have to emit the
				 * sign first.
				 *//* If we have a width update width to hold the padding we need
		 * for justification.  The result may be negative, which will
		 * result in no padding.
		 *
		 * If a non-negative padding width is present and we're doing
		 * right-justification, emit the padding now.
		 *//* The converted value is now stored in [bps, bpe), excluding
		 * any required zero padding.
		 *
		 * The unjustified output will be:
		 *
		 * * any sign character (sint-only)
		 * * any altform prefix
		 * * for FP:
		 *   * any pre-decimal content from the converted value
		 *   * any pad0_value padding (!postdp)
		 *   * any decimal point in the converted value
		 *   * any pad0_value padding (postdp)
		 *   * any pre-exponent content from the converted value
		 *   * any pad0_pre_exp padding
		 *   * any exponent content from the converted value
		 * * for non-FP:
		 *   * any pad0_prefix
		 *   * the converted value
		 *//* If we don't have a converted value to emit, move
		 * on.
		 *//* Add an empty default with break, this is a defensive
			 * programming. Static analysis tool won't raise a violation
			 * if default is empty, but has that comment.
			 *//* Use 0x prefix *//* Implementation-defined: null is "(nil)", non-null
			 * has 0x prefix followed by significant address hex
			 * digits, no leading zeros.
			 *//* Set pad0_value to satisfy precision *//* Zero-padding flag is ignored for integer
				 * conversions with precision.
				 *//* Update pad0 values based on precision and converted
			 * length.  Note that a non-empty sign is not in the
			 * converted sequence, but it does not affect the
			 * padding size.
			 *//* sint/uint overlay in the union, and so
			 * can't appear in read and write operations
			 * in the same statement.
			 *//* Do formatting, either into the buffer or
		 * referencing external data.
		 *//* We've now consumed all arguments related to this
		 * specification.  If the conversion is invalid, or is
		 * something we don't support, then output the original
		 * specification and move on.
		 *//* ptrdiff_t *//* size_t *//* Though ssize_t is the signed equivalent of
				 * size_t for POSIX, there is no uptrdiff_t.
				 * Assume that size_t and ptrdiff_t are the
				 * unsigned and signed equivalents of each
				 * other.  This can be checked in a platform
				 * test.
				 *//* Extract the value based on the argument category and length.
		 *
		 * Note that the length modifier doesn't affect the value of a
		 * pointer argument.
		 *//* Get the value to be converted from the args.
		 *
		 * This can't be extracted to a helper function because
		 * passing a pointer to va_list doesn't work on x86_64.  See
		 * https://stackoverflow.com/a/8048892.
		 *//* FP conversion requires knowing the precision. *//* Reuse width and precision memory in conv for value
		 * padding counts.
		 *//* If dynamic precision is specified, process it, otherwise
		 * set precision if present.  For floating point where
		 * precision is not present use 6.
		 *//* If dynamic width is specified, process it,
		 * otherwise set width if present.
		 *//* Force union into RAM with conversion state to
		 * mitigate LLVM code generation bug.
		 *//* Skip over the argument tag as it is not being
			 * used here.
			 *//* Output sequence of characters, returning a negative error if output
 * failed.
 *//* Output character, returning EOF if output failed, otherwise
 * updating count.
 *
 * NB: c is evaluated exactly once: side-effects are OK
 *//* Outline function to emit all characters in [sp, ep). *//* Add an empty default with break, this is a defensive programming.
		 * Static analysis tool won't raise a violation if default is empty,
		 * but has that comment.
		 *//* Store a count into the pointer provided in a %n specifier.
 *
 * @param conv the specifier that indicates the size of the value into which
 * the count will be stored.
 *
 * @param dp where the count should be stored.
 *
 * @param count the count to be stored.
 *//* Set the end of the encoded sequence, and return its start.  Also
	 * store EOS as a non-digit/non-decimal value so we don't have to
	 * check against bpe when iterating in multiple places.
	 *//* Cache whether there's padding required *//* At most 3 digits to the decimal.  Spit them out. *//* Emit the explicit exponent, if format requires it. *//* Emit the decimal point only if required by the alternative
		 * format, or if more digits are to follow.
		 *//* Emit the one digit before the decimal.  If it's not zero,
		 * this is significant so reduce the base-10 exponent.
		 *//* e or E *//* Emit the digits above the decimal point. *//* Make sure rounding didn't make fract >= 1.0 *//* 0.5 *//* Round the value to the last digit being printed. *//* Use the specified precision and exponent to select the
		 * representation and correct the precision and zero-pruning
		 * in accordance with the ISO C rule.
		 *//*
	 * The binary fractional point is located somewhere above bit 63.
	 * Move it between bits 59 and 60 to give 4 bits of room to the
	 * integer part.
	 *//* Bring back our fractional number to full scale *//*
		 * Perform fract / 5 / 2 * 10.
		 * The +2 is there to do round the result of the division
		 * by 5 not to lose too much precision in extreme cases.
		 *//* Perform fract * 5 * 2 / 10 *//*
		 * Make room to allow a multiplication by 5 without overflow.
		 * We test only the top part for faster code.
		 *//*
	 * Let's consider:
	 *
	 *	value = fract * 2^expo * 10^decexp
	 *
	 * Initially decexp = 0. The goal is to bring exp between
	 * 0 and -2 as the magnitude of a fractional decimal digit is 3 bits.
	 *//* +1 since .1 vs 1. *//* Adjust the offset exponent to be signed rather than offset,
		 * and set the implicit 1 bit in the (shifted) 53-bit
		 * fraction.
		 *//* Fraction is subnormal.  Normalize it and correct
			 * the exponent.
			 *//* Non-zero values need normalization. *//* Remainder of code operates on a 64-bit fraction, so shift up (and
	 * discard garbage from the exponent where the implicit 1 would be
	 * stored).
	 *//* Append the leading significant "digits". *//* Pad out to full range since this is below the decimal
		 * point.
		 *//* Get the fractional value as a hexadecimal string, using x
		 * for a and X for A.
		 *//* Record whether we must retain the decimal point even if we
		 * can prune zeros.
		 *//* Round only if the bit that would round is
			 * set.
			 *//* If we didn't get precision from a %a specification then we
		 * treat it as from a %a specification with no precision: full
		 * range, zero-pruning enabled.
		 *
		 * Otherwise we have to cap the precision of the generated
		 * fraction, or possibly round it.
		 *//* Remove the offset from the exponent, and store the
		 * non-fractional value.  Subnormals require increasing the
		 * exponent as first bit isn't the implicit bit.
		 *//* Handle converting to the hex representation. *//* The case of an F specifier is no longer relevant. *//* No zero-padding with text values *//* Exponent of all-ones signals infinity or NaN, which are
	 * text constants regardless of specifier.
	 *//* Extract the non-negative offset exponent and fraction.  Record
	 * whether the value is subnormal.
	 *//* Prepend the sign: '-' if negative, flags control
	 * non-negative behavior.
	 *//* Convert the IEEE 754-2008 double to text format.
 *
 * @param value the 64-bit floating point value.
 *
 * @param conv details about how the conversion is to proceed.  Some fields
 * are adjusted based on the value being converted.
 *
 * @param precision the precision for the conversion (generally digits past
 * the decimal point).
 *
 * @param bps pointer to the first character in a buffer that will hold the
 * converted value.
 *
 * @param bpe On entry this points to the end of the buffer reserved to hold
 * the converted value.  On exit it is updated to point just past the
 * converted value.
 *
 * return a pointer to the start of the converted value.  This may not be @p
 * bps but will be consistent with the exit value of *bpe.
 *//* Mask for the high-bit of a uint64_t representation of a fractional
 * value.
 *//* Mask for the sign (negative) bit of an IEEE 754-2008 double precision
 * float.
 *//* Number of bits in the exponent of an IEEE 754-2008 double precision
 * float.
 *//* Number of hex "digits" in the fractional part of an IEEE 754-2008
 * double precision float.
 *//* Number of bits in the fractional part of an IEEE 754-2008 double
 * precision float.
 *//* Record required alternate forms.  This can be determined
	 * from the radix without re-checking specifier.
	 *//* Writes the given value into the buffer in the specified base.
 *
 * Precision is applied *ONLY* within the space allowed.
 *
 * Alternate form value is applied to o, x, and X conversions.
 *
 * The buffer is filled backwards, so the input bpe is the end of the
 * generated representation.  The returned pointer is to the first
 * character of the representation.
 *//* Extract the next decimal character in the converted representation of a
 * fractional component.
 *//* Division by 10 *//* CONFIG_64BIT *//* The actual multiplication. *//*
	 * Apply a bias of 1 to v. We can't add it to v as this would overflow
	 * it when at max range. Factor it out with the multiplier upfront.
	 *//*
	 * Force the multiplier constant into a register and make it
	 * opaque to the compiler, otherwise gcc tries to be too smart
	 * for its own good with a large expansion of adds and shifts.
	 *//*
 * Tiny integer divide-by-five routine.  The full 64 bit division
 * implementations in libgcc are very large on some architectures, and
 * currently nothing in Zephyr pulls it into the link.  So it makes
 * sense to define this much smaller special case here to avoid
 * including it just for printf.
 *
 * It works by multiplying v by the reciprocal of 5 i.e.:
 *
 *	result = v * ((1 << 64) / 5) / (1 << 64)
 *
 * This produces a 128-bit result, but we drop the bottom 64 bits which
 * accounts for the division by (1 << 64). The product is kept to 64 bits
 * by summing partial multiplications and shifting right by 32 which on
 * most 32-bit architectures means only a register drop.
 *
 * Here the multiplier is: (1 << 64) / 5 = 0x3333333333333333
 * i.e. a 62 bits value. To compensate for the reduced precision, we
 * add an initial bias of 1 to v. This conveniently allows for keeping
 * the multiplier in a single 32-bit register given its pattern.
 * Enlarging the multiplier to 64 bits would also work but carry handling
 * on the summing of partial mults would be necessary, and a final right
 * shift would be needed, requiring more instructions.
 *//* The compiler can optimize this on its own on 64-bit architectures *//* Skip over the opening %.  If the conversion specifier is %,
	 * that's the only thing that should be there, so
	 * fast-exit.
	 *//* Extract the complete C99 conversion specification.
 *
 * @param conv pointer to the conversion being defined.
 *
 * @param sp pointer to the % that introduces a conversion specification.
 *
 * @return pointer to the first character that follows the specification.
 *//* p: only LENGTH_NONE
		 *
		 * s: LENGTH_NONE or LENGTH_L but wide
		 * characters not supported.
		 *//* Anything except L *//* PTR cases are distinct *//* The l specifier has no effect.  Otherwise length
		 * modifiers other than L are invalid.
		 *//* When FP enabled %a support is still conditional. *//* Don't support if disabled *//* Add an empty default with break, this is a defensive
				 * programming. Static analysis tool won't raise a violation
				 * if default is empty, but has that comment.
				 *//* Disable conversion that might produce truncated
			 * results with buffers sized for 32 bits.
			 *//* For c LENGTH_NONE and LENGTH_L would be ok,
		 * but we don't support formatting wide characters.
		 *//* L length specifier not acceptable *//* Extract a C99 conversion specifier.
 *
 * This is the character that identifies the representation of the converted
 * value.
 *
 * @param conv pointer to the conversion being defined.
 *
 * @param sp pointer to the first character after the length element of a
 * conversion specification.
 *
 * @return a pointer the first character that follows the specifier.
 *//* We recognize and consume these, but can't format
		 * them.
		 *//** Extract a C99 conversion specification length.
 *
 * @param conv pointer to the conversion being defined.
 *
 * @param sp pointer to the first character after the precision element of a
 * conversion specification.
 *
 * @return a pointer the first character that follows the precision.
 *//** Extract a C99 conversion specification precision.
 *
 * @param conv pointer to the conversion being defined.
 *
 * @param sp pointer to the first character after the width element of a
 * conversion specification.
 *
 * @return a pointer the first character that follows the precision.
 *//** Extract a C99 conversion specification width.
 *
 * @param conv pointer to the conversion being defined.
 *
 * @param sp pointer to the first character after the flags element of a
 * conversion specification.
 *
 * @return a pointer the first character that follows the width.
 *//* space && plus => !plus, handled in emitter code *//* zero && dash => !zero *//** Extract C99 conversion specification flags.
 *
 * @param conv pointer to the conversion being defined.
 *
 * @param sp pointer to the first character after the % of a conversion
 * specifier.
 *
 * @return a pointer the first character that follows the flags.
 *//** Get a size represented as a sequence of decimal digits.
 *
 * @param[inout] str where to read from.  Updated to point to the first
 * unconsumed character.  There must be at least one non-digit character in
 * the referenced text.
 *
 * @return the decoded integer value.
 *//** Number of extra zeros to be inserted after a decimal
		 * point due to precision.
		 *
		 * Inserts at <> in: VVVV.FFFF<>eEE
		 *
		 * Valid after conversion begins.
		 *//** Precision from specification.
		 *
		 * Valid until conversion begins.
		 *//** Number of extra zeroes to be inserted around a
		 * formatted value:
		 *
		 * * before a formatted integer value due to precision
		 *   and flag_zero; or
		 * * before a floating point mantissa decimal point
		 *   due to precision; or
		 * * after a floating point mantissa decimal point due
		 *   to precision.
		 *
		 * For example for zero-padded hexadecimal integers
		 * this would insert where the angle brackets are in:
		 * 0x<>hhhh.
		 *
		 * For floating point numbers this would insert at
		 * either <1> or <2> depending on #pad_postdp:
		 * VVV<1>.<2>FFFFeEEE
		 *
		 * Valid after conversion begins.
		 *//** Width value from specification.
		 *
		 * Valid until conversion begins.
		 *//** Conversion specifier character *//** Set for floating point values that have a non-zero
	 * pad0_prefix or pad0_pre_exp.
	 *//** Set when pad0_value zeroes are to be to be inserted after
	 * the decimal point in a floating point conversion.
	 *//** If set alternate form requires 0x before hex. *//** If set alternate form requires 0 before octal. *//** Conversion specifier category (value from specifier_cat_enum) *//** Indicates an a or A conversion specifier.
	 *
	 * This affects how precision is handled.
	 *//** Length modifier (value from length_mod_enum) *//** Precision from int argument
	 *
	 * prec_value is set to the value of a non-negative argument.
	 * If the argument is negative prec_present is cleared.
	 *//** Precision field present *//** Width value from int argument
	 *
	 * width_value is set to the absolute value of the argument.
	 * If the argument is negative flag_dash is also set.
	 *//** Width field present *//** Pad with leading zeroes *//** Alternative form *//** Space for non-negative sign *//** Explicit sign *//** Left-justify value in width *//** Indicates flags are valid but not supported *//** Indicates flags are inconsistent *//* Structure capturing all attributes of a conversion
 * specification.
 *
 * Initial values come from the specification, but are updated during
 * the conversion.
 *//* For PTR conversions *//* For FP conversions with L length *//* For FP conversions without L length *//* For UINT conversions *//* For SINT conversions *//* Storage for an argument value. *//* Case label to identify conversions for pointer arguments.  The
 * corresponding argument_value tag is ptr and the category is
 * SPECIFIER_PTR.
 *//* Case label to identify conversions for floating point arguments.
 * The corresponding argument_value tag is either dbl or ldbl,
 * depending on length modifier, and the category is SPECIFIER_FP.
 *//* Case label to identify conversions for signed integral arguments.
 * The corresponding argument_value tag is uint and category is
 * SPECIFIER_UINT.
 *//* Case label to identify conversions for signed integral values.  The
 * corresponding argument_value tag is sint and category is
 * SPECIFIER_SINT.
 *//* WCHAR_MIN defined *//* wchar rank vs int *//* Signed or unsigned, it'll be int *//* wchar signed *//* We need two pieces of information about wchar_t:
 * * WCHAR_IS_SIGNED: whether it's signed or unsigned;
 * * WINT_TYPE: the type to use when extracting it from va_args
 *
 * The former can be determined from the value of WCHAR_MIN if it's defined.
 * It's not for minimal libc, so treat it as whatever char is.
 *
 * The latter should be wint_t, but minimal libc doesn't provide it.  We can
 * substitute wchar_t as long as that type does not undergo default integral
 * promotion as an argument.  But it does for at least one toolchain (xtensa),
 * and where it does we need to use the promoted type in va_arg() to avoid
 * build errors, otherwise we can use the base type.  We can tell that
 * integral promotion occurs if WCHAR_MAX is strictly less than INT_MAX.
 *//* a, A, e, E, f, F, g, G *//* n, p, s *//* c, o, u, x, X *//* d, i *//* unrecognized *//* Categories of conversion specifiers. *//* long double *//* intmax *//* long long *//* long *//* short *//* char *//* int *//* The allowed types of length modifier. *//* The float code may extract up to 16 digits, plus a prefix, a
 * leading 0, a dot, and an exponent in the form e+xxx for a total of
 * 24. Add a trailing NULL so the buffer length required is 25.
 *//* The maximum buffer size required is for octal formatting: one character for
 * every 3 bits.  Neither EOS nor alternate forms are required.
 *//* Provide typedefs used for signed and unsigned integral types
 * capable of holding all convertible integral values.
 *//* newlib doesn't declare this function unless __POSIX_VISIBLE >= 200809.  No
 * idea how to make that happen, so lets put it right here.
 *//*
 * Copyright (c) 1997-2010, 2012-2015 Wind River Systems, Inc.
 * Copyright (c) 2020 Nordic Semiconductor ASA
 *
 * SPDX-License-Identifier: Apache-2.0
 */vmaxlen/home/haojie/zephyrproject/zephyr/include/zephyr/linker/utils.hlinker_is_in_rodataRO_ENDRO_STARTZEPHYR_INCLUDE_LINKER_UTILS_H_defined(CONFIG_ARM) || defined(CONFIG_ARC) || defined(CONFIG_X86) || \/* ZEPHYR_INCLUDE_LINKER_UTILS_H_ *//**
 * @brief Check if address is in read only section.
 *
 * Note that this may return false if the address lies outside
 * the compiler's default read only sections (e.g. .rodata
 * section), depending on the linker script used. This also
 * applies to constants with explicit section attributes.
 *
 * @param addr Address.
 *
 * @return True if address identified within read only section.
 *//home/haojie/zephyrproject/zephyr/lib/os/cbprintf_packaged.c<zephyr/linker/utils.h>cbprintf_package_convertin_packaged != NULLbuf32args_sizeros_nbrrws_nbrfmt_presentrw_cpyro_cpycbprintf_package_desc *in_descsizeof(int)out_lenstr_posstrl_cnt"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idxLOG_LEVEL_WRN"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"fmt, arg_idxUTIL_CAT(Z_LOG_FUNC_PREFIX_, 2U)Z_LOG_STR(2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)CONFIG_LOG_FUNC_NAME_PREFIX_WRN_XXXXCONFIG_LOG_FUNC_NAME_PREFIX_WRN_XXXXCONFIG_LOG_FUNC_NAME_PREFIX_WRN (1)UTIL_CAT(Z_LOG_FUNC_PREFIX_2U)(Z_LOG_STR_WITH_PREFIX("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))("%s: " "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (const char *)__func__ , fmt, arg_idx)("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)Z_LOG_FUNC_PREFIX_2UNUM_VA_ARGS_LESS_1(_,"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)(Z_LOG_STR_WITH_PREFIX2("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))_,"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idxarg_idxNUM_VA_ARGS_LESS_1("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)(, GET_ARGS_LESS_N(1, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))(, fmt, arg_idx), fmt, arg_idx"%s: " "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (const char *)__func__ , fmt, arg_idx_XXXX0 ("%s: " "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (const char *)__func__ , fmt, arg_idx)REVERSE_ARGS("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)arg_idx , fmt , "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"fmt , "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(0, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") = ("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0)(__auto_type "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" = ("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0)("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d")(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(1, fmt) = (fmt) + 0)(__auto_type _v1 = (fmt) + 0)(fmt)_ZZZZ1 (fmt)__auto_type _v1 = (fmt) + 0(Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(2, arg_idx) = (arg_idx) + 0)(__auto_type _v2 = (arg_idx) + 0)(arg_idx)_ZZZZ2 (arg_idx)__auto_type _v2 = (arg_idx) + 0FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2(Z_LOG_MSG_STR_VAR_IN_SECTION(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)))(static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d";)NUM_VA_ARGS_LESS_1(_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))(static const char _fmt[] __in_section(_log_strings, static, _CONCAT(_fmt, _)) __used __noasan = GET_ARG_N(1, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2);)_,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)_,"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d";_XXXXCONFIG_LOG_FMT_SECTION (static const char _fmt[] __attribute__((section("." "_log_strings" "." "static" "." "_fmt_"))) __attribute__((__used__)) = "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d";)NUM_VA_ARGS_LESS_1("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2)(Z_CBPRINTF_HAS_PCHAR_ARGS(((0 << 3) | (0 ? ((1UL << (1)) | (1UL << (0))) : 0)), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))0, 0, _src, 2U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))( bool can_simple = LOG_MSG_SIMPLE_CHECK("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2); if (can_simple && ((0) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(0, _src, 2U, Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2)), (0)))LOG_MSG_SIMPLE_ARG_CNT_CHECK("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2)( LOG_MSG_SIMPLE_ARG_TYPE_CHECK("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))Z_LOG_FMT_ARGS(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx))(Z_LOG_FMT_ARGS_2(_fmt,FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", fmt, arg_idx)))("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2)(COND_CODE_0(NUM_VA_ARGS_LESS_1("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2), (_fmt), (_fmt, GET_ARGS_LESS_N(1, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))))(_fmt, GET_ARGS_LESS_N(1, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))( LOG_MSG_SIMPLE_FUNC(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2); )( z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2); )(z_log_msg_simple_create_0(_src, 2U, GET_ARG_N(1, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2)))(z_log_msg_simple_create_0(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"))(COND_CODE_1(2, ( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2, dummy, dummy) ) ))(z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2))( Z_LOG_MSG_SIMPLE_CREATE_1(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2, dummy) )( z_log_msg_simple_create_1(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1) )( Z_LOG_MSG_SIMPLE_CREATE_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2, dummy, dummy) )( z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2) )"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2, dummy"(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2, dummy, dummy_XXXX2 ( z_log_msg_simple_create_1(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1) )z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2)_ZZZZ2 (z_log_msg_simple_create_0(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"))z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);_XXXX0 ( _Bool can_simple = _Generic(_v1, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0) || _Generic(_v2, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0); if (can_simple && ((0) == 0) && !k_is_user_context()) { ; z_log_msg_simple_create_2(_src, 2U, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d", (uint32_t)(uintptr_t)_v1, (uint32_t)(uintptr_t)_v2);; _mode = Z_LOG_MSG_MODE_SIMPLE; break; } )(Z_CBPRINTF_HAS_PCHAR_ARGS(0, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))(Z_CBPRINTF_HAS_PCHAR_ARGS(_flags, "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2))REVERSE_ARGS("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d" , _v1 , _v2)_v2 , _v1 , "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"_v1 , "(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d"!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE))!((sizeof(double) < 1) && _Generic(("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0, long double : 1, default : 0) && !0)_Generic(("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__(("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0))_Generic(("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0, float : 1, double : 1, long double : 1, long long : 1, unsigned long long : 1, default : __alignof__(("(unsigned) char * used for %%p argument. " "It's recommended to cast it to void * because " "it may cause misbehavior in certain " "configurations. String:\"%s\" argument:%d") + 0))drop_ro_str_pos(CBPRINTF_PACKAGE_CONVERT_KEEP_RO_STR |
					 CBPRINTF_PACKAGE_CONVERT_RO_STR)arg_posis_ro%c: (unsigned) char * used for %%p argument. It's recommended to cast it to void * because it may cause misbehavior in certain configurations. String:"%s" argument:%d
char[168]in_packagedin_lenstrlstrl_len(unsigned) char * used for %%p argument. It's recommended to cast it to void * because it may cause misbehavior in certain configurations. String:"%s" argument:%dchar[163]calculate_string_lengthout_desccpy_str_poskeep_str_posscpy_cntkeep_cntscpy_cnt < sizeof(cpy_str_pos)keep_cnt < sizeof(keep_str_pos)in_desc_backupstrs_lenlocstr_lenis_ptrmodis_fmt_speccbpprintf_externalcbprintf_package_hdr_ext *hdrpss_nbrs_idxsizeof(*hdr)cbprintf_packagecbvprintf_packagebuf0str_ptr_posstr_ptr_args_rw_cnts_ro_cntparsingrws_pos_enfros_cntis_str_argsizeof(*pkg_hdr)formatterpackagedsizeof(char *)VA_STACK_ALIGN(char *)&v"String with too many arguments"!__builtin_types_compatible_p(__typeof__(str_ptr_pos), __typeof__(&(str_ptr_pos)[0]))"str_ptr_pos[] too small""unexpected size %u"VA_STACK_ALIGN(int)'2''3''4''5''6''7''8''9'VA_STACK_ALIGN(intmax_t)sizeof(intmax_t)VA_STACK_ALIGN(size_t)VA_STACK_ALIGN(ptrdiff_t)VA_STACK_ALIGN(long long)VA_STACK_ALIGN(long)VA_STACK_ALIGN(void *)VA_STACK_ALIGN(long double)sizeof(long double)VA_STACK_ALIGN(double)Z_CBPRINTF_VA_STACK_LL_DBL_MEMCPYunion <unnamed> *double *do_roprocess_strings_ptr_idxARRAY_SIZE(str_ptr_pos)"too many format args"append_stringget_package_lenpackaged != NULLcbprintf_via_va_listptr_in_rodatalddcbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL(Z_LOG_EVAL(CONFIG_LOG_OVERRIDE_LEVEL, (1), (Z_LOG_EVAL(_LOG_LEVEL_RESOLVE(cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL), (1), (0))) ))(Z_LOG_EVAL(_LOG_LEVEL_RESOLVE(cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL), (1), (0)))_LOG_LEVEL_RESOLVE(cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL)GET_ARG_N(1, cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL)CONFIG_CBPRINTF_PACKAGE_LOG_LEVELlog_dynamic_cbprintf_packagelog_const_cbprintf_packagesizeof(va_list) == sizeof(void *)"architecture specific support is needed"STR_POS_MASKSTR_POS_RO_FLAGBUF_OFFSET((uintptr_t)buf - (uintptr_t)buf0)BIT_MASK(7)defined(CONFIG_CBPRINTF_PACKAGE_SUPPORT_TAGGED_ARGUMENTS) && \defined(CBPRINTF_VIA_UNIT_TEST)defined(__CHECKER__)defined(__aarch64__)defined(__xtensa__)defined(CONFIG_CBPRINTF_PACKAGE_SUPPORT_TAGGED_ARGUMENTS)(UTIL_CAT(cbprintf_package, _str))(cbprintf_package_str)(STRINGIFY(cbprintf_package))("cbprintf_package")Z_LOG_ITEM_CONST_DATA(cbprintf_package)_CONCAT(log_const_cbprintf_package, _)log_const_cbprintf_package_( static const char UTIL_CAT(cbprintf_package, _str)[] __in_section(_log_strings, static, _CONCAT(cbprintf_package, _)) __used __noasan = STRINGIFY(cbprintf_package);)( static const char cbprintf_package_str[] __attribute__((section("." "_log_strings" "." "static" "." "cbprintf_package_"))) __attribute__((__used__)) = "cbprintf_package";)_XXXXCONFIG_LOG_FMT_SECTION ( static const char cbprintf_package_str[] __attribute__((section("." "_log_strings" "." "static" "." "cbprintf_package_"))) __attribute__((__used__)) = "cbprintf_package";)_CONCAT(cbprintf_package, _)cbprintf_package_Z_DO_LOG_MODULE_REGISTER(cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL)(_LOG_MODULE_DATA_CREATE(GET_ARG_N(1, cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL), _LOG_LEVEL_RESOLVE(cbprintf_package, CONFIG_CBPRINTF_PACKAGE_LOG_LEVEL)))(const __attribute__((__aligned__(__alignof(struct log_source_const_data)))) struct log_source_const_data log_const_cbprintf_package __attribute__((section("." "_log_const" "." "static" "." "log_const_cbprintf_package_"))) __attribute__((__used__)) = { .name = "cbprintf_package", .level = 0U }; )_XXXX0 (const __attribute__((__aligned__(__alignof(struct log_source_const_data)))) struct log_source_const_data log_const_cbprintf_package __attribute__((section("." "_log_const" "." "static" "." "log_const_cbprintf_package_"))) __attribute__((__used__)) = { .name = "cbprintf_package", .level = 0U }; )(_LOG_MODULE_DYNAMIC_DATA_CREATE(cbprintf_package);)(__attribute__((__aligned__(__alignof(struct log_source_dynamic_data)))) struct log_source_dynamic_data log_dynamic_cbprintf_package __attribute__((section("." "_log_dynamic" "." "static" "." "log_dynamic_cbprintf_package_"))) __attribute__((__used__)) ;)_XXXXCONFIG_LOG_RUNTIME_FILTERING (__attribute__((__aligned__(__alignof(struct log_source_dynamic_data)))) struct log_source_dynamic_data log_dynamic_cbprintf_package __attribute__((section("." "_log_dynamic" "." "static" "." "log_dynamic_cbprintf_package_"))) __attribute__((__used__)) ;)LOG_ITEM_DYNAMIC_DATA(cbprintf_package)_CONCAT(log_dynamic_cbprintf_package, _)log_dynamic_cbprintf_package__XXXXCONFIG_LOG_FMT_SECTION (cbprintf_package_str)"cbprintf_package"/* Empty call (can be interpreted as flushing) *//* Append strings *//* Copy appended strings from source package to destination. *//* Copy string positions which are kept. *//* Restore input descriptor. *//* Copy package header and arguments. *//* Temporary overwrite input descriptor to allow bulk transfer *//* Set amount of strings appended to the package. *//* Drop information about ro_str location. *//* Go through read-write strings and identify which shall be appended.
	 * Note that there may be read-only strings there. Use address evaluation
	 * to determine if strings is read-only.
	 *//* If read-only strings shall be appended to the output package copy
	 * their indexes to the local array, otherwise indicate that indexes
	 * shall remain in the output package.
	 *//* Up to one will be kept since if both types are kept it returns earlier. *//* At least one is copied in. *//* string length decremented by 1 because argument
				 * index is dropped.
				 *//* If possible store calculated string length. *//* Since location is being dropped, decrement
				 * output length by 2 (argument index + position)
				 *//* Handle RW strings. *//* If null destination, just calculate output length. *//* Pointer to array with string locations. Array starts with read-only
	 * string locations.
	 *//* If we got here, it means that coping will be more complex and will be
	 * done with strings appending.
	 * Retrieve the size of the arg list.
	 *//* If flags are not set or appending request without rw string indexes
	 * present is chosen, just do a simple copy (or length calculation).
	 * Assuming that it is the most common case.
	 *//* Get number of RW string indexes in the package and check if copying
	 * includes appending those strings.
	 *//* Get number of RO string indexes in the package and check if copying
	 * includes appending those strings.
	 *//* Function checks if nth argument is a pointer (%p). Returns true is yes. Returns
 * false if not or if string does not have nth argument.
 *//* Function checks if character might be format specifier. Check is relaxed since
 * compiler ensures that correct format specifier is used so it is enough to check
 * that character is not one of potential modifier (e.g. number, dot, etc.).
 *//* Turn this into a va_list and  print it *//* Skip past the header *//* move to next string *//* update the pointer with current string location *//* Locate pointer location for this string *//*
	 * Patch in string pointers.
	 *//* Locate the string table *//* Retrieve the size of the arg list and number of strings. *//*
	 * TODO: remove pointers for appended strings since they're useless.
	 * TODO: explore leveraging same mechanism to remove alignment padding
	 *//* copy the string with its terminating '\0' *//* store the pointer position prefix *//* make sure it fits *//* find the string length including terminating '\0' *//* clear the in-buffer pointer (less entropy if compressed) *//* retrieve the string pointer *//* Process only RW strings. *//* Store strings prefixed by their pointer location. *//* Store strings pointer locations of read only strings. *//* Strings are appended, update append counter. *//* Strings are appended, update location counter. *//* Record end of argument list. *//* Clear our buffer header. We made room for it initially. *//*
	 * If all we wanted was to count required buffer size
	 * then we have it now.
	 *//*
	 * We remember the size of the argument list as a multiple of
	 * sizeof(int) and limit it to a 8-bit field. That means 1020 bytes
	 * worth of va_list, or about 127 arguments on a 64-bit system
	 * (twice that on 32-bit systems). That ought to be good enough.
	 *//*
					 * Add the string length, the final '\0'
					 * and size of the pointer position prefix.
					 *//*
					 * Add only pointer position prefix and
					 * argument index when counting strings.
					 *//*
					 * Add only pointer position prefix
					 * when counting strings.
					 *//* flag read-only string. *//*
					 * Remember string pointer location.
					 * We will append non-ro strings later.
					 *//*
				 * In the do_ro case we must consider
				 * room for possible STR_POS_RO_FLAG.
				 * Otherwise the index range is 8 bits
				 * and any overflow is caught later.
				 *//* nothing to do *//* copy va_list data over to our buffer *//* make sure the data fits *//* align destination buffer location *//*
				 * Handle floats separately as they may be
				 * held in a different register set.
				 *//* Scan the format string *//* CONFIG_CBPRINTF_PACKAGE_SUPPORT_TAGGED_ARGUMENTS *//*
			 * There are lots of __fallthrough here since
			 * quite a few of the data types have the same
			 * storage size.
			 *//* End of arguments *//*
			 * Here we copy the tag over to the package.
			 *//*
	 * Then process the format string itself.
	 * Here we branch directly into the code processing strings
	 * which is in the middle of the following while() loop. That's the
	 * reason for the post-decrement on fmt as it will be incremented
	 * prior to the next (actually first) round of that loop.
	 *//*
	 * Otherwise we must ensure we can store at least
	 * the pointer to the format string itself.
	 *//*
		 * The space to store the data is represented by both the
		 * buffer offset as well as the extra string data to be
		 * appended. When only figuring out the needed space, we
		 * don't append anything. Instead, we reuse the len variable
		 * to sum the size of that data.
		 *
		 * Also, we subtract any initial misalignment offset from
		 * the total as this won't be part of the buffer. To avoid
		 * going negative with an unsigned variable, we add an offset
		 * (CBPRINTF_PACKAGE_ALIGNMENT) that will be removed before
		 * returning.
		 *//*
	 * When buf0 is NULL we don't store anything.
	 * Instead we count the needed space to store the data.
	 * In this case, incoming len argument indicates the anticipated
	 * buffer "misalignment" offset.
	 *//*
	 * Make room to store the arg list size, the number of
	 * appended writable strings and the number of appended
	 * read-only strings. They both occupy 1 byte each.
	 * Skip a byte. Then a uint32_t to store flags used to
	 * create the package.
	 *
	 * Given the next value to store is the format string pointer
	 * which is guaranteed to be at least 4 bytes, we just reserve
	 * multiple of pointer size for the above to preserve alignment.
	 *
	 * Refer to union cbprintf_package_hdr for more details.
	 *//* Xtensa requires package to be 16 bytes aligned. *//* Buffer must be aligned at least to size of a pointer. *//* Get number of first read only strings present in the string.
	 * There is always at least 1 (fmt) but flags can indicate more, e.g
	 * fixed prefix appended to all strings.
	 *//* Flag indicates that rw strings are stored as array with positions,
	 * instead of appending them to the package.
	 *//* Argument index. Preincremented thus starting from -1.*//* number of ro strings *//* number of rw strings *//* index into str_ptr_pos[] *//* string pointer argument index *//* string pointer positions *//* current argument's required alignment *//* current argument's size *//* current buffer position *//* buffer start (may be NULL) *//* Buffer offset abstraction for better code clarity. *//*
 * Internally, a byte is used to store location of a string argument within a
 * package. MSB bit is set if string is read-only so effectively 7 bits are
 * used for index, which should be enough.
 *//* Move beyond strings appended to the package. *//* Move beyond read-only string indexes array. *//* Move beyond args. *//*
 * Default implementation shared by many architectures like
 * 32-bit ARM and Intel.
 *
 * We assume va_list is a simple pointer.
 *//* create a valid va_list with our buffer *//*
 * Reference:
 *
 * gcc source code (gcc/config/xtensa/xtensa.c)
 * xtensa_build_builtin_va_list(), xtensa_va_start(),
 * xtensa_gimplify_va_arg_expr()
 *//*
 * Reference:
 *
 * System V Application Binary Interface
 * AMD64 Architecture Processor Supplement
 *//*
 * Reference:
 *
 * Procedure Call Standard for the ARM 64-bit Architecture
 *//*
 * va_list creation
 *//* Unit test is X86 (or other host) but not using Zephyr
	 * linker scripts.
	 *//**
 * @brief Check if address is in read only section.
 *
 * @param addr Address.
 *
 * @return True if address identified within read only section.
 *//*
 * Copyright (c) 2021 BayLibre, SAS
 *
 * SPDX-License-Identifier: Apache-2.0
 */architecture specific support is needed/home/haojie/zephyrproject/zephyr/lib/os/dec.cnum_digitsdigit(char)'0'/*
 * Copyright (c) 2019 Oticon A/S
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/lib/os/heap.hsize_too_bigCHUNK_UNITbucket_idxusable_szchunksz_to_bytesmin_chunk_sizebytes_to_chunkszchunkszheap_footer_byteschunk_header_bytessolo_free_headerset_left_chunk_sizeLEFT_SIZEright_chunkleft_chunkset_next_free_chunkFREE_NEXTset_prev_free_chunkFREE_PREVnext_free_chunkprev_free_chunkset_chunk_sizeSIZE_AND_USEDset_chunk_usedchunk_unit_t *cmem~1Uchunk_sizechunk_usedchunk_setval == (uint32_t)valval == (uint16_t)valc <= h->end_chunkchunk_fieldchunk_bufbig_heapbig_heap_bytesbig_heap_chunksCONFIG_SYS_HEAP_SMALL_ONLY_XXXXCONFIG_SYS_HEAP_SMALL_ONLY_XXXXCONFIG_SYS_HEAP_SMALL_ONLY 1CONFIG_SYS_HEAP_BIG_ONLY_XXXXCONFIG_SYS_HEAP_BIG_ONLY_XXXXCONFIG_SYS_HEAP_BIG_ONLY 1sizeof(void *) > 4U0x7fffUchunksz_tchunk_unit_tchunk_fieldsz_heap_bucketchunkid_tz_heap_bucket[0]bucketsavail_bucketsend_chunkchunkid_t[2]unsigned int[2]chunk0_hdrCHECK(x)ZEPHYR_INCLUDE_LIB_OS_HEAP_H_CONFIG_SYS_HEAP_VALIDATEheap_print_info/* ZEPHYR_INCLUDE_LIB_OS_HEAP_H_ *//* For debugging *//*
	 * Quick check to bail out early if size is too big.
	 * Also guards against potential arithmetic overflows elsewhere.
	 *//*
 * Note: no need to preserve the used bit here as the chunk is never in use
 * when its size is modified, and potential set_chunk_used() is always
 * invoked after set_chunk_size().
 *//* the struct z_heap matches with the first chunk *//* big_heap needs uint32_t, small_heap needs uint16_t *//* Chunks are identified by their offset in 8 byte units from the
 * first address in the buffer (a zero-valued chunkid_t is used as a
 * null; that chunk would always point into the metadata at the start
 * of the heap and cannot be allocated).  They are prefixed by a
 * variable size header that depends on the size of the heap.  Heaps
 * with fewer than 2^15 units (256kb) of storage use shorts to store
 * the fields, otherwise the units are 32 bit integers for a 16Gb heap
 * space (larger spaces really aren't in scope for this code, but
 * could be handled similarly I suppose).  Because of that design
 * there's a certain amount of boilerplate API needed to expose the
 * field accessors since we can't use natural syntax.
 *
 * The fields are:
 *   LEFT_SIZE: The size of the left (next lower chunk in memory)
 *              neighbor chunk.
 *   SIZE_AND_USED: the total size (including header) of the chunk in
 *                  8-byte units.  The bottom bit stores a "used" flag.
 *   FREE_PREV: Chunk ID of the previous node in a free list.
 *   FREE_NEXT: Chunk ID of the next node in a free list.
 *
 * The free lists are circular lists, one for each power-of-two size
 * category.  The free list pointers exist only for free chunks,
 * obviously.  This memory is part of the user's buffer when
 * allocated.
 *
 * The field order is so that allocated buffers are immediately bounded
 * by SIZE_AND_USED of the current chunk at the bottom, and LEFT_SIZE of
 * the following chunk at the top. This ordering allows for quick buffer
 * overflow detection by testing left_chunk(c + chunk_size(c)) == c.
 *//* Theese validation checks are non-trivially expensive, so enable
 * only when debugging the heap code.  They shouldn't be routine
 * assertions.
 *//*
 * Internal heap APIs
 */chunksz_inchunks/home/haojie/zephyrproject/zephyr/lib/os/heap-validate.c"heap.h"nb_bucketsoverheadHeap at %p contains %d units in %d buckets

"Heap at %p contains %d units in %d buckets\n\n"  bucket#    min units        total      largest      largest
             threshold       chunks      (units)      (bytes)
  -----------------------------------------------------------
"  bucket#    min units        total      largest      largest\n"
	       "             threshold       chunks      (units)      (bytes)\n"
	       "  -----------------------------------------------------------\n"char[187]largestchunk_size(h, curr)z_heap_bucket *%9d %12d %12d %12d %12zd
"%9d %12d %12d %12d %12zd\n"
Chunk dump:
"\nChunk dump:\n"chunk %4d: [%c] size=%-4d left=%-4d right=%d
"chunk %4d: [%c] size=%-4d left=%-4d right=%d\n"char[46]
%zd free bytes, %zd allocated bytes, overhead = %zd bytes (%zd.%zd%%)
"\n%zd free bytes, %zd allocated bytes, overhead = %zd bytes (%zd.%zd%%)\n"char[72]srz_heap_stress_block *sizeof(struct z_heap_stress_block)z_heap_stress_rec *rand_free_choicerand_alloc_sizescalerand_alloc_choicesr->total_bytes < 0xffffffffU / 100"too big for u32!"full_pctfree_chance 0xffffffffU0x80000000Urand322862933555777941757UL3037000493ULc0emptyzeroprev_chunkget_alloc_infocheck_nextsbidxemptybitemptylistempties_matchvalid_chunk(h, b->next)valid_chunkchunk_size(h, c) > 0c + chunk_size(h, c) <= h->end_chunkin_bounds(h, c)right_chunk(h, left_chunk(h, c)) == cleft_chunk(h, right_chunk(h, c)) == c!solo_free_header(h, c)chunk_used(h, left_chunk(h, c))chunk_used(h, right_chunk(h, c))in_bounds(h, prev_free_chunk(h, c))in_bounds(h, next_free_chunk(h, c))in_boundsc >= right_chunk(h, 0)c < h->end_chunkchunk_size(h, c) < h->end_chunkz_heap_stress_recz_heap_stress_blockbytes_allocedblocks_allocednblocksblocksVALIDATE(cond)do { if (!(cond)) { return false; } } while (0)/* The end marker chunk has a header. It is part of the overhead. *//*
 * Print heap info for debugging / analysis purpose
 *//* General purpose heap stress test.  Takes function pointers to allow
 * for testing multiple heap APIs with the same rig.  The alloc and
 * free functions are passed back the argument as a context pointer.
 * The "log" function is for readable user output.  The total_bytes
 * argument should reflect the size of the heap being tested.  The
 * scratch array is used to store temporary state and should be sized
 * about half as large as the heap itself. Returns true on success.
 *//* Returns the index of a randomly chosen block to free *//* Min scale of 4 means that the half of the requests in the
	 * smallest size have an average size of 8
	 *//* Chooses a size of block to allocate, logarithmically favoring
 * smaller blocks (i.e. blocks twice as large are half as frequent
 *//* The way this works is to scale the chance of choosing to
		 * allocate vs. free such that it's even odds when the heap is
		 * at the target percent, with linear tapering on the low
		 * slope (i.e. we choose to always allocate with an empty
		 * heap, allocate 50% of the time when the heap is exactly at
		 * the target, and always free when above the target).  In
		 * practice, the operations aren't quite symmetric (you can
		 * always free, but your allocation might fail), and the units
		 * aren't matched (we're doing math based on bytes allocated
		 * and ignoring the overhead) but this is close enough.  And
		 * yes, the math here is coarse (in units of percent), but
		 * that's good enough and fits well inside 32 bit quantities.
		 * (Note precision issue when heap size is above 40MB
		 * though!).
		 *//* Edge cases: no blocks allocated, and no space for a new one *//* seed *//* Very simple LCRNG (from https://nuclear.llnl.gov/CNP/rng/rngman/node4.html)
 *
 * Here to guarantee cross-platform test repeatability.
 *//* Now we are valid, but have managed to invert all the in-use
	 * fields.  One more linear pass to fix them up
	 *//* Go through the free lists again checking that the linear
	 * pass caught all the blocks and that they now show UNUSED.
	 * Mark them USED.
	 *//* Should have exactly consumed the buffer *//*
	 * Walk through the chunks linearly again, verifying that all chunks
	 * but solo headers are now USED (i.e. all free blocks were found
	 * during enumeration).  Mark all such blocks UNUSED and solo headers
	 * USED.
	 *//* Check the free lists: entry count should match, empty bit
	 * should be correct, and all chunk entries should point into
	 * valid unused chunks.  Mark those chunks USED, temporarily.
	 *//*
	 * Validate sys_heap_runtime_stats_get API.
	 * Iterate all chunks in sys_heap to get total allocated bytes and
	 * free bytes, then compare with the results of
	 * sys_heap_runtime_stats_get function.
	 *//*
	 * Walk through the chunks linearly, verifying sizes and end pointer.
	 *//* Validate multiple state dimensions for the bucket "next" pointer
 * and see that they match.  Probably should unify the design a
 * bit...
 *//* White-box sys_heap validation code.  Uses internal data structures.
 * Not expected to be useful in production apps.  This checks every
 * header field of every chunk and returns true if the totality of the
 * data structure is a valid heap.  It doesn't necessarily tell you
 * that it is the CORRECT heap given the history of alloc/free calls
 * that it can't inspect.  In a pathological case, you can imagine
 * something scribbling a copy of a previously-valid heap on top of a
 * running one and corrupting it. YMMV.
 */alloc_bytes/home/haojie/zephyrproject/zephyr/include/zephyr/sys/heap_listener.hheap_listener_notify_resizeheap_idold_heap_endnew_heap_endheap_listener_notify_freeheap_listener_notify_allocHEAP_ID_FROM_POINTER(heap_pointer)((uintptr_t)NULL)ZEPHYR_INCLUDE_SYS_HEAP_LISTENER_Hdefined(CONFIG_HEAP_LISTENER) || defined(__DOXYGEN__)/* ZEPHYR_INCLUDE_SYS_HEAP_LISTENER_H *//* CONFIG_HEAP_LISTENER *//**
 * @brief Define heap event listener node for resize event
 *
 * Sample usage:
 * @code
 * void on_heap_resized(uintptr_t heap_id, void *old_heap_end, void *new_heap_end)
 * {
 *   LOG_INF("Libc heap end moved from %p to %p", old_heap_end, new_heap_end);
 * }
 *
 * HEAP_LISTENER_RESIZE_DEFINE(my_listener, HEAP_ID_LIBC, on_heap_resized);
 * @endcode
 *
 * @param name		Name of the heap event listener object
 * @param _heap_id	Identifier of the heap to be listened
 * @param _resize_cb	Function to be called when the listened heap is resized
 *//**
 * @brief Define heap event listener node for free event
 *
 * Sample usage:
 * @code
 * void on_heap_free(uintptr_t heap_id, void *mem, size_t bytes)
 * {
 *   LOG_INF("Memory freed at %p, size %ld", mem, bytes);
 * }
 *
 * HEAP_LISTENER_FREE_DEFINE(my_listener, HEAP_ID_LIBC, on_heap_free);
 * @endcode
 *
 * @param name		Name of the heap event listener object
 * @param _heap_id	Identifier of the heap to be listened
 * @param _free_cb	Function to be called for free event
 *//**
 * @brief Define heap event listener node for allocation event
 *
 * Sample usage:
 * @code
 * void on_heap_alloc(uintptr_t heap_id, void *mem, size_t bytes)
 * {
 *   LOG_INF("Memory allocated at %p, size %ld", mem, bytes);
 * }
 *
 * HEAP_LISTENER_ALLOC_DEFINE(my_listener, HEAP_ID_LIBC, on_heap_alloc);
 * @endcode
 *
 * @param name		Name of the heap event listener object
 * @param _heap_id	Identifier of the heap to be listened
 * @param _alloc_cb	Function to be called for allocation event
 *//**
 * @brief Libc heap identifier
 *
 * Identifier of the global libc heap.
 *//**
 * @brief Construct heap identifier from heap pointer
 *
 * Construct a heap identifier from a pointer to the heap object, such as
 * sys_heap.
 *
 * @param heap_pointer Pointer to the heap object
 *//**
 * @brief Notify listeners of heap resize event
 *
 * Notify registered heap event listeners with matching heap identifier that the
 * heap has been resized.
 *
 * @param heap_id Heap identifier
 * @param old_heap_end Address of the heap end before the change
 * @param new_heap_end Address of the heap end after the change
 *//**
 * @brief Notify listeners of heap free event
 *
 * Notify registered heap event listeners with matching heap identifier that
 * memory is freed on heap
 *
 * @param heap_id Heap identifier
 * @param mem Pointer to the freed memory
 * @param bytes Size of freed memory
 *//**
 * @brief Notify listeners of heap allocation event
 *
 * Notify registered heap event listeners with matching heap identifier that an
 * allocation has been done on heap
 *
 * @param heap_id Heap identifier
 * @param mem Pointer to the allocated memory
 * @param bytes Size of allocated memory
 *//**
 * @brief Unregister heap event listener
 *
 * Remove the listener from the global list of heap listeners that can be
 * notified by different heap implementations upon certain events related to the
 * heap usage.
 *
 * @param listener Pointer to the heap_listener object
 *//**
 * @brief Register heap event listener
 *
 * Add the listener to the global list of heap listeners that can be notified by
 * different heap implementations upon certain events related to the heap usage.
 *
 * @param listener Pointer to the heap_listener object
 *//**
	 * The heap event to be notified.
	 *//**
	 * Identifier of the heap whose events are listened.
	 *
	 * It can be a heap pointer, if the heap is represented as an object,
	 * or 0 in the case of the global libc heap.
	 *//** Singly linked list node *//**
 * @typedef heap_listener_free_cb_t
 * @brief Callback used when memory is freed from heap
 *
 * @note Heaps managed by libraries outside of code in
 *       Zephyr main code repository may not emit this event.
 *
 * @note The number of bytes freed may not match exactly to
 *       the request to the allocation function. Internal
 *       mechanism of the heap dictates how memory is
 *       allocated or freed.
 *
 * @param heap_id Heap identifier
 * @param mem Pointer to the freed memory
 * @param bytes Size of freed memory
 *//**
 * @typedef heap_listener_alloc_cb_t
 * @brief Callback used when there is heap allocation
 *
 * @note Heaps managed by libraries outside of code in
 *       Zephyr main code repository may not emit this event.
 *
 * @note The number of bytes allocated may not match exactly
 *       to the request to the allocation function. Internal
 *       mechanism of the heap may allocate more than
 *       requested.
 *
 * @param heap_id Heap identifier
 * @param mem Pointer to the allocated memory
 * @param bytes Size of allocated memory
 *//**
 * @typedef heap_listener_resize_cb_t
 * @brief Callback used when heap is resized
 *
 * @note Minimal C library does not emit this event.
 *
 * @param heap_id Identifier of heap being resized
 * @param old_heap_end Pointer to end of heap before resize
 * @param new_heap_end Pointer to end of heap after resize
 *//*
	 * Dummy event so an un-initialized but zero-ed listener node
	 * will not trigger any callbacks.
	 *//**
 * @defgroup heap_listener_apis Heap Listener APIs
 * @ingroup heaps
 * @{
 *//home/haojie/zephyrproject/zephyr/lib/os/heap.c<zephyr/sys/heap_listener.h>bytes / CHUNK_UNIT <= 0x7fffU"heap size is too big"bytes / CHUNK_UNIT <= 0x7fffffffUbytes > heap_footer_bytes(bytes)"heap size is too small"(uint8_t *)mem + bytesheap_szheap_sz > chunksz(sizeof(struct z_heap))chunk0_sizesizeof(struct z_heap)sizeof(struct z_heap_bucket)chunk0_size + min_chunk_size(h) <= heap_szCONFIG_MSAN(__sanitizer_dtor_callback(mem, bytes))_XXXXCONFIG_MSAN_XXXXCONFIG_MSAN (__sanitizer_dtor_callback(mem, bytes))end > addr(align & (align - 1)) == 0"align must be a power of 2"align_gapchunks_needsplit_sizeptr2MIN(prev_size, bytes)(((prev_size) < (bytes)) ? (prev_size) : (bytes))prev_sizegaprewchunk_header_bytes(h)padded_szmem + rewmem + bytesc_endc >= c0 && c < c_end && c_end <= c0 + padded_sz(__msan_allocated_memory(mem, bytes))_XXXXCONFIG_MSAN (__msan_allocated_memory(mem, bytes))chunk_szalloc_chunkbib->next != 0 CONFIG_SYS_HEAP_ALLOC_LOOPSbi + 1bmaskchunk_size(h, c) >= szminbucketbi <= bucket_idx(h, h->end_chunk)chunk_basechunk_used(h, c)"unexpected heap state (double-free?) for memory at %p""corrupted heap bounds (buffer overflow?) for memory at %p"mem_to_chunkidfree_chunkmerge_chunksnewszsplit_chunkssz0lszrszrc > lcrc - lc < chunk_size(h, lc)free_list_addfree_list_add_bidx(h->avail_buckets & BIT(bidx)) == 0h->avail_buckets & BIT(bidx)secondfree_list_removefree_list_remove_bidx!chunk_used(h, c)chunk_mem!(((uintptr_t)ret) & (big_heap(h) ? 7 : 3))CONFIG_SYS_HEAP_LISTENER/* the end marker chunk *//* chunk containing the free heap *//* chunk containing our struct z_heap *//* Round the start up, the end down *//* Reserve the end marker chunk's header *//* Must fit in a 31 bit count of HUNK_UNIT *//* Must fit in a 15 bit count of HUNK_UNIT *//*
	 * Fallback: allocate and copy
	 *
	 * Note for heap listener notification:
	 * The calls to allocation and free functions generate
	 * notification already, so there is no need to those here.
	 *//* Expand: split the right chunk and append *//* Shrink in place, split off and free unused suffix *//* We're good already *//* ptr is not sufficiently aligned *//* special realloc semantics *//* Split and free unused suffix *//* Split and free unused prefix *//* Get corresponding chunks *//* Align allocated memory *//*
	 * Find a free block that is guaranteed to fit.
	 * We over-allocate to account for alignment and then free
	 * the extra allocations afterwards.
	 *//*
	 * Split align and rewind values (if any).
	 * We allow for one bit of rewind in addition to the alignment
	 * value to efficiently accommodate z_heap_aligned_alloc().
	 * So if e.g. align = 0x28 (32 | 8) this means we align to a 32-byte
	 * boundary and then rewind 8 bytes.
	 *//* Split off remainder if any *//* Otherwise pick the smallest non-empty bucket guaranteed to
	 * fit and use that unconditionally.
	 *//* First try a bounded count of items from the minimal bucket
	 * size.  These may not fit, trying (e.g.) three means that
	 * (assuming that chunk sizes are evenly distributed[1]) we
	 * have a 7/8 chance of finding a match, thus keeping the
	 * number of such blocks consumed by allocation higher than
	 * the number of smaller blocks created by fragmenting larger
	 * ones.
	 *
	 * [1] In practice, they are never evenly distributed, of
	 * course.  But even in pathological situations we still
	 * maintain our constant time performance and at worst see
	 * fragmentation waste of the order of the block allocated
	 * only.
	 *//*
	 * It is easy to catch many common memory overflow cases with
	 * a quick check on this and next chunk header fields that are
	 * immediately before and after the freed memory.
	 *//*
	 * This should catch many double-free cases.
	 * This is cheap enough so let's do it all the time.
	 *//* ISO C free() semantics *//*
 * Return the closest chunk ID corresponding to given memory pointer.
 * Here "closest" is only meaningful in the context of sys_heap_aligned_alloc()
 * where wanted alignment might not always correspond to a chunk header
 * boundary.
 *//* Merge with free left chunk? *//* Merge with free right chunk? *//* Does not modify free list *//* Splits a chunk "lc" into a left chunk and a right chunk at "rc".
 * Leaves both chunks marked "free"
 *//* Insert before (!) the "next" pointer *//* Empty list, first item *//* this is the last chunk */lc/home/haojie/zephyrproject/zephyr/lib/os/hex.cdec0xf(char)'a'/* regular hex conversion *//* if hexlen is uneven, insert leading zero nibble *//home/haojie/zephyrproject/zephyr/include/zephyr/sys/multi_heap.hsys_multi_heap *sys_multi_heap_fn_tsys_multi_heapsys_multi_heap_recsys_multi_heap_rec[8]MAX_MULTI_HEAPSheapschoicenheapsZEPHYR_INCLUDE_SYS_MULTI_HEAP_H_sys_multi_heap_freeconst sys_multi_heap_recconst sys_multi_heap_rec *sys_multi_heap_rec *sys_multi_heap_get_heapconst sys_multi_heapconst sys_multi_heap *sys_multi_heap_aligned_allocsys_multi_heap_allocsys_multi_heap_add_heapsys_multi_heap_init/* ZEPHYR_INCLUDE_SYS_MULTI_HEAP_H_ *//**
 * @brief Free memory allocated from multi heap
 *
 * Returns the specified block, which must be the return value of a
 * previously successful sys_multi_heap_alloc() or
 * sys_multi_heap_aligned_alloc() call, to the heap backend from which
 * it was allocated.
 *
 * Accepts NULL as a block parameter, which is specified to have no
 * effect.
 *
 * @param mheap Multi heap pointer
 * @param block Block to free, must be a pointer to a block allocated by sys_multi_heap_alloc
 *//**
 * @brief Get a specific heap for provided address
 *
 * Finds a single system heap (with user_data)
 * controlling the provided pointer
 *
 * @param mheap Multi heap pointer
 * @param addr address to be found, must be a pointer to a block allocated by sys_multi_heap_alloc
 * @return 0 multi_heap_rec pointer to a structure to be filled with return data
 *			 or NULL if the heap has not been found
 *//**
 * @brief Allocate aligned memory from multi heap
 *
 * Just as for sys_multi_heap_alloc(), allocates a block of memory of
 * the specified size in bytes.  Takes an additional parameter
 * specifying a power of two alignment, in bytes.
 *
 * @param mheap Multi heap pointer
 * @param cfg Opaque configuration parameter, as for sys_multi_heap_fn_t
 * @param align Power of two alignment for the returned pointer, in bytes
 * @param bytes Requested size of the allocation, in bytes
 * @return A valid pointer to heap memory, or NULL if no memory is available
 *//**
 * @brief Allocate memory from multi heap
 *
 * Just as for sys_heap_alloc(), allocates a block of memory of the
 * specified size in bytes.  Takes an opaque configuration pointer
 * passed to the multi heap choice function, which is used by
 * integration code to choose a heap backend.
 *
 * @param mheap Multi heap pointer
 * @param cfg Opaque configuration parameter, as for sys_multi_heap_fn_t
 * @param bytes Requested size of the allocation, in bytes
 * @return A valid pointer to heap memory, or NULL if no memory is available
 *//**
 * @brief Add sys_heap to multi heap
 *
 * This adds a known sys_heap backend to an existing multi heap,
 * allowing the multi heap internals to track the bounds of the heap
 * and determine which heap (if any) from which a freed block was
 * allocated.
 *
 * @param mheap A sys_multi_heap to which to add a heap
 * @param heap The heap to add
 * @param user_data pointer to any data for the heap
 *//**
 * @brief Initialize multi-heap
 *
 * Initialize a sys_multi_heap struct with the specified choice
 * function.  Note that individual heaps must be added later with
 * sys_multi_heap_add_heap so that the heap bounds can be tracked by
 * the multi heap code.
 *
 * @note In general a multiheap is likely to be instantiated
 * semi-statically from system configuration (for example, via
 * linker-provided bounds on available memory in different regions, or
 * from devicetree definitions of hardware-provided addressable
 * memory, etc...).  The general expectation is that a soc- or
 * board-level platform device will be initialized at system boot from
 * these upstream configuration sources and not that an application
 * will assemble a multi-heap on its own.
 *
 * @param heap A sys_multi_heap to initialize
 * @param choice_fn A sys_multi_heap_fn_t callback used to select
 *                  heaps at allocation time
 *//**
 * @brief Multi-heap choice function
 *
 * This is a user-provided functions whose responsibility is selecting
 * a specific sys_heap backend based on the opaque cfg value, which is
 * specified by the user as an argument to sys_multi_heap_alloc(), and
 * performing the allocation on behalf of the caller.  The callback is
 * free to choose any registered heap backend to perform the
 * allocation, and may choose to pad the user-provided values as
 * needed, and to use an aligned allocation where required by the
 * specified configuration.
 *
 * NULL may be returned, which will cause the
 * allocation to fail and a NULL reported to the calling code.
 *
 * @param mheap Multi-heap structure.
 * @param cfg An opaque user-provided value.  It may be interpreted in
 *            any way by the application
 * @param align Alignment of requested memory (or zero for no alignment)
 * @param size The user-specified allocation size in bytes
 * @return A pointer to the allocated memory
 *//**
 * @brief Multi-heap allocator
 *
 * A sys_multi_heap represents a single allocator made from multiple,
 * separately managed pools of memory that must be accessed via a
 * unified API.  They can be discontiguous, and in many cases will be
 * expected to have different capabilities (for example: latency,
 * cacheability, cpu affinity, etc...)
 *
 * Allocation from the multiheap provides an opaque "configuration"
 * value to specify requirements and heuristics to assist the choice
 * in backend, which is then provided to a user-specified "choice"
 * function whose job it is to select a heap based on information in
 * the config specifier and runtime state (heap full state, etc...)
 *//* Copyright (c) 2021 Intel Corporation
 * SPDX-License-Identifier: Apache-2.0
 */mheapchoice_fn/home/haojie/zephyrproject/zephyr/lib/os/multi_heap.c<zephyr/sys/multi_heap.h>haddrbaddrmheap->nheaps < ARRAY_SIZE(mheap->heaps)lowestlowest_addr/* Now i stores the index of the heap after our target (even
	 * if it's invalid and our target is the last!)
	 * FIXME: return -ENOENT when a proper heap is not found
	 *//* Search the heaps array to find the correct heap
	 *
	 * FIXME: just a linear search currently, as the list is
	 * always short for reasonable apps and this code is very
	 * quick.  The array is stored in sorted order though, so a
	 * binary search based on the block address is the design
	 * goal.
	 *//* Now sort them in memory order, simple extraction sort */filtersLOG_INSTANCE_REGISTER(_module_name,_inst_name,_level)IF_ENABLED(CONFIG_LOG, (Z_LOG_INSTANCE_REGISTER(_module_name, _inst_name, _level)))Z_LOG_INSTANCE_REGISTER(_module_name,_inst_name,_level)Z_LOG_CONST_ITEM_REGISTER( Z_LOG_INSTANCE_FULL_NAME(_module_name, _inst_name), STRINGIFY(_module_name._inst_name), _level); IF_ENABLED(CONFIG_LOG_RUNTIME_FILTERING, (Z_LOG_RUNTIME_INSTANCE_REGISTER(_module_name, _inst_name)))Z_LOG_RUNTIME_INSTANCE_REGISTER(_module_name,_inst_name)STRUCT_SECTION_ITERABLE_ALTERNATE(log_dynamic, log_source_dynamic_data, LOG_INSTANCE_DYNAMIC_DATA(_module_name, _inst_name))LOG_INSTANCE_PTR_DECLARE(_name)COND_CODE_1(CONFIG_LOG, (Z_LOG_INSTANCE_STRUCT * _name), (int _name[TOOLCHAIN_HAS_ZLA ? 0 : 1]))Z_LOG_INSTANCE_STRUCTCOND_CODE_1(CONFIG_LOG_RUNTIME_FILTERING, (struct log_source_dynamic_data), (const struct log_source_const_data))LOG_INSTANCE_PTR_INIT(_name,_module_name,_inst_name)LOG_OBJECT_PTR_INIT(_name, LOG_INSTANCE_PTR(_module_name, _inst_name))LOG_INSTANCE_PTR(_module_name,_inst_name)Z_LOG_OBJECT_PTR(Z_LOG_INSTANCE_FULL_NAME(_module_name, _inst_name))Z_LOG_OBJECT_PTR(_name)COND_CODE_1(CONFIG_LOG_RUNTIME_FILTERING, (&LOG_ITEM_DYNAMIC_DATA(_name)), (&Z_LOG_ITEM_CONST_DATA(_name)))Z_LOG_INSTANCE_FULL_NAME(_module_name,_inst_name)UTIL_CAT(_module_name, UTIL_CAT(_, _inst_name))LOG_OBJECT_PTR_INIT(_name,_object)IF_ENABLED(CONFIG_LOG, (._name = _object,))Z_LOG_CONST_ITEM_REGISTER(_name,_str_name,_level)const STRUCT_SECTION_ITERABLE_ALTERNATE(log_const, log_source_const_data, Z_LOG_ITEM_CONST_DATA(_name)) = { .name = _str_name, .level = (_level), }Z_LOG_ITEM_CONST_DATA(_name)UTIL_CAT(log_const_, _name)ZEPHYR_INCLUDE_LOGGING_LOG_INSTANCE_H_CONFIG_NIOS2defined(CONFIG_RISCV) && defined(CONFIG_64BIT)/* ZEPHYR_INCLUDE_LOGGING_LOG_INSTANCE_H_ *//**
 * @brief Macro for registering instance for logging with independent filtering.
 *
 * Module instance provides filtering of logs on instance level instead of
 * module level. Instance create using this macro can later on be used with
 * @ref LOG_INSTANCE_PTR_INIT or referenced by @ref LOG_INSTANCE_PTR.
 *
 * @param _module_name Module name.
 * @param _inst_name Instance name.
 * @param _level Initial static filtering.
 *//**
 * @brief Declare a logger instance pointer in the module structure.
 *
 * If logging is disabled then element in the structure is still declared to avoid
 * compilation issues. If compiler supports zero length arrays then it is utilized
 * to not use any space, else a byte array is created.
 *
 * @param _name Name of a structure element that will have a pointer to logging
 * instance object.
 *//** @brief Macro for initializing a pointer to the logger instance.
 *
 * @p _module_name and @p _inst_name are concatenated to form a name of the object.
 *
 * Macro is intended to be used in user structure initializer to initialize a field
 * in the structure that holds pointer to the logging instance. Structure field
 * should be declared using @p LOG_INSTANCE_PTR_DECLARE.
 *
 * @param _name Name of a structure element that have a pointer to logging instance object.
 * @param _module_name Module name.
 * @param _inst_name Instance name.
 *//** @brief Get pointer to a logging instance.
 *
 * Instance is identified by @p _module_name and @p _inst_name.
 *
 * @param _module_name Module name.
 * @param _inst_name Instance name.
 *
 * @return Pointer to a logging instance.
 *//** @internal
 *
 * Returns a pointer associated with given logging instance. When runtime filtering
 * is enabled then dynamic instance is returned.
 *
 * @param _name Name of the instance.
 *
 * @return Pointer to the instance object (static or dynamic).
 *//** @internal
 *
 * Create a name for which contains module and instance names.
 *//** @brief Initialize pointer to logger instance with explicitly provided object.
 *
 * Macro can be used to initialized a pointer with object that is not unique to
 * the given instance, thus not created with @ref LOG_INSTANCE_REGISTER.
 *
 * @param _name Name of the structure element for holding logging object.
 * @param _object Pointer to a logging instance object.
 *//** @internal
 *
 * Create static logging instance in read only memory.
 *
 * @param _name name of the module. With added prefix forms name of variable and
 * memory section.
 *
 * @param _str_name Name of the module that will be used when message is formatted.
 *
 * @param _level Messages up to this level are compiled in.
 *//** @internal
 *
 * Creates name of variable and section for constant log data.
 *
 *  @param _name Name.
 *//* Workaround: RV64 needs to ensure that structure is just 8 bytes. *//* Workaround alert! Dummy data to ensure that structure is >8 bytes.
	 * Nios2 uses global pointer register for structures <=8 bytes and
	 * apparently does not handle well variables placed in custom sections.
	 *//** @brief Dynamic data associated with the source of log messages. *//** @brief Constant data associated with the source of log messages. */mpsc_pbuf_genericmpsc_pbuf_skipmpsc_pbuf_hdrskipbusyvalidMPSC_PBUF_HDRuint32_t valid: 1; uint32_t busy: 1MPSC_PBUF_HDR_BITSZEPHYR_INCLUDE_SYS_MPSC_PACKET_H_/* ZEPHYR_INCLUDE_SYS_MPSC_PACKET_H_ *//** @brief Generic packet header. *//** @brief Skip packet used internally by the packet buffer. *//** @brief Header that must be added to the first word in each packet.
 *
 * This fields are controlled by the packet buffer and unless specified must
 * not be used. Fields must be added at the top of the packet header structure.
 *//** @brief Number of bits in the first word which are used by the buffer. *//**
 * @brief Multi producer, single consumer packet header
 * @defgroup mpsc_packet MPSC (Multi producer, single consumer) packet header
 * @ingroup mpsc_buf
 * @{
 */ZEPHYR_INCLUDE_SYS_CBPRINTF_CXX_H___cplusplus >= 201103L/* ZEPHYR_INCLUDE_SYS_CBPRINTF_CXX_H_ *//* Determine the type of elements in an array *//* Determine if a type is an array *//* C++ version for checking if two arguments are same type *//* C++ version for caluculating argument alignment. *//* C++ version for long double detection. *//* C++ version for storing arguments. *//* C++ version for calculating argument size. *//* C++ version for determining if variable type is numeric and fits in 32 bit word. *//* C++ version for detecting a pointer to a string. */<zephyr/sys/cbprintf_cxx.h>___is_nullz_cbprintf_wcpyZ_CBPRINTF_STATIC_PACKAGE(packaged,inlen,outlen,align_offset,flags,__VA_ARGS__...)Z_CBPRINTF_STATIC_PACKAGE_GENERIC(packaged, inlen, outlen, align_offset, flags, __VA_ARGS__)Z_CBPRINTF_STATIC_PACKAGE_GENERIC(buf,_inlen,_outlen,_align_offset,flags,__VA_ARGS__...)do { _Pragma("GCC diagnostic push") _Pragma("GCC diagnostic ignored \"-Wpointer-arith\"") Z_CBPRINTF_SUPPRESS_SIZEOF_ARRAY_DECAY BUILD_ASSERT(!IS_ENABLED(CONFIG_XTENSA) || (IS_ENABLED(CONFIG_XTENSA) && !(_align_offset % CBPRINTF_PACKAGE_ALIGNMENT)), "Xtensa requires aligned package."); BUILD_ASSERT((_align_offset % sizeof(int)) == 0, "Alignment offset must be multiply of a word."); IF_ENABLED(CONFIG_CBPRINTF_STATIC_PACKAGE_CHECK_ALIGNMENT, (__ASSERT(!((uintptr_t)buf & (CBPRINTF_PACKAGE_ALIGNMENT - 1)), "Buffer must be aligned.");)) uint32_t _flags = flags; bool _ros_pos_en = (_flags) & CBPRINTF_PACKAGE_ADD_RO_STR_POS; bool _rws_pos_en = (_flags) & CBPRINTF_PACKAGE_ADD_RW_STR_POS; bool _cros_en = (_flags) & CBPRINTF_PACKAGE_CONST_CHAR_RO; uint8_t *_pbuf = buf; uint8_t _rws_pos_idx = 0; uint8_t _ros_pos_idx = 0; uint8_t _alls_cnt = Z_CBPRINTF_PCHAR_COUNT(0, __VA_ARGS__); uint8_t _fros_cnt = Z_CBPRINTF_PACKAGE_FIRST_RO_STR_CNT_GET(_flags); uint8_t _rws_cnt = _cros_en ? Z_CBPRINTF_PCHAR_COUNT(_flags, __VA_ARGS__) : _alls_cnt - _fros_cnt; uint8_t _ros_cnt = _ros_pos_en ? (1 + _alls_cnt - _rws_cnt) : 0; uint8_t *_ros_pos_buf; Z_CBPRINTF_ON_STACK_ALLOC(_ros_pos_buf, _ros_cnt); uint8_t *_rws_buffer; Z_CBPRINTF_ON_STACK_ALLOC(_rws_buffer, 2 * _rws_cnt); size_t _pmax = !___is_null(buf) ? _inlen : INT32_MAX; int _pkg_len = 0; int _total_len = 0; int _pkg_offset = _align_offset; union cbprintf_package_hdr *_len_loc; if (_rws_cnt && !((_flags) & CBPRINTF_PACKAGE_ADD_RW_STR_POS)) { _outlen = -EINVAL; break; } if (_pmax < sizeof(*_len_loc)) { _outlen = -ENOSPC; break; } _len_loc = (union cbprintf_package_hdr *)_pbuf; _pkg_len += sizeof(*_len_loc); _pkg_offset += sizeof(*_len_loc); FOR_EACH_IDX(Z_CBPRINTF_PACK_ARG, (;), __VA_ARGS__); _total_len = _pkg_len; _total_len += _ros_cnt; _total_len += 2 * _rws_cnt; if (_pbuf != NULL) { uint8_t *_pbuf_loc = &_pbuf[_pkg_len]; for (size_t _ros_idx = 0; _ros_idx < _ros_cnt; _ros_idx++) { *_pbuf_loc++ = _ros_pos_buf[_ros_idx]; } for (size_t _rws_idx = 0; _rws_idx < (2 * _rws_cnt); _rws_idx++) { *_pbuf_loc++ = _rws_buffer[_rws_idx]; } } _outlen = (_total_len > (int)_pmax) ? -ENOSPC : _total_len; if (_pbuf != NULL) { union cbprintf_package_hdr pkg_hdr = { .desc = { .len = (uint8_t)(_pkg_len / sizeof(int)), .str_cnt = 0, .ro_str_cnt = _ros_cnt, .rw_str_cnt = _rws_cnt, } }; IF_ENABLED(CONFIG_CBPRINTF_PACKAGE_HEADER_STORE_CREATION_FLAGS, (pkg_hdr.desc.pkg_flags = flags)); *_len_loc = pkg_hdr; } _Pragma("GCC diagnostic pop") } while (false)Z_CBPRINTF_ON_STACK_ALLOC(_name,_len)__ASSERT(_len <= 32, "Too many string arguments."); uint8_t _name ## _buf4[4]; uint8_t _name ## _buf8[8]; uint8_t _name ## _buf12[12]; uint8_t _name ## _buf16[16]; uint8_t _name ## _buf32[32]; _name = (_len) <= 4 ? _name ## _buf4 : ((_len) <= 8 ? _name ## _buf8 : ((_len) <= 12 ? _name ## _buf12 : ((_len) <= 16 ? _name ## _buf16 : _name ## _buf32)))Z_CBPRINTF_SUPPRESS_SIZEOF_ARRAY_DECAYZ_CBPRINTF_PACK_ARG(arg_idx,arg)Z_CBPRINTF_PACK_ARG2(arg_idx, _pbuf, _pkg_len, _pkg_offset, _pmax, arg)Z_CBPRINTF_PACK_ARG2(arg_idx,_buf,_idx,_align_offset,_max,_arg)do { BUILD_ASSERT(!((sizeof(double) < VA_STACK_ALIGN(long double)) && Z_CBPRINTF_IS_LONGDOUBLE(_arg) && !IS_ENABLED(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE)), "Packaging of long double not enabled in Kconfig."); while (_align_offset % Z_CBPRINTF_ALIGNMENT(_arg) != 0UL) { _idx += sizeof(int); _align_offset += sizeof(int); } uint32_t _arg_size = Z_CBPRINTF_ARG_SIZE(_arg); uint32_t _loc = _idx / sizeof(int); if (arg_idx < 1 + _fros_cnt) { if (_ros_pos_en) { _ros_pos_buf[_ros_pos_idx++] = _loc; } } else if (Z_CBPRINTF_IS_PCHAR(_arg, 0)) { if (_cros_en) { if (Z_CBPRINTF_IS_X_PCHAR(arg_idx, _arg, _flags)) { if (_rws_pos_en) { _rws_buffer[_rws_pos_idx++] = arg_idx - 1; _rws_buffer[_rws_pos_idx++] = _loc; } } else { if (_ros_pos_en) { _ros_pos_buf[_ros_pos_idx++] = _loc; } } } else if (_rws_pos_en) { _rws_buffer[_rws_pos_idx++] = arg_idx - 1; _rws_buffer[_rws_pos_idx++] = _idx / sizeof(int); } } if (_buf && _idx < (int)_max) { Z_CBPRINTF_STORE_ARG(&_buf[_idx], _arg); } _idx += _arg_size; _align_offset += _arg_size; } while (false)Z_CBPRINTF_IS_LONGDOUBLE(x)_Generic((x) + 0, long double : 1, default : 0)Z_CBPRINTF_ALIGNMENT(_arg)MAX(_Generic((_arg) + 0, float : VA_STACK_ALIGN(double), double : VA_STACK_ALIGN(double), long double : VA_STACK_ALIGN(long double), long long : VA_STACK_ALIGN(long long), unsigned long long : VA_STACK_ALIGN(long long), default : __alignof__((_arg) + 0)), VA_STACK_MIN_ALIGN)Z_CBPRINTF_STORE_ARG(buf,arg)do { if (Z_CBPRINTF_VA_STACK_LL_DBL_MEMCPY) { __auto_type _v = (arg) + 0; double _d = _Generic((arg) + 0, float : (arg) + 0, default : 0.0); (void)_v; (void)_d; size_t arg_size = Z_CBPRINTF_ARG_SIZE(arg); size_t _wsize = arg_size / sizeof(int); z_cbprintf_wcpy((int *)buf, (int *) _Generic((arg) + 0, float : &_d, default : &_v), _wsize); } else { *_Generic((arg) + 0, char : (int *)buf, unsigned char: (int *)buf, short : (int *)buf, unsigned short : (int *)buf, int : (int *)buf, unsigned int : (unsigned int *)buf, long : (long *)buf, unsigned long : (unsigned long *)buf, long long : (long long *)buf, unsigned long long : (unsigned long long *)buf, float : (double *)buf, double : (double *)buf, long double : (long double *)buf, default : (const void **)buf) = arg; } } while (false)Z_CBPRINTF_ARG_SIZE(v)({ __auto_type __v = (v) + 0; (void)__v; size_t __arg_size = _Generic((v), float : sizeof(double), default : sizeof((__v)) ); __arg_size; })Z_CBPRINTF_MUST_RUNTIME_PACKAGE(flags,__VA_ARGS__...)({ _Pragma("GCC diagnostic push") _Pragma("GCC diagnostic ignored \"-Wpointer-arith\"") int _rv; if ((flags) & CBPRINTF_PACKAGE_ADD_RW_STR_POS) { _rv = 0; } else { _rv = Z_CBPRINTF_PCHAR_COUNT(flags, __VA_ARGS__) > 0 ? 1 : 0; } _Pragma("GCC diagnostic pop") _rv; })Z_CBPRINTF_PCHAR_COUNT(flags,__VA_ARGS__...)COND_CODE_0(NUM_VA_ARGS_LESS_1(__VA_ARGS__), (0), (Z_CBPRINTF_HAS_PCHAR_ARGS(flags, __VA_ARGS__)))Z_CBPRINTF_HAS_PCHAR_ARGS(flags,fmt,__VA_ARGS__...)(FOR_EACH_IDX_FIXED_ARG(Z_CBPRINTF_IS_X_PCHAR, (+), flags, __VA_ARGS__))Z_CBPRINTF_IS_X_PCHAR(idx,x,flags)(idx < Z_CBPRINTF_PACKAGE_FIRST_RO_STR_CNT_GET(flags) ? 0 : Z_CBPRINTF_IS_PCHAR(x, flags))Z_CBPRINTF_IS_WORD_NUM(x)_Generic(x, char : 1, unsigned char : 1, short : 1, unsigned short : 1, int : 1, unsigned int : 1, long : sizeof(long) <= 4, unsigned long : sizeof(long) <= 4, default : 0)Z_CBPRINTF_IS_PCHAR(x,flags)_Generic((x) + 0, char * : 1, const char * : ((flags) & CBPRINTF_PACKAGE_CONST_CHAR_RO) ? 0 : 1, volatile char * : 1, const volatile char * : 1, unsigned char * : 1, const unsigned char * : ((flags) & CBPRINTF_PACKAGE_CONST_CHAR_RO) ? 0 : 1, volatile unsigned char * : 1, const volatile unsigned char * : 1, wchar_t * : 1, const wchar_t * : ((flags) & CBPRINTF_PACKAGE_CONST_CHAR_RO) ? 0 : 1, volatile wchar_t * : 1, const volatile wchar_t * : 1, default : 0)VA_STACK_ALIGN(type)ZEPHYR_INCLUDE_SYS_CBPRINTF_INTERNAL_H_defined(__sparc__)defined(__riscv)CONFIG_RISCV_ISA_RV32EVA_STACK_ALIGNZ_C_GENERICdefined(__x86_64__) || defined(__riscv) || defined(__aarch64__)CONFIG_NO_OPTIMIZATIONS/* ZEPHYR_INCLUDE_SYS_CBPRINTF_INTERNAL_H_ *//* _cplusplus *//*
 * Note that qualifiers of char * must be explicitly matched
 * due to type matching in C++, where remove_cv() does not work.
 *//*
 * Figure out if this is a char array since (char *) and (char[])
 * are of different types in C++.
 *//*
 * Determine if incoming type is char.
 *//*
 * Get the type of elements in an array.
 *//*
 * Remove qualifiers like const, volatile. And also transform
 * C++ argument reference back to its basic type.
 *//* Z_C_GENERIC *//* Small trick needed to avoid warning on always true *//* fmt, ... *//* Store length in the header, set number of dumped strings to 0 *//* Store length *//* Append string locations. *//* Append string indexes to the package. *//* Pack remaining arguments *//* package starts with string address and field with length *//* If string has rw string arguments CBPRINTF_PACKAGE_ADD_RW_STR_POS is a must. *//* Variable holds count of non const string pointers. *//* Variable holds count of all string pointer arguments. *//** @brief Statically package a formatted string with arguments.
 *
 * @param buf buffer. If null then only length is calculated.
 *
 * @param _inlen buffer capacity on input. Ignored when @p buf is null.
 *
 * @param _outlen number of bytes required to store the package.
 *
 * @param _align_offset Input buffer alignment offset in words. Where offset 0
 * means that buffer is aligned to CBPRINTF_PACKAGE_ALIGNMENT.
 *
 * @param flags Option flags. See @ref CBPRINTF_PACKAGE_FLAGS.
 *
 * @param ... String with variable list of arguments.
 *//* When the first argument of Z_CBPRINTF_STATIC_PACKAGE_GENERIC() is a
 * static memory location, some compiler warns you if you compare the
 * location against NULL.  ___is_null() is used to kill this warning.
 *
 * The warnings would be visible when you built with -save-temps=obj,
 * our standard debugging tip for macro problems.
 *
 * https://github.com/zephyrproject-rtos/zephyr/issues/51528
 *//* Allocation to avoid using VLA and alloca. Alloc frees space when leaving
 * a function which can lead to increased stack usage if logging is used
 * multiple times. VLA is not always available.
 *
 * Use large array when optimization is off to avoid increased stack usage.
 *//* When using clang additional warning needs to be suppressed since each
 * argument of fmt string is used for sizeof() which results in the warning
 * if argument is a string literal. Suppression is added here instead of
 * the macro which generates the warning to not slow down the compiler.
 *//** @brief Package single argument.
 *
 * Macro is called in a loop for each argument in the string.
 *
 * @param arg argument.
 *//** @brief Safely package arguments to a buffer.
 *
 * Argument is put into the buffer if capable buffer is provided. Length is
 * incremented even if data is not packaged.
 *
 * @param _buf buffer.
 *
 * @param _idx index. Index is postincremented.
 *
 * @param _align_offset Current index with alignment offset.
 *
 * @param _max maximum index (buffer capacity).
 *
 * @param _arg argument.
 *//** @brief Detect long double variable as a constant expression.
 *
 * Macro is used in static assertion. On some platforms C++ static inline
 * template function is not a constant expression and cannot be used. In that
 * case long double usage will not be detected.
 *
 * @param x Argument.
 *
 * @return 1 if @p x is a long double, 0 otherwise.
 *//** @brief Return alignment needed for given argument.
 *
 * @param _arg Argument
 *
 * @return Alignment in bytes.
 *//* Static code analysis may complain about unused variable. *//* If required, copy arguments by word to avoid unaligned access.*//** @brief Promote and store argument in the buffer.
 *
 * @param buf Buffer.
 *
 * @param arg Argument.
 *//** @brief Get storage size for given argument.
 *
 * Floats are promoted to double so they use size of double, others int storage
 * or it's own storage size if it is bigger than int.
 *
 * @param x argument.
 *
 * @return Number of bytes used for storing the argument.
 *//**
 * @brief Check if formatted string must be packaged in runtime.
 *
 * @param ... String with arguments (fmt, ...).
 *
 * @retval 1 if string must be packaged at runtime.
 * @retval 0 if string can be statically packaged.
 *//** @brief Calculate number of char * or wchar_t * arguments in the arguments.
 *
 * @param fmt string.
 *
 * @param ... string arguments.
 *
 * @return number of arguments which are char * or wchar_t *.
 *//* @brief Check if argument is a certain type of char pointer. What exectly is checked
 * depends on @p flags. If flags is 0 then 1 is returned if @p x is a char pointer.
 *
 * @param idx Argument index.
 * @param x Argument.
 * @param flags Flags. See @p CBPRINTF_PACKAGE_FLAGS.
 *
 * @retval 1 if @p x is char pointer meeting criteria identified by @p flags.
 * @retval 0 otherwise.
 *//** @brief Check if argument fits in 32 bit word.
 *
 * @param x Input argument.
 *
 * @retval 1 if variable is of type that fits in 32 bit word.
 * @retval 0 if variable is of different type.
 *//* wchar_t * *//* unsigned char * *//* char * *//** @brief Return 1 if argument is a pointer to char or wchar_t
 *
 * @param x argument.
 *
 * @return 1 if char * or wchar_t *, 0 otherwise.
 *//* The SPARC V8 ABI guarantees that the arguments of a variable argument
 * list function are stored on the stack at addresses which are 32-bit
 * aligned. It means that variables of type unit64_t and double may not
 * be properly aligned on the stack.
 *
 * The compiler is aware of the ABI and takes care of this. However,
 * as we are directly accessing the variable argument list here, we need
 * to take the alignment into consideration and copy 64-bit arguments
 * as 32-bit words.
 *//*
 * Default alignment values if not specified by architecture config
 *//* CONFIG_RISCV_ISA_RV32E *//* there are no gaps on the stack *//*
 * Special alignment cases
 */cbprintf_package_arg_typeCBPRINTF_PACKAGE_ARG_TYPE_ENDCBPRINTF_PACKAGE_ARG_TYPE_CHARCBPRINTF_PACKAGE_ARG_TYPE_UNSIGNED_CHARCBPRINTF_PACKAGE_ARG_TYPE_SHORTCBPRINTF_PACKAGE_ARG_TYPE_UNSIGNED_SHORTCBPRINTF_PACKAGE_ARG_TYPE_INTCBPRINTF_PACKAGE_ARG_TYPE_UNSIGNED_INTCBPRINTF_PACKAGE_ARG_TYPE_LONGCBPRINTF_PACKAGE_ARG_TYPE_UNSIGNED_LONGCBPRINTF_PACKAGE_ARG_TYPE_LONG_LONGCBPRINTF_PACKAGE_ARG_TYPE_UNSIGNED_LONG_LONGCBPRINTF_PACKAGE_ARG_TYPE_FLOATCBPRINTF_PACKAGE_ARG_TYPE_DOUBLECBPRINTF_PACKAGE_ARG_TYPE_LONG_DOUBLECBPRINTF_PACKAGE_ARG_TYPE_PTR_CHARCBPRINTF_PACKAGE_ARG_TYPE_PTR_VOIDCBPRINTF_PACKAGE_ARG_TYPE_MAXCBPRINTF_PACKAGE_ARG_TYPE_COUNTZEPHYR_INCLUDE_SYS_CBPRINTF_ENUMS_H_/* ZEPHYR_INCLUDE_SYS_CBPRINTF_ENUMS_H_ *//** End of argument list *//** @brief cbprintf package argument type
 *
 * This is used to tag each argument in cbprintf in the variable
 * length argument list.
 */<zephyr/sys/cbprintf_enums.h><zephyr/sys/cbprintf_internal.h>cbpprintfcbvprintf_tagged_argscbprintfcbprintf_fsc_packagecbprintf_package_copybuf_descz_cbprintf_buf_desc *z_cbprintf_cpydesc&((uint8_t *)desc->buf)[desc->off]z_cbprintf_buf_desccbvprintf_external_formatter_funccbprintf_convert_cbcbprintf_cbcbprintf_package_hdr_extcbprintf_package_hdrcbprintf_package_descrw_str_cntro_str_cntstr_cntZ_IS_POW2(CBPRINTF_PACKAGE_ALIGNMENT)((((((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1))))) != 0) && ((((((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1))))) & (((((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1)))))-1)) == 0))CBPRINTF_PACKAGE_ALIGNMENT(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1))))CBPRINTF_STATIC_PACKAGE(packaged,inlen,outlen,align_offset,flags,__VA_ARGS__...)Z_CBPRINTF_STATIC_PACKAGE(packaged, inlen, outlen, align_offset, flags, __VA_ARGS__)CBPRINTF_MUST_RUNTIME_PACKAGE(flags,__VA_ARGS__...)Z_CBPRINTF_MUST_RUNTIME_PACKAGE(flags, __VA_ARGS__)Z_CBVPRINTF_PROCESS_FLAG_TAGGED_ARGSCBPRINTF_PACKAGE_CONVERT_PTR_CHECKCBPRINTF_PACKAGE_COPY_KEEP_RO_STRCBPRINTF_PACKAGE_CONVERT_KEEP_RO_STR __DEPRECATED_MACROCBPRINTF_PACKAGE_CONVERT_KEEP_RO_STRCBPRINTF_PACKAGE_COPY_RW_STRCBPRINTF_PACKAGE_CONVERT_RW_STR __DEPRECATED_MACROCBPRINTF_PACKAGE_CONVERT_RW_STRCBPRINTF_PACKAGE_COPY_RO_STRCBPRINTF_PACKAGE_CONVERT_RO_STR __DEPRECATED_MACROCBPRINTF_PACKAGE_CONVERT_RO_STRCBPRINTF_PACKAGE_ARGS_ARE_TAGGEDCBPRINTF_PACKAGE_ADD_STRING_IDXS(CBPRINTF_PACKAGE_ADD_RO_STR_POS | CBPRINTF_PACKAGE_CONST_CHAR_RO)Z_CBPRINTF_PACKAGE_FIRST_RO_STR_CNT_GET(flags)(((flags) >> Z_CBPRINTF_PACKAGE_FIRST_RO_STR_OFFSET) & Z_CBPRINTF_PACKAGE_FIRST_RO_STR_MASK)CBPRINTF_PACKAGE_FIRST_RO_STR_CNT(n)(n << Z_CBPRINTF_PACKAGE_FIRST_RO_STR_OFFSET)Z_CBPRINTF_PACKAGE_FIRST_RO_STR_MASKBIT_MASK(Z_CBPRINTF_PACKAGE_FIRST_RO_STR_BITS)Z_CBPRINTF_PACKAGE_FIRST_RO_STR_OFFSETCBPRINTF_PACKAGE_ADD_RW_STR_POSCBPRINTF_PACKAGE_ADD_RO_STR_POSCBPRINTF_PACKAGE_CONST_CHAR_ROZ_POW2_CEIL(COND_CODE_1(CONFIG_CBPRINTF_PACKAGE_LONGDOUBLE, (sizeof(long double)), (MAX(sizeof(double), sizeof(long long)))))ZEPHYR_INCLUDE_SYS_CBPRINTF_H_CONFIG_CBPRINTF_LIBC_SUBSTSdefined(__cplusplus) || TOOLCHAIN_HAS_C_GENERIC__xtensa__defined(CONFIG_CBPRINTF_PACKAGE_HEADER_STORE_CREATION_FLAGS) && !defined(CONFIG_64BIT)__CHECKER__/* ZEPHYR_INCLUDE_SYS_CBPRINTF_H_ *//* CONFIG_CBPRINTF_LIBC_SUBSTS *//* CONFIG_PICOLIBC *//** @brief vsnprintf using Zephyrs cbprintf infrastructure.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced when
 * @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param str where the formatted content should be written
 *
 * @param size maximum number of chaacters for the formatted output, including
 * the terminating null byte.
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap a reference to the values to be converted.
 *
 * @return The number of characters that would have been written to @p
 * str, excluding the terminating null byte.  This is greater than the
 * number actually written if @p size is too small.
 *//** @brief snprintf using Zephyrs cbprintf infrastructure.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced
 * when @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param str where the formatted content should be written
 *
 * @param size maximum number of chaacters for the formatted output,
 * including the terminating null byte.
 *
 * @param format a standard ISO C format string with characters and
 * conversion specifications.
 *
 * @param ... arguments corresponding to the conversion specifications found
 * within @p format.
 *
 * @return The number of characters that would have been written to @p
 * str, excluding the terminating null byte.  This is greater than the
 * number actually written if @p size is too small.
 *//** @brief vprintf using Zephyrs cbprintf infrastructure.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced when
 * @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap a reference to the values to be converted.
 *
 * @return The number of characters printed.
 *//** @brief printf using Zephyrs cbprintf infrastructure.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced
 * when @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param format a standard ISO C format string with characters and
 * conversion specifications.
 *
 * @param ... arguments corresponding to the conversion specifications found
 * within @p format.
 *
 * @return The number of characters printed.
 *//** @brief vfprintf using Zephyrs cbprintf infrastructure.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced when
 * @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param stream the stream to which the output should be written.
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap a reference to the values to be converted.
 *
 * @return The number of characters printed.
 *//** @brief fprintf using Zephyrs cbprintf infrastructure.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced
 * when @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param stream the stream to which the output should be written.
 *
 * @param format a standard ISO C format string with characters and
 * conversion specifications.
 *
 * @param ... arguments corresponding to the conversion specifications found
 * within @p format.
 *
 * return The number of characters printed.
 *//** @brief Generate the output for a previously captured format
 * operation.
 *
 * @param out the function used to emit each generated character.
 *
 * @param ctx context provided when invoking out
 *
 * @param packaged the data required to generate the formatted output, as
 * captured by cbprintf_package() or cbvprintf_package(). The alignment
 * requirement on this data is the same as when it was initially created.
 *
 * @note Memory indicated by @p packaged will be modified in a non-destructive
 * way, meaning that it could still be reused with this function again.
 *
 * @return the number of characters printed, or a negative error value
 * returned from invoking @p out.
 *//** @brief varargs-aware *printf-like output through a callback with tagged arguments.
 *
 * This is essentially vsprintf() except the output is generated
 * character-by-character using the provided @p out function.  This allows
 * formatting text of unbounded length without incurring the cost of a
 * temporary buffer.
 *
 * Note that the argument list @p ap are tagged.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced when
 * @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param out the function used to emit each generated character.
 *
 * @param ctx context provided when invoking out
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap a reference to the values to be converted.
 *
 * @return the number of characters generated, or a negative error value
 * returned from invoking @p out.
 *//** @brief varargs-aware *printf-like output through a callback.
 *
 * This is essentially vsprintf() except the output is generated
 * character-by-character using the provided @p out function.  This allows
 * formatting text of unbounded length without incurring the cost of a
 * temporary buffer.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced when
 * @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param out the function used to emit each generated character.
 *
 * @param ctx context provided when invoking out
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap a reference to the values to be converted.
 *
 * @return the number of characters generated, or a negative error value
 * returned from invoking @p out.
 *//** @brief varargs-aware *printf-like output through a callback.
 *
 * This is essentially vsprintf() except the output is generated
 * character-by-character using the provided @p out function.  This allows
 * formatting text of unbounded length without incurring the cost of a
 * temporary buffer.
 *
 * @note This function is available only when
 * @kconfig{CONFIG_CBPRINTF_LIBC_SUBSTS} is selected.
 *
 * @note The functionality of this function is significantly reduced when
 * @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param out the function used to emit each generated character.
 *
 * @param ctx context provided when invoking out
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap a reference to the values to be converted.
 *
 * @param flags flags on how to process the inputs.
 *              @see Z_CBVPRINTF_PROCESS_FLAGS.
 *
 * @return the number of characters generated, or a negative error value
 * returned from invoking @p out.
 *//** @brief *printf-like output through a callback.
 *
 * This is essentially printf() except the output is generated
 * character-by-character using the provided @p out function.  This allows
 * formatting text of unbounded length without incurring the cost of a
 * temporary buffer.
 *
 * All formatting specifiers of C99 are recognized, and most are supported if
 * the functionality is enabled.
 *
 * @note The functionality of this function is significantly reduced
 * when @kconfig{CONFIG_CBPRINTF_NANO} is selected.
 *
 * @param out the function used to emit each generated character.
 *
 * @param ctx context provided when invoking out
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ... arguments corresponding to the conversion specifications found
 * within @p format.
 *
 * @return the number of characters printed, or a negative error value
 * returned from invoking @p out.
 *//** @brief Generate the output for a previously captured format
 * operation using an external formatter.
 *
 * @param out the function used to emit each generated character.
 *
 * @param formatter external formatter function.
 *
 * @param ctx a pointer to an object that provides context for the
 * external formatter.
 *
 * @param packaged the data required to generate the formatted output, as
 * captured by cbprintf_package() or cbvprintf_package(). The alignment
 * requirement on this data is the same as when it was initially created.
 *
 * @note Memory indicated by @p packaged will be modified in a non-destructive
 * way, meaning that it could still be reused with this function again.
 *
 * @return printf like return values: the number of characters printed,
 * or a negative error value returned from external formatter.
 *//** @brief Convert package to fully self-contained (fsc) package.
 *
 * Package may not be self contain since strings by default are stored by address.
 * Package may be partially self-contained when transient (not read only) strings
 * are appended to the package. Such package can be decoded only when there is an
 * access to read-only strings.
 *
 * Fully self-contained has (fsc) contains all strings used in the package. A package
 * can be converted to fsc package if it was create with @ref CBPRINTF_PACKAGE_ADD_RO_STR_POS
 * flag. Such package will contain necessary data to find read only strings in
 * the package and copy them into the package body.
 *
 * @param in_packaged pointer to original package created with
 * @ref CBPRINTF_PACKAGE_ADD_RO_STR_POS.
 *
 * @param in_len @p in_packaged length.
 *
 * @param packaged pointer to location where fully self-contained version of the
 * input package will be written. Pass a null pointer to calculate space required.
 *
 * @param len must be set to the number of bytes available at @p packaged. Not
 * used if @p packaged is null.
 *
 * @retval nonegative the number of bytes successfully stored at @p packaged.
 * This will not exceed @p len. If @p packaged is null, calculated length.
 * @retval -ENOSPC if @p packaged was not null and the space required to store
 * exceed @p len.
 * @retval -EINVAL if @p in_packaged is null.
 *//** @brief Copy package with optional appending of strings.
 *
 * @ref cbprintf_package_convert is used to convert and store converted package
 * in the new location.
 *
 * @param in_packaged Input package.
 *
 * @param in_len Input package length. If 0 package length will be retrieved
 * from the @p in_packaged
 *
 * @param[out] packaged Output package. If null only length of the output package
 * is calculated.
 *
 * @param len Available space in the location pointed by @p packaged. Not used when
 * @p packaged is null.
 *
 * @param flags Flags. See @ref CBPRINTF_PACKAGE_CONVERT_FLAGS.
 *
 * @param[in, out] strl if @p packaged is null, it is a pointer to the array where
 * @p strl_len first string lengths will is stored. If @p packaged is not null,
 * it contains lengths of first @p strl_len strings. It can be used to optimize
 * copying so that string length is calculated only once (at length calculation
 * phase when @p packaged is null.)
 *
 * @param strl_len Number of elements in @p strl array.
 *
 * @retval Positive Output package size.
 * @retval -ENOSPC if @p packaged was not null and the space required to store
 * exceed @p len.
 *//* @internal Function callback used for package copying. *//* @interal Context used for package copying. *//** @brief Convert a package.
 *
 * Converting may include appending strings used in the package to the package body.
 * If input package was created with @ref CBPRINTF_PACKAGE_ADD_RO_STR_POS or
 * @ref CBPRINTF_PACKAGE_ADD_RW_STR_POS, it contains information where strings
 * are located within the package. This information can be used to copy strings
 * during the conversion.
 *
 * @p cb is called with portions of the output package. At the end of the conversion
 * @p cb is called with null buffer.
 *
 * @param in_packaged Input package.
 *
 * @param in_len Input package length. If 0 package length will be retrieved
 * from the @p in_packaged
 *
 * @param cb callback called with portions of the converted package. If null only
 * length of the output package is calculated.
 *
 * @param ctx Context provided to the @p cb.
 *
 * @param flags Flags. See @ref CBPRINTF_PACKAGE_CONVERT_FLAGS.
 *
 * @param[in, out] strl if @p packaged is null, it is a pointer to the array where
 * @p strl_len first string lengths will is stored. If @p packaged is not null,
 * it contains lengths of first @p strl_len strings. It can be used to optimize
 * copying so that string length is calculated only once (at length calculation
 * phase when @p packaged is null.)
 *
 * @param strl_len Number of elements in @p strl array.
 *
 * @retval Positive output package size.
 * @retval -ENOSPC if @p packaged was not null and the space required to store
 * exceed @p len.
 *//** @brief Capture state required to output formatted data later.
 *
 * Like cbprintf() but instead of processing the arguments and emitting the
 * formatted results immediately all arguments are captured so this can be
 * done in a different context, e.g. when the output function can block.
 *
 * In addition to the values extracted from arguments this will ensure that
 * copies are made of the necessary portions of any string parameters that are
 * not confirmed to be stored in read-only memory (hence assumed to be safe to
 * refer to directly later).
 *
 * @param packaged pointer to where the packaged data can be stored.  Pass a
 * null pointer to store nothing but still calculate the total space required.
 * The data stored here is relocatable, that is it can be moved to another
 * contiguous block of memory. The pointer must be aligned to a multiple of
 * the largest element in the argument list.
 *
 * @param len this must be set to the number of bytes available at @p packaged.
 * Ignored if @p packaged is NULL.
 *
 * @param flags option flags. See @ref CBPRINTF_PACKAGE_FLAGS.
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ap captured stack arguments corresponding to the conversion
 * specifications found within @p format.
 *
 * @retval nonegative the number of bytes successfully stored at @p packaged.
 * This will not exceed @p len.
 * @retval -EINVAL if @p format is not acceptable
 * @retval -ENOSPC if @p packaged was not null and the space required to store
 * exceed @p len.
 *//** @brief Capture state required to output formatted data later.
 *
 * Like cbprintf() but instead of processing the arguments and emitting the
 * formatted results immediately all arguments are captured so this can be
 * done in a different context, e.g. when the output function can block.
 *
 * In addition to the values extracted from arguments this will ensure that
 * copies are made of the necessary portions of any string parameters that are
 * not confirmed to be stored in read-only memory (hence assumed to be safe to
 * refer to directly later).
 *
 * @param packaged pointer to where the packaged data can be stored.  Pass a
 * null pointer to store nothing but still calculate the total space required.
 * The data stored here is relocatable, that is it can be moved to another
 * contiguous block of memory. However, under condition that alignment is
 * maintained. It must be aligned to at least the size of a pointer.
 *
 * @param len this must be set to the number of bytes available at @p packaged
 * if it is not null. If @p packaged is null then it indicates hypothetical
 * buffer alignment offset in bytes compared to CBPRINTF_PACKAGE_ALIGNMENT
 * alignment. Buffer alignment offset impacts returned size of the package.
 * Xtensa requires that buffer is always aligned to CBPRINTF_PACKAGE_ALIGNMENT
 * so it must be multiply of CBPRINTF_PACKAGE_ALIGNMENT or 0 when @p packaged is
 * null.
 *
 * @param flags option flags. See @ref CBPRINTF_PACKAGE_FLAGS.
 *
 * @param format a standard ISO C format string with characters and conversion
 * specifications.
 *
 * @param ... arguments corresponding to the conversion specifications found
 * within @p format.
 *
 * @retval nonegative the number of bytes successfully stored at @p packaged.
 * This will not exceed @p len.
 * @retval -EINVAL if @p format is not acceptable
 * @retval -EFAULT if @p packaged alignment is not acceptable
 * @retval -ENOSPC if @p packaged was not null and the space required to store
 * exceed @p len.
 *//** @brief Statically package string.
 *
 * Build string package from formatted string. It assumes that formatted
 * string is in the read only memory.
 *
 * If _Generic is not supported then runtime packaging is performed.
 *
 * @param packaged pointer to where the packaged data can be stored. Pass a null
 * pointer to skip packaging but still calculate the total space required.
 * The data stored here is relocatable, that is it can be moved to another
 * contiguous block of memory. It must be aligned to the size of the longest
 * argument. It is recommended to use CBPRINTF_PACKAGE_ALIGNMENT for alignment.
 *
 * @param inlen set to the number of bytes available at @p packaged. If
 * @p packaged is NULL the value is ignored.
 *
 * @param outlen variable updated to the number of bytes required to completely
 * store the packed information. If input buffer was too small it is set to
 * -ENOSPC.
 *
 * @param align_offset input buffer alignment offset in bytes. Where offset 0
 * means that buffer is aligned to CBPRINTF_PACKAGE_ALIGNMENT. Xtensa requires
 * that @p packaged is aligned to CBPRINTF_PACKAGE_ALIGNMENT so it must be
 * multiply of CBPRINTF_PACKAGE_ALIGNMENT or 0.
 *
 * @param flags option flags. See @ref CBPRINTF_PACKAGE_FLAGS.
 *
 * @param ... formatted string with arguments. Format string must be constant.
 *//** @brief Determine if string must be packaged in run time.
 *
 * Static packaging can be applied if size of the package can be determined
 * at compile time. In general, package size can be determined at compile time
 * if there are no string arguments which might be copied into package body if
 * they are considered transient.
 *
 * @note By default any char pointers are considered to be pointing at transient
 * strings. This can be narrowed down to non const pointers by using
 * @ref CBPRINTF_PACKAGE_CONST_CHAR_RO.
 *
 * @param ... String with arguments.
 * @param flags option flags. See @ref CBPRINTF_PACKAGE_FLAGS.
 *
 * @retval 1 if string must be packaged in run time.
 * @retval 0 string can be statically packaged.
 *//** @brief Signature for a external formatter function identical to cbvprintf.
 *
 * This function expects the following parameters:
 *
 * @param out the function used to emit each generated character.
 *
 * @param ctx a pointer to an object that provides context for the
 * external formatter.
 *
 * @param fmt a standard ISO C format string with characters and
 * conversion specifications.
 *
 * @param ap captured stack arguments corresponding to the conversion
 * specifications found within @p fmt.
 *
 * @return vprintf like return values: the number of characters printed,
 * or a negative error value returned from external formatter.
 *//** @brief Signature for a cbprintf multibyte callback function.
 *
 * @param buf data.
 * @param len data length.
 * @param ctx a pointer to an object that provides context for the operation.
 *
 * return Amount of copied data or negative error code.
 *//* int c, void *ctx *//** @brief Signature for a cbprintf callback function.
 *
 * This function expects two parameters:
 *
 * * @p c a character to output.  The output behavior should be as if
 *   this was cast to an unsigned char.
 * * @p ctx a pointer to an object that provides context for the
 *   output operation.
 *
 * The declaration does not specify the parameter types.  This allows a
 * function like @c fputc to be used without requiring all context pointers to
 * be to a @c FILE object.
 *
 * @return the value of @p c cast to an unsigned char then back to
 * int, or a negative error code that will be returned from
 * cbprintf().
 *//** @brief Indicates the arguments are tagged.
 *
 * This tells z_cbvprintf_impl() that the incoming arguments are
 * tagged, and should be processed accordingly.
 *//**
 * @defgroup Z_CBVPRINTF_PROCESS_FLAGS cbvprintf processing flags.
 * @{
 *//** @brief Check format string if %p argument was treated as %s in the package.
 *
 * Static packaging is done based only on types of arguments used for a format
 * string. Without looking into format specifiers present in the string. Because
 * of that if (unsigned) char pointer is used for %p it will be considered as
 * a string location and during conversion an attempt to append a string to a
 * package may be performed. This can lead to misbehavior, in the best case
 * package will be bigger and in the worst case memory fault or security violation
 * may occur.
 *
 * When this flag is set, format string will be checked to detect cases when
 * string candidate is a pointer used for %p and string appending from unexpected
 * location is avoided. Additionally, an log warning is generated to encourage
 * user to cast such argument to void *. It is recommended because there are
 * configurations where string is not accessible and inspection cannot be done.
 * In those cases there are no means to detect such cases.
 *//** @deprecated Use @ref CBPRINTF_PACKAGE_CONVERT_KEEP_RO_STR instead. *//** @brief Keep read-only location indexes in the package.
 *
 * If it is set read-only string pointers are kept in the package after copy. If
 * not set they are discarded.
 *//** @deprecated Use @ref CBPRINTF_PACKAGE_CONVERT_RW_STR instead. *//** @brief Append read-write strings from source package to destination package.
 *
 * If package was created with @ref CBPRINTF_PACKAGE_ADD_RW_STR_POS it contains
 * arrays of indexes where string address can be found in the package. When flag
 * is set, list of read-write strings is examined and if they are not determined
 * to be read-only, they are copied into the destination package.
 * If @ref CBPRINTF_PACKAGE_CONVERT_RO_STR is not set, remaining string locations
 * are considered as pointing to read-only location and they are copy to the
 * package if @ref CBPRINTF_PACKAGE_CONVERT_KEEP_RO_STR is set.
 *//** @deprecated Use @ref CBPRINTF_PACKAGE_CONVERT_RO_STR instead. *//** @brief Append read-only strings from source package to destination package.
 *
 * If package was created with @ref CBPRINTF_PACKAGE_ADD_RO_STR_POS
 * or @ref CBPRINTF_PACKAGE_ADD_RW_STR_POS it contains arrays of indexes where
 * string address can be found in the package. When flag is set, read-only strings
 * are copied into destination package. Address of strings indicated as read-write
 * are also checked and if determined to be read-only they are also copied.
 *//**
 * @defgroup CBPRINTF_PACKAGE_CONVERT_FLAGS Package convert flags
 * @{
 *//** @brief Indicate the incoming arguments are tagged.
 *
 * When set, this indicates that the incoming arguments are tagged, and
 * need to be processed accordingly.
 *//** @brief Append indexes of read-only string arguments in the package.
 *
 * When used, package contains locations of read-only string arguments. Package
 * with that information can be converted to fully self-contain package using
 * @ref cbprintf_fsc_package.
 *//** @brief Get number of first format string arguments which are known to be read-only
 * string.
 *//** @brief Indicate that @p n first string format arguments are char pointers to
 * read-only location.
 *
 * Runtime algorithm (address analysis) is skipped for those strings.
 *
 * @param n Number of string arguments considered as read-only.
 *//** @brief Append locations (within the package) of read-write string pointers.
 *
 * When this flag is not used then read-write strings are appended to the package.
 *//** @brief Append locations (within the package) of read-only string pointers. *//** @brief Assume that const char pointer is pointing to read only (constant) strings.
 *
 * Flag is valid only for @ref CBPRINTF_STATIC_PACKAGE.
 *//**@defgroup CBPRINTF_PACKAGE_FLAGS Package flags
 * @{
 *//** @brief Required alignment of the buffer used for packaging. *//**
 * @defgroup cbprintf_apis Formatted Output APIs
 * @ingroup utilities
 * @{
 *//* Z_C_GENERIC is used there *//**
 * @endcond
 *//**
 * @cond INTERNAL_HIDDEN
 *
 * Assert that the package hdr does indeed align properly.
 *//*
	 * When extending this struct, make sure this align
	 * to pointer size.
	 *//** Pointer to format string *//** Header of package *//** @brief cbprintf package header with format string pointer.
 *
 * cbprintf package header with format string pointer.
 *//** Header description *//** @brief cbprintf package header
 *
 * cbprintf package header, without the format string pointer.
 *//*
	 * On Xtensa, the first argument needs to be aligned to 8-byte.
	 * With 32-bit pointers, we need another 4 bytes padding so
	 * that whole struct cbprintf_package_hdr_ext is of multiple of
	 * 8 bytes.
	 *//** Flags used to create the package *//** Number of read-write strings, indexes appended to the package *//** Number of read-only strings, indexes appended to the package *//** Number of appended strings in the package. *//** Package length (in 32 bit words) *//**
 * @brief cbprintf package descriptor.
 *//* __xtensa__ *//* Determine if _Generic is supported using macro from toolchain.h.
 *
 * @note Z_C_GENERIC is also set for C++ where functionality is implemented
 * using overloading and templates.
 */z_log_msg_runtime_vcreatez_impl_z_log_msg_runtime_vcreatez_log_msg_static_createz_impl_z_log_msg_static_createz_log_msg_simple_create_2z_impl_z_log_msg_simple_create_2z_log_msg_simple_create_1z_impl_z_log_msg_simple_create_1z_log_msg_simple_create_0z_impl_z_log_msg_simple_create_0Z_INCLUDE_SYSCALLS_LOG_MSG_Hdlenpackage_flagsarg0arg1<syscalls/log_msg.h><zephyr/logging/log_instance.h>log_msg_get_packagelog_msg_get_datalog_msg_get_tidlog_msg_get_timestamplog_msg_get_sourcelog_msg_get_levellog_msg_get_domainlog_msg_generic_get_wlenconst log_msg_genericconst log_msg_generic *generic_msgconst log_msgconst log_msg *log_msg_get_total_wlendesc.package_lendesc.data_lenROUND_UP(Z_LOG_MSG_LEN(desc.package_len, desc.data_len), Z_LOG_MSG_ALIGNMENT)((((unsigned long)((__builtin_offsetof (struct log_msg, data) + desc.package_len + (desc.data_len))) + ((unsigned long)((((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1))))) - 1)) / (unsigned long)((((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1)))))) * (unsigned long)((((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1))))))Z_LOG_MSG_LEN(desc.package_len, desc.data_len)(__builtin_offsetof (struct log_msg, data) + desc.package_len + (desc.data_len))Z_LOG_MSG_ALIGNMENTz_log_item_is_msgZ_LOG_MSG_LOGz_log_msg_runtime_createz_log_msg_finalizez_log_msg_allocz_log_msg_modeZ_LOG_MSG_MODE_RUNTIMEZ_LOG_MSG_MODE_FROM_STACKZ_LOG_MSG_MODE_ZERO_COPYZ_LOG_MSG_MODE_SIMPLElog_msg_genericlog_msg_generic_hdrlog_msglog_msg_hdrlog_msg_sourcelog_msg_desclog_timestamp_tloggenericZ_LOG_MSG_PADDINGpaddingdynamicfixedpackage_lensizeof(struct log_msg) % Z_LOG_MSG_ALIGNMENT == 0sizeof(struct log_msg) % (((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) <= 2UL ? ((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) : (1UL << (8 * sizeof(long) - __builtin_clzl(((((sizeof(double)) > (sizeof(long long))) ? (sizeof(double)) : (sizeof(long long)))) - 1)))) == 0"Log msg size must aligned"Z_LOG_MSG_CREATE(_try_0cpy,_mode,_domain_id,_source,_level,_data,_dlen,__VA_ARGS__...)Z_LOG_MSG_CREATE2(_try_0cpy, _mode, UTIL_CAT(Z_LOG_FUNC_PREFIX_, _level), _domain_id, _source, _level, _data, _dlen, Z_LOG_STR(_level, __VA_ARGS__))Z_LOG_MSG_CREATE2(_try_0cpy,_mode,_cstr_cnt,_domain_id,_source,_level,_data,_dlen,__VA_ARGS__...)do { _Pragma("GCC diagnostic push") _Pragma("GCC diagnostic ignored \"-Wpointer-arith\"") FOR_EACH_IDX(Z_LOG_LOCAL_ARG_CREATE, (;), __VA_ARGS__); _Pragma("GCC diagnostic pop") Z_LOG_MSG_CREATE3(_try_0cpy, _mode, _cstr_cnt, _domain_id, _source, _level, _data, _dlen, FOR_EACH_IDX(Z_LOG_LOCAL_ARG_NAME, (,), __VA_ARGS__)); } while (false)Z_LOG_LOCAL_ARG_CREATE(idx,arg)COND_CODE_0(idx, (), (Z_AUTO_TYPE Z_LOG_LOCAL_ARG_NAME(idx, arg) = (arg) + 0))Z_LOG_LOCAL_ARG_NAME(idx,arg)COND_CODE_0(idx, (arg), (_v ## idx))Z_AUTO_TYPE__auto_typeZ_LOG_MSG_CREATE3(_try_0cpy,_mode,_cstr_cnt,_domain_id,_source,_level,_data,_dlen,__VA_ARGS__...)do { Z_LOG_MSG_STR_VAR(_fmt, ## __VA_ARGS__); bool has_rw_str = CBPRINTF_MUST_RUNTIME_PACKAGE( Z_LOG_MSG_CBPRINTF_FLAGS(_cstr_cnt), __VA_ARGS__); if (IS_ENABLED(CONFIG_LOG_SPEED) && _try_0cpy && ((_dlen) == 0) && !has_rw_str) { LOG_MSG_DBG("create zero-copy message\n"); Z_LOG_MSG_SIMPLE_CREATE(_cstr_cnt, _domain_id, _source, _level, Z_LOG_FMT_ARGS(_fmt, ## __VA_ARGS__)); _mode = Z_LOG_MSG_MODE_ZERO_COPY; } else { IF_ENABLED(UTIL_AND(IS_ENABLED(CONFIG_LOG_SIMPLE_MSG_OPTIMIZE), UTIL_AND(UTIL_NOT(_domain_id), UTIL_NOT(_cstr_cnt))), ( bool can_simple = LOG_MSG_SIMPLE_CHECK(__VA_ARGS__); if (can_simple && ((_dlen) == 0) && !k_is_user_context()) { LOG_MSG_DBG("create fast message\n"); Z_LOG_MSG_SIMPLE_ARGS_CREATE(_domain_id, _source, _level, Z_LOG_FMT_ARGS(_fmt, ## __VA_ARGS__)); _mode = Z_LOG_MSG_MODE_SIMPLE; break; } ) ) LOG_MSG_DBG("create on stack message\n"); Z_LOG_MSG_STACK_CREATE(_cstr_cnt, _domain_id, _source, _level, _data, _dlen, Z_LOG_FMT_ARGS(_fmt, ## __VA_ARGS__)); _mode = Z_LOG_MSG_MODE_FROM_STACK; } (void)_mode; } while (false)Z_LOG_MSG_STR_VAR(_name,__VA_ARGS__...)IF_ENABLED(CONFIG_LOG_FMT_SECTION, (Z_LOG_MSG_STR_VAR_IN_SECTION(_name, ## __VA_ARGS__)))Z_LOG_MSG_STR_VAR_IN_SECTION(_name,__VA_ARGS__...)COND_CODE_0(NUM_VA_ARGS_LESS_1(_, ## __VA_ARGS__), ( ), (static const char _name[] __in_section(_log_strings, static, _CONCAT(_name, _)) __used __noasan = GET_ARG_N(1, __VA_ARGS__);))Z_LOG_FMT_RUNTIME_ARGS(__VA_ARGS__...)Z_LOG_FMT_ARGS(__VA_ARGS__)Z_LOG_FMT_ARGS(_name,__VA_ARGS__...)COND_CODE_0(NUM_VA_ARGS_LESS_1(_, ## __VA_ARGS__), (NULL), (Z_LOG_FMT_ARGS_2(_name, ## __VA_ARGS__)))Z_LOG_FMT_ARGS_2(_name,__VA_ARGS__...)COND_CODE_1(CONFIG_LOG_FMT_SECTION, (COND_CODE_0(NUM_VA_ARGS_LESS_1(__VA_ARGS__), (_name), (_name, GET_ARGS_LESS_N(1, __VA_ARGS__)))), (__VA_ARGS__))Z_LOG_MSG_SIMPLE_CREATE(__VA_ARGS__...)Z_LOG_MSG_STACK_CREATE(_cstr_cnt,_domain_id,_source,_level,_data,_dlen,__VA_ARGS__...)do { int _plen; uint32_t _options = Z_LOG_MSG_CBPRINTF_FLAGS(_cstr_cnt) | CBPRINTF_PACKAGE_ADD_RW_STR_POS; if (GET_ARG_N(1, __VA_ARGS__) == NULL) { _plen = 0; } else { CBPRINTF_STATIC_PACKAGE(NULL, 0, _plen, Z_LOG_MSG_ALIGN_OFFSET, _options, __VA_ARGS__); } TOOLCHAIN_IGNORE_WSHADOW_BEGIN struct log_msg *_msg; TOOLCHAIN_IGNORE_WSHADOW_END Z_LOG_MSG_ON_STACK_ALLOC(_msg, Z_LOG_MSG_LEN(_plen, 0)); Z_LOG_ARM64_VLA_PROTECT(); if (_plen != 0) { CBPRINTF_STATIC_PACKAGE(_msg->data, _plen, _plen, Z_LOG_MSG_ALIGN_OFFSET, _options, __VA_ARGS__); } struct log_msg_desc _desc = Z_LOG_MSG_DESC_INITIALIZER(_domain_id, _level, (uint32_t)_plen, _dlen); LOG_MSG_DBG("creating message on stack: package len: %d, data len: %d\n", _plen, (int)(_dlen)); z_log_msg_static_create((void *)_source, _desc, _msg->data, _data); } while (false)Z_LOG_MSG_SIMPLE_ARGS_CREATE(_domain_id,_source,_level,__VA_ARGS__...)IF_ENABLED(LOG_MSG_SIMPLE_ARG_CNT_CHECK(__VA_ARGS__), ( LOG_MSG_SIMPLE_FUNC(_source, _level, __VA_ARGS__); ))LOG_MSG_SIMPLE_FUNC(_source,_level,__VA_ARGS__...)Z_LOG_MSG_SIMPLE_FUNC2(NUM_VA_ARGS_LESS_1(__VA_ARGS__), _source, _level, __VA_ARGS__)Z_LOG_MSG_SIMPLE_FUNC2(arg_cnt,_source,_level,__VA_ARGS__...)COND_CODE_0(arg_cnt, (z_log_msg_simple_create_0(_source, _level, GET_ARG_N(1, __VA_ARGS__))), (COND_CODE_1(arg_cnt, ( Z_LOG_MSG_SIMPLE_CREATE_1(_source, _level, __VA_ARGS__, dummy) ), ( Z_LOG_MSG_SIMPLE_CREATE_2(_source, _level, __VA_ARGS__, dummy, dummy) ) )))Z_LOG_MSG_SIMPLE_CREATE_2(_source,_level,__VA_ARGS__...)z_log_msg_simple_create_2(_source, _level, GET_ARG_N(1, __VA_ARGS__), (uint32_t)(uintptr_t)GET_ARG_N(2, __VA_ARGS__), (uint32_t)(uintptr_t)GET_ARG_N(3, __VA_ARGS__))Z_LOG_MSG_SIMPLE_CREATE_1(_source,_level,__VA_ARGS__...)z_log_msg_simple_create_1(_source, _level, GET_ARG_N(1, __VA_ARGS__), (uint32_t)(uintptr_t)GET_ARG_N(2, __VA_ARGS__))LOG_MSG_SIMPLE_CHECK(__VA_ARGS__...)COND_CODE_1(CONFIG_64BIT, (0), ( COND_CODE_1(LOG_MSG_SIMPLE_ARG_CNT_CHECK(__VA_ARGS__), ( LOG_MSG_SIMPLE_ARG_TYPE_CHECK(__VA_ARGS__)), (0))))LOG_MSG_SIMPLE_ARG_TYPE_CHECK(__VA_ARGS__...)UTIL_CAT(LOG_MSG_SIMPLE_ARG_TYPE_CHECK_, NUM_VA_ARGS_LESS_1(__VA_ARGS__))(__VA_ARGS__)LOG_MSG_SIMPLE_ARG_TYPE_CHECK_2(fmt,arg0,arg1)Z_CBPRINTF_IS_WORD_NUM(arg0) || Z_CBPRINTF_IS_WORD_NUM(arg1)LOG_MSG_SIMPLE_ARG_TYPE_CHECK_1(fmt,arg)Z_CBPRINTF_IS_WORD_NUM(arg)LOG_MSG_SIMPLE_ARG_TYPE_CHECK_0(fmt)LOG_MSG_SIMPLE_ARG_CNT_CHECK(__VA_ARGS__...)COND_CODE_1(UTIL_CAT(_LOG_MSG_SIMPLE_XXXX, NUM_VA_ARGS_LESS_1(__VA_ARGS__)), (1), (0))_LOG_MSG_SIMPLE_XXXX2_LOG_MSG_SIMPLE_XXXX1_LOG_MSG_SIMPLE_XXXX0Z_LOG_ARM64_VLA_PROTECT()Z_LOG_MSG_ALIGNED_WLEN(pkg_len,data_len)DIV_ROUND_UP(ROUND_UP(Z_LOG_MSG_LEN(pkg_len, data_len), Z_LOG_MSG_ALIGNMENT), sizeof(uint32_t))Z_LOG_MSG_LEN(pkg_len,data_len)(offsetof(struct log_msg, data) + pkg_len + (data_len))offsetof(struct log_msg, data)Z_LOG_MSG_ON_STACK_ALLOC(ptr,len)long long _ll_buf32[32 / sizeof(long long)]; long long _ll_buf48[48 / sizeof(long long)]; long long _ll_buf64[64 / sizeof(long long)]; long long _ll_buf128[128 / sizeof(long long)]; long long _ll_buf256[256 / sizeof(long long)]; long double _ld_buf32[32 / sizeof(long double)]; long double _ld_buf48[48 / sizeof(long double)]; long double _ld_buf64[64 / sizeof(long double)]; long double _ld_buf128[128 / sizeof(long double)]; long double _ld_buf256[256 / sizeof(long double)]; if (sizeof(long double) == Z_LOG_MSG_ALIGNMENT) { ptr = (len > 128) ? (struct log_msg *)_ld_buf256 : ((len > 64) ? (struct log_msg *)_ld_buf128 : ((len > 48) ? (struct log_msg *)_ld_buf64 : ((len > 32) ? (struct log_msg *)_ld_buf48 : (struct log_msg *)_ld_buf32))); } else { ptr = (len > 128) ? (struct log_msg *)_ll_buf256 : ((len > 64) ? (struct log_msg *)_ll_buf128 : ((len > 48) ? (struct log_msg *)_ll_buf64 : ((len > 32) ? (struct log_msg *)_ll_buf48 : (struct log_msg *)_ll_buf32))); } if (IS_ENABLED(CONFIG_LOG_TEST_CLEAR_MESSAGE_SPACE)) { memset(ptr, 0, len); }Z_LOG_MSG_CBPRINTF_FLAGS(_cstr_cnt)(CBPRINTF_PACKAGE_FIRST_RO_STR_CNT(_cstr_cnt) | (IS_ENABLED(CONFIG_LOG_MSG_APPEND_RO_STRING_LOC) ? CBPRINTF_PACKAGE_ADD_STRING_IDXS : 0))Z_LOG_MSG_DESC_INITIALIZER(_domain_id,_level,_plen,_dlen){ .valid = 0, .busy = 0, .type = Z_LOG_MSG_LOG, .domain = _domain_id, .level = _level, .package_len = _plen, .data_len = _dlen, }((sizeof(struct log_msg_hdr) % Z_LOG_MSG_ALIGNMENT) > 0 ? (Z_LOG_MSG_ALIGNMENT - (sizeof(struct log_msg_hdr) % Z_LOG_MSG_ALIGNMENT)) : 0)LOG_MSG_GENERIC_HDRMPSC_PBUF_HDR; uint32_t type:1Z_LOG_MSG_MAX_PACKAGEBIT_MASK(Z_LOG_MSG_PACKAGE_BITS)Z_LOG_MSG_PACKAGE_BITSLOG_MSG_DBG(__VA_ARGS__...)IF_ENABLED(LOG_MSG_DEBUG, (printk(__VA_ARGS__)))ZEPHYR_INCLUDE_LOGGING_LOG_MSG_H_CONFIG_LOG_TIMESTAMP_64BIT(INTPTR_MAX > INT32_MAX) && !CONFIG_LOG_TIMESTAMP_64BITCONFIG_LOG_THREAD_ID_PREFIXCONFIG_LOG_USE_VLAdefined(CONFIG_LOG_USE_TAGGED_ARGUMENTS)defined(CONFIG_LOG_ALWAYS_RUNTIME) || \__INTPTR_MAX__/* ZEPHYR_INCLUDE_LOGGING_LOG_MSG_H_ *//** @brief Get string package.
 *
 * @param msg log message.
 *
 * @param len location where string package length is written.
 *
 * @return pointer to the package.
 *//** @brief Get data buffer.
 *
 * @param msg log message.
 *
 * @param len location where data length is written.
 *
 * @return pointer to the data buffer.
 *//** @brief Get Thread ID.
 *
 * @param msg Log message.
 *
 * @return Thread ID.
 *//** @brief Get timestamp.
 *
 * @param msg Log message.
 *
 * @return Timestamp.
 *//** @brief Get message source data.
 *
 * @param msg Log message.
 *
 * @return Pointer to the source data.
 *//** @brief Get log message level.
 *
 * @param msg Log message.
 *
 * @return Log level.
 *//** @brief Get log message domain ID.
 *
 * @param msg Log message.
 *
 * @return Domain ID
 *//** @brief Get length of the log item.
 *
 * @param item Item.
 *
 * @return Length in 32 bit words.
 *//** @brief Get total length (in 32 bit words) of a log message.
 *
 * @param desc Log message descriptor.
 *
 * @return Length.
 *//** @brief Create message at runtime.
 *
 * Function allows to build any log message based on input data. Processing
 * time is significantly higher than statically message creating.
 *
 * @param domain_id Domain ID.
 *
 * @param source Source.
 *
 * @param level Log level.
 *
 * @param data Data.
 *
 * @param dlen Data length.
 *
 * @param package_flags Package flags.
 *
 * @param fmt String.
 *
 * @param ... String arguments.
 *//** @brief Create message at runtime.
 *
 * Function allows to build any log message based on input data. Processing
 * time is significantly higher than statically message creating.
 *
 * @param domain_id Domain ID.
 *
 * @param source Source.
 *
 * @param level Log level.
 *
 * @param data Data.
 *
 * @param dlen Data length.
 *
 * @param package_flags Package flags.
 *
 * @param fmt String.
 *
 * @param ap Variable list of string arguments.
 *//** @brief Create a logging message from message details and string package.
 *
 * @param source Source.
 *
 * @param desc Message descriptor.
 *
 * @param package Package.
 *
 * @oaram data Data.
 *//** @brief Create log message using simplified method for string with two arguments.
 *
 * @param source Pointer to the source structure.
 * @param level  Severity level.
 * @param fmt    String pointer.
 * @param arg0   String argument.
 * @param arg1   String argument.
 *//** @brief Create log message using simplified method for string with a one argument.
 *
 * @param source Pointer to the source structure.
 * @param level  Severity level.
 * @param fmt    String pointer.
 * @param arg    String argument.
 *//** @brief Create log message using simplified method for string with no arguments.
 *
 * @param source Pointer to the source structure.
 * @param level  Severity level.
 * @param fmt    String pointer.
 *//** @brief Finalize message.
 *
 * Finalization includes setting source, copying data and timestamp in the
 * message followed by committing the message.
 *
 * @param msg Message.
 *
 * @param source Address of the source descriptor.
 *
 * @param desc Message descriptor.
 *
 * @param data Data.
 *//** @brief Allocate log message.
 *
 * @param wlen Length in 32 bit words.
 *
 * @return allocated space or null if cannot be allocated.
 *//* CONFIG_LOG_ALWAYS_RUNTIME ||
	* (!LOG && (!TOOLCHAIN_HAS_PRAGMA_DIAG || !TOOLCHAIN_HAS_C_AUTO_TYPE))
	*//* First level of processing creates stack variables to be passed for further processing.
 * This is done to prevent multiple evaluations of input arguments (in case argument
 * evaluation has side effects, e.g. it is a non-pure function call).
 *//* Create local variable from input variable (expect for the first (fmt) argument). *//* Macro for getting name of a local variable with the exception of the first argument
 * which is a formatted string in log message.
 *//* CONFIG_LOG_ALWAYS_RUNTIME *//** @brief Create log message and write it into the logger buffer.
 *
 * Macro handles creation of log message which includes storing log message
 * description, timestamp, arguments, copying string arguments into message and
 * copying user data into the message space. The are 3 modes of message
 * creation:
 * - at compile time message size is determined, message is allocated and
 *   content is written directly to the message. It is the fastest but cannot
 *   be used in user mode. Message size cannot be determined at compile time if
 *   it contains data or string arguments which are string pointers.
 * - at compile time message size is determined, string package is created on
 *   stack, message is created in function call. String package can only be
 *   created on stack if it does not contain unexpected pointers to strings.
 * - string package is created at runtime. This mode has no limitations but
 *   it is significantly slower.
 *
 * @param _try_0cpy If positive then, if possible, message content is written
 * directly to message. If 0 then, if possible, string package is created on
 * the stack and message is created in the function call.
 *
 * @param _mode Used for testing. It is set according to message creation mode
 *		used.
 *
 * @param _cstr_cnt Number of constant strings present in the string. It is
 * used to help detect messages which must be runtime processed, compared to
 * message which can be prebuilt at compile time.
 *
 * @param _domain_id Domain ID.
 *
 * @param _source Pointer to the constant descriptor of the log message source.
 *
 * @param _level Log message level.
 *
 * @param _data Pointer to the data. Can be null.
 *
 * @param _dlen Number of data bytes. 0 if data is not provided.
 *
 * @param ...  Optional string with arguments (fmt, ...). It may be empty.
 *//** @brief Create variable in the dedicated memory section (if enabled).
 *
 * Variable is initialized with a format string from the log message.
 *
 * @param _name Variable name.
 * @param ... Optional log message with arguments (may be empty).
 *//* No args provided, no variable *//* Macro handles case when there is no string provided, in that case variable
 * is not created.
 *//* CONFIG_LOG_USE_TAGGED_ARGUMENTS *//** @brief Wrapper for log message string with tagged arguments.
 *
 * Wrapper is replacing first argument with a variable from a dedicated memory
 * section if option is enabled. Macro handles the case when there is no
 * log message provided. Each subsequent arguments are tagged by preceding
 * each argument with its type value.
 *
 * @param _name Name of the variable with log message string. It is optionally used.
 * @param ... Optional log message with arguments (may be empty).
 *//** @brief Wrapper for log message string with arguments.
 *
 * Wrapper is replacing first argument with a variable from a dedicated memory
 * section if option is enabled. Macro handles the case when there is no
 * log message provided.
 *
 * @param _name Name of the variable with log message string. It is optionally used.
 * @param ... Optional log message with arguments (may be empty).
 *//* Macro handles case when local variable with log message string is created. It
 * replaces original string literal with that variable.
 *//* Alternative empty macro created to speed up compilation when LOG_SPEED is
 * disabled (default).
 *//** @brief Create log message using simplified method.
 *
 * Macro is gated by the argument count check to run @ref LOG_MSG_SIMPLE_FUNC only
 * on entries with 2 or less arguments.
 *
 * @param _domain_id	Domain ID.
 * @param _source	Pointer to the source structure.
 * @param _level	Severity level.
 * @param ...		String with arguments.
 *//** @brief Call specific function to create a log message.
 *
 * Macro picks matching function (based on number of arguments) and calls it.
 * String arguments are casted to uint32_t.
 *
 * @param _source	Source.
 * @param _level	Severity level.
 * @param ...		String with arguments.
 *//* Call specific function based on the number of arguments.
 * Since up 2 to arguments are supported COND_CODE_0 and COND_CODE_1 can be used to
 * handle all cases (0, 1 and 2 arguments). When tracing is enable then for each
 * function a macro is create. The difference between function and macro is that
 * macro is applied to any input arguments so we need to make sure that it is
 * always called with proper number of arguments. For that it is wrapped around
 * into another macro and dummy arguments to cover for cases when there is less
 * arguments in a log call.
 *//* Helper macro for handing log with two arguments. Macro casts arguments to uint32_t.
 *//* Helper macro for handing log with one argument. Macro casts the first argument to uint32_t. *//** @brief Check if message can be handled using simplified method.
 *
 * Following conditions must be met:
 * - 32 bit platform
 * - Number of arguments from 0 to 2
 * - Type of an argument must be a numeric value that fits in 32 bit word.
 *
 * @param ... String with arguments.
 *
 * @retval 1 if message qualifies.
 * @retval 0 if message does not qualify.
 *//** brief Determine if string arguments types allow to use simplified message creation mode.
 *
 * @param ... String with arguments.
 *//* Set of marcos used to determine if arguments type allows simplified message creation mode. *//* Determine if amount of arguments (less than 3) qualifies to  simple message. *//*
 * With Zephyr SDK 0.14.2, aarch64-zephyr-elf-gcc (10.3.0) fails to ensure $sp
 * is below the active memory during message construction. As a result,
 * interrupts happening in the middle of that process can end up smashing active
 * data and causing a logging fault. Work around this by inserting a compiler
 * barrier after the allocation and before any use to make sure GCC moves the
 * stack pointer soon enough
 *//* Z_LOG_MSG_USE_VLA *//* During test fill with 0's to simplify message comparison *//* When VLA cannot be used we need to trick compiler a bit and create multiple
 * fixed size arrays and take the smallest one that will fit the message.
 * Compiler will remove unused arrays and stack usage will be kept similar
 * to vla case, rounded to the size of the used buffer.
 *//* Mode optimized for simple messages with 0 to 2 32 bit word arguments.*//* Mode calculates size of the message and allocates it and writes
	 * directly to the message space. It is the fastest method but requires
	 * more code size.
	 *//* Mode creates statically a string package on stack and calls a
	 * function for creating a message. It takes code size than
	 * Z_LOG_MSG_MODE_ZERO_COPY but is a bit slower.
	 *//* Runtime mode is least efficient but supports all cases thus it is
	 * treated as a fallback method when others cannot be used.
	 *//** @brief Method used for creating a log message.
 *
 * It is used for testing purposes to validate that expected mode was used.
 *//* Adding padding to ensure that cbprintf package that follows is
	 * properly aligned.
	 *//* Messages are aligned to alignment required by cbprintf package. *//* Attempting to keep best alignment. When address is 64 bit and timestamp 32
 * swap the order to have 16 byte header instead of 24 byte.
 *//**
 * @brief Log message API
 * @defgroup log_msg Log message API
 * @ingroup logger
 * @{
 */Log msg size must alignedlog2_genericz_log_printf_arg_checkerlog_dynamic_source_idsizeof(struct log_source_dynamic_data)log_const_source_idsizeof(struct log_source_const_data)z_log_minimal_level_to_char'W'LOG_LEVEL_INF'D''?'z_log_minimal_printkz_log_minimal_vprintkz_log_minimal_hexdump_print_log_dynamic_list_end_log_dynamic_list_start_log_const_list_end_log_const_list_startLOG_INSTANCE_DYNAMIC_DATA(_module_name,_inst)LOG_ITEM_DYNAMIC_DATA(Z_LOG_INSTANCE_FULL_NAME(_module_name, _inst))LOG_ITEM_DYNAMIC_DATA(_name)UTIL_CAT(log_dynamic_, _name)Z_LOG_PRINTK(_is_raw,__VA_ARGS__...)do { if (!IS_ENABLED(CONFIG_LOG)) { break; } if (IS_ENABLED(CONFIG_LOG_MODE_MINIMAL)) { z_log_minimal_printk(__VA_ARGS__); break; } int _mode; if (0) { z_log_printf_arg_checker(__VA_ARGS__); } Z_LOG_MSG_CREATE(!IS_ENABLED(CONFIG_USERSPACE), _mode, Z_LOG_LOCAL_DOMAIN_ID, (const void *)(uintptr_t)_is_raw, LOG_LEVEL_INTERNAL_RAW_STRING, NULL, 0, __VA_ARGS__);} while (0)LOG_LEVEL_INTERNAL_RAW_STRINGZ_LOG_RUNTIME_FILTER(_filter)LOG_FILTER_SLOT_GET(&_filter, LOG_FILTER_AGGR_SLOT_IDX)LOG_FILTER_FIRST_BACKEND_SLOT_IDXLOG_FILTER_AGGR_SLOT_GET(_filters)LOG_FILTER_SLOT_GET(_filters, LOG_FILTER_AGGR_SLOT_IDX)LOG_FILTER_SLOT_SET(_filters,_id,_filter)do { *(_filters) &= ~(LOG_FILTER_SLOT_MASK << LOG_FILTER_SLOT_SHIFT(_id)); *(_filters) |= ((_filter) & LOG_FILTER_SLOT_MASK) << LOG_FILTER_SLOT_SHIFT(_id); } while (false)LOG_FILTER_SLOT_GET(_filters,_id)((*(_filters) >> LOG_FILTER_SLOT_SHIFT(_id)) & LOG_FILTER_SLOT_MASK)LOG_FILTER_SLOT_SHIFT(_id)(LOG_FILTER_SLOT_SIZE * (_id))LOG_FILTER_SLOT_MASK(BIT(LOG_FILTER_SLOT_SIZE) - 1U)LOG_FILTERS_NUM_OF_SLOTS(32 / LOG_FILTER_SLOT_SIZE)LOG_LEVEL_BITSZ_LOG_HEXDUMP_INSTANCE(_level,_inst,_data,_length,_str)Z_LOG_HEXDUMP2(_level, 1, COND_CODE_1(CONFIG_LOG_RUNTIME_FILTERING, (NULL), (Z_LOG_INST(_inst))), (struct log_source_dynamic_data *)COND_CODE_1( CONFIG_LOG_RUNTIME_FILTERING, (Z_LOG_INST(_inst)), (NULL)), _data, _length, _str)Z_LOG_HEXDUMP(_level,_data,_length,__VA_ARGS__...)Z_LOG_HEXDUMP2(_level, 0, __log_current_const_data, __log_current_dynamic_data, _data, _length, __VA_ARGS__)Z_LOG_HEXDUMP2(_level,_inst,_source,_dsource,_data,_len,__VA_ARGS__...)do { const char *_str = GET_ARG_N(1, __VA_ARGS__); if (!Z_LOG_CONST_LEVEL_CHECK(_level)) { break; } if (_inst && !IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING)) { if (_level > ((struct log_source_const_data *)_source)->level) { break; } } bool is_user_context = k_is_user_context(); uint32_t filters = IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING) ? (_dsource)->filters : 0; if (IS_ENABLED(CONFIG_LOG_MODE_MINIMAL)) { Z_LOG_TO_PRINTK(_level, "%s", _str); z_log_minimal_hexdump_print(_level, (const char *)_data, _len); break; } if (!IS_ENABLED(CONFIG_LOG_FRONTEND) && IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING) && !is_user_context && _level > Z_LOG_RUNTIME_FILTER(filters)) { break; } int mode; void *_src = IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING) ? (void *)_dsource : (void *)_source; Z_LOG_MSG_CREATE(UTIL_NOT(IS_ENABLED(CONFIG_USERSPACE)), mode, Z_LOG_LOCAL_DOMAIN_ID, _src, _level, _data, _len, COND_CODE_0(NUM_VA_ARGS_LESS_1(_, ## __VA_ARGS__), (), (COND_CODE_0(NUM_VA_ARGS_LESS_1(__VA_ARGS__), ("%s", __VA_ARGS__), (__VA_ARGS__)))));} while (false)Z_LOG_INSTANCE(_level,_inst,__VA_ARGS__...)do { (void)_inst; Z_LOG2(_level, 1, COND_CODE_1(CONFIG_LOG_RUNTIME_FILTERING, (NULL), (Z_LOG_INST(_inst))), (struct log_source_dynamic_data *)COND_CODE_1( CONFIG_LOG_RUNTIME_FILTERING, (Z_LOG_INST(_inst)), (NULL)), __VA_ARGS__); } while (0)Z_LOG(_level,__VA_ARGS__...)Z_LOG2(_level, 0, __log_current_const_data, __log_current_dynamic_data, __VA_ARGS__)Z_LOG2(_level,_inst,_source,_dsource,__VA_ARGS__...)do { if (!Z_LOG_CONST_LEVEL_CHECK(_level)) { break; } if (IS_ENABLED(CONFIG_LOG_MODE_MINIMAL)) { Z_LOG_TO_PRINTK(_level, __VA_ARGS__); break; } if (_inst != 0 && !IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING)) { if (_level > ((struct log_source_const_data *)_source)->level) { break; } } bool is_user_context = k_is_user_context(); if (!IS_ENABLED(CONFIG_LOG_FRONTEND) && IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING) && !is_user_context && _level > Z_LOG_RUNTIME_FILTER((_dsource)->filters)) { break; } int _mode; void *_src = IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING) ? (void *)_dsource : (void *)_source; Z_LOG_MSG_CREATE(UTIL_NOT(IS_ENABLED(CONFIG_USERSPACE)), _mode, Z_LOG_LOCAL_DOMAIN_ID, _src, _level, NULL, 0, __VA_ARGS__); (void)_mode; if (false) { z_log_printf_arg_checker(__VA_ARGS__); } } while (false)Z_LOG_INST(_inst)COND_CODE_1(CONFIG_LOG, (_inst), NULL)Z_LOG_TO_VPRINTK(_level,fmt,valist)do { z_log_minimal_printk("%c: ", z_log_minimal_level_to_char(_level)); z_log_minimal_vprintk(fmt, valist); z_log_minimal_printk("\n"); } while (false)Z_LOG_TO_PRINTK(_level,fmt,__VA_ARGS__...)do { z_log_minimal_printk("%c: " fmt "\n", z_log_minimal_level_to_char(_level), ## __VA_ARGS__); } while (false)Z_LOG_CONST_LEVEL_CHECK(_level)(IS_ENABLED(CONFIG_LOG) && (Z_LOG_LEVEL_CHECK(_level, CONFIG_LOG_OVERRIDE_LEVEL, LOG_LEVEL_NONE) || ((IS_ENABLED(CONFIG_LOG_OVERRIDE_LEVEL) == false) && (_level <= __log_level) && (_level <= CONFIG_LOG_MAX_LEVEL) ) ))Z_LOG_LEVEL_CHECK(_level,_check_level,_default_level)(_level <= Z_LOG_RESOLVED_LEVEL(_check_level, _default_level))Z_LOG_STR(_level,__VA_ARGS__...)COND_CODE_1(UTIL_CAT(Z_LOG_FUNC_PREFIX_ ## _level), (Z_LOG_STR_WITH_PREFIX(__VA_ARGS__)), (__VA_ARGS__))Z_LOG_STR_WITH_PREFIX(__VA_ARGS__...)COND_CODE_0(NUM_VA_ARGS_LESS_1(_, ## __VA_ARGS__), ("%s", (const char *)__func__), (Z_LOG_STR_WITH_PREFIX2(__VA_ARGS__)))Z_LOG_STR_WITH_PREFIX2(__VA_ARGS__...)"%s: " GET_ARG_N(1, __VA_ARGS__), (const char *)__func__ COND_CODE_0(NUM_VA_ARGS_LESS_1(__VA_ARGS__), (), (, GET_ARGS_LESS_N(1, __VA_ARGS__)) )COND_CODE_1(CONFIG_LOG_FUNC_NAME_PREFIX_DBG, (1), (0))Z_LOG_FUNC_PREFIX_3UCOND_CODE_1(CONFIG_LOG_FUNC_NAME_PREFIX_INF, (1), (0))COND_CODE_1(CONFIG_LOG_FUNC_NAME_PREFIX_WRN, (1), (0))COND_CODE_1(CONFIG_LOG_FUNC_NAME_PREFIX_ERR, (1), (0))Z_LOG_FUNC_PREFIX_0ULOG_CURRENT_MODULE_ID()(__log_level != 0 ? log_const_source_id(__log_current_const_data) : 0U)_LOG_ZZZZ4U_LOG_YYYY,_LOG_ZZZZ4_LOG_ZZZZ3U_LOG_ZZZZ3_LOG_ZZZZ2U_LOG_ZZZZ2_LOG_ZZZZ1U_LOG_ZZZZ1Z_LOG_EVAL1(_eval_level,_iftrue,_iffalse)__COND_CODE(_LOG_ZZZZ ## _eval_level, _iftrue, _iffalse)Z_LOG_EVAL(_eval_level,_iftrue,_iffalse)Z_LOG_EVAL1(_eval_level, _iftrue, _iffalse)_LOG_XXXX4U_LOG_XXXX4_LOG_XXXX3U_LOG_XXXX3_LOG_XXXX2U_LOG_XXXX2_LOG_XXXX1U_LOG_XXXX1_LOG_XXXX0U_LOG_XXXX0Z_LOG_RESOLVED_LEVEL1(_level,_default)__COND_CODE(_LOG_XXXX ## _level, (_level), (_default))Z_LOG_RESOLVED_LEVEL(_level,_default)Z_LOG_RESOLVED_LEVEL1(_level, _default)LOG_FUNCTION_PREFIX_MASK(((uint32_t)IS_ENABLED(CONFIG_LOG_FUNC_NAME_PREFIX_ERR) << LOG_LEVEL_ERR) | ((uint32_t)IS_ENABLED(CONFIG_LOG_FUNC_NAME_PREFIX_WRN) << LOG_LEVEL_WRN) | ((uint32_t)IS_ENABLED(CONFIG_LOG_FUNC_NAME_PREFIX_INF) << LOG_LEVEL_INF) | ((uint32_t)IS_ENABLED(CONFIG_LOG_FUNC_NAME_PREFIX_DBG) << LOG_LEVEL_DBG))CONFIG_LOG_MAX_LEVELCONFIG_LOG_DEFAULT_LEVELZEPHYR_INCLUDE_LOGGING_LOG_CORE_H_/* ZEPHYR_INCLUDE_LOGGING_LOG_CORE_H_ *//**
 * @brief Writes a generic log message to the logging v2.
 *
 * @note This function is intended to be used when porting other log systems.
 *
 * @param level          Log level..
 * @param fmt            String to format.
 * @param ap             Pointer to arguments list.
 *//** @brief Dummy function to trigger log messages arguments type checking. *//** @brief Get index of the log source based on the address of the dynamic data
 *         associated with the source.
 *
 * @param data Address of the dynamic data.
 *
 * @return Source ID.
 *//** @brief Creates name of variable and section for runtime log data.
 *
 *  @param _name Name.
 *//** @brief Get index of the log source based on the address of the constant data
 *         associated with the source.
 *
 * @param data Address of the constant data.
 *
 * @return Source ID.
 *//** @brief Create message for logging printk-like string or a raw string.
 *
 * Part of printk string processing is appending of carriage return after any
 * new line character found in the string. If it is not desirable then @p _is_raw
 * can be set to 1 to indicate raw string. This information is stored in the source
 * field which is not used for its typical purpose in this case.
 *
 * @param _is_raw	Set to 1 to indicate raw string, set to 0 to indicate printk.
 * @param ...		Format string with arguments.
 *//** @brief Log level value used to indicate log entry that should not be
 *	   formatted (raw string).
 *//* Return aggregated (highest) level for all enabled backends, e.g. if there
 * are 3 active backends, one backend is set to get INF logs from a module and
 * two other backends are set for ERR, returned level is INF.
 *//** @brief Bit offset of a slot.
 *
 *  @param _id Slot ID.
 *//** @brief Slot mask. *//** @brief Number of slots in one word. *//** @brief Filter slot size. *//** @brief Number of bits used to encode log level. *//*****************************************************************************//****************** Filtering macros *****************************************//* For instance logging check instance specific static level *//** @internal
 * @brief Generic logging macro.
 *
 * It checks against static levels (resolved at compile timer), runtime levels
 * and modes and dispatch to relevant processing path.
 *
 * @param _level Log message severity level.
 *
 * @param _inst Set to 1 for instance specific log message. 0 otherwise.
 *
 * @param _source Pointer to static source descriptor object. NULL when runtime filtering
 * is enabled.
 *
 * @param _dsource Pointer to dynamic source descriptor. NULL when runtime filtering
 * is disabled.
 *
 * @param _data Hexdump data;
 *
 * @param _len Hexdump data length.
 *
 * @param ... String.
 *//****************** Macros for hexdump logging *******************************//* evaluated once when log is enabled.*//* Placed here to ensure that __VA_ARGS__ are*//* Arguments checker present but never evaluated.*//** @internal
 * @brief Generic logging macro.
 *
 * It checks against static levels (resolved at compile timer), runtime levels
 * and modes and dispatch to relevant processing path.
 *
 * @param _level Log message severity level.
 *
 * @param _inst Set to 1 for instance specific log message. 0 otherwise.
 *
 * @param _source Pointer to static source descriptor object. NULL when runtime filtering
 * is enabled.
 *
 * @param _dsource Pointer to dynamic source descriptor. NULL when runtime filtering
 * is disabled.
 *
 * @param ... String with arguments.
 *//****************** Macros for standard logging ******************************//****************** Definitions used by minimal logging *********************//**
 * @brief Handle optional injection of function name as the first argument.
 *
 * Additionally, macro is handling the empty message case.
 *//* Macro handles case when no format string is provided: e.g. LOG_DBG().
 * Handling of format string is deferred to the next level macro.
 *//**
 * @brief Macro for optional injection of function name as first argument of
 *	  formatted string. COND_CODE_0() macro is used to handle no arguments
 *	  case.
 *
 * The purpose of this macro is to prefix string literal with format specifier
 * for function name and inject function name as first argument. In order to
 * handle string with no arguments _LOG_Z_EVAL is used.
 *//* Set of defines that are set to 1 if function name prefix is enabled for given level. *//**
 *
 * @brief Macro for getting ID of current module.
 *//**
 * @brief Macro for conditional code generation if provided log level allows.
 *
 * Macro behaves similarly to standard \#if \#else \#endif clause. The
 * difference is that it is evaluated when used and not when header file is
 * included.
 *
 * @param _eval_level Evaluated level. If level evaluates to one of existing log
 *		      log level (1-4) then macro evaluates to _iftrue.
 * @param _iftrue     Code that should be inserted when evaluated to true. Note,
 *		      that parameter must be provided in brackets.
 * @param _iffalse    Code that should be inserted when evaluated to false.
 *		      Note, that parameter must be provided in brackets.
 *//** @brief Macro for returning local level value if defined or default.
 *
 * Check @ref IS_ENABLED macro for detailed explanation of the trick.
 *//* Id of local domain. *//* This header file keeps all macros and functions needed for creating logging
 * messages (macros like @ref LOG_ERR).
 */z_log_vprintkLOG_LEVEL_SET(level)static const uint32_t __log_level __unused = Z_LOG_RESOLVED_LEVEL(level, 0)LOG_MODULE_DECLARE(__VA_ARGS__...)extern const struct log_source_const_data Z_LOG_ITEM_CONST_DATA(GET_ARG_N(1, __VA_ARGS__)); extern struct log_source_dynamic_data LOG_ITEM_DYNAMIC_DATA(GET_ARG_N(1, __VA_ARGS__)); static const struct log_source_const_data * __log_current_const_data __unused = Z_DO_LOG_MODULE_REGISTER(__VA_ARGS__) ? &Z_LOG_ITEM_CONST_DATA(GET_ARG_N(1, __VA_ARGS__)) : NULL; static struct log_source_dynamic_data * __log_current_dynamic_data __unused = (Z_DO_LOG_MODULE_REGISTER(__VA_ARGS__) && IS_ENABLED(CONFIG_LOG_RUNTIME_FILTERING)) ? &LOG_ITEM_DYNAMIC_DATA(GET_ARG_N(1, __VA_ARGS__)) : NULL; static const uint32_t __log_level __unused = _LOG_LEVEL_RESOLVE(__VA_ARGS__)LOG_MODULE_REGISTER(__VA_ARGS__...)COND_CODE_1( Z_DO_LOG_MODULE_REGISTER(__VA_ARGS__), (_LOG_MODULE_DATA_CREATE(GET_ARG_N(1, __VA_ARGS__), _LOG_LEVEL_RESOLVE(__VA_ARGS__))), () ) LOG_MODULE_DECLARE(__VA_ARGS__)Z_DO_LOG_MODULE_REGISTER(__VA_ARGS__...)COND_CODE_1(CONFIG_LOG, (Z_LOG_EVAL(CONFIG_LOG_OVERRIDE_LEVEL, (1), (Z_LOG_EVAL(_LOG_LEVEL_RESOLVE(__VA_ARGS__), (1), (0))) )), (0))_LOG_MODULE_DATA_CREATE(_name,_level)_LOG_MODULE_CONST_DATA_CREATE(_name, _level); _LOG_MODULE_DYNAMIC_DATA_COND_CREATE(_name)_LOG_MODULE_DYNAMIC_DATA_COND_CREATE(_name)IF_ENABLED(CONFIG_LOG_RUNTIME_FILTERING, (_LOG_MODULE_DYNAMIC_DATA_CREATE(_name);))_LOG_MODULE_DYNAMIC_DATA_CREATE(_name)STRUCT_SECTION_ITERABLE_ALTERNATE(log_dynamic, log_source_dynamic_data, LOG_ITEM_DYNAMIC_DATA(_name))_LOG_MODULE_CONST_DATA_CREATE(_name,_level)IF_ENABLED(CONFIG_LOG_FMT_SECTION, ( static const char UTIL_CAT(_name, _str)[] __in_section(_log_strings, static, _CONCAT(_name, _)) __used __noasan = STRINGIFY(_name);)) IF_ENABLED(LOG_IN_CPLUSPLUS, (extern)) const STRUCT_SECTION_ITERABLE_ALTERNATE(log_const, log_source_const_data, Z_LOG_ITEM_CONST_DATA(_name)) = { .name = COND_CODE_1(CONFIG_LOG_FMT_SECTION, (UTIL_CAT(_name, _str)), (STRINGIFY(_name))), .level = _level }_LOG_ARG1(arg1,__VA_ARGS__...)_LOG_LEVEL_RESOLVE(__VA_ARGS__...)LOG_INST_HEXDUMP_DBG(_log_inst,_data,_length,_str)Z_LOG_HEXDUMP_INSTANCE(LOG_LEVEL_DBG, _log_inst, _data, _length, _str)LOG_INST_HEXDUMP_INF(_log_inst,_data,_length,_str)Z_LOG_HEXDUMP_INSTANCE(LOG_LEVEL_INF, _log_inst, _data, _length, _str)LOG_INST_HEXDUMP_WRN(_log_inst,_data,_length,_str)Z_LOG_HEXDUMP_INSTANCE(LOG_LEVEL_WRN, _log_inst, _data, _length, _str)LOG_INST_HEXDUMP_ERR(_log_inst,_data,_length,_str)Z_LOG_HEXDUMP_INSTANCE(LOG_LEVEL_ERR, _log_inst, _data, _length, _str)LOG_HEXDUMP_DBG(_data,_length,_str)Z_LOG_HEXDUMP(LOG_LEVEL_DBG, _data, _length, _str)LOG_HEXDUMP_INF(_data,_length,_str)Z_LOG_HEXDUMP(LOG_LEVEL_INF, _data, _length, _str)LOG_HEXDUMP_WRN(_data,_length,_str)Z_LOG_HEXDUMP(LOG_LEVEL_WRN, _data, _length, _str)LOG_HEXDUMP_ERR(_data,_length,_str)Z_LOG_HEXDUMP(LOG_LEVEL_ERR, _data, _length, _str)LOG_INST_DBG(_log_inst,__VA_ARGS__...)Z_LOG_INSTANCE(LOG_LEVEL_DBG, _log_inst, __VA_ARGS__)LOG_INST_INF(_log_inst,__VA_ARGS__...)Z_LOG_INSTANCE(LOG_LEVEL_INF, _log_inst, __VA_ARGS__)LOG_INST_WRN(_log_inst,__VA_ARGS__...)Z_LOG_INSTANCE(LOG_LEVEL_WRN, _log_inst, __VA_ARGS__)LOG_INST_ERR(_log_inst,__VA_ARGS__...)Z_LOG_INSTANCE(LOG_LEVEL_ERR, _log_inst, __VA_ARGS__)LOG_RAW(__VA_ARGS__...)Z_LOG_PRINTK(1, __VA_ARGS__)LOG_PRINTK(__VA_ARGS__...)Z_LOG_PRINTK(0, __VA_ARGS__)LOG_DBG(__VA_ARGS__...)Z_LOG(LOG_LEVEL_DBG, __VA_ARGS__)LOG_INF(__VA_ARGS__...)Z_LOG(LOG_LEVEL_INF, __VA_ARGS__)LOG_WRN(__VA_ARGS__...)Z_LOG(LOG_LEVEL_WRN, __VA_ARGS__)LOG_ERR(__VA_ARGS__...)Z_LOG(LOG_LEVEL_ERR, __VA_ARGS__)ZEPHYR_INCLUDE_LOGGING_LOG_H_!defined(CONFIG_LOG)CONFIG_LOG_CUSTOM_HEADERdefined(__CDT_PARSER__) || defined(__JETBRAINS_IDE__)/* ZEPHYR_INCLUDE_LOGGING_LOG_H_ *//*
 * Eclipse CDT or JetBrains Clion parser is sometimes confused by logging API
 * code and freezes the whole IDE. Following lines hides LOG_x macros from them.
 *//* This include must always be at the end of log.h *//**
 * @brief Macro for setting log level in the file or function where instance
 * logging API is used.
 *
 * @param level Level used in file or in function.
 *
 *//**
 * @brief Macro for declaring a log module (not registering it).
 *
 * Modules which are split up over multiple files must have exactly
 * one file use LOG_MODULE_REGISTER() to create module-specific state
 * and register the module with the logger core.
 *
 * The other files in the module should use this macro instead to
 * declare that same state. (Otherwise, LOG_INF() etc. will not be
 * able to refer to module-specific state variables.)
 *
 * Macro accepts one or two parameters:
 * - module name
 * - optional log level. If not provided then default log level is used in
 *  the file.
 *
 * Example usage:
 * - LOG_MODULE_DECLARE(foo, CONFIG_FOO_LOG_LEVEL)
 * - LOG_MODULE_DECLARE(foo)
 *
 * @note The module's state is declared only if LOG_LEVEL for the
 *       current source file is non-zero or it is not defined and
 *       CONFIG_LOG_DEFAULT_LEVEL is non-zero.  In other cases,
 *       this macro has no effect.
 * @see LOG_MODULE_REGISTER
 *//**
 * @brief Create module-specific state and register the module with Logger.
 *
 * This macro normally must be used after including <zephyr/logging/log.h> to
 * complete the initialization of the module.
 *
 * Module registration can be skipped in two cases:
 *
 * - The module consists of more than one file, and another file
 *   invokes this macro. (LOG_MODULE_DECLARE() should be used instead
 *   in all of the module's other files.)
 * - Instance logging is used and there is no need to create module entry. In
 *   that case LOG_LEVEL_SET() should be used to set log level used within the
 *   file.
 *
 * Macro accepts one or two parameters:
 * - module name
 * - optional log level. If not provided then default log level is used in
 *  the file.
 *
 * Example usage:
 * - LOG_MODULE_REGISTER(foo, CONFIG_FOO_LOG_LEVEL)
 * - LOG_MODULE_REGISTER(foo)
 *
 *
 * @note The module's state is defined, and the module is registered,
 *       only if LOG_LEVEL for the current source file is non-zero or
 *       it is not defined and CONFIG_LOG_DEFAULT_LEVEL is non-zero.
 *       In other cases, this macro has no effect.
 * @see LOG_MODULE_DECLARE
 *//* Determine if data for the module shall be created. It is created if logging
 * is enabled, override level is set or module specific level is set (not off).
 *//* Return first argument *//* Macro expects that optionally on second argument local log level is provided.
 * If provided it is returned, otherwise default log level is returned or
 * LOG_LEVEL, if it was locally defined.
 *//**
 * @brief Writes an formatted string to the log.
 *
 * @details Conditionally compiled (see CONFIG_LOG_PRINTK). Function provides
 * printk functionality.
 *
 * It is less efficient compared to standard logging because static packaging
 * cannot be used.
 *
 * @param fmt Formatted string to output.
 * @param ap  Variable parameters.
 *//**
 * @brief Writes a DEBUG level hexdump message associated with the instance to
 *        the log.
 *
 * @details It's meant to write developer oriented information.
 *
 * @param _log_inst   Pointer to the log structure associated with the instance.
 * @param _data       Pointer to the data to be logged.
 * @param _length     Length of data (in bytes).
 * @param _str        Persistent, raw string.
 *//**
 * @brief Writes an INFO level hexdump message associated with the instance to
 *        the log.
 *
 * @details It's meant to write generic user oriented messages.
 *
 * @param _log_inst   Pointer to the log structure associated with the instance.
 * @param _data       Pointer to the data to be logged.
 * @param _length     Length of data (in bytes).
 * @param _str        Persistent, raw string.
 *//**
 * @brief Writes a WARNING level hexdump message associated with the instance to
 *        the log.
 *
 * @details It's meant to register messages related to unusual situations that
 * are not necessarily errors.
 *
 * @param _log_inst   Pointer to the log structure associated with the instance.
 * @param _data       Pointer to the data to be logged.
 * @param _length     Length of data (in bytes).
 * @param _str        Persistent, raw string.
 *//**
 * @brief Writes an ERROR hexdump message associated with the instance to the
 *        log.
 *
 * Message is associated with specific instance of the module which has
 * independent filtering settings (if runtime filtering is enabled) and
 * message prefix (\<module_name\>.\<instance_name\>). It's meant to report
 * severe errors, such as those from which it's not possible to recover.
 *
 * @param _log_inst   Pointer to the log structure associated with the instance.
 * @param _data       Pointer to the data to be logged.
 * @param _length     Length of data (in bytes).
 * @param _str        Persistent, raw string.
 *//**
 * @brief Writes a DEBUG level message to the log.
 *
 * @details It's meant to write developer oriented information.
 *
 * @param _data   Pointer to the data to be logged.
 * @param _length Length of data (in bytes).
 * @param _str    Persistent, raw string.
 *//**
 * @brief Writes an INFO level message to the log.
 *
 * @details It's meant to write generic user oriented messages.
 *
 * @param _data   Pointer to the data to be logged.
 * @param _length Length of data (in bytes).
 * @param _str    Persistent, raw string.
 *//**
 * @brief Writes a WARNING level message to the log.
 *
 * @details It's meant to register messages related to unusual situations that
 * are not necessarily errors.
 *
 * @param _data   Pointer to the data to be logged.
 * @param _length Length of data (in bytes).
 * @param _str    Persistent, raw string.
 *//**
 * @brief Writes an ERROR level hexdump message to the log.
 *
 * @details It's meant to report severe errors, such as those from which it's
 * not possible to recover.
 *
 * @param _data   Pointer to the data to be logged.
 * @param _length Length of data (in bytes).
 * @param _str    Persistent, raw string.
 *//**
 * @brief Writes a DEBUG level message associated with the instance to the log.
 *
 * Message is associated with specific instance of the module which has
 * independent filtering settings (if runtime filtering is enabled) and
 * message prefix (\<module_name\>.\<instance_name\>). It's meant to write
 * developer oriented information.
 *
 * @param _log_inst Pointer to the log structure associated with the instance.
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Writes an INFO level message associated with the instance to the log.
 *
 * Message is associated with specific instance of the module which has
 * independent filtering settings (if runtime filtering is enabled) and
 * message prefix (\<module_name\>.\<instance_name\>). It's meant to write
 * generic user oriented messages.
 *
 * @param _log_inst Pointer to the log structure associated with the instance.
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Writes a WARNING level message associated with the instance to the
 *        log.
 *
 * Message is associated with specific instance of the module which has
 * independent filtering settings (if runtime filtering is enabled) and
 * message prefix (\<module_name\>.\<instance_name\>). It's meant to register
 * messages related to unusual situations that are not necessarily errors.
 *
 * @param _log_inst Pointer to the log structure associated with the instance.
 * @param ...       A string optionally containing printk valid conversion
 *                  specifier, followed by as many values as specifiers.
 *//**
 * @brief Writes an ERROR level message associated with the instance to the log.
 *
 * Message is associated with specific instance of the module which has
 * independent filtering settings (if runtime filtering is enabled) and
 * message prefix (\<module_name\>.\<instance_name\>). It's meant to report
 * severe errors, such as those from which it's not possible to recover.
 *
 * @param _log_inst Pointer to the log structure associated with the instance.
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Unconditionally print raw log message.
 *
 * Provided string is printed as is without appending any characters (e.g., color or newline).
 *
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Unconditionally print raw log message.
 *
 * The result is same as if printk was used but it goes through logging
 * infrastructure thus utilizes logging mode, e.g. deferred mode.
 *
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Writes a DEBUG level message to the log.
 *
 * @details It's meant to write developer oriented information.
 *
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Writes an INFO level message to the log.
 *
 * @details It's meant to write generic user oriented messages.
 *
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Writes a WARNING level message to the log.
 *
 * @details It's meant to register messages related to unusual situations that
 * are not necessarily errors.
 *
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Writes an ERROR level message to the log.
 *
 * @details It's meant to report severe errors, such as those from which it's
 * not possible to recover.
 *
 * @param ... A string optionally containing printk valid conversion specifier,
 * followed by as many values as specifiers.
 *//**
 * @brief Logger API
 * @defgroup log_api Logging API
 * @ingroup logger
 * @{
 *//**
 * @brief Logging
 * @defgroup logging Logging
 * @ingroup os_services
 * @{
 * @}
 *//home/haojie/zephyrproject/zephyr/include/zephyr/llext/symbol.hllext_symtablellext_symbolllext_const_symbolllext_symbol *symssym_cntconst void *constEXPORT_SYMBOL(x)static const STRUCT_SECTION_ITERABLE(llext_const_symbol, x ## _sym) = { .name = STRINGIFY(x), .addr = x, }ZEPHYR_LLEXT_SYMBOL_H/* ZEPHYR_LLEXT_SYMBOL_H *//**
 * @brief Export a constant symbol to a table of symbols
 *
 * Takes a symbol (function or object) by symbolic name and adds the name
 * and address of the symbol to a table of symbols that may be used for linking.
 *
 * @param x Symbol to export
 *//** Array of symbols *//** Number of symbols in the table *//**
 * @brief A symbol table
 *
 * An array of symbols
 *//** Address of symbol *//** Name of symbol *//**
 * @brief Symbols are named memory addresses
 *
 * Symbols may be named function or global objects that have been exported
 * for linking. These are mutable and should come from extensions where
 * the location may need updating depending on where memory is placed.
 *//**
 * @brief Constant symbols are unchangeable named memory addresses
 *
 * Symbols may be named function or global objects that have been exported
 * for linking. These constant symbols are useful in the base image
 * as they may be placed in ROM.
 *//**
 * @brief Linkable loadable extension symbol
 * @defgroup llext_symbols LLEXT symbols
 * @ingroup llext
 * @{
 *//home/haojie/zephyrproject/zephyr/include/zephyr/llext/home/haojie/zephyrproject/zephyr/lib/os/printk.c<zephyr/llext/symbol.h>CONFIG_LOG_PRINTK_XXXXCONFIG_LOG_PRINTK_XXXXCONFIG_LOG_PRINTK 1(int(*)(char, FILE *))buf_char_out(int(*)(char, FILE *))char_outbuf_out_context *consolechar_outbuf_char_outchar[0]CONFIG_PRINTK_BUFFER_SIZEbuf_flush__printk_get_hookbuf_out_contextbuf_countconst llext_const_symbolprintk_sym._llext_const_symbol.static.printk_sym_struct llext_const_symbol_llext_const_symbol_CONCAT(printk_sym, _)printk_sym__char_outdefined(CONFIG_PRINTK_SYNC)CONFIG_PRINTK_SYNC__alignof(struct llext_const_symbol)/* defined(CONFIG_PRINTK) *//**
 * @brief Output a string
 *
 * Output a string on output installed by platform at init time. Some
 * printf-like formatting is available.
 *
 * Available formatting:
 * - %x/%X:  outputs a number in hexadecimal format
 * - %s:     outputs a null-terminated string
 * - %p:     pointer, same as %x with a 0x prefix
 * - %u:     outputs a number in unsigned decimal format
 * - %d/%i:  outputs a number in signed decimal format
 *
 * Field width (with or without leading zeroes) is supported.
 * Length attributes h, hh, l, ll and z are supported. However, integral
 * values with %lld and %lli are only printed if they fit in a long
 * otherwise 'ERR' is printed. Full 64-bit values may be printed with %llx.
 *
 * @param fmt formatted string to output
 *//**
 * @brief Get the current character output routine for printk
 *
 * To be called by any console driver that would like to save
 * current hook - if any - for later re-installation.
 *
 * @return a function pointer or NULL if no hook is set
 *//**
 * @brief Install the character output routine for printk
 *
 * To be called by the platform's console driver at init time. Installs a
 * routine that outputs one ASCII character at a time.
 * @param fn putc routine to install
 *//* do nothing *//**
 * @brief Default character output routine that does nothing
 * @param c Character to swallow
 *
 * Note this is defined as a weak symbol, allowing architecture code
 * to override it where possible to enable very early logging.
 *
 * @return 0
 *//* Option present only when CONFIG_USERSPACE enabled. *//**
 * @file
 * @brief Low-level debug output
 *
 * Low-level debugging output. Platform installs a character output routine at
 * init time. If no routine is installed, a nop routine is called.
 *//*
 * Copyright (c) 2010, 2013-2014 Wind River Systems, Inc.
 *
 * SPDX-License-Identifier: Apache-2.0
 */ctx_p/home/haojie/zephyrproject/zephyr/lib/os/rb.cstack_left_limbrbnode *[]stackszstacksz0hiparentloparentnode2ctmpBLACKis_black(node) || is_black(child)"both nodes red?!"(get_child(node, 0U) == NULL) || (get_child(node, 1U) == NULL)fix_missing_blackis_black(n)sib(c0 && is_red(c0)) || (c1 && is_red(c1))is_red(outer)c1inneroutern_sidenull_nodeis_black(tree->root)fix_extra_red(get_child(node, 0U) == NULL) || is_black(get_child(node, 0U))(get_child(node, 1U) == NULL) || is_black(get_child(node, 1U))stacksz >= 2grandparentauntparent_siderotateget_sideget_child(parent, 0U) == child || get_child(parent, 1U) == childfind_and_stackchset_color~1ULis_redis_blackget_colorset_childnewget_childrb_colorCHECK(n)/* If we had no left tree and are a right child then our
	 * parent was already walked, so walk up the stack looking for
	 * a left child (whose parent is unwalked, and thus next).
	 *//* Otherwise if the node is a left child of its parent, the
	 * next node is the parent (note that the root is stacked
	 * above with is_left set to 0, so this condition still works
	 * even if node has no parent).
	 *//* The next child from a given node is the leftmost child of
	 * it's right subtree if it has a right child
	 *//* Initialization condition, pick the leftmost child of the
	 * root as our first node, initializing the stack on the way.
	 *//* The foreach tracking works via a dynamic stack allocated via
 * alloca().  The current node is found in stack[top] (and its parent
 * is thus stack[top-1]).  The side of each stacked node from its
 * parent is stored in is_left[] (i.e. if is_left[top] is true, then
 * node/stack[top] is the left child of stack[top-1]).  The special
 * case of top == -1 indicates that the stack is uninitialized and we
 * need to push an initial stack starting at the root.
 *//* Pushes the node and its chain of left-side children onto the stack
 * in the foreach struct, returning the last node, which is the next
 * node to iterate.  By construction node will always be a right child
 * or the root, so is_left must be false.
 *//* We may have rotated up into the root! *//* Check colors, if one was red (at least one must have been
		 * black in a valid tree), then we're done.
		 *//* Red childless nodes can just be dropped *//* Special case: if the node to be removed is childless, then
	 * we leave it in place while we do the missing black
	 * rotations, which will replace it with a proper NULL when
	 * they isolate it.
	 *//* Removing the root *//* Now swap the position of node/node2 in the tree.
		 * Design note: this is a spot where being an
		 * intrusive data structure hurts us fairly badly.
		 * The trees you see in textbooks do this by swapping
		 * the "data" pointers between the two nodes, but we
		 * have a few special cases to check.  In principle
		 * this works by swapping the child pointers between
		 * the nodes and retargeting the nodes pointing to
		 * them from their parents, but: (1) the upper node
		 * may be the root of the tree and not have a parent,
		 * and (2) the lower node may be a direct child of the
		 * upper node.  Remember to swap the color bits of the
		 * two nodes also.  And of course we don't have parent
		 * pointers, so the stack tracking this structure
		 * needs to be swapped too!
		 *//* We can only remove a node with zero or one child, if we
	 * have two then pick the "biggest" child of side 0 (smallest
	 * of 1 would work too) and swap our spot in the tree with
	 * that one
	 *//* Finally, the sibling must have a red child in the
		 * far/outer slot.  We can rotate sib with our parent
		 * and recolor to produce a valid tree.
		 *//* Restore stack state to have N on the top
			 * and make sib reflect the new sibling
			 *//* We know sibling has at least one red child.  Fix it
		 * so that the far/outer position (i.e. on the
		 * opposite side from N) is definitely red.
		 *//* Recoloring makes the whole tree OK *//* Balance the sibling's subtree by
				 * coloring it red, then our parent
				 * has a missing black so iterate
				 * upward
				 *//* Cases where the sibling has only black children
		 * have simple resolutions
		 *//* Guarantee the sibling is black, rotating N down a
		 * level if needed (after rotate() our parent is the
		 * child of our previous-sibling, so N is lower in the
		 * tree)
		 *//* Loop upward until we reach the root *//* Called for a node N (at the top of the stack) which after a
 * deletion operation is "missing a black" in its subtree.  By
 * construction N must be black (because if it was red it would be
 * trivially fixed by recoloring and we wouldn't be here).  Fixes up
 * the tree to preserve red/black rules.  The "null_node" pointer is
 * for situations where we are removing a childless black node.  The
 * tree munging needs a real node for simplicity, so we use it and
 * then clean it up (replace it with a simple NULL child in the
 * parent) when finished.
 *//* If we exit the loop, it's because our node is now the root,
	 * which must be black.
	 *//* Rotate the grandparent with parent, swapping colors *//* We can rotate locally to fix the whole tree.  First
		 * make sure that node is on the same side of parent
		 * as parent is of grandparent.
		 *//* We colored the grandparent red, which might
			 * have a red parent, so continue iterating
			 * from there.
			 *//* We are guaranteed to have a grandparent if our
		 * parent is red, as red nodes cannot be the root
		 *//* Correct child colors are a precondition of the loop *//* The node at the top of the provided stack is red, and its parent is
 * too.  Iteratively fix the tree so it becomes a valid red black tree
 * again
 *//* Swaps the position of the two nodes at the top of the provided
 * stack, modifying the stack accordingly. Does not change the color
 * of either node.  That is, it effects the following transition (or
 * its mirror if N is on the other side of P, of course):
 *
 *    P          N
 *  N  c  -->  a   P
 * a b            b c
 *
 *//* Searches the tree down to a node that is either identical with the
 * "node" argument or has an empty/leaf child pointer where "node"
 * should be, leaving all nodes found in the resulting stack.  Note
 * that tree must not be empty and that stack should be allocated to
 * contain at least tree->max_depth entries!  Returns the number of
 * entries pushed onto the stack.
 *//* #define CHECK(n) __ASSERT_NO_MSG(n) *//* These assertions are very useful when debugging the tree code
 * itself, but produce significant performance degradation as they are
 * checked many times per operation.  Leave them off unless you're
 * working on the rbtree code itself
 */colorsys_semkernel_semSYS_SEM_DEFINE(_name,_initial_count,_count_limit)STRUCT_SECTION_ITERABLE_ALTERNATE(k_sem, sys_sem, _name) = { .kernel_sem = Z_SEM_INITIALIZER(_name.kernel_sem, _initial_count, _count_limit) }; BUILD_ASSERT(((_count_limit) != 0) && ((_initial_count) <= (_count_limit)))ZEPHYR_INCLUDE_SYS_SEM_H_sys_sem_count_getsys_sem *sys_sem_takesys_sem_givesys_sem_init/**
 * @brief Get sys_sem's value
 *
 * This routine returns the current value of @a sem.
 *
 * @param sem Address of the sys_sem.
 *
 * @return Current value of sys_sem.
 *//**
 * @brief Take a sys_sem.
 *
 * This routine takes @a sem.
 *
 * @param sem Address of the sys_sem.
 * @param timeout Waiting period to take the sys_sem,
 *                or one of the special values K_NO_WAIT and K_FOREVER.
 *
 * @retval 0 sys_sem taken.
 * @retval -EINVAL Parameter address not recognized.
 * @retval -ETIMEDOUT Waiting period timed out.
 * @retval -EACCES Caller does not have enough access.
 *//**
 * @brief Give a semaphore.
 *
 * This routine gives @a sem, unless the semaphore is already at its
 * maximum permitted count.
 *
 * @param sem Address of the semaphore.
 *
 * @retval 0 Semaphore given.
 * @retval -EINVAL Parameter address not recognized.
 * @retval -EACCES Caller does not have enough access.
 * @retval -EAGAIN Count reached Maximum permitted count and try again.
 *//**
 * @brief Initialize a semaphore.
 *
 * This routine initializes a semaphore instance, prior to its first use.
 *
 * @param sem Address of the semaphore.
 * @param initial_count Initial semaphore count.
 * @param limit Maximum permitted semaphore count.
 *
 * @retval 0 Initial success.
 * @retval -EINVAL Bad parameters, the value of limit should be located in
 *         (0, INT_MAX] and initial_count shouldn't be greater than limit.
 *//* Stuff this in the section with the rest of the k_sem objects, since they
 * are identical and can be treated as a k_sem in the boot initialization code
 *//**
 * @brief Statically define and initialize a sys_sem
 *
 * The semaphore can be accessed outside the module where it is defined using:
 *
 * @code extern struct sys_sem <name>; @endcode
 *
 * Route this to memory domains using K_APP_DMEM().
 *
 * @param _name Name of the semaphore.
 * @param _initial_count Initial semaphore count.
 * @param _count_limit Maximum permitted semaphore count.
 *//**
 * @defgroup user_semaphore_apis User mode semaphore APIs
 * @ingroup kernel_apis
 * @{
 *//**
 * sys_sem structure
 *//*
 * sys_sem exists in user memory working as counter semaphore for
 * user mode thread when user mode enabled. When user mode isn't
 * enabled, sys_sem behaves like k_sem.
 *//**
 * @file
 *
 * @brief public sys_sem APIs.
 *//home/haojie/zephyrproject/zephyr/lib/os/sem.cret_value-116-ETIMEDOUTsys_csrand_getz_impl_sys_csrand_getsys_rand_getz_impl_sys_rand_getsys_rand32_getz_impl_sys_rand32_getZ_INCLUDE_SYSCALLS_RANDOM_H<syscalls/random.h>ZEPHYR_INCLUDE_RANDOM_RANDOM_H_/* ZEPHYR_INCLUDE_RANDOM_RANDOM_H_ *//**
 * @brief Fill the destination buffer with cryptographically secure
 * random data values.
 *
 * @note If the random values requested do not need to be cryptographically
 * secure then use sys_rand_get() instead.
 *
 * @param [out] dst destination buffer to fill.
 * @param len size of the destination buffer.
 *
 * @return 0 if success, -EIO if entropy reseed error
 *
 *//**
 * @brief Fill the destination buffer with random data values that should
 * pass general randomness tests.
 *
 * @note The random values returned are not considered cryptographically
 * secure random number values.
 *
 * @param [out] dst destination buffer to fill with random data.
 * @param len size of the destination buffer.
 *
 *//**
 * @brief Return a 32-bit random value that should pass general
 * randomness tests.
 *
 * @note The random value returned is not a cryptographically secure
 * random number value.
 *
 * @return 32-bit random value.
 *//**
 * @brief Random Function APIs
 * @defgroup random_api Random Function APIs
 * @ingroup crypto
 * @{
 *//**
 * @file
 * @brief Random number generator header file
 *
 * This header file declares prototypes for the kernel's random number
 * generator APIs.
 *
 * Typically, a platform enables the appropriate source for the random
 * number generation based on the hardware platform's capabilities or
 * (for testing purposes only) enables the TEST_RANDOM_GENERATOR
 * configuration option.
 *//*
 * Copyright (c) 2013-2014 Wind River Systems, Inc.
 * Copyright (c) 2023 Intel Corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/include/zephyr/random/home/haojie/zephyrproject/zephyr/lib/os/thread_entry.c/*
	 * Compiler can't tell that k_thread_abort() won't return and issues a
	 * warning unless we tell it that control never gets this far.
	 *//*
 * Common thread entry point function (used by all threads)
 *
 * This routine invokes the actual thread entry point function and passes
 * it three arguments. It also handles graceful termination of the thread
 * if the entry point function ever returns.
 *
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 *//* CONFIG_STACK_CANARIES_TLS *//**
 * @file
 * @brief Thread entry
 *
 * This file provides the common thread entry function
 */_MACHTIME_H_defined(__rtems__) || defined(__VISIUM__) || defined(__riscv)defined(__aarch64__) || defined(__arm__) || defined(__thumb__)/* _MACHTIME_H_ */timespectv_nsec_SYS__TIMESPEC_H_/* !_SYS__TIMESPEC_H_ *//* and nanoseconds *//*-
 * SPDX-License-Identifier: BSD-3-Clause
 *
 * Copyright (c) 1982, 1986, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@(#)time.h	8.5 (Berkeley) 5/4/95
 * from: FreeBSD: src/sys/sys/time.h,v 1.43 2000/03/20 14:09:05 phk Exp
 *	$FreeBSD: head/sys/sys/_timespec.h 326023 2017-11-20 19:43:44Z pfg $
 */itimerspec_SYS_TIMESPEC_H_/* _SYS_TIMESPEC_H_ *//*
 * Structure defined by POSIX.1b to be like a itimerval, but with
 * timespecs. Used in the timer_*() system calls.
 *//*-
 * Copyright (c) 1982, 1986, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@(#)time.h	8.5 (Berkeley) 5/4/95
 * from: FreeBSD: src/sys/sys/time.h,v 1.43 2000/03/20 14:09:05 phk Exp
 *	$FreeBSD$
 */<machine/time.h>tzsettm *localtime_rconst time_tconst time_t *const time_t *__restrict__tm *__restrict__gmtime_rctime_rasctime_rconst tmconst tm *const tm *__restrict__strftime_lstrftimelocaltimegmtimectimeasctimetimetime_t *mktimedifftimeclocktmtm_isdsttm_ydaytm_wdaytm_yeartm_montm_mdaytm_hourtm_mintm_secchar *[2]_tznameCLOCK_REALTIME((clockid_t) 1)TIMER_ABSTIMECLOCK_DISALLOWEDCLOCK_ALLOWEDCLOCK_DISABLEDCLOCK_ENABLEDtznameCLK_TCKCLOCKS_PER_SEC_CLOCKS_PER_SEC__TIME_H___TM_GMTOFF__TM_ZONE__BSD_VISIBLE || __SVID_VISIBLE || __GNU_VISIBLEHAVE_GETDATEdefined(_POSIX_TIMERS)defined(_POSIX_CLOCK_SELECTION)defined(_POSIX_CPUTIME)defined(_POSIX_THREAD_CPUTIME)defined(_POSIX_MONOTONIC_CLOCK)defined(_POSIX_CPUTIME) || defined(_POSIX_THREAD_CPUTIME)/* _TIME_H_ *//* _POSIX_CPUTIME or _POSIX_THREAD_CPUTIME *//* CPU-time Clock Attribute Access, P1003.4b/D8, p. 56 *//* _POSIX_CPUTIME *//* Accessing a Process CPU-time CLock, P1003.4b/D8, p. 55 *//*  The identifier for the system-wide monotonic clock, which is defined
 *  as a clock whose value cannot be set via clock_settime() and which
 *  cannot have backward clock jumps. *//*  When used in a clock or timer function call, this is interpreted as
    the identifier of the CPU_time clock associated with the THREAD
    making the function call.  *//* When used in a clock or timer function call, this is interpreted as
   the identifier of the CPU_time clock associated with the PROCESS
   making the function call.  *//* Manifest Constants, P1003.4b/D8, p. 55 *//* Manifest Constants, P1003.1b-1993, p. 262 *//* Flag indicating time is "absolute" with respect to the clock
   associated with a time.  Value 4 is historic. *//*   accessible. *//*   thread shall not have a CPU-time clock *//* If a thread is created with this value, the *//*   shall be accessible. *//*   CPU-time clock attached to that thread *//* If a thread is created with this value a *//* values for the pthread cputime_clock_allowed attribute *//* clock is disabled *//* clock is enabled, i.e. counting execution time *//* values for the clock enable attribute *//* CPU-time Clock Attributes, P1003.4b/D8, p. 54 *//* _POSIX_CLOCK_SELECTION *//* _POSIX_TIMERS *//* High Resolution Sleep, P1003.1b-1993, p. 269 *//* Per-Process Timers, P1003.1b-1993, p. 267 *//* Delete a Per_process Timer, P1003.1b-1993, p. 266 *//* Create a Per-Process Timer, P1003.1b-1993, p. 264 *//* Clocks, P1003.1b-1993, p. 263 *//*__CYGWIN__*//* __POSIX_VISIBLE *//* POSIX defines the external tzname being defined in time.h *//* defines for the opengroup specifications Derived from Issue 1 of the SVID.  *//* HAVE_GETDATE *//* __GNU_VISIBLE *//* getdate_r returns the error code as above *//* __XSI_VISIBLE >= 4 *//* !_REENT_ONLY *//* getdate_err is set to one of the following values to indicate the error.
     1  the DATEMSK environment variable is null or undefined,
     2  the template file cannot be opened for reading,
     3  failed to get file status information,
     4  the template file is not a regular file,
     5  an error is encountered while reading the template file,
     6  memory allication failed (not enough memory available),
     7  there is no line in the template that matches the input,
     8  invalid input specification  *//* getdate functions *//* Get _CLOCKS_PER_SEC_ *//*
 * time.h
 * 
 * Struct and function declarations for dealing with time.
 */_maxsize_t_timer_time_tblock_timeptr_time2_time1/home/haojie/zephyrproject/zephyr/include/zephyr/sys/timeutil.htimeutil_sync_statetimeutil_sync_instanttimeutil_sync_configskewlatestconst timeutil_sync_configconst timeutil_sync_config *timeutil_sync_config *localreflocal_Hzref_HzZEPHYR_INCLUDE_SYS_TIMEUTIL_H_timeutil_sync_skew_to_ppbtimeutil_sync_local_from_refconst timeutil_sync_stateconst timeutil_sync_state *timeutil_sync_state *timeutil_sync_ref_from_localtimeutil_sync_estimate_skewtimeutil_sync_state_set_skewconst timeutil_sync_instantconst timeutil_sync_instant *timeutil_sync_instant *timeutil_sync_state_updatetimeutil_timegmtimeutil_timegm64/* ZEPHYR_INCLUDE_SYS_TIMEUTIL_H_ *//**
 * @brief Convert from a skew to an error in parts-per-billion.
 *
 * A skew of 1.0 has zero error.  A skew less than 1 has a positive
 * error (clock is faster than it should be).  A skew greater than one
 * has a negative error (clock is slower than it should be).
 *
 * Note that due to the limited precision of @c float compared with @c
 * double the smallest error that can be represented is about 120 ppb.
 * A "precise" time source may have error on the order of 2000 ppb.
 *
 * A skew greater than 3.14748 may underflow the 32-bit
 * representation; this represents a clock running at less than 1/3
 * its nominal rate.
 *
 * @return skew error represented as parts-per-billion, or INT32_MIN
 * if the skew cannot be represented in the return type.
 *//**
 * @brief Interpolate a local timescale instant from a reference
 * instant.
 *
 * @param tsp pointer to a time synchronization state.  This must have a base
 * and a skew installed.
 *
 * @param ref an instant measured in the reference timescale.  This
 * may be before or after the base instant.
 *
 * @param localp where the corresponding instant in the local
 * timescale should be stored.  An interpolated value before local
 * time 0 is provided without error.  If interpolation fails the
 * referenced object is not modified.
 *
 * @retval 0 if successful with a skew of 1
 * @retval 1 if successful with a skew not equal to 1
 * @retval -EINVAL
 *   * the time synchronization state is not adequately initialized
 *   * @p refp is null
 *//**
 * @brief Interpolate a reference timescale instant from a local
 * instant.
 *
 * @param tsp pointer to a time synchronization state.  This must have a base
 * and a skew installed.
 *
 * @param local an instant measured in the local timescale.  This may
 * be before or after the base instant.
 *
 * @param refp where the corresponding instant in the reference
 * timescale should be stored.  A negative interpolated reference time
 * produces an error.  If interpolation fails the referenced object is
 * not modified.
 *
 * @retval 0 if interpolated using a skew of 1
 * @retval 1 if interpolated using a skew not equal to 1
 * @retval -EINVAL
 *   * the times synchronization state is not adequately initialized
 *   * @p refp is null
 * @retval -ERANGE the interpolated reference time would be negative
 *//**
 * @brief Estimate the skew based on current state.
 *
 * Using the base and latest syncpoints from the state determine the
 * skew of the local clock relative to the reference clock.  See
 * timeutil_sync_state::skew.
 *
 * @param tsp pointer to a time synchronization state.  The base and latest
 * syncpoints must be present and the latest syncpoint must be after
 * the base point in the local time scale.
 *
 * @return the estimated skew, or zero if skew could not be estimated.
 *//**
 * @brief Update the state with a new skew and possibly base value.
 *
 * Set the skew from a value retrieved from persistent storage, or
 * calculated based on recent skew estimations including from
 * timeutil_sync_estimate_skew().
 *
 * Optionally update the base timestamp.  If the base is replaced the
 * latest instant will be cleared until timeutil_sync_state_update() is
 * invoked.
 *
 * @param tsp pointer to a time synchronization state.
 *
 * @param skew the skew to be used.  The value must be positive and
 * shouldn't be too far away from 1.
 *
 * @param base optional new base to be set.  If provided this becomes
 * the base timestamp that will be used along with skew to convert
 * between reference and local timescale instants.  Setting the base
 * clears the captured latest value.
 *
 * @return 0 if skew was updated
 * @return -EINVAL if skew was not valid
 *//**
 * @brief Record a new instant in the time synchronization state.
 *
 * Note that this updates only the latest persisted instant.  The skew
 * is not adjusted automatically.
 *
 * @param tsp pointer to a timeutil_sync_state object.
 *
 * @param inst the new instant to be recorded.  This becomes the base
 * instant if there is no base instant, otherwise the value must be
 * strictly after the base instant in both the reference and local
 * time scales.
 *
 * @retval 0 if installation succeeded in providing a new base
 * @retval 1 if installation provided a new latest instant
 * @retval -EINVAL if the new instant is not compatible with the base instant
 *//** The scale factor used to correct for clock skew.
	 *
	 * The nominal rate for the local counter is assumed to be
	 * inaccurate but stable, i.e. it will generally be some
	 * parts-per-million faster or slower than specified.
	 *
	 * A duration in observed local clock ticks must be multiplied by
	 * this value to produce a duration in ticks of a clock operating at
	 * the nominal local rate.
	 *
	 * A zero value indicates that the skew has not been initialized.
	 * If the value is zero when #base is initialized the skew will be
	 * set to 1.  Otherwise the skew is assigned through
	 * timeutil_sync_state_set_skew().
	 *//** The most recent instant in both time scales.
	 *
	 * This is captured here to provide data for skew calculation.
	 *//** The base instant in both time scales. *//** Pointer to reference and local rate information. *//**
 * @brief State required to convert instants between time scales.
 *
 * This state in conjunction with functions that manipulate it capture
 * the offset information necessary to convert between two timescales
 * along with information that corrects for skew due to inaccuracies
 * in clock rates.
 *
 * State objects should be zero-initialized before use.
 *//** The corresponding instance in the local time scale.
	 *
	 * This may be zero in a valid timeutil_sync_instant object.
	 *//** An instant in the reference time scale.
	 *
	 * This must never be zero in an initialized timeutil_sync_instant
	 * object.
	 *//**
 * @brief Representation of an instant in two time scales.
 *
 * Capturing the same instant in two time scales provides a
 * registration point that can be used to convert between those time
 * scales.
 *//** The nominal local counter rate in Hz.
	 *
	 * This value is assumed to be inaccurate but reasonably stable.  For
	 * a local clock driven by a crystal oscillator an error of 25 ppm is
	 * common; for an RC oscillator larger errors should be expected.  The
	 * timeutil_sync infrastructure can calculate the skew between the
	 * local and reference clocks and apply it when converting between
	 * time scales.
	 *
	 * The value must be positive.
	 *//** The nominal instance counter rate in Hz.
	 *
	 * This value is assumed to be precise, but may drift depending on
	 * the reference clock source.
	 *
	 * The value must be positive.
	 *//**
 * @brief Immutable state for synchronizing two clocks.
 *
 * Values required to convert durations between two time scales.
 *
 * @note The accuracy of the translation and calculated skew between sources
 * depends on the resolution of these frequencies.  A reference frequency with
 * microsecond or nanosecond resolution would produce the most accurate
 * tracking when the local reference is the Zephyr tick counter.  A reference
 * source like an RTC chip with 1 Hz resolution requires a much larger
 * interval between sampled instants to detect relative clock drift.
 *//**
 * @}
 * @defgroup timeutil_sync_apis Time Synchronization APIs
 * @ingroup timeutil_apis
 * @{
 *//**
 * @brief Convert broken-down time to a POSIX epoch offset in seconds.
 *
 * @param tm pointer to broken down time.
 *
 * @return the corresponding time in the POSIX epoch time scale.  If
 * the time cannot be represented then @c (time_t)-1 is returned and
 * @c errno is set to @c ERANGE`.
 *
 * @see http://man7.org/linux/man-pages/man3/timegm.3.html
 *//**
 * @brief Convert broken-down time to a POSIX epoch offset in seconds.
 *
 * @param tm pointer to broken down time.
 *
 * @return the corresponding time in the POSIX epoch time scale.
 *
 * @see http://man7.org/linux/man-pages/man3/timegm.3.html
 *//**
 * @defgroup timeutil_apis Time Utility APIs
 * @ingroup utilities
 * @defgroup timeutil_repr_apis Time Representation APIs
 * @ingroup timeutil_apis
 * @{
 *//**
 * @file
 * @brief Utilities supporting operation on time data structures.
 *
 * POSIX defines gmtime() to convert from time_t to struct tm, but all
 * inverse transformations are non-standard or require access to time
 * zone information.  timeutil_timegm() implements the functionality
 * of the GNU extension timegm() function, but changes the error value
 * as @c EOVERFLOW is not a standard C error identifier.
 *
 * timeutil_timegm64() is provided to support full precision
 * conversion on platforms where @c time_t is limited to 32 bits.
 *//*
 * Copyright (c) 2019 Peter Bigot Consulting, LLC
 *
 * SPDX-License-Identifier: Apache-2.0
 */tsplocalprefpinst/home/haojie/zephyrproject/zephyr/lib/os/timeutil.c<zephyr/sys/timeutil.h>ppb641.01000000000.01E9ppb32ref_deltalocal_deltalocal_abs1.0fref_abs-34-ERANGEsizeof(rv)sizeof(int32_t)sizeof(rv) == sizeof(int32_t)(sizeof(rv) == sizeof(int32_t))(int64_t)INT32_MIN(int64_t)INT32_MAXyndays60LL8640086400LLtime_days_from_civilerayoedoy153Udoe365U100U146097719468/* (x / 1.0) != x for large values of x.
		 * Therefore only apply the division if the skew is not one.
		 *//* (x * 1.0) != x for large values of x.
		 * Therefore only apply the multiplication if the skew is not one.
		 *//** Convert a civil (proleptic Gregorian) date to days relative to
 * 1970-01-01.
 *
 * @param y the calendar year
 * @param m the calendar month, in the range [1, 12]
 * @param d the day of the month, in the range [1, last_day_of_month(y, m)]
 *
 * @return the signed number of days between the specified day and
 * 1970-01-01
 *
 * @see http://howardhinnant.github.io/date_algorithms.html#days_from_civil
 *//*
 * The time_days_from_civil function is derived directly from public
 * domain content written by Howard Hinnant and available at:
 * http://howardhinnant.github.io/date_algorithms.html#days_from_civil
 *//home/haojie/zephyrproject/zephyr/misc/empty_file.c/home/haojie/zephyrproject/zephyr/misc/home/haojie/zephyrproject/zephyr/samples/hello_world/src/main.cHello World! %s
"Hello World! %s\n"char[17]qemu_x86/home/haojie/zephyrproject/zephyr/samples/hello_world/src/home/haojie/zephyrproject/zephyr/samples/hello_world/home/haojie/zephyrproject/zephyr/samples/home/haojie/zephyrproject/zephyr/subsys/random/rand32_timer.cudstblocksizeoutlensizeof(ret)(void *)udst&retrand32_lock/**
 * @brief Fill destination buffer with random numbers
 *
 * The pseudo-random number generator returns values that are based off the
 * target's clock counter, which means that successive calls will return
 * different values.
 *
 * @param dst destination buffer to fill
 * @param outlen size of destination buffer to fill
 *//* initial seed value *//**
 * @brief Get a 32 bit random number
 *
 * This pseudo-random number generator returns values that are based off the
 * target's clock counter, which means that successive calls will return
 * different values.
 *
 * @return a 32-bit number
 *//**
 * @file
 * @brief Non-random number generator based on system timer
 *
 * This module provides a non-random implementation of sys_rand32_get(), which
 * is not meant to be used in a final product as a truly random number
 * generator. It was provided to allow testing on a platform that does not (yet)
 * provide a random number generator.
 *//home/haojie/zephyrproject/zephyr/subsys/random/home/haojie/zephyrproject/zephyr/subsys/home/haojie/zephyrproject/zephyr/subsys/tracing/tracing_none.c/*
 * Copyright (c) 2019 Intel corporation
 *
 * SPDX-License-Identifier: Apache-2.0
 *//home/haojie/zephyrproject/zephyr/subsys/tracing/home/haojie/test/codeql/cpp/tools/linux64/extractor--mimic/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/libexec/gcc/x86_64-zephyr-elf/12.2.0/cc1-quiet-I-imultilib32/soft-float-iprefix/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/bin/../lib/gcc/x86_64-zephyr-elf/12.2.0/-isysroot/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/x86_64-zephyr-elf-MDzephyr/CMakeFiles/zephyr.dir/lib/os/printk.c.d-MFzephyr/CMakeFiles/zephyr.dir/lib/os/printk.c.obj.d-MTzephyr/CMakeFiles/zephyr.dir/lib/os/printk.c.obj-isystem/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/bin/../lib/gcc/../../picolibc/include-DKERNELPICOLIBC_INTEGER_PRINTF_SCANF_FORTIFY_SOURCE=1_POSIX_C_SOURCE=200809__ZEPHYR__=1-imacros-ftls-model=local-exec-dumpdirzephyr/CMakeFiles/zephyr.dir/lib/os/-dumpbaseprintk.c.c-dumpbase-ext.c-m32-msoft-float-mpreferred-stack-boundary=2-mno-mmx-mno-sse-mtune=i586-march=i586-g-gdwarf-4-Os-Wall-Wformat=1-Wformat-security-Wno-format-zero-length-Wno-pointer-sign-Wpointer-arith-Wexpansion-to-defined-Wno-unused-but-set-variable-Werror=implicit-int-std=c99-fdiagnostics-color=always-fno-strict-aliasing-fno-printf-return-value-fno-common-fno-pie-fno-asynchronous-unwind-tables-fno-reorder-functions-fno-defer-pop-fmacro-prefix-map=/home/haojie/zephyrproject/zephyr/samples/hello_world=CMAKE_SOURCE_DIR-fmacro-prefix-map=/home/haojie/zephyrproject/zephyr=ZEPHYR_BASE-fmacro-prefix-map=/home/haojie/zephyrproject=WEST_TOPDIR-ffunction-sections-fdata-sections--param=min-pagesize=0-o/tmp/ccZff56q.szephyr/kernel/CMakeFiles/kernel.dir/errno.c.dzephyr/kernel/CMakeFiles/kernel.dir/errno.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/errno.c.obj__ZEPHYR_SUPERVISOR__zephyr/kernel/CMakeFiles/kernel.dir/errno.c.c-Wshadow/tmp/ccr7RPhM.szephyr/kernel/CMakeFiles/kernel.dir/banner.c.dzephyr/kernel/CMakeFiles/kernel.dir/banner.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/banner.c.objbanner.c.c/tmp/ccOqcPuW.szephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_ioapic.c.dzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_ioapic.c.obj.dzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_ioapic.c.objzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_ioapic.c.c/tmp/cc2DEIHG.szephyr/kernel/CMakeFiles/kernel.dir/msg_q.c.dzephyr/kernel/CMakeFiles/kernel.dir/msg_q.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/msg_q.c.objmsg_q.c.c/tmp/ccwM940c.szephyr/CMakeFiles/offsets.dir/arch/x86/core/offsets/offsets.c.dzephyr/CMakeFiles/offsets.dir/arch/x86/core/offsets/offsets.c.obj.dzephyr/CMakeFiles/offsets.dir/arch/x86/core/offsets/offsets.c.objzephyr/CMakeFiles/offsets.dir/arch/x86/core/offsets/offsets.c.c/tmp/ccXUJnrZ.szephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/abort.c.dzephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/abort.c.obj.dzephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/abort.c.objzephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/abort.c.c/tmp/ccAOPGYI.szephyr/kernel/CMakeFiles/kernel.dir/mutex.c.dzephyr/kernel/CMakeFiles/kernel.dir/mutex.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/mutex.c.objmutex.c.c/tmp/ccVQOlIv.sCMakeFiles/app.dir/src/main.c.dCMakeFiles/app.dir/src/main.c.obj.dCMakeFiles/app.dir/src/main.c.objCMakeFiles/app.dir/src/main.c.c/tmp/ccvBQ8NS.szephyr/kernel/CMakeFiles/kernel.dir/mmu.c.dzephyr/kernel/CMakeFiles/kernel.dir/mmu.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/mmu.c.objmmu.c.c/tmp/ccZupNTD.szephyr/CMakeFiles/zephyr.dir/subsys/tracing/tracing_none.c.dzephyr/CMakeFiles/zephyr.dir/subsys/tracing/tracing_none.c.obj.dzephyr/CMakeFiles/zephyr.dir/subsys/tracing/tracing_none.c.objzephyr/CMakeFiles/zephyr.dir/subsys/tracing/tracing_none.c.c/tmp/ccHat4PM.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/x86_mmu.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/x86_mmu.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/x86_mmu.c.objzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/x86_mmu.c.c/tmp/cceDKMXo.szephyr/kernel/CMakeFiles/kernel.dir/system_work_q.c.dzephyr/kernel/CMakeFiles/kernel.dir/system_work_q.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/system_work_q.c.objsystem_work_q.c.c/tmp/ccuxKzmN.szephyr/drivers/console/CMakeFiles/drivers__console.dir/uart_console.c.dzephyr/drivers/console/CMakeFiles/drivers__console.dir/uart_console.c.obj.dzephyr/drivers/console/CMakeFiles/drivers__console.dir/uart_console.c.objzephyr/drivers/console/CMakeFiles/drivers__console.dir/uart_console.c.c/tmp/cc24VOGf.szephyr/kernel/CMakeFiles/kernel.dir/mempool.c.dzephyr/kernel/CMakeFiles/kernel.dir/mempool.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/mempool.c.objmempool.c.c/tmp/ccmohkhq.szephyr/kernel/CMakeFiles/kernel.dir/busy_wait.c.dzephyr/kernel/CMakeFiles/kernel.dir/busy_wait.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/busy_wait.c.objbusy_wait.c.c/tmp/ccVTJ9mG.szephyr/kernel/CMakeFiles/kernel.dir/fatal.c.dzephyr/kernel/CMakeFiles/kernel.dir/fatal.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/fatal.c.objfatal.c.c/tmp/ccSgZFpl.szephyr/kernel/CMakeFiles/kernel.dir/device.c.dzephyr/kernel/CMakeFiles/kernel.dir/device.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/device.c.objdevice.c.c/tmp/ccRqoeOs.szephyr/CMakeFiles/zephyr.dir/lib/os/bitarray.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/bitarray.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/bitarray.c.objbitarray.c.c/tmp/ccS1RJht.szephyr/CMakeFiles/zephyr.dir/misc/generated/configs.c.dzephyr/CMakeFiles/zephyr.dir/misc/generated/configs.c.obj.dzephyr/CMakeFiles/zephyr.dir/misc/generated/configs.c.objzephyr/CMakeFiles/zephyr.dir/misc/generated/configs.c.c/tmp/ccA3oyTm.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/multiboot.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/multiboot.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/multiboot.c.objmultiboot.c.c/tmp/ccgJU309.szephyr/kernel/CMakeFiles/kernel.dir/mem_slab.c.dzephyr/kernel/CMakeFiles/kernel.dir/mem_slab.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/mem_slab.c.objmem_slab.c.c/tmp/ccSeEYYQ.szephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_loapic.c.dzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_loapic.c.obj.dzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_loapic.c.objintc_loapic.c.c/tmp/ccd8hTCm.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/tls.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/tls.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/tls.c.objzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/tls.c.c/tmp/ccIdWjmy.szephyr/CMakeFiles/zephyr.dir/lib/os/timeutil.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/timeutil.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/timeutil.c.objtimeutil.c.c/tmp/ccnHKmYl.szephyr/drivers/serial/CMakeFiles/drivers__serial.dir/uart_ns16550.c.dzephyr/drivers/serial/CMakeFiles/drivers__serial.dir/uart_ns16550.c.obj.dzephyr/drivers/serial/CMakeFiles/drivers__serial.dir/uart_ns16550.c.objzephyr/drivers/serial/CMakeFiles/drivers__serial.dir/uart_ns16550.c.c/tmp/ccQQXK63.szephyr/CMakeFiles/zephyr.dir/lib/os/multi_heap.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/multi_heap.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/multi_heap.c.objmulti_heap.c.c/tmp/ccAcjtSv.szephyr/CMakeFiles/zephyr.dir/lib/os/assert.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/assert.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/assert.c.objassert.c.c/tmp/ccn0S6cn.szephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/malloc.c.dzephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/malloc.c.obj.dzephyr/lib/libc/common/CMakeFiles/lib__libc__common.dir/source/stdlib/malloc.c.objmalloc.c.c/tmp/cc0fOtRX.szephyr/drivers/timer/CMakeFiles/drivers__timer.dir/sys_clock_init.c.dzephyr/drivers/timer/CMakeFiles/drivers__timer.dir/sys_clock_init.c.obj.dzephyr/drivers/timer/CMakeFiles/drivers__timer.dir/sys_clock_init.c.objzephyr/drivers/timer/CMakeFiles/drivers__timer.dir/sys_clock_init.c.c/tmp/cc86qb8G.szephyr/kernel/CMakeFiles/kernel.dir/timeout.c.dzephyr/kernel/CMakeFiles/kernel.dir/timeout.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/timeout.c.objtimeout.c.c/tmp/cchoP6Zh.szephyr/CMakeFiles/zephyr.dir/lib/os/cbprintf_packaged.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/cbprintf_packaged.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/cbprintf_packaged.c.objcbprintf_packaged.c.c/tmp/ccGKJiTz.szephyr/kernel/CMakeFiles/kernel.dir/queue.c.dzephyr/kernel/CMakeFiles/kernel.dir/queue.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/queue.c.objqueue.c.c/tmp/ccSxqUVI.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/cpuid.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/cpuid.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/cpuid.c.objcpuid.c.c/tmp/ccHSbwjP.sCMakeCCompilerId.ca-/tmp/ccNTgtEH.szephyr/CMakeFiles/zephyr.dir/lib/os/thread_entry.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/thread_entry.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/thread_entry.c.objthread_entry.c.c/tmp/cc15slzY.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/soft_float_stubs.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/soft_float_stubs.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/soft_float_stubs.c.objsoft_float_stubs.c.c/tmp/cc8gyNdC.szephyr/kernel/CMakeFiles/kernel.dir/init.c.dzephyr/kernel/CMakeFiles/kernel.dir/init.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/init.c.objinit.c.c/tmp/ccEqYnEc.szephyr/CMakeFiles/zephyr.dir/lib/os/rb.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/rb.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/rb.c.objrb.c.c/tmp/ccb1sDR7.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/tls.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/tls.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/tls.c.obj/tmp/ccDIicbC.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/irq_manage.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/irq_manage.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/irq_manage.c.objirq_manage.c.c/tmp/cc9yDyyn.szephyr/CMakeFiles/zephyr.dir/lib/os/hex.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/hex.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/hex.c.objhex.c.c/tmp/cc4vq7xV.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/cpuhalt.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/cpuhalt.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/cpuhalt.c.objcpuhalt.c.c/tmp/ccYoiUNx.szephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_system_apic.c.dzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_system_apic.c.obj.dzephyr/drivers/interrupt_controller/CMakeFiles/drivers__interrupt_controller.dir/intc_system_apic.c.objintc_system_apic.c.c/tmp/ccY1CEzE.szephyr/lib/libc/picolibc/CMakeFiles/lib__libc__picolibc.dir/libc-hooks.c.dzephyr/lib/libc/picolibc/CMakeFiles/lib__libc__picolibc.dir/libc-hooks.c.obj.dzephyr/lib/libc/picolibc/CMakeFiles/lib__libc__picolibc.dir/libc-hooks.c.objzephyr/lib/libc/picolibc/CMakeFiles/lib__libc__picolibc.dir/libc-hooks.c.c/tmp/ccPW4uyT.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/early_serial.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/early_serial.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/early_serial.c.objearly_serial.c.c/tmp/ccj4Alxc.szephyr/kernel/CMakeFiles/kernel.dir/version.c.dzephyr/kernel/CMakeFiles/kernel.dir/version.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/version.c.objversion.c.c/tmp/ccbXQFtH.szephyr/CMakeFiles/zephyr.dir/lib/os/cbprintf_complete.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/cbprintf_complete.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/cbprintf_complete.c.objcbprintf_complete.c.c/tmp/ccEfxW8h.szephyr/CMakeFiles/zephyr_final.dir/misc/empty_file.c.dzephyr/CMakeFiles/zephyr_final.dir/misc/empty_file.c.obj.dzephyr/CMakeFiles/zephyr_final.dir/misc/empty_file.c.objzephyr/CMakeFiles/zephyr_final.dir/misc/empty_file.c.c/tmp/ccq93j1v.szephyr/CMakeFiles/zephyr.dir/lib/os/heap-validate.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/heap-validate.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/heap-validate.c.objheap-validate.c.c/tmp/ccMYUfNk.szephyr/CMakeFiles/zephyr.dir/lib/os/heap.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/heap.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/heap.c.objheap.c.c/tmp/ccexX2OT.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/memmap.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/memmap.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/memmap.c.objmemmap.c.c/tmp/ccoqGMjl.szephyr/subsys/random/CMakeFiles/subsys__random.dir/rand32_timer.c.dzephyr/subsys/random/CMakeFiles/subsys__random.dir/rand32_timer.c.obj.dzephyr/subsys/random/CMakeFiles/subsys__random.dir/rand32_timer.c.objzephyr/subsys/random/CMakeFiles/subsys__random.dir/rand32_timer.c.c/tmp/ccrpipBM.szephyr/kernel/CMakeFiles/kernel.dir/sem.c.dzephyr/kernel/CMakeFiles/kernel.dir/sem.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/sem.c.objsem.c.c/tmp/ccPVZ3aY.szephyr/kernel/CMakeFiles/kernel.dir/condvar.c.dzephyr/kernel/CMakeFiles/kernel.dir/condvar.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/condvar.c.objcondvar.c.c/tmp/ccJVvMmg.szephyr/CMakeFiles/zephyr.dir/lib/os/sem.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/sem.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/sem.c.obj/tmp/cc7Cb411.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/fatal.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/fatal.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/fatal.c.obj/tmp/ccoJ1WS2.szephyr/kernel/CMakeFiles/kernel.dir/sched.c.dzephyr/kernel/CMakeFiles/kernel.dir/sched.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/sched.c.objsched.c.c/tmp/ccltnr9K.szephyr/kernel/CMakeFiles/kernel.dir/work.c.dzephyr/kernel/CMakeFiles/kernel.dir/work.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/work.c.objwork.c.c/tmp/ccwQsxpI.szephyr/kernel/CMakeFiles/kernel.dir/kheap.c.dzephyr/kernel/CMakeFiles/kernel.dir/kheap.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/kheap.c.objkheap.c.c/tmp/cciRGdxj.szephyr/kernel/CMakeFiles/kernel.dir/thread.c.dzephyr/kernel/CMakeFiles/kernel.dir/thread.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/thread.c.objthread.c.c/tmp/ccURZXIg.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/thread.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/thread.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/thread.c.obj/tmp/ccJ3BKfH.szephyr/kernel/CMakeFiles/kernel.dir/timer.c.dzephyr/kernel/CMakeFiles/kernel.dir/timer.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/timer.c.objtimer.c.c/tmp/ccL46tkr.szephyr/kernel/CMakeFiles/kernel.dir/idle.c.dzephyr/kernel/CMakeFiles/kernel.dir/idle.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/idle.c.objidle.c.c/tmp/cc7VvUYz.szephyr/kernel/CMakeFiles/kernel.dir/main_weak.c.dzephyr/kernel/CMakeFiles/kernel.dir/main_weak.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/main_weak.c.objmain_weak.c.c/tmp/cc4fL8GY.szephyr/drivers/timer/CMakeFiles/drivers__timer.dir/hpet.c.dzephyr/drivers/timer/CMakeFiles/drivers__timer.dir/hpet.c.obj.dzephyr/drivers/timer/CMakeFiles/drivers__timer.dir/hpet.c.objhpet.c.c/tmp/ccAiSMMw.szephyr/kernel/CMakeFiles/kernel.dir/dynamic_disabled.c.dzephyr/kernel/CMakeFiles/kernel.dir/dynamic_disabled.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/dynamic_disabled.c.objdynamic_disabled.c.c/tmp/ccPS5XZh.szephyr/CMakeFiles/zephyr_pre0.dir/misc/empty_file.c.dzephyr/CMakeFiles/zephyr_pre0.dir/misc/empty_file.c.obj.dzephyr/CMakeFiles/zephyr_pre0.dir/misc/empty_file.c.objzephyr/CMakeFiles/zephyr_pre0.dir/misc//tmp/cczhx6zY.szephyr/kernel/CMakeFiles/kernel.dir/stack.c.dzephyr/kernel/CMakeFiles/kernel.dir/stack.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/stack.c.objstack.c.c/tmp/cc5P9lYR.szephyr/kernel/CMakeFiles/kernel.dir/mailbox.c.dzephyr/kernel/CMakeFiles/kernel.dir/mailbox.c.obj.dzephyr/kernel/CMakeFiles/kernel.dir/mailbox.c.objmailbox.c.c/tmp/cctk9Y20.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/prep_c.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/prep_c.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/prep_c.c.objprep_c.c.c/tmp/ccyqG1NP.szephyr/CMakeFiles/zephyr.dir/lib/os/dec.c.dzephyr/CMakeFiles/zephyr.dir/lib/os/dec.c.obj.dzephyr/CMakeFiles/zephyr.dir/lib/os/dec.c.objdec.c.c/tmp/ccHth3yJ.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/spec_ctrl.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/spec_ctrl.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/spec_ctrl.c.objspec_ctrl.c.c/tmp/cc4j1sux.s/home/haojie/zephyr-sdk-0.16.3/x86_64-zephyr-elf/libexec/gcc/x86_64-zephyr-elf/12.2.0/cc1plusCMakeCXXCompilerId.cpp.cpp/tmp/cc31x57o.szephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/fatal.c.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/fatal.c.obj.dzephyr/arch/arch/x86/core/CMakeFiles/arch__x86__core.dir/ia32/fatal.c.obj/tmp/ccUH5E30.s/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/CompilerIdC/a.out/home/haojie/zephyrproject/zephyr/build/CMakeFiles/3.22.1/CompilerIdCXX/a.out/home/haojie/zephyrproject/zephyr/build/zephyr/zephyr.elf/home/haojie/zephyrproject/zephyr/build/zephyr/zephyr_pre0.elf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           u   xb    